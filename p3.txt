pathlib --- オブジェクト指向のファイルシステムパス
バージョン 3.4 で追加.
ソースコード: Lib/pathlib.py
このモジュールはファイルシステムのパスを表すクラスを提供していて、様々なオペレーティングシステムについての適切な意味論をそれらのクラスに持たせています。 Path クラスは 純粋パス と 具象パス からなります。 純粋パスは I/O を伴わない純粋な計算操作を提供します。 具象パスは純粋パスを継承していますが、 I/O 操作も提供しています。
あなたが今までこのモジュールを使用したことがない場合や、タスクに適しているのがどのクラスかわからない場合は、 Path はきっとあなたに必要なものでしょう。 Path はコードが実行されているプラットフォーム用の 具象パス のインスタンスを作成します。
純粋パスは、以下のようないくつかの特殊なケースで有用です:
Unix マシン上で Windows のパスを扱いたいとき (またはその逆)。Unix 上で実行しているときに WindowsPath のインスタンスを作成することはできませんが、PureWindowsPath なら可能になります。
実際に OS にアクセスすることなしにパスを操作するだけのコードを確認したいとき。この場合、純粋クラスのインスタンスを一つ作成すれば、それが OS にアクセスすることはないので便利です。
参考 PEP 428: The pathlib module -- オブジェクト指向のファイルシステムパス。
参考 文字列による低水準のパス操作の場合は os.path も使用できます。
基本的な使い方
メインクラスをインポートします:
>>>
>>> from pathlib import Path
サブディレクトリの一覧を取得します:
>>>
>>> p = Path('.')
>>> [x for x in p.iterdir() if x.is_dir()]
[PosixPath('.hg'), PosixPath('docs'), PosixPath('dist'),
 PosixPath('__pycache__'), PosixPath('build')]
このディレクトリツリー内の Python ソースファイルの一覧を取得します:
>>>
>>> list(p.glob('**/*.py'))
[PosixPath('test_pathlib.py'), PosixPath('setup.py'),
 PosixPath('pathlib.py'), PosixPath('docs/conf.py'),
 PosixPath('build/lib/pathlib.py')]
ディレクトリツリー内を移動します:
>>>
>>> p = Path('/etc')
>>> q = p / 'init.d' / 'reboot'
>>> q
PosixPath('/etc/init.d/reboot')
>>> q.resolve()
PosixPath('/etc/rc.d/init.d/halt')
パスのプロパティを問い合わせます:
>>>
>>> q.exists()
True
>>> q.is_dir()
False
ファイルを開きます:
>>>
>>> with q.open() as f: f.readline()
...
'#!/bin/bash\n'
純粋パス
純粋パスオブジェクトは実際にファイルシステムにアクセスしないパス操作処理を提供します。これらのクラスにアクセスするには 3 つの方法があり、それらを フレーバー と呼んでいます:
class pathlib.PurePath(*pathsegments)
システムのパスのフレーバーを表すジェネリッククラスです (インスタンスを作成することで PurePosixPath または PureWindowsPath のどちらかが作成されます):
>>>
>>> PurePath('setup.py')      # Running on a Unix machine
PurePosixPath('setup.py')
pathsegments の各要素は、部分パスの文字列表現か、文字列を返す os.PathLike インターフェイスを実装しているオブジェクトか、その他の path オブジェクトです。
>>>
>>> PurePath('foo', 'some/path', 'bar')
PurePosixPath('foo/some/path/bar')
>>> PurePath(Path('foo'), Path('bar'))
PurePosixPath('foo/bar')
pathsegments が空のとき、現在のディレクトリとみなされます:
>>>
>>> PurePath()
PurePosixPath('.')
絶対パスが複数与えられた場合、最後の要素がアンカーとして取られます (os.path.join() の挙動を真似ています):
>>>
>>> PurePath('/etc', '/usr', 'lib64')
PurePosixPath('/usr/lib64')
>>> PureWindowsPath('c:/Windows', 'd:bar')
PureWindowsPath('d:bar')
ただし、Windows のパスでは、ローカルルートを変更してもそれまでのドライブ設定は破棄されません:
>>>
>>> PureWindowsPath('c:/Windows', '/Program Files')
PureWindowsPath('c:/Program Files')
誤ったスラッシュおよび単一ドットは無視されますが、2 個のドット ('..') は、シンボリックリンクのときにパスの意味の変更を意味するため受け付けれられます:
>>>
>>> PurePath('foo//bar')
PurePosixPath('foo/bar')
>>> PurePath('foo/./bar')
PurePosixPath('foo/bar')
>>> PurePath('foo/../bar')
PurePosixPath('foo/../bar')
(通常 PurePosixPath('foo/../bar') は PurePosixPath('bar') と等価になりますが、foo が他のディレクトリへのシンボリックリンクの場合は等価になりません)
純粋パスオブジェクトは os.PathLike インターフェースを実装しており、そのインタフェースを受理する箇所ならどこでも使用することができます。
バージョン 3.6 で変更: os.PathLike インターフェースがサポートされました。
class pathlib.PurePosixPath(*pathsegments)
PurePath のサブクラスです。このパスフレーバーは非 Windows パスを表します:
>>>
>>> PurePosixPath('/etc')
PurePosixPath('/etc')
pathsegments の指定は PurePath と同じです。
class pathlib.PureWindowsPath(*pathsegments)
PurePath のサブクラスです。このパスフレーバーは Windows ファイルシステムパスを表します:
>>>
>>> PureWindowsPath('c:/Program Files/')
PureWindowsPath('c:/Program Files')
pathsegments の指定は PurePath と同じです。
これらクラスはあらゆるシステムコールを行わないため、起動しているシステムにかかわらずインスタンスを作成できます。
全般的な性質
パスオブジェクトはイミュータブルでハッシュ可能です。 同じフレーバーのパスオブジェクトは比較ならびに順序付け可能です。 これらのプロパティは、フレーバーのケースフォールディング (訳注: 比較のために正規化すること、例えば全て大文字にする) のセマンティクスに従います。
>>>
>>> PurePosixPath('foo') == PurePosixPath('FOO')
False
>>> PureWindowsPath('foo') == PureWindowsPath('FOO')
True
>>> PureWindowsPath('FOO') in { PureWindowsPath('foo') }
True
>>> PureWindowsPath('C:') < PureWindowsPath('d:')
True
異なるフレーバーのパスオブジェクト同士の比較は等価になることはなく、順序付けもできません:
>>>
>>> PureWindowsPath('foo') == PurePosixPath('foo')
False
>>> PureWindowsPath('foo') < PurePosixPath('foo')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: '<' not supported between instances of 'PureWindowsPath' and 'PurePosixPath'
演算子
演算子スラッシュ "/" はパスの追加を行います。os.path.join() と似ています:
>>>
>>> p = PurePath('/etc')
>>> p
PurePosixPath('/etc')
>>> p / 'init.d' / 'apache2'
PurePosixPath('/etc/init.d/apache2')
>>> q = PurePath('bin')
>>> '/usr' / q
PurePosixPath('/usr/bin')
os.PathLike を実装したオブジェクトが受理できる箇所ならどこでも、パスオブジェクトが使用できます:
>>>
>>> import os
>>> p = PurePath('/etc')
>>> os.fspath(p)
'/etc'
パスオブジェクトの文字列表現はそのシステム自身の Raw ファイルシステムパス (ネイティブの形式、例えば Windows では区切り文字がバックスラッシュ) になり、文字列としてファイルパスを取るあらゆる関数に渡すことができます:
>>>
>>> p = PurePath('/etc')
>>> str(p)
'/etc'
>>> p = PureWindowsPath('c:/Program Files')
>>> str(p)
'c:\\Program Files'
同様に、パスオブジェクトを bytes で呼び出すと、Raw ファイルシステムパスを os.fsencode() でエンコードされたバイト列オブジェクトで返します:
>>>
>>> bytes(p)
b'/etc'
注釈 bytes での呼び出しは Unix 上での使用のみ推奨します。Windows では Unicode 形式が標準的なファイルシステムパス表現になります。
個別の構成要素へのアクセス
パスの個別の "構成要素" へアクセスするには、以下のプロパティを使用します:
PurePath.parts
パスのさまざまな構成要素へのアクセス手段を提供するタプルになります:
>>>
>>> p = PurePath('/usr/bin/python3')
>>> p.parts
('/', 'usr', 'bin', 'python3')
>>> p = PureWindowsPath('c:/Program Files/PSF')
>>> p.parts
('c:\\', 'Program Files', 'PSF')
(ドライブ名とローカルルートは単一要素にまとめられます)
メソッドとプロパティ
純粋パスは以下のメソッドとプロパティを提供します:
PurePath.drive
ドライブ文字または名前を表す文字列があればそれになります:
>>>
>>> PureWindowsPath('c:/Program Files/').drive
'c:'
>>> PureWindowsPath('/Program Files/').drive
''
>>> PurePosixPath('/etc').drive
''
UNC 共有名もドライブとみなされます:
>>>
>>> PureWindowsPath('//host/share/foo.txt').drive
'\\\\host\\share'
PurePath.root
ローカルまたはグローバルルートを表す文字列があればそれになります:
>>>
>>> PureWindowsPath('c:/Program Files/').root
'\\'
>>> PureWindowsPath('c:Program Files/').root
''
>>> PurePosixPath('/etc').root
'/'
UNC 共有名は常にルートを持ちます:
>>>
>>> PureWindowsPath('//host/share').root
'\\'
PurePath.anchor
ドライブとルートを結合した文字列になります:
>>>
>>> PureWindowsPath('c:/Program Files/').anchor
'c:\\'
>>> PureWindowsPath('c:Program Files/').anchor
'c:'
>>> PurePosixPath('/etc').anchor
'/'
>>> PureWindowsPath('//host/share').anchor
'\\\\host\\share\\'
PurePath.parents
パスの論理的な上位パスにアクセスできるイミュータブルなシーケンスになります:
>>>
>>> p = PureWindowsPath('c:/foo/bar/setup.py')
>>> p.parents[0]
PureWindowsPath('c:/foo/bar')
>>> p.parents[1]
PureWindowsPath('c:/foo')
>>> p.parents[2]
PureWindowsPath('c:/')
PurePath.parent
パスの論理的な上位パスになります:
>>>
>>> p = PurePosixPath('/a/b/c/d')
>>> p.parent
PurePosixPath('/a/b/c')
アンカーの位置を超えることや空のパスになる位置には対応していません:
>>>
>>> p = PurePosixPath('/')
>>> p.parent
PurePosixPath('/')
>>> p = PurePosixPath('.')
>>> p.parent
PurePosixPath('.')
注釈 これは純粋な字句操作であるため、以下のような挙動になります:
>>>
>>> p = PurePosixPath('foo/..')
>>> p.parent
PurePosixPath('foo')
任意のファイルシステムパスを上位方向に移動したい場合、シンボリックリンクの解決や ".." 要素の除去のため、最初に Path.resolve() を呼ぶことを推奨します。
PurePath.name
パス要素の末尾を表す文字列があればそれになります。ドライブやルートは含まれません:
>>>
>>> PurePosixPath('my/library/setup.py').name
'setup.py'
UNC ドライブ名は考慮されません:
>>>
>>> PureWindowsPath('//some/share/setup.py').name
'setup.py'
>>> PureWindowsPath('//some/share').name
''
PurePath.suffix
末尾の要素に拡張子があればそれになります:
>>>
>>> PurePosixPath('my/library/setup.py').suffix
'.py'
>>> PurePosixPath('my/library.tar.gz').suffix
'.gz'
>>> PurePosixPath('my/library').suffix
''
PurePath.suffixes
パスのファイル拡張子のリストになります:
>>>
>>> PurePosixPath('my/library.tar.gar').suffixes
['.tar', '.gar']
>>> PurePosixPath('my/library.tar.gz').suffixes
['.tar', '.gz']
>>> PurePosixPath('my/library').suffixes
[]
PurePath.stem
パス要素の末尾から拡張子を除いたものになります:
>>>
>>> PurePosixPath('my/library.tar.gz').stem
'library.tar'
>>> PurePosixPath('my/library.tar').stem
'library'
>>> PurePosixPath('my/library').stem
'library'
PurePath.as_posix()
フォワードスラッシュ (/) を使用したパスを表す文字列を返します:
>>>
>>> p = PureWindowsPath('c:\\windows')
>>> str(p)
'c:\\windows'
>>> p.as_posix()
'c:/windows'
PurePath.as_uri()
file URI で表したパスを返します。絶対パスではない場合に ValueError を送出します。
>>>
p = PurePosixPath('/etc/passwd')
p.as_uri()
'file:///etc/passwd'
p = PureWindowsPath('c:/Windows')
p.as_uri()
'file:///c:/Windows'
PurePath.is_absolute()
パスが絶対パスかどうかを返します。パスが絶対パスとみなされるのは、ルートと (フレーバーが許す場合) ドライブとの両方が含まれる場合です:
>>>
>>> PurePosixPath('/a/b').is_absolute()
True
>>> PurePosixPath('a/b').is_absolute()
False
>>> PureWindowsPath('c:/a/b').is_absolute()
True
>>> PureWindowsPath('/a/b').is_absolute()
False
>>> PureWindowsPath('c:').is_absolute()
False
>>> PureWindowsPath('//some/share').is_absolute()
True
PurePath.is_relative_to(*other)
このパスが other パスに対して相対なのかそうでないのかの結果を返します。
>>>
p = PurePath('/etc/passwd')
p.is_relative_to('/etc')
True
p.is_relative_to('/usr')
False
バージョン 3.9 で追加.
PurePath.is_reserved()
PureWindowsPath の場合はパスが Windows 上で予約されていれば True を返し、そうでなければ False を返します。PurePosixPath の場合は常に False を返します。
>>>
PureWindowsPath('nul').is_reserved()
True
PurePosixPath('nul').is_reserved()
False
ファイルシステムで予約されたパスを呼び出すと、原因不明で失敗したり、予期せぬ結果になります。
PurePath.joinpath(*other)
このメソッドの呼び出しは引数 other を順々に繋げることと等価になります:
>>>
>>> PurePosixPath('/etc').joinpath('passwd')
PurePosixPath('/etc/passwd')
>>> PurePosixPath('/etc').joinpath(PurePosixPath('passwd'))
PurePosixPath('/etc/passwd')
>>> PurePosixPath('/etc').joinpath('init.d', 'apache2')
PurePosixPath('/etc/init.d/apache2')
>>> PureWindowsPath('c:').joinpath('/Program Files')
PureWindowsPath('c:/Program Files')
PurePath.match(pattern)
現在のパスが glob 形式で与えられたパターンと一致したら True を、一致しなければ False を返します。
pattern が相対表記であればパスは相対および絶対パスを取ることができ、右から一致を調べます:
>>>
>>> PurePath('a/b.py').match('*.py')
True
>>> PurePath('/a/b/c.py').match('b/*.py')
True
>>> PurePath('/a/b/c.py').match('a/*.py')
False
pattern が絶対表記であれば、パスは絶対パスでなければならず、パス全体が一致しなければなりません:
>>>
>>> PurePath('/a.py').match('/*.py')
True
>>> PurePath('a/b.py').match('/*.py')
False
他のメソッドと同様に、大文字小文字の区別はプラットフォームの設定に従います:
>>>
>>> PurePosixPath('b.py').match('*.PY')
False
>>> PureWindowsPath('b.py').match('*.PY')
True
PurePath.relative_to(*other)
other で表されたパスから現在のパスへの相対パスを返します。それが不可能だった場合は ValueError が送出されます:
>>>
>>> p = PurePosixPath('/etc/passwd')
>>> p.relative_to('/')
PurePosixPath('etc/passwd')
>>> p.relative_to('/etc')
PurePosixPath('passwd')
>>> p.relative_to('/usr')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "pathlib.py", line 694, in relative_to
    .format(str(self), str(formatted)))
注記: この関数は PurePath の一部分であり、文字列で処理を行います。 根底のファイル構造をチェックしたりアクセスしたりはしません。
PurePath.with_name(name)
現在のパスの name 部分を変更したパスを返します。オリジナルパスに name 部分がない場合は ValueError が送出されます:
>>>
>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')
>>> p.with_name('setup.py')
PureWindowsPath('c:/Downloads/setup.py')
>>> p = PureWindowsPath('c:/')
>>> p.with_name('setup.py')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/antoine/cpython/default/Lib/pathlib.py", line 751, in with_name
    raise ValueError("%r has an empty name" % (self,))
ValueError: PureWindowsPath('c:/') has an empty name
PurePath.with_stem(stem)
Return a new path with the stem changed. If the original path doesn't have a name, ValueError is raised:
>>>
>>> p = PureWindowsPath('c:/Downloads/draft.txt')
>>> p.with_stem('final')
PureWindowsPath('c:/Downloads/final.txt')
>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')
>>> p.with_stem('lib')
PureWindowsPath('c:/Downloads/lib.gz')
>>> p = PureWindowsPath('c:/')
>>> p.with_stem('')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/antoine/cpython/default/Lib/pathlib.py", line 861, in with_stem
    return self.with_name(stem + self.suffix)
  File "/home/antoine/cpython/default/Lib/pathlib.py", line 851, in with_name
    raise ValueError("%r has an empty name" % (self,))
ValueError: PureWindowsPath('c:/') has an empty name
バージョン 3.9 で追加.
PurePath.with_suffix(suffix)
suffix を変更した新しいパスを返します。 元のパスに suffix が無かった場合、代わりに新しい suffix が追加されます。 suffix が空文字列だった場合、元の suffix は除去されます:
>>>
>>> p = PureWindowsPath('c:/Downloads/pathlib.tar.gz')
>>> p.with_suffix('.bz2')
PureWindowsPath('c:/Downloads/pathlib.tar.bz2')
>>> p = PureWindowsPath('README')
>>> p.with_suffix('.txt')
PureWindowsPath('README.txt')
>>> p = PureWindowsPath('README.txt')
>>> p.with_suffix('')
PureWindowsPath('README')
具象パス
具象パスは純粋パスクラスのサブクラスです。純粋パスが提供する操作に加え、パスオブジェクト上でシステムコールを呼ぶメソッドも提供しています。具象パスのインスタンスを作成するには 3 つの方法があります:
class pathlib.Path(*pathsegments)
PurePath のサブクラスであり、システムのパスフレーバーの具象パスを表します (このインスタンスの作成で PosixPath か WindowsPath のどちらかが作成されます):
>>>
>>> Path('setup.py')
PosixPath('setup.py')
pathsegments の指定は PurePath と同じです。
class pathlib.PosixPath(*pathsegments)
Path および PurePosixPath のサブクラスで、非 Windows ファイルシステムの具象パスを表します:
>>>
>>> PosixPath('/etc')
PosixPath('/etc')
pathsegments の指定は PurePath と同じです。
class pathlib.WindowsPath(*pathsegments)
Path および PureWindowsPath のサブクラスで、Windows ファイルシステムの具象パスを表します:
>>>
>>> WindowsPath('c:/Program Files/')
WindowsPath('c:/Program Files')
pathsegments の指定は PurePath と同じです。
インスタンスを作成できるのはシステムと一致するフレーバーのみです (互換性のないパスフレーバーでのシステムコールの許可はバグやアプリケーションの異常終了の原因になります):
>>>
>>> import os
>>> os.name
'posix'
>>> Path('setup.py')
PosixPath('setup.py')
>>> PosixPath('setup.py')
PosixPath('setup.py')
>>> WindowsPath('setup.py')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "pathlib.py", line 798, in __new__
    % (cls.__name__,))
NotImplementedError: cannot instantiate 'WindowsPath' on your system
メソッド
具象パスは純粋パスに加え、以下のメソッドを提供します。これらメソッドの多くはシステムコールが失敗すると OSError を送出します。(例えばパスが存在しない場合)
バージョン 3.8 で変更: exists(), is_dir(), is_file(), is_mount(), is_symlink(), is_block_device(), is_char_device(), is_fifo(), is_socket() は、OSレベルで表現不能な文字を含むパスに対して、例外を送出する代わりに False を返すようになりました。
classmethod Path.cwd()
(os.getcwd() が返す) 現在のディレクトリを表す新しいパスオブジェクトを返します:
>>>
>>> Path.cwd()
PosixPath('/home/antoine/pathlib')
classmethod Path.home()
ユーザーのホームディレクトリ (os.path.expanduser() での ~ の返り値) を表す新しいパスオブジェクトを返します:
>>>
>>> Path.home()
PosixPath('/home/antoine')
バージョン 3.5 で追加.
>>>
>>> p = Path('setup.py')
>>> p.stat().st_size
956
>>> p.stat().st_mtime
1327883547.852554
Path.chmod(mode)
os.chmod() のようにファイルのモードとアクセス権限を変更します:
>>>
>>> p = Path('setup.py')
>>> p.stat().st_mode
33277
>>> p.chmod(0o444)
>>> p.stat().st_mode
33060
Path.exists()
パスが既存のファイルかディレクトリを指しているかどうかを返します:
>>>
>>> Path('.').exists()
True
>>> Path('setup.py').exists()
True
>>> Path('/etc').exists()
True
>>> Path('nonexistentfile').exists()
False
注釈 パスがシンボリックリンクを指している場合、exists() はシンボリックリンクが既存のファイルかディレクトリを指しているかどうかを返します。
Path.expanduser()
パス要素 ~ および ~user を os.path.expanduser() が返すように展開した新しいパスオブジェクトを返します:
>>>
>>> p = PosixPath('~/films/Monty Python')
>>> p.expanduser()
PosixPath('/home/eric/films/Monty Python')
バージョン 3.5 で追加.
Path.glob(pattern)
Glob the given relative pattern in the directory represented by this path, yielding all matching files (of any kind):
>>>
>>> sorted(Path('.').glob('*.py'))
[PosixPath('pathlib.py'), PosixPath('setup.py'), PosixPath('test_pathlib.py')]
>>> sorted(Path('.').glob('*/*.py'))
[PosixPath('docs/conf.py')]
パターン "**" は "このディレクトリおよびすべてのサブディレクトリを再帰的に走査" を意味します。言い換えれば、再帰的な Glob 走査が可能という意味です:
>>>
>>> sorted(Path('.').glob('**/*.py'))
[PosixPath('build/lib/pathlib.py'),
 PosixPath('docs/conf.py'),
 PosixPath('pathlib.py'),
 PosixPath('setup.py'),
 PosixPath('test_pathlib.py')]
注釈 パターン "**" を大きなディレクトリツリーで使用するととてつもなく時間がかかるかもしれません。
Path.group()
ファイルを所有するグループ名を返します。ファイルの GID がシステムのデータベースに見つからなかった場合は KeyError が送出されます。
Path.is_dir()
パスがディレクトリ (またはディレクトリへのシンボリックリンク) を指していた場合 True を返し、その他の種類のファイルだった場合 False を返します。
パスが存在しないか壊れたシンボリックリンクだった場合にも False が返されます; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.is_file()
パスが一般ファイル (または一般ファイルへのシンボリックリンク) を指していた場合 True を返します。その他の種類のファイルを指していた場合 False を返します。
パスが存在しないか壊れたシンボリックリンクだった場合にも False が返されます; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.is_mount()
パス名 path がマウントポイント mount point (ファイルシステムの中で異なるファイルシステムがマウントされているところ) なら True を返します。 POSIX では、この関数は path の親ディレクトリである path/.. が path と異なるデバイス上にあるか、あるいは path/.. と path が同じデバイス上の同じ i-node を指しているかをチェックします --- これによってすべての Unix と POSIX 系システムでマウントポイントが検出できます。 この関数は Windows では実装されていません。
バージョン 3.7 で追加.
Path.is_symlink()
パスがシンボリックリンクを指していた場合 True を返し、その他の場合は False を返します。
パスが存在しない場合も False を返します; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.is_socket()
パスが Unix ソケット (または Unix ソケットへのシンボリックリンク) を指していた場合 True を返します。その他の種類のファイルの場合 False を返します。
パスが存在しないか壊れたシンボリックリンクだった場合にも False が返されます; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.is_fifo()
パスが FIFO (または FIFO へのシンボリックリンク) を指していた場合 True を返します。その他の種類のファイルの場合は False を返します。
パスが存在しないか壊れたシンボリックリンクだった場合にも False が返されます; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.is_block_device()
パスがブロックデバイス (またはブロックデバイスへのシンボリックリンク) を指していた場合 True を返します。その他の種類のファイルの場合は False を返します。
パスが存在しないか壊れたシンボリックリンクだった場合にも False が返されます; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.is_char_device()
パスがキャラクターデバイス (またはキャラクターデバイスへのシンボリックリンク) を指していた場合、True を返します。その他の種類のファイルの場合 False を返します。
パスが存在しないか壊れたシンボリックリンクだった場合にも False が返されます; (パーミッションエラーのような) その他のエラーは伝搬されます。
Path.iterdir()
パスがディレクトリを指していた場合、ディレクトリの内容のパスオブジェクトを yield します:
>>>
>>> p = Path('docs')
>>> for child in p.iterdir(): child
...
PosixPath('docs/conf.py')
PosixPath('docs/_templates')
PosixPath('docs/make.bat')
PosixPath('docs/index.rst')
PosixPath('docs/_build')
PosixPath('docs/_static')
PosixPath('docs/Makefile')
Path.lchmod(mode)
Path.chmod() のように振る舞いますが、パスがシンボリックリンクを指していた場合、リンク先ではなくシンボリックリンク自身のモードが変更されます。
Path.lstat()
Path.stat() のように振る舞いますが、パスがシンボリックリンクを指していた場合、リンク先ではなくシンボリックリンク自身の情報を返します。
Path.mkdir(mode=0o777, parents=False, exist_ok=False)
与えられたパスに新しくディレクトリを作成します。mode が与えられていた場合、プロセスの umask 値と組み合わせてファイルのモードとアクセスフラグを決定します。パスがすでに存在していた場合 FileExistsError が送出されます。
parents の値が真の場合、このパスの親ディレクトリを必要に応じて作成します; それらのアクセス制限はデフォルト値が取られ、mode は使用されません (POSIX の mkdir -p コマンドを真似ています)。
parents の値が偽の場合 (デフォルト)、親ディレクトリがないと FileNotFoundError を送出します。
exist_ok の値が (デフォルトの) 偽の場合、対象のディレクトリがすでに存在すると FileExistsError を送出します。
exist_ok の値が真の場合、パス要素の末尾がすでに存在するがディレクトリではないときは FileExistsError 例外を送出しますが、ディレクトリであれば送出しません (POSIX の mkdir -p コマンドの挙動と同じ)。
バージョン 3.5 で変更: exist_ok 引数が追加されました。
Path.open(mode='r', buffering=-1, encoding=None, errors=None, newline=None)
組み込み関数 open() のようにパスが指しているファイルを開きます:
>>>
>>> p = Path('setup.py')
>>> with p.open() as f:
...     f.readline()
...
'#!/usr/bin/env python3\n'
Path.owner()
ファイルの所有者のユーザー名を返します。ファイルの UID がシステムのデータベースに見つからない場合 KeyError が送出されます。
Path.read_bytes()
指定されたファイルの内容をバイナリオブジェクトで返します:
>>>
>>> p = Path('my_binary_file')
>>> p.write_bytes(b'Binary file contents')
20
>>> p.read_bytes()
b'Binary file contents'
バージョン 3.5 で追加.
Path.read_text(encoding=None, errors=None)
指定されたファイルの内容を文字列としてデコードして返します:
>>>
>>> p = Path('my_text_file')
>>> p.write_text('Text file contents')
18
>>> p.read_text()
'Text file contents'
ファイルを開いた後に閉じます。 オプションのパラメーターの意味は open() と同じです。
バージョン 3.5 で追加.
>>>
>>> p = Path('mylink')
>>> p.symlink_to('setup.py')
>>> p.readlink()
PosixPath('setup.py')
バージョン 3.9 で追加.
>>>
>>> p = Path('foo')
>>> p.open('w').write('some text')
9
>>> target = Path('bar')
>>> p.rename(target)
PosixPath('bar')
>>> target.open().read()
'some text'
Path.resolve(strict=False)
パスを絶対パスにし、あらゆるシンボリックリンクを解決します。新しいパスオブジェクトが返されます:
>>>
>>> p = Path()
>>> p
PosixPath('.')
>>> p.resolve()
PosixPath('/home/antoine/pathlib')
".." 要素は除去されます (このような挙動を示すのはこのメソッドだけです):
>>>
>>> p = Path('docs/../setup.py')
>>> p.resolve()
PosixPath('/home/antoine/pathlib/setup.py')
パスが存在せず strict が True の場合、 FileNotFoundError が送出されます。 strict が False の場合は、パスは可能な限り解決され、残りの部分は存在するかのチェックをせずに追加されます。 もしパスの解決にあたって無限ループする場合は、RuntimeError が送出されます。
バージョン 3.6 で追加: strict 引数 (3.6以前の挙動は strict です。)
>>>
>>> sorted(Path().rglob("*.py"))
[PosixPath('build/lib/pathlib.py'),
 PosixPath('docs/conf.py'),
 PosixPath('pathlib.py'),
 PosixPath('setup.py'),
 PosixPath('test_pathlib.py')]
Path.rmdir()
現在のディレクトリを削除します。ディレクトリは空でなければなりません。
Path.samefile(other_path)
このパスが参照するファイルが other_path (Path オブジェクトか文字列) と同じであれば True を、異なるファイルであれば False を返します。意味的には os.path.samefile() および os.path.samestat() と同じです。
なんらかの理由でどちらかのファイルにアクセスできない場合は OSError が送出されます。
>>>
>>> p = Path('spam')
>>> q = Path('eggs')
>>> p.samefile(q)
False
>>> p.samefile('spam')
True
バージョン 3.5 で追加.
Path.symlink_to(target, target_is_directory=False)
現在のパスに target へのシンボリックリンクを作成します。Windows では、リンク対象がディレクトリの場合 target_is_directory が真でなければなりません (デフォルトは False)。POSIX では、target_is_directory の値は無視されます。
>>>
>>> p = Path('mylink')
>>> p.symlink_to('setup.py')
>>> p.resolve()
PosixPath('/home/antoine/pathlib/setup.py')
>>> p.stat().st_size
956
>>> p.lstat().st_size
8
注釈 引数の並び (link, target) は os.symlink() とは逆です。
Path.touch(mode=0o666, exist_ok=True)
与えられたパスにファイルを作成します。mode が与えられた場合、プロセスの umask 値と組み合わせてファイルのモードとアクセスフラグが決定されます。ファイルがすでに存在した場合、exist_ok が真ならばこの関数は正常に終了します (そしてファイルの更新日付が現在の日時に変更されます)。その他の場合は FileExistsError が送出されます。
Path.unlink(missing_ok=False)
このファイルまたはシンボリックリンクを削除します。パスがディレクトリを指している場合は Path.rmdir() を使用してください。
missing_ok の値が (デフォルトの) 偽の場合、対象のファイルが存在しないと FileNotFoundError を送出します。
バージョン 3.8 で追加.
Path.write_bytes(data)
指定されたファイルをバイトモードで開き、data を書き込み、ファイルを閉じます:
>>>
>>> p = Path('my_binary_file')
>>> p.write_bytes(b'Binary file contents')
20
>>> p.read_bytes()
b'Binary file contents'
同じ名前のファイルがすでにあれば上書きされます。
バージョン 3.5 で追加.
Path.write_text(data, encoding=None, errors=None)
指定されたファイルをテキストモードで開き、data を書き込み、ファイルを閉じます:
>>>
>>> p = Path('my_text_file')
>>> p.write_text('Text file contents')
18
>>> p.read_text()
'Text file contents'
バージョン 3.5 で追加.
os モジュールにあるツールとの対応付け
下にあるのは、様々な os 関数とそれに相当する PurePath あるいは Path の同等のものとの対応表です。
注釈 os.path.relpath() および PurePath.relative_to() は使い道が重なるところもありますが、それらの意味論は同等だと見なすには違い過ぎています。
os および os.path
pathlib
os.path.abspath()
Path.resolve()
os.chmod()
Path.chmod()
os.mkdir()
Path.mkdir()
os.makedirs()
Path.mkdir()
os.rename()
Path.rename()
os.replace()
Path.replace()
os.rmdir()
Path.rmdir()
os.remove(), os.unlink()
Path.unlink()
os.getcwd()
Path.cwd()
os.path.exists()
Path.exists()
os.path.expanduser()
Path.expanduser() および Path.home()
os.listdir()
Path.iterdir()
os.path.isdir()
Path.is_dir()
os.path.isfile()
Path.is_file()
os.path.islink()
Path.is_symlink()
os.link()
Path.link_to()
os.symlink()
Path.symlink_to()
os.readlink()
Path.readlink()
os.stat()
Path.stat(), Path.owner(), Path.group()
os.path.isabs()
PurePath.is_absolute()
os.path.join()
PurePath.joinpath()
os.path.basename()
PurePath.name
os.path.dirname()
PurePath.parent
os.path.samefile()
Path.samefile()
os.path.splitext()
PurePath.suffix
os.path --- 共通のパス名操作
このモジュールには、パス名を操作する便利な関数が実装されています。ファイルの読み書きに関しては open() を、ファイルシステムへのアクセスに関しては os モジュールを参照してください。パスパラメータは文字列またはバイト列で渡すことができます。アプリケーションは、ファイル名を Unicode 文字列で表すことが推奨されています。残念ながら、Unix では文字列で表すことのできないファイル名があるため、Unix 上で任意のファイル名をサポートする必要のあるアプリケーションは、そのパス名にバイト列を使用すべきです。逆に、バイト列オブジェクトを使用すると Windows (標準の mbcs エンコーディング) 上ではすべてのファイル名を表すことができないため、Windows アプリケーションはファイルアクセスのために文字列オブジェクトを使用するべきです。
Unix シェルとは異なり、Python はあらゆるパス展開を 自動的には 行いません。アプリケーションがシェルのようなパス展開を必要とした場合は、 expanduser() や expandvars() といった関数を明示的に呼び出すことで行えます。(glob モジュールも参照してください)
参考 pathlib モジュールは高水準のパスオブジェクトを提供します。
注釈 以下のすべての関数は、そのパラメータにバイト列のみ、あるいは文字列のみ受け付けます。パスまたはファイル名を返す場合、返り値は同じ型のオブジェクトになります。
注釈 OS によって異なるパス名の決まりがあるため、標準ライブラリにはこのモジュールのいくつかのバージョンが含まれています。 os.path モジュールは常に現在 Python が動作している OS に適したパスモジュールであるため、ローカルのパスを扱うのに適しています。各々のモジュールをインポートして 常に 一つのフォーマットを利用することも可能です。これらはすべて同じインタフェースを持っています:
posixpath UNIX スタイルのパス用
ntpath Windows パス用
バージョン 3.8 で変更: exists()、 lexists()、 isdir()、 isfile()、 islink()、および ismount() は、OS レベルで表現できない文字列を含む可能性がある例外を送出する代わりに False を返すようになりました。
os.path.abspath(path)
パス名 path の正規化された絶対パスを返します。ほとんどのプラットフォームでは、これは関数 normpath() を次のように呼び出した時と等価です: normpath(join(os.getcwd(), path))。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.basename(path)
パス名 path の末尾のファイル名部分を返します。これは関数 split() に path を渡した時に返されるペアの 2 番めの要素です。この関数が返すのは Unix の basename とは異なります; Unix の basename は '/foo/bar/' に対して 'bar' を返しますが、関数 basename() は空文字列 ('') を返します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.5 で追加.
バージョン 3.6 で変更: path-like objects のシーケンスを受け入れるようになりました。
os.path.commonprefix(list)
list 内のすべてのパスに共通する接頭辞のうち、最も長いものを (パス名の 1 文字 1 文字を判断して) 返します。list が空の場合、空文字列 ('') を返します。
注釈 この関数は一度に 1 文字ずつ処理するため、不正なパスを返す場合があります。有効なパスを取得するためには、commonpath() を参照してください。
>>>
>>> os.path.commonprefix(['/usr/lib', '/usr/local/lib'])
'/usr/l'
>>> os.path.commonpath(['/usr/lib', '/usr/local/lib'])
'/usr'
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.dirname(path)
パス名 path のディレクトリ名を返します。これは関数 split() に path を渡した時に返されるペアの 1 番めの要素です。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.exists(path)
path が実在するパスかオープンしているファイル記述子を参照している場合 True を返します。壊れたシンボリックリンクについては False を返します。一部のプラットフォームでは、たとえ path が物理的に存在していたとしても、要求されたファイルに対する os.stat() の実行権がなければこの関数が False を返すことがあります。
バージョン 3.3 で変更: path は整数でも可能になりました: それがオープンしているファイル記述子なら True が返り、それ以外なら False が返ります。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.lexists(path)
path が実在するパスなら True を返します。壊れたシンボリックリンクについては True を返します。 os.lstat() がない環境では exists() と等価です。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.expanduser(path)
Unix および Windows では、与えられた引数の先頭のパス要素 ~ 、または ~user を、 user のホームディレクトリのパスに置き換えて返します。
Unix では、先頭の ~ は、環境変数 HOME が設定されているならその値に置き換えられます。設定されていない場合は、現在のユーザのホームディレクトリをビルトインモジュール pwd を使ってパスワードディレクトリから探して置き換えます。先頭の ~user については、直接パスワードディレクトリから探します。
置き換えに失敗したり、引数のパスがチルダで始まっていなかった場合は、パスをそのまま返します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.8 で変更: Windowsで HOME が使えなくなりました。
os.path.expandvars(path)
引数のパスの環境変数を展開して返します。引数の中の $name または ${name} のような形式の文字列は環境変数、 name の値に置き換えられます。不正な変数名や存在しない変数名の場合には変換されず、そのまま返します。
Windows では、 $name や ${name} の形式に加えて、 %name% の形式もサポートされています。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.getatime(path)
path に最後にアクセスした時刻を返します。 返り値は、エポック (time モジュールを参照) からの経過秒数を与える浮動小数点数です。 ファイルが存在しない、あるいはアクセスできなかった場合は OSError を送出します。
os.path.getmtime(path)
path に最後に更新した時刻を返します。 返り値は、エポック (time モジュールを参照) からの経過秒数を与える浮動小数点数です。 ファイルが存在しない、あるいはアクセスできなかった場合は OSError を送出します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.getctime(path)
システムの ctime、Unix系など一部のシステムでは最後にメタデータが変更された時刻、Windows などその他のシステムでは path の作成時刻を返します。返り値はエポック (time モジュールを参照) からの経過時間を示す秒数になります。ファイルが存在しない、あるいはアクセスできなかった場合は OSError を送出します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.getsize(path)
path のサイズをバイト数で返します。ファイルが存在しない、あるいはアクセスできなかった場合は OSError を送出します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.isabs(path)
path が絶対パスなら True を返します。すなわち、 Unix ではスラッシュで始まり、 Windows ではドライブレターに続く (バック) スラッシュで始まる場合です。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.isfile(path)
path が 存在する 一般ファイルなら True を返します。 この関数はシンボリックリンクの先を辿るので、同じパスに対して islink() と isfile() の両方が真を返すことがあります。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.isdir(path)
path が 存在する ディレクトリなら True を返します。 この関数はシンボリックリンクの先を辿るので、同じパスに対して islink() と isdir() の両方が真を返すことがあります。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.islink(path)
path が 存在する ディレクトリを指すシンボリックリンクなら True を返します。 Python ランタイムがシンボリックリンクをサポートしていないプラットフォームでは、常に False を返します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.ismount(path)
パス名 path がマウントポイント mount point (ファイルシステムの中で異なるファイルシステムがマウントされているところ) なら、 True を返します。 POSIX では、この関数は path の親ディレクトリである path/.. が path と異なるデバイス上にあるか、あるいは path/.. と path が同じデバイス上の同じ i-node を指しているかをチェックします --- これによって全ての Unix 系システムと POSIX 標準でマウントポイントが検出できます。 だたし、同じファイルシステムの bind mount の信頼できる検出はできません。 Windows では、ドライブレターを持つルートと共有 UNC は常にマウントポイントであり、また他のパスでは、入力のパスが異なるデバイスからのものか見るために GetVolumePathName が呼び出されます。
バージョン 3.4 で追加: Windows での、ルートでないマウントポイントの検出をサポートするようになっています。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
Windows の場合は、絶対パスの要素 (たとえば r'\foo') が見つかった場合はドライブレターはリセットされません。要素にドライブレターが含まれていれば、それより前の要素は全て破棄され、ドライブレターがリセットされます。各ドライブに対してカレントディレクトリがあるので、 os.path.join("c:", "foo") によって、 c:\foo ではなく、ドライブ C: 上のカレントディレクトリからの相対パス(c:foo) が返されることに注意してください。
バージョン 3.6 で変更: path と paths が path-like object を受け付けるようになりました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.normpath(path)
パスを正規化します。余分な区切り文字や上位レベル参照を除去し、A//B、A/B/、A/./B や A/foo/../B などはすべて A/B になります。この文字列操作は、シンボリックリンクを含むパスの意味を変えてしまう場合があります。Windows では、スラッシュをバックスラッシュに変換します。大文字小文字の正規化には normcase() を使用してください。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.realpath(path)
パスの中のシンボリックリンク (もしそれが当該オペレーティングシステムでサポートされていれば) を取り除いて、指定されたファイル名を正規化したパスを返します。
注釈 シンボリックリンクが循環している場合、循環したリンクのうちの一つのパスが返されます。ただし、どのパスが返されるかは保証されません。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.8 で変更: Windows においてシンボリックリンクとジャンクションが解決されるようになりました。
os.path.relpath(path, start=os.curdir)
カレントディレクトリあるいはオプションの start ディレクトリからの path への相対パスを返します。これはパス計算で行っており、ファイルシステムにアクセスして path や start の存在や性質を確認することはありません。
start のデフォルト値は os.curdir です。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.samefile(path1, path2)
引数の両パス名が同じファイルまたはディレクトリを参照している場合、 True を返します。これは、デバイス番号と i-node 番号で決定されます。どちらかのパス名への os.stat() 呼び出しが失敗した場合、例外が送出されます。
バージョン 3.2 で変更: Windows サポートを追加しました。
バージョン 3.4 で変更: Windows が他のプラットフォームと同じ実装を使用するようになりました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.sameopenfile(fp1, fp2)
ファイル記述子 fp1 と fp2 が同じファイルを参照していたら True を返します。
バージョン 3.2 で変更: Windows サポートを追加しました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.samestat(stat1, stat2)
stat タプル stat1 と stat2 が同じファイルを参照していれば True を返します。これらのタプルは os.fstat() 、 os.lstat() あるいは os.stat() の返り値で構いません。この関数は samefile() と sameopenfile() を使用した比較に基いて実装しています。
バージョン 3.4 で変更: Windows サポートを追加しました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.split(path)
パス名 path を (head, tail) のペアに分割します。 tail はパス名の構成要素の末尾で、 head はそれより前の部分です。 tail はスラッシュを含みません; もし path がスラッシュで終わっていれば tail は空文字列になります。もし path にスラッシュがなければ、 head は空文字になります。 path が空文字なら、 head と tail の両方が空文字になります。 head の末尾のスラッシュは head がルートディレクトリ (または 1 個以上のスラッシュだけ) でない限り取り除かれます。 join(head, tail) は常に path と同じ場所を返しますが、文字列としては異なるかもしれません。関数 dirname(), basename() も参照してください。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.splitdrive(path)
パス名 path を (drive, tail) のペアに分割します。drive はマウントポイントか空文字列になります。ドライブ指定をサポートしていないシステムでは、drive は常に空文字になります。どの場合でも、drive + tail は path と等しくなります。
Windows では、パス名はドライブ名/UNC 共有ポイントと相対パスに分割されます。
パスがドライブレターを含む場合、ドライブレターにはコロンまでが含まれます。例えば、splitdrive("c:/dir") は ("c:", "/dir") を返します。
パスが UNC パスを含む場合、ドライブレターにはホスト名と共有名までが含まれますが、共有名の後の区切り文字は含まれません。例えば、splitdrive("//host/computer/dir") は ("//host/computer", "/dir") を返します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.splitext(path)
パス名 path を (root, ext) のペアに分割します。 root + ext == path になります。 ext は空文字列か 1 つのピリオドで始まり、多くても 1 つのピリオドを含みます。ベースネームを導出するピリオドは無視されます; splitext('.cshrc') は ('.cshrc', '') を返します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.path.supports_unicode_filenames
ファイル名に任意の Unicode 文字列を (システムの制限内で) 使用できる場合は True になります。
fileinput --- 複数の入力ストリームをまたいだ行の繰り返し処理をサポートする
ソースコード: Lib/fileinput.py
このモジュールは標準入力やファイルの並びにまたがるループを素早く書くためのヘルパークラスと関数を提供しています。単一のファイルを読み書きしたいだけなら、 open() を参照してください。
典型的な使い方は以下の通りです:
import fileinput
for line in fileinput.input():
    process(line)
このスクリプトは sys.argv[1:] に列挙されている全てのファイルの行に渡って反復処理を行います。もし列挙されているものがなければ、 sys.stdin がデフォルトとして扱われます。 ファイル名として '-' が与えられた場合も、 sys.stdin に置き換えられ、 mode と openhook は無視されます。 別のファイル名リストを使いたい時には、そのリストを input() の最初の引数に与えます。 ファイル名が 1 つでも受け付けます。
全てのファイルはデフォルトでテキストモードでオープンされます。しかし、 input() や FileInput をコールする際に mode パラメータを指定すれば、これをオーバーライドすることができます。オープン中あるいは読み込み中にI/Oエラーが発生した場合には、 OSError が発生します。
バージョン 3.3 で変更: 以前は IOError が送出されました; それは現在 OSError のエイリアスです。
sys.stdin が2回以上使われた場合は、2回目以降は行を返しません。ただしインタラクティブに利用している時や明示的にリセット (sys.stdin.seek(0) を使う) を行った場合はその限りではありません。
空のファイルは開いた後すぐ閉じられます。空のファイルはファイル名リストの最後にある場合にしか外部に影響を与えません。
ファイルの各行は、各種改行文字まで含めて返されます。ファイルの最後が改行文字で終っていない場合には、改行文字で終わらない行が返されます。
ファイルのオープン方法を制御するためのオープン時フックは、 fileinput.input() あるいは FileInput() の openhook パラメータで設定します。このフックは、ふたつの引数 filename と mode をとる関数でなければなりません。そしてその関数の返り値はオープンしたファイルオブジェクトとなります。このモジュールには、便利なフックが既に用意されています。
以下の関数がこのモジュールの基本的なインタフェースです:
fileinput.input(files=None, inplace=False, backup='', *, mode='r', openhook=None)
FileInput クラスのインスタンスを作ります。生成されたインスタンスは、このモジュールの関数群が利用するグローバルな状態として利用されます。この関数への引数は FileInput クラスのコンストラクタへ渡されます。
FileInput のインスタンスは with 文の中でコンテキストマネージャーとして使用できます。 次の例では、仮に例外が生じたとしても with 文から抜けた後で input は閉じられます:
with fileinput.input(files=('spam.txt', 'eggs.txt')) as f:
    for line in f:
        process(line)
バージョン 3.2 で変更: コンテキストマネージャとして使うことができるようになりました。
以下の関数は fileinput.input() 関数によって作られたグローバルな状態を利用します。アクティブな状態が無い場合には、 RuntimeError が発生します。
fileinput.filename()
現在読み込み中のファイル名を返します。一行目が読み込まれる前は None を返します。
fileinput.fileno()
現在のファイルの "ファイル記述子" を整数値で返します。ファイルがオープンされていない場合 (最初の行の前、ファイルとファイルの間) は -1 を返します。
fileinput.lineno()
最後に読み込まれた行の、累積した行番号を返します。1行目が読み込まれる前は 0 を返します。最後のファイルの最終行が読み込まれた後には、その行の行番号を返します。
fileinput.filelineno()
現在のファイル中での行番号を返します。1行目が読み込まれる前は 0 を返します。最後のファイルの最終行が読み込まれた後には、その行のファイル中での行番号を返します。
fileinput.isfirstline()
最後に読み込まれた行がファイルの1行目なら True 、そうでなければ False を返します。
fileinput.isstdin()
最後に読み込まれた行が sys.stdin から読み込まれていれば True 、そうでなければ False を返します。
fileinput.nextfile()
現在のファイルを閉じます。次の繰り返しでは(存在すれば)次のファイルの最初の行が読み込まれます。閉じたファイルの読み込まれなかった行は、累積の行数にカウントされません。ファイル名は次のファイルの最初の行が読み込まれるまで変更されません。最初の行の読み込みが行われるまでは、この関数は呼び出されても何もしませんので、最初のファイルをスキップするために利用することはできません。最後のファイルの最終行が読み込まれた後にも、この関数は呼び出されても何もしません。
fileinput.close()
シーケンスを閉じます。
このモジュールのシーケンスの振舞いを実装しているクラスのサブクラスを作ることもできます:
class fileinput.FileInput(files=None, inplace=False, backup='', *, mode='r', openhook=None)
FileInput クラスはモジュールの関数に対応するメソッド filename() 、 fileno() 、 lineno() 、 filelineno() 、 isfirstline() 、 isstdin() 、 nextfile() および close() を実装しています。それに加えて、次の入力行を返す readline() メソッドと、シーケンスの振舞いの実装をしている __getitem__() メソッドがあります。シーケンスはシーケンシャルに読み込むことしかできません。つまりランダムアクセスと readline() を混在させることはできません。
mode を使用すると、 open() に渡すファイルモードを指定することができます。これは 'r' 、 'rU' 、 'U' および 'rb' のうちのいずれかとなります。
openhook を指定する場合は、ふたつの引数 filename と mode をとる関数でなければなりません。この関数の返り値は、オープンしたファイルオブジェクトとなります。inplace と openhook を同時に使うことはできません。
FileInput のインスタンスは with 文の中でコンテキストマネージャーとして使用できます。 次の例では、仮に例外が生じたとしても with 文から抜けた後で input は閉じられます:
with FileInput(files=('spam.txt', 'eggs.txt')) as input:
    process(input)
バージョン 3.2 で変更: コンテキストマネージャとして使うことができるようになりました。
バージョン 3.4 で非推奨: 'rU' および 'U' モード。
インプレース(in-place)フィルタオプション: キーワード引数 inplace=True が fileinput.input() か FileInput クラスのコンストラクタに渡された場合には、入力ファイルはバックアップファイルに移動され、標準出力が入力ファイルに設定されます(バックアップファイルと同じ名前のファイルが既に存在していた場合には、警告無しに置き替えられます)。これによって入力ファイルをその場で書き替えるフィルタを書くことができます。キーワード引数 backup (通常は backup='.<拡張子>' という形で利用します)が与えられていた場合、バックアップファイルの拡張子として利用され、バックアップファイルは削除されずに残ります。デフォルトでは、拡張子は '.bak' になっていて、出力先のファイルが閉じられればバックアップファイルも消されます。インプレースフィルタ機能は、標準入力を読み込んでいる間は無効にされます。
このモジュールには、次のふたつのオープン時フックが用意されています:
fileinput.hook_compressed(filename, mode)
gzip や bzip2 で圧縮された (拡張子が '.gz' や '.bz2' の) ファイルを、 gzip モジュールや bz2 モジュールを使って透過的にオープンします。ファイルの拡張子が '.gz' や '.bz2' でない場合は、通常通りファイルをオープンします (つまり、 open() をコールする際に伸長を行いません)。
使用例: fi = fileinput.FileInput(openhook=fileinput.hook_compressed)
fileinput.hook_encoded(encoding, errors=None)
各ファイルを open() でオープンするフックを返します。指定した encoding および errors でファイルを読み込みます。
使用例: fi = fileinput.FileInput(openhook=fileinput.hook_encoded("utf-8", "surrogateescape"))
バージョン 3.6 で変更: オプションの errors 引数が追加されました。
stat --- stat() の結果を解釈する
ソースコード: Lib/stat.py
stat モジュールでは、 os.stat() 、 os.lstat() 、および os.fstat() が存在する場合に、これらの関数が返す内容を解釈するための定数や関数を定義しています。 stat() 、 fstat() 、および lstat() の関数呼び出しについての完全な記述はシステムのドキュメントを参照してください。
バージョン 3.4 で変更: stat モジュールは、C 実装に裏付けされるようになりました。
stat モジュールでは、特殊なファイル型を判別するための以下の関数を定義しています:
stat.S_ISDIR(mode)
ファイルのモードがディレクトリの場合にゼロでない値を返します。
stat.S_ISCHR(mode)
ファイルのモードがキャラクタ型の特殊デバイスファイルの場合にゼロでない値を返します。
stat.S_ISBLK(mode)
ファイルのモードがブロック型の特殊デバイスファイルの場合にゼロでない値を返します。
stat.S_ISREG(mode)
ファイルのモードが通常ファイルの場合にゼロでない値を返します。
stat.S_ISFIFO(mode)
ファイルのモードが FIFO (名前つきパイプ) の場合にゼロでない値を返します。
stat.S_ISLNK(mode)
ファイルのモードがシンボリックリンクの場合にゼロでない値を返します。
stat.S_ISSOCK(mode)
ファイルのモードがソケットの場合にゼロでない値を返します。
stat.S_ISDOOR(mode)
ファイルのモードがドアの場合にゼロでない値を返します。
バージョン 3.4 で追加.
stat.S_ISPORT(mode)
ファイルのモードがイベントポートの場合にゼロでない値を返します。
バージョン 3.4 で追加.
stat.S_ISWHT(mode)
ファイルのモードがホワイトアウトの場合にゼロでない値を返します。
バージョン 3.4 で追加.
より一般的なファイルのモードを操作するための二つの関数が定義されています:
stat.S_IMODE(mode)
os.chmod() で設定することのできる一部のファイルモード --- すなわち、ファイルの許可ビット (permission bits) に加え、 (サポートされているシステムでは) スティッキービット (sticky bit)、実行グループ ID 設定 (set-group-id) および実行ユーザ ID 設定 (set-user-id) ビット --- を返します。
stat.S_IFMT(mode)
ファイルの形式を記述しているファイルモードの一部 (上記の S_IS*() 関数で使われます) を返します。
通常、ファイルの形式を調べる場合には os.path.is*() 関数を使うことになります; ここで挙げた関数は同じファイルに対して複数のテストを同時に行いたいが、 stat() システムコールを何度も呼び出してオーバヘッドが生じるのを避けたい場合に便利です。これらはまた、ブロック型およびキャラクタ型デバイスに対するテストのように、 os.path で扱うことのできないファイルの情報を調べる際にも便利です。
以下はプログラム例です:
import os, sys
from stat import *
def walktree(top, callback):
    '''recursively descend the directory tree rooted at top,
       calling the callback function for each regular file'''
    for f in os.listdir(top):
        pathname = os.path.join(top, f)
        mode = os.stat(pathname).st_mode
        if S_ISDIR(mode):
            # It's a directory, recurse into it
            walktree(pathname, callback)
        elif S_ISREG(mode):
            # It's a file, call the callback function
            callback(pathname)
        else:
            # Unknown file type, print a message
            print('Skipping %s' % pathname)
def visitfile(file):
    print('visiting', file)
if __name__ == '__main__':
    walktree(sys.argv[1], visitfile)
ファイルのモードを人間が可読な文字列に変換するために、追加のユーティリティ関数が提供されています。
stat.filemode(mode)
ファイルのモードを '-rwxrwxrwx' 形式の文字列に変換します。
バージョン 3.3 で追加.
バージョン 3.4 で変更: この関数は、S_IFDOOR 、 S_IFPORT 、 S_IFWHT をサポートしています。
以下の全ての変数は、 os.stat() 、 os.fstat() 、または os.lstat() が返す 10 要素のタプルにおけるインデクスを単にシンボル定数化したものです。
stat.ST_MODE
Iノードの保護モード。
stat.ST_INO
Iノード番号。
stat.ST_DEV
Iノードが存在するデバイス。
stat.ST_NLINK
該当する Iノードへのリンク数。
stat.ST_UID
ファイルの所持者のユーザ ID。
stat.ST_GID
ファイルの所持者のグループ ID。
stat.ST_SIZE
通常ファイルではバイトサイズ; いくつかの特殊ファイルでは処理待ちのデータ量。
stat.ST_ATIME
最後にアクセスした時刻。
stat.ST_MTIME
最後に変更された時刻。
stat.ST_CTIME
オペレーティングシステムから返される"ctime"。あるOS(Unixなど)では最後にメタデータが更新された時間となり、別のOS(Windowsなど)では作成時間となります(詳細については各プラットフォームのドキュメントを参照してください)。
"ファイルサイズ" の解釈はファイルの型によって異なります。通常のファイルの場合、サイズはファイルの大きさをバイトで表したものです。ほとんどの Unix 系 (特に Linux) における FIFO やソケットの場合、"サイズ" は os.stat() 、 os.fstat() 、あるいは os.lstat() を呼び出した時点で読み出し待ちであったデータのバイト数になります; この値は時に有用で、特に上記の特殊なファイルを非ブロックモードで開いた後にポーリングを行いたいといった場合に便利です。他のキャラクタ型およびブロック型デバイスにおけるサイズフィールドの意味はさらに異なっていて、背後のシステムコールの実装によります。
以下の変数は、 ST_MODE フィールドで使用されるフラグを定義しています。
最初に挙げる、以下のフラグを使うよりは、上記の関数を使うほうがポータブルです:
stat.S_IFSOCK
ソケット。
stat.S_IFLNK
シンボリックリンク。
stat.S_IFREG
通常のファイル。
stat.S_IFBLK
ブロックデバイス。
stat.S_IFDIR
ディレクトリ。
stat.S_IFCHR
キャラクターデバイス。
stat.S_IFIFO
FIFO。
stat.S_IFDOOR
ドア。
バージョン 3.4 で追加.
stat.S_IFPORT
イベントポート。
バージョン 3.4 で追加.
stat.S_IFWHT
ホワイトアウト。
バージョン 3.4 で追加.
注釈 S_IFDOOR 、 S_IFPORT 、または S_IFWHT は、プラットフォームがこれらのファイルタイプをサポートしていない場合、0 として定義されます。
以下のフラグは、 os.chmod() の mode 引数に使うこともできます:
stat.S_ISUID
UID ビットを設定する。
stat.S_ISGID
グループIDビットを設定する。このビットには幾つかの特殊ケースがあります。ディレクトリに対して設定されていた場合、 BSD のセマンティクスが利用される事を示しています。すなわち、そこに作成されるファイルは、作成したプロセスの有効グループID (effective group ID) ではなくそのディレクトリのグループIDを継承し、そこに作成されるディレクトリにも S_ISGID ビットが設定されます。グループ実行ビット (S_IXGRP) が設定されていないファイルに対してこのビットが設定されていた場合、強制ファイル/レコードロックを意味します (S_ENFMT も参照してください)。
stat.S_ISVTX
スティッキービット。このビットがディレクトリに対して設定されているとき、そのディレクトリ内のファイルは、そのファイルのオーナー、あるいはそのディレクトリのオーナーか特権プロセスのみが、リネームや削除をすることが出来ることを意味しています。
stat.S_IRWXU
ファイルオーナーの権限に対するマスク。
stat.S_IRUSR
オーナーがリード権限を持っている。
stat.S_IWUSR
オーナーがライト権限を持っている。
stat.S_IXUSR
オーナーが実行権限を持っている。
stat.S_IRWXG
グループの権限に対するマスク。
stat.S_IRGRP
グループがリード権限を持っている。
stat.S_IWGRP
グループがライト権限を持っている。
stat.S_IXGRP
グループが実行権限を持っている。
stat.S_IRWXO
その他 (グループ外) の権限に対するマスク。
stat.S_IROTH
その他はリード権限を持っている。
stat.S_IWOTH
その他はライト権限を持っている。
stat.S_IXOTH
その他は実行権限を持っている。
stat.S_ENFMT
System V ファイルロック強制。このフラグは S_ISGID と共有されています。グループ実行ビット (S_IXGRP) が設定されていないファイルでは、ファイル/レコードのロックが強制されます。
stat.S_IREAD
S_IRUSR の、 Unix V7 のシノニム。
stat.S_IWRITE
S_IWUSR の、 Unix V7 のシノニム。
stat.S_IEXEC
S_IXUSR の、 Unix V7 のシノニム。
以下のフラグを os.chflags() の flags 引数として利用できます:
stat.UF_NODUMP
ファイルをダンプしない。
stat.UF_IMMUTABLE
ファイルは変更されない。
stat.UF_APPEND
ファイルは追記しかされない。
stat.UF_OPAQUE
ユニオンファイルシステムのスタックを通したとき、このディレクトリは不透明です。
stat.UF_NOUNLINK
ファイルはリネームや削除されない。
stat.UF_COMPRESSED
ファイルは圧縮して保存される (Mac OS X 10.6+)。
stat.UF_HIDDEN
ファイルは GUI で表示されるべきでない (Mac OS X 10.5+)。
stat.SF_ARCHIVED
ファイルはアーカイブされているかもしれません。
stat.SF_IMMUTABLE
ファイルは変更されない。
stat.SF_APPEND
ファイルは追記しかされない。
stat.SF_NOUNLINK
ファイルはリネームや削除されない。
stat.SF_SNAPSHOT
このファイルはスナップショットファイルです。
詳しい情報は *BSD か Mac OS システムの man page chflags(2) を参照してください。
Windows では、os.stat() が返す st_file_attributes メンバー内のビットを検証する際に、以下のファイル属性定数を使用できます。これらの定数の意味について詳しくは、Windows API documentation を参照してください。
stat.FILE_ATTRIBUTE_ARCHIVE
stat.FILE_ATTRIBUTE_COMPRESSED
stat.FILE_ATTRIBUTE_DEVICE
stat.FILE_ATTRIBUTE_DIRECTORY
stat.FILE_ATTRIBUTE_ENCRYPTED
stat.FILE_ATTRIBUTE_HIDDEN
stat.FILE_ATTRIBUTE_INTEGRITY_STREAM
stat.FILE_ATTRIBUTE_NORMAL
stat.FILE_ATTRIBUTE_NOT_CONTENT_INDEXED
stat.FILE_ATTRIBUTE_NO_SCRUB_DATA
stat.FILE_ATTRIBUTE_OFFLINE
stat.FILE_ATTRIBUTE_READONLY
stat.FILE_ATTRIBUTE_REPARSE_POINT
stat.FILE_ATTRIBUTE_SPARSE_FILE
stat.FILE_ATTRIBUTE_SYSTEM
stat.FILE_ATTRIBUTE_TEMPORARY
stat.FILE_ATTRIBUTE_VIRTUAL
バージョン 3.5 で追加.
Windows では、os.lstat() が返す st_reparse_tag メンバーとの比較に次の定数が 使えます。 これらはよく知られている定数ですが、全てを網羅したリストではありません。
stat.IO_REPARSE_TAG_SYMLINK
stat.IO_REPARSE_TAG_MOUNT_POINT
stat.IO_REPARSE_TAG_APPEXECLINK
バージョン 3.8 で追加.
filecmp --- ファイルおよびディレクトリの比較
ソースコード: Lib/filecmp.py
filecmp モジュールでは、ファイルおよびディレクトリを比較するため、様々な時間／正確性のトレードオフに関するオプションを備えた関数を定義しています。ファイルの比較については、 difflib モジュールも参照してください。
filecmp モジュールでは以下の関数を定義しています:
filecmp.cmp(f1, f2, shallow=True)
名前が f1 および f2 のファイルを比較し、二つのファイルが同じらしければ True を返し、そうでなければ False を返します。
shallow が真の場合、同一の os.stat() シグニチャを持つファイルは等しいとみなされます。そうでなければ、ファイルの内容が比較されます。
可搬性と効率のために、この関数は外部プログラムを一切呼び出さないので注意してください。
この関数は過去の比較と結果のキャッシュを使用します。ファイルの os.stat() 情報が変更された場合、キャッシュの項目は無効化されます。clear_cache() を使用して全キャッシュを削除することが出来ます。
filecmp.cmpfiles(dir1, dir2, common, shallow=True)
dir1 と dir2 ディレクトリの中の、common で指定されたファイルを比較します。
ファイル名からなる3つのリスト: match, mismatch, errors を返します。match には双方のディレクトリで一致したファイルのリストが含まれ、mismatch にはそうでないファイル名のリストが入ります。そして errors は比較されなかったファイルが列挙されます。errors になるのは、片方あるいは両方のディレクトリに存在しなかった、ユーザーにそのファイルを読む権限がなかった、その他何らかの理由で比較を完了することができなかった場合です。
引数 shallow はその意味も標準の設定も filecmp.cmp() と同じです。
例えば、cmpfiles('a', 'b', ['c', 'd/e']) は a/c を b/c と、a/d/e を b/d/e と、それぞれ比較します。'c' と 'd/e' はそれぞれ、返される3つのリストのいずれかに登録されます。
filecmp.clear_cache()
filecmp のキャッシュをクリアします。背後のファイルシステムの mtime 分解能未満でのファイル変更後にすぐに比較するような場合に有用です。
バージョン 3.4 で追加.
dircmp クラス
class filecmp.dircmp(a, b, ignore=None, hide=None)
ディレクトリ a および b を比較するための新しいディレクトリ比較オブジェクトを生成します。 ignore は比較の際に無視するファイル名のリストで、標準の設定では filecmp.DEFAULT_IGNORES です。 hide は表示しない名前のリストで、標準の設定では [os.curdir, os.pardir] です。
dircmp クラスは、 filecmp.cmp() で説明されているような 浅い 比較を行うことによりファイルを比較します。
dircmp クラスは以下のメソッドを提供しています:
report()
a と b の比較を (sys.stdout に) 表示します。
report_partial_closure()
a および b およびそれらの直下にある共通のサブディレクトリ間での比較結果を出力します。
report_full_closure()
a および b およびそれらの共通のサブディレクトリ間での比較結果を (再帰的に比較して) 出力します。
dircmp クラスは、比較されているディレクトリ階層に関する様々な情報のビットを得るために使用することのできる、興味深い属性を数多く提供しています。
すべての属性は __getattr__() フックによって遅延評価されるので、計算が軽い属性のみを使用した場合は、属性の計算による速度の低下は起こりません。
left
ディレクトリ a です。
right
ディレクトリ b です。
left_list
a にあるファイルおよびサブディレクトリです。hide および ignore でフィルタされています。
right_list
b にあるファイルおよびサブディレクトリです。hide および ignore でフィルタされています。
common
a および b の両方にあるファイルおよびサブディレクトリです。
left_only
a だけにあるファイルおよびサブディレクトリです。
right_only
b だけにあるファイルおよびサブディレクトリです。
common_dirs
a および b の両方にあるサブディレクトリです。
common_files
a および b の両方にあるファイルです。
common_funny
a および b の両方にあり、ディレクトリ間でタイプが異なるか、 os.stat() がエラーを報告するような名前です。
same_files
クラスのファイル比較オペレータを用いて a と b の両方において同一のファイルです。
diff_files
a と b の両方に存在し、クラスのファイル比較オペレータに基づいて内容が異なるファイルです。
funny_files
a および b 両方にあるが、比較されなかったファイルです。
subdirs
common_dirs のファイル名を dircmp オブジェクトに対応付けた辞書です。
filecmp.DEFAULT_IGNORES
バージョン 3.4 で追加.
デフォルトで dircmp に無視されるディレクトリのリストです。
これは subdirs 属性を使用して 2 つのディレクトリを再帰的に探索して、共通の異なるファイルを示すための単純化された例です:
>>>
>>> from filecmp import dircmp
>>> def print_diff_files(dcmp):
...     for name in dcmp.diff_files:
...         print("diff_file %s found in %s and %s" % (name, dcmp.left,
...               dcmp.right))
...     for sub_dcmp in dcmp.subdirs.values():
...         print_diff_files(sub_dcmp)
...
>>> dcmp = dircmp('dir1', 'dir2') 
>>> print_diff_files(dcmp) 
tempfile --- 一時ファイルやディレクトリの作成
ソースコード: Lib/tempfile.py
このモジュールは一時ファイルやディレクトリを作成します。 サポートされている全てのプラットフォームで動作します。 TemporaryFile、NamedTemporaryFile、TemporaryDirectory、 SpooledTemporaryFile は自動的に後始末をし、コンテキストマネージャとして使うことの出来る高水準のインターフェイスです。 mkstemp() と mkdtemp() は手動で後始末をしなければならない低水準の関数です。
ユーザが呼び出し可能な全ての関数とコンストラクタは追加の引数を受け取ります。 その引数によって一時ファイルやディレクトリの場所と名前を直接操作することが出来ます。 このモジュールに使用されるファイル名はランダムな文字を含みます。そのためファイルは共有された一時ディレクトリに安全に作成されます。 後方互換性を保つために引数の順序は若干奇妙です。 分かりやすさのためにキーワード引数を使用してください。
このモジュールではユーザが呼び出し可能な以下の項目を定義しています:
tempfile.TemporaryFile(mode='w+b', buffering=-1, encoding=None, newline=None, suffix=None, prefix=None, dir=None, *, errors=None)
一時的な記憶領域として使うことの出来る file-like object を返します。 ファイルは mkstemp() と同じルールにより安全に作成されます。 オブジェクトは閉じられる (オブジェクトのガベージコレクションによる暗黙的なものも含みます) とすぐに破壊されます。 Unix では、そのファイルのディレクトリエントリは全く作成されないか、ファイル作成後すぐに削除されます。 これは他のプラットフォームではサポートされません。 よって、この関数で作成された一時ファイルがファイルシステムで可視な名前を持つかどうかをコードで当てにすべきではありません。
返されたオブジェクトをコンテキストマネージャとして使うことが出来ます （使用例 を参照してください）。 コンテキストの完了やファイルオブジェクトの破壊で、一時ファイルはファイルシステムから削除されます。
dir、prefix、suffix 引数の意味とデフォルトは mkstemp() のものと同じです。
返されたオブジェクトは、POSIXプラットフォームでは本物のファイルオブジェクトです。 それ以外のプラットフォームでは、file 属性が下層の本物のファイルであるファイル様オブジェクトです。
os.O_TMPFILE フラグは、利用可能で動作する場合に用いられます (Linux 固有で、Linux kernel 3.11 以降)。
バージョン 3.5 で変更: 利用可能であれば os.O_TMPFILE フラグが使用されます。
バージョン 3.8 で変更: Added errors parameter.
tempfile.NamedTemporaryFile(mode='w+b', buffering=-1, encoding=None, newline=None, suffix=None, prefix=None, dir=None, delete=True, *, errors=None)
この関数は、ファイルシステム上でファイルが可視の名前を持つことが保証される (Unix においてはディレクトリエントリが unlink されない) 点以外は TemporaryFile() と正確に同じことを行います。 その名前は、返されたファイル様オブジェクトの name 属性から取得することができます。 名前付き一時ファイルがまだ開かれている間にこの名前を使って再度ファイルを開くことができるかどうかは、プラットフォームによって異なります (Unix 上では可能ですが、 Windows NT 以降ではできません)。 delete が真の場合 (デフォルト)、ファイルは閉じられたら即座に削除されます。 返されたオブジェクトは常にファイル様オブジェクトで、その file 属性は元になった本物のファイルオブジェクトです。 このファイルライクオブジェクトは、通常のファイルのように with 文の中で使用することができます。
tempfile.SpooledTemporaryFile(max_size=0, mode='w+b', buffering=-1, encoding=None, newline=None, suffix=None, prefix=None, dir=None, *, errors=None)
この関数はファイルサイズが max_size を超えるかファイルの fileno() メソッドが呼ばれるまで、データがメモリにスプールされる点以外は TemporaryFile() と正確に同じことを行います。 上記条件を満たすと内容はディスクに書き込まれ、操作は TemporaryFile() と同様に進みます。
この関数が返すファイルは、追加で1つのメソッド rollover() を持っています。このメソッドが呼ばれると、(サイズに関係なく)メモリからディスクへのロールオーバーが実行されます。
返されたオブジェクトはファイル様オブジェクトで、その _file 属性は (バイナリかテキスト mode が指定されたかどうかに依存して) io.BytesIO か io.TextIOWrapper オブジェクト、あるいは rollover() が呼ばれたかどうかに依存して本物のファイルオブジェクトになります。 このファイル様オブジェクトは、通常のファイルオブジェクトと同じように with 文中で使用することが出来ます。
バージョン 3.3 で変更: truncate メソッドが size 引数を受け取るようになりました。
tempfile.TemporaryDirectory(suffix=None, prefix=None, dir=None)
この関数は mkdtemp() と同じルールを使用して安全に一時ディレクトリを作成します。 返されたオブジェクトは、コンテキストマネージャとして使用することができます (使用例 を参照)。 コンテキストの完了や一時ディレクトリの破壊で新規作成された一時ディレクトリとその中身はファイルシステムから削除されます。
ディレクトリ名は返されたオブジェクトの name 属性から取得できます。返されたオブジェクトがコンテキストマネージャとして使用された場合、 name は with 文内の as 節のターゲットがあればそれに割り当てられます。
cleanup() メソッドを呼んでディレクトリを明示的に片付けることができます。
バージョン 3.2 で追加.
tempfile.mkstemp(suffix=None, prefix=None, dir=None, text=False)
可能な限り最も安全な手段で一時ファイルを生成します。 プラットフォームが os.open() の os.O_EXCL フラグを正しく実装している限り、ファイルの作成で競合が起こることはありません。 作成したユーザのユーザ ID からのみファイルを読み書き出来ます。 プラットフォームがファイルが実行可能かどうかを示す許可ビットを使用している場合、ファイルは誰からも実行不可です。 このファイルのファイル記述子は子プロセスに継承されません。
TemporaryFile() と違って、 mkstemp() のユーザは用済みになった時に一時ファイルを削除しなければなりません。
suffix が None でない場合、ファイル名はその接尾辞で終わります。 そうでない場合、接尾辞はありません。 mkstemp() はファイル名と接尾辞の間にドットを追加しません。 必要であれば suffix の先頭につけてください。
prefix が None でない場合、ファイル名はその接頭辞で始まります。 そうでない場合、デフォルトの接頭辞が使われます。 必要に応じ、デフォルトは gettempprefix() または gettempprefixb() の返り値です。
dir が None でない場合、ファイルはそのディレクトリ下に作成されます。 None の場合、デフォルトのディレクトリが使われます。デフォルトのディレクトリはプラットフォームに依存するリストから選ばれますが、アプリケーションのユーザは TMPDIR、TEMP、または TMP 環境変数を設定することでディレクトリの場所を管理することができます。そのため、生成されるファイル名が、os.popen() で外部コマンドにクォーティング無しで渡すことができるなどといった、扱いやすい性質を持つ保証はありません。
suffix、prefix、dir のいずれかが None でない場合、それらは同じ型でなければなりません。 bytes の場合、返された名前は str でなはく bytes です。 他の挙動はデフォルトで返り値を bytes に強制的にしたい場合は suffix=b'' を渡してください。
mkstemp() は開かれたファイルを扱うための OS レベルのハンドル (os.open() が返すものと同じ) とファイルの絶対パス名が順番に並んだタプルを返します。
バージョン 3.5 で変更: suffix、prefix、dir は bytes の返り値を得るために bytes で渡すことが出来ます。 それ以前は str のみ許されていました。 適切なデフォルト値を使用するよう、suffix と prefix は None を受け入れ、デフォルトにするようになりました。
バージョン 3.6 で変更: dir パラメタが path-like object を受け付けるようになりました。
tempfile.mkdtemp(suffix=None, prefix=None, dir=None)
可能な限り安全な方法で一時ディレクトリを作成します。 ディレクトリの生成で競合は発生しません。 ディレクトリを作成したユーザ ID だけが、このディレクトリに対して内容を読み出したり、書き込んだり、検索したりすることができます。
mkdtemp() のユーザは用済みになった時に一時ディレクトリとその中身を削除しなければなりません。
prefix, suffix, dir 引数は mkstemp() 関数のものと同じです。
mkdtemp() は新たに生成されたディレクトリの絶対パス名を返します。
バージョン 3.5 で変更: suffix、prefix、dir は bytes の返り値を得るために bytes で渡すことが出来ます。 それ以前は str のみ許されていました。 適切なデフォルト値を使用するよう、suffix と prefix は None を受け入れ、デフォルトにするようになりました。
バージョン 3.6 で変更: dir パラメタが path-like object を受け付けるようになりました。
tempfile.gettempdir()
一時ファイルに用いられるディレクトリの名前を返します。 これはモジュール内の全ての関数の dir 引数のデフォルト値を定義します。
Python は呼び出したユーザがファイルを作ることの出来るディレクトリを検索するのに標準的なリストを使用します。 そのリストは:
環境変数 TMPDIR で与えられているディレクトリ名。
環境変数 TEMP で与えられているディレクトリ名。
環境変数 TMP で与えられているディレクトリ名。
プラットフォーム依存の場所:
Windows ではディレクトリ C:\TEMP 、 C:\TMP 、 \TEMP 、および \TMP の順。
その他の全てのプラットフォームでは、 /tmp 、 /var/tmp 、および /usr/tmp の順。
最後の手段として、現在の作業ディレクトリ。
この検索の結果はキャッシュされます。以下の tempdir の記述を参照してください。
tempfile.gettempdirb()
gettempdir() と同じですが返り値は bytesです。
バージョン 3.5 で追加.
tempfile.gettempprefix()
一時ファイルを生成する際に使われるファイル名の接頭辞を返します。 これにはディレクトリ部は含まれません。
tempfile.gettempprefixb()
gettempprefix() と同じですが返り値は bytes です。
バージョン 3.5 で追加.
モジュールはグローバル変数を使用して、 gettempdir() が返す、一時ファイルに用いられるディレクトリ名を記憶します。 直接設定して選考過程を上書き出来ますが、推奨されません。 このモジュールの全ての関数はディレクトリを指定する dir 引数を受け取ります。 この方法が推奨されます。
tempfile.tempdir
None 以外の値に設定された場合、このモジュールで定義されている全ての関数の dir 引数のデフォルト値として定義されます。
tempdir が (デフォルトの) None の場合、 gettempprefix() を除く上記のいずれかの関数を呼び出す際は常に gettempdir() で述べられているアルゴリズムによって初期化されます。
使用例
tempfile モジュールの典型的な使用法のいくつかの例を挙げます:
>>>
>>> import tempfile
# create a temporary file and write some data to it
>>> fp = tempfile.TemporaryFile()
>>> fp.write(b'Hello world!')
# read data from file
>>> fp.seek(0)
>>> fp.read()
b'Hello world!'
# close the file, it will be removed
>>> fp.close()
# create a temporary file using a context manager
>>> with tempfile.TemporaryFile() as fp:
...     fp.write(b'Hello world!')
...     fp.seek(0)
...     fp.read()
b'Hello world!'
>>>
# file is now closed and removed
# create a temporary directory using the context manager
>>> with tempfile.TemporaryDirectory() as tmpdirname:
...     print('created temporary directory', tmpdirname)
>>>
# directory and contents have been removed
非推奨の関数と変数
一時ファイルを作成する歴史的な手法は、まず mktemp() 関数でファイル名を作り、その名前を使ってファイルを作成するというものでした。 残念ながらこの方法は安全ではありません。 なぜなら、mktemp() の呼び出しと最初のプロセスが続いてファイル作成を試みる間に、異なるプロセスがその名前でファイルを同時に作成するかもしれないからです。 解決策は二つのステップを同時に行い、ファイルをすぐに作成するというものです。 この方法は mkstemp() や上述している他の関数で使用されています。
tempfile.mktemp(suffix='', prefix='tmp', dir=None)
バージョン 2.3 で非推奨: 代わりに mkstemp() を使って下さい。
呼び出し時には存在しなかった、ファイルの絶対パス名を返します。 prefix、suffix、dir 引数は mkstemp() のものと似ていますが、bytes のファイル名、suffix=None、そして prefix=None がサポートされていない点で異なります。
警告 この関数を使うとプログラムのセキュリティホールになる可能性があります。この関数がファイル名を返した後、あなたがそのファイル名を使って次に何かをしようとする段階に至る前に、誰か他の人間があなたを出し抜くことができてしまいます。 mktemp() の利用は、 NamedTemporaryFile() に delete=False 引数を渡すことで、簡単に置き換えることができます:
>>>
>>> f = NamedTemporaryFile(delete=False)
>>> f.name
'/tmp/tmptjujjt'
>>> f.write(b"Hello World!\n")
13
>>> f.close()
>>> os.unlink(f.name)
>>> os.path.exists(f.name)
False
glob --- Unix 形式のパス名のパターン展開
ソースコード: Lib/glob.py
glob モジュールは Unix シェルで使われているルールに従い指定されたパターンに一致するすべてのパス名を見つけ出します。返される結果の順序は不定です。チルダ展開は行われませんが、*, ?, および [] で表現される文字範囲については正しくマッチされます。これは、関数 os.scandir() および fnmatch.fnmatch() を使用して行われており、実際にサブシェルを呼び出しているわけではありません。fnmatch.fnmatch() と異なり、glob はドット (.) で始まるファイル名は特別扱いする点に注意してください。(チルダおよびシェル変数の展開を利用したい場合は os.path.expanduser() および os.path.expandvars() を使用してください。)
リテラルにマッチさせるには、メタ文字を括弧に入れてください。例えば、'[?]' は文字 '?' にマッチします。
参考 pathlib モジュールは高水準のパスオブジェクトを提供します。
glob.glob(pathname, *, recursive=False)
recursive が真の場合、パターン "**" はあらゆるファイルや0個以上のディレクトリ、サブディレクトリおよびディレクトリへのシンボリックリンクにマッチします。パターンの末尾が os.sep または os.altsep の場合、ファイルは一致しません。
引数 pathname, recursive を指定して 監査イベント glob.glob を送出します。
注釈 パターン "**" を大きなディレクトリツリーで使用するととてつもなく時間がかかるかもしれません。
バージョン 3.5 で変更: "**" を使った再帰的な glob がサポートされました。
glob.iglob(pathname, *, recursive=False)
実際には一度にすべてを格納せずに、glob() と同じ値を順に生成する イテレーター を返します。
引数 pathname, recursive を指定して 監査イベント glob.glob を送出します。
glob.escape(pathname)
すべての特殊文字 ('?' 、 '*' 、 '[') をエスケープします。特殊文字を含んでいる可能性のある任意のリテラル文字列をマッチさせたいときに便利です。drive/UNC sharepoints の特殊文字はエスケープされません。たとえば Windows では escape('//?/c:/Quo vadis?.txt') は '//?/c:/Quo vadis[?].txt' を返します。
バージョン 3.4 で追加.
たとえば、次の 3 個のファイル 1.gif, 2.txt, card.gif と、ファイル 3.txt だけを含んだサブディレクトリ sub があった場合、glob() は以下の結果を返します。パスに接頭する要素がどう維持されるかに注意してください。:
>>>
>>> import glob
>>> glob.glob('./[0-9].*')
['./1.gif', './2.txt']
>>> glob.glob('*.gif')
['1.gif', 'card.gif']
>>> glob.glob('?.gif')
['1.gif']
>>> glob.glob('**/*.txt', recursive=True)
['2.txt', 'sub/3.txt']
>>> glob.glob('./**/', recursive=True)
['./', './sub/']
ディレクトリが . で始まるファイルを含んでいる場合、デフォルトでそれらはマッチしません。例えば、 card.gif と .card.gif を含むディレクトリを考えてください:
>>>
>>> import glob
>>> glob.glob('*.gif')
['card.gif']
>>> glob.glob('.c*')
['.card.gif']
参考
fnmatch モジュール
シェル形式の (パスではない) ファイル名展開
fnmatch --- Unix ファイル名のパターンマッチ
ソースコード: Lib/fnmatch.py
このモジュールは Unix のシェル形式のワイルドカードに対応しています。これらは、 (re モジュールでドキュメント化されている) 正規表現とは 異なります 。シェル形式のワイルドカードで使われる特殊文字は、次のとおりです。
Pattern
意味
*
すべてにマッチします
?
任意の一文字にマッチします
[seq]
seq にある任意の文字にマッチします
[!seq]
seq にない任意の文字にマッチします
リテラルにマッチさせるには、メタ文字を括弧に入れてください。例えば、'[?]' は文字 '?' にマッチします。
ファイル名の区切り文字 (Unixでは '/') はこのモジュールに固有なものでは ない ことに注意してください。パス名展開については、 glob モジュールを参照してください (glob はパス名の部分にマッチさせるのに filter() を使っています)。同様に、ピリオドで始まるファイル名はこのモジュールに固有ではなくて、 * と ? のパターンでマッチします。
fnmatch.fnmatch(filename, pattern)
filename の文字列が pattern の文字列にマッチするかテストして、 True 、 False のいずれかを返します。 どちらの引数とも os.path.normcase() を使って、大文字、小文字が正規化されます。 オペレーティングシステムが標準でどうなっているかに関係なく、大文字、小文字を区別して比較する場合には、 fnmatchcase() が使えます。
次の例では、カレントディレクトリにある、拡張子が .txt である全てのファイルを表示しています:
import fnmatch
import os
for file in os.listdir('.'):
    if fnmatch.fnmatch(file, '*.txt'):
        print(file)
fnmatch.fnmatchcase(filename, pattern)
filename が pattern にマッチするかテストして、 True 、 False を返します。比較は大文字、小文字を区別し、 os.path.normcase() は適用しません。
fnmatch.translate(pattern)
シェルスタイルの pattern を、re.match() で使用するための正規表現に変換して返します。
例:
>>>
import fnmatch, re
>>>
regex = fnmatch.translate('*.txt')
regex
'(?s:.*\\.txt)\\Z'
reobj = re.compile(regex)
reobj.match('foobar.txt')
<re.Match object; span=(0, 10), match='foobar.txt'>
参考
glob モジュール
Unix シェル形式のパス展開。
linecache --- テキストラインにランダムアクセスする
ソースコード: Lib/linecache.py
linecache モジュールは、キャッシュ (一つのファイルから何行も読んでおくのが一般的です) を使って、内部で最適化を図りつつ、Python ソースファイルの任意の行を取得するのを可能にします。 traceback モジュールは、整形されたトレースバックにソースコードを含めるためにこのモジュールを利用しています。
tokenize.open() 関数は、ファイルを開くために使用されます。この関数は、 tokenize.detect_encoding() を使用してファイルのエンコーディングを取得します。エンコーディングトークンが存在しない場合、デフォルトの UTF-8 になります。
linecache モジュールでは次の関数が定義されています:
linecache.getline(filename, lineno, module_globals=None)
filename という名前のファイルから lineno 行目を取得します。この関数は決して例外を発生させません --- エラーの際には '' を返します (行末の改行文字は、見つかった行に含まれます)。
filename という名前のファイルが見付からなかった場合、この関数は最初に module_globals にある PEP 302 __loader__ を確認します。 ローダーが存在していて、 get_source メソッドが実装されていた場合、ソースコードの行を決定します (get_source() が None を返した場合は、 '' が返ります)。 最後に、 filename が相対ファイル名だった場合、モジュール検索パス sys.path のエントリからの相対パスを探します。
linecache.clearcache()
キャッシュをクリアします。それまでに getline() を使って読み込んだファイルの行が必要でなくなったら、この関数を使ってください。
linecache.checkcache(filename=None)
キャッシュが有効かどうかを確認します。キャッシュしたファイルがディスク上で変更された可能性があり、更新後のバージョンが必要な場合にこの関数を使用します。 filename が与えられない場合、全てのキャッシュエントリを確認します。
linecache.lazycache(filename, module_globals)
後々の呼び出しで module_globals が None となっていても、ファイルの形式でないモジュールの行を後から getline() で取得するのに十分な詳細を把握しておきます。 この関数により、モジュールの globals を無限に持ち運ぶ必要無しに、実際に必要な行まで
バージョン 3.5 で追加.
以下はプログラム例です:
>>>
>>> import linecache
>>> linecache.getline(linecache.__file__, 8)
'import sys\n'
shutil --- 高水準のファイル操作
ソースコード: Lib/shutil.py
shutil モジュールはファイルやファイルの集まりに対する高水準の操作方法を多数提供します。特にファイルのコピーや削除のための関数が用意されています。個別のファイルに対する操作については、 os モジュールも参照してください。
警告 高水準のファイルコピー関数 (shutil.copy(), shutil.copy2()) でも、ファイルのメタデータの全てをコピーすることはできません。
POSIXプラットフォームでは、これはACLやファイルのオーナー、グループが失われることを意味しています。 Mac OSでは、リソースフォーク(resource fork)やその他のメタデータが利用されません。これは、リソースが失われ、ファイルタイプや生成者コード(creator code)が正しくなくなることを意味しています。 Windowsでは、ファイルオーナー、ACL、代替データストリームがコピーされません。
ディレクトリとファイルの操作
shutil.copyfileobj(fsrc, fdst[, length])
ファイル形式のオブジェクト fsrc の内容を fdst へコピーします。整数値 length は与えられた場合バッファサイズを表します。特に length が負の場合、チャンク内のソースデータを繰り返し操作することなくデータをコピーします。デフォルトでは、制御不能なメモリ消費を避けるためにデータはチャンク内に読み込まれます。 fsrc オブジェクトの現在のファイル位置が0でない場合、現在の位置からファイル終端までの内容のみがコピーされることに注意してください。
dst は書き込み可能でなければなりません。そうでない場合、 OSError 例外を送出します。 dst がすでに存在する場合、そのファイルは置き換えられます。キャラクタデバイスやブロックデバイスなどの特殊なファイルとパイプをこの関数でコピーすることはできません。
follow_symlinks が偽で src がシンボリックリンクの場合、 src のリンク先をコピーする代わりに新しいシンボリックリンクを作成します。
バージョン 3.3 で変更: 以前は OSError の代わりに IOError が送出されていました。 follow_symlinks 引数が追加されました。 dst を返すようになりました。
バージョン 3.4 で変更: Error の代わりに SameFileError を送出します。後者は前者のサブクラスなのでこの変更は後方互換です。
exception shutil.SameFileError
copyfile() のコピー元と先が同じファイルの場合送出されます。
バージョン 3.4 で追加.
shutil.copymode(src, dst, *, follow_symlinks=True)
バージョン 3.3 で変更: follow_symlinks 引数が追加されました。
shutil.copystat(src, dst, *, follow_symlinks=True)
follow_symlinks が偽の場合、 src と dst の両方がシンボリックリンクであれば、 copystat() はリンク先ではなくてシンボリックリンク自体を操作します。 src からシンボリックリンクの情報を読み込み、 dst のシンボリックリンクにその情報を書き込みます。
注釈 すべてのプラットフォームでシンボリックリンクの検査と変更ができるわけではありません。 Python はその機能が利用かどうかを調べる方法を用意しています。
os.chmod in os.supports_follow_symlinks が True の場合 copystat() はシンボリックリンクのパーミッションを変更できます。
os.utime in os.supports_follow_symlinks が True の場合 copystat() はシンボリックリンクの最終アクセス時間と最終変更時間を変更できます。
os.chflags in os.supports_follow_symlinks が True の場合 copystat() はシンボリックリンクのフラグを変更できます。 (os.chflags がないプラットフォームもあります。)
機能の幾つか、もしくは全てが利用できないプラットフォームでシンボリックリンクを変更しようとした場合、 copystat() は可能な限り全てをコピーします。copystat() が失敗を返すことはありません。
より詳しい情報は os.supports_follow_symlinks を参照して下さい。
バージョン 3.3 で変更: follow_symlinks 引数と Linux の拡張属性がサポートされました。
shutil.copy(src, dst, *, follow_symlinks=True)
follow_symlinks が偽で、 src がシンボリックリンクの場合、 dst はシンボリックリンクとして作成されます。 follow_symlinks が真で src がシンボリックリンクの場合、 dst には src のリンク先のファイルがコピーされます。
copy() はファイルのデータとパーミッションをコピーします。 (os.chmod() を参照) その他の、ファイルの作成時間や変更時間などのメタデータはコピーしません。 コピー元のファイルのメタデータを保存したい場合は、 copy2() を利用してください。
バージョン 3.3 で変更: follow_symlinks 引数が追加されました。新しく作成されたファイルのパスを返すようになりました。
shutil.copy2(src, dst, *, follow_symlinks=True)
copy2() はファイルのメタデータを保持しようとすることを除けば copy() と等価です。
copy2() はファイルのメタデータをコピーするために copystat() を利用します。シンボリックリンクのメタデータを変更するためのプラットフォームサポートについては copystat() を参照して下さい。
バージョン 3.3 で変更: follow_symlinks 引数が追加されました。 拡張ファイルシステム属性もコピーしようと試みます (現在は Linux のみ)。新しく作成されたファイルへのパスを返すようになりました。
shutil.ignore_patterns(*patterns)
このファクトリ関数は、 copytree() 関数の ignore 引数に渡すための呼び出し可能オブジェクトを作成します。 glob形式の patterns にマッチするファイルやディレクトリが無視されます。下の例を参照してください。
shutil.copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2, ignore_dangling_symlinks=False, dirs_exist_ok=False)
symlinks が真の場合、ソースツリー内のシンボリックリンクは新しいツリーでもシンボリックになり、元のシンボリックリンクのメタデータはプラットフォームが許す限りコピーされます。偽の場合や省略された場合、リンク先のファイルの内容とメタデータが新しいツリーにコピーされます。
symlinks が偽の場合、リンク先のファイルが存在しなければ、コピー処理終了時に送出される Error 例外のエラーリストに例外が追加されます。オプションの ignore_dangling_symlinks フラグを真に設定してこのエラーを送出させないこともできます。このオプションは os.symlink() をサポートしていないプラットフォーム上では効果がないことに注意してください。
ignore は copytree() が走査しているディレクトリと os.listdir() が返すその内容のリストを引数として受け取ることのできる呼び出し可能オブジェクトでなければなりません。 copytree() は再帰的に呼び出されるので、 ignore はコピーされる各ディレクトリ毎に呼び出されます。 ignore の戻り値はカレントディレクトリに相対的なディレクトリ名およびファイル名のシーケンス（すなわち第二引数の項目のサブセット）でなければなりません。それらの名前はコピー中に無視されます。 ignore_patterns() を用いて glob 形式のパターンによって無視する呼び出し可能オブジェクトを作成することが出来ます。
例外が発生した場合、理由のリストとともに Error を送出します。
バージョン 3.3 で変更: symlinks が偽の場合メタデータをコピーします。 dst を返すようになりました。
バージョン 3.2 で変更: カスタムコピー機能を提供できるように copy_function 引数が追加されました。 symlinks が偽の時にダングリング (宙ぶらりんの) シンボリックリンクエラーを送出させないために ignore_dangling_symlinks 引数が追加されました。
shutil.rmtree(path, ignore_errors=False, onerror=None)
ディレクトリツリー全体を削除します。 path はディレクトリを指していなければなりません (ただしディレクトリに対するシンボリックリンクではいけません)。ignore_errors が真である場合、削除に失敗したことによるエラーは無視されます。偽や省略された場合はこれらのエラーは onerror で与えられたハンドラを呼び出して処理され、onerror が省略された場合は例外を送出します。
注釈 必要な fd ベースの関数をサポートしているプラットフォームでは、 シンボリックリンク攻撃に耐性のあるバージョンの rmtree() がデフォルトで利用されます。それ以外のプラットフォームでは、 rmtree() の実装はシンボリックリンク攻撃の影響を受けます。適当なタイミングと環境で攻撃者はファイルシステム上のシンボリックリンクを操作して、それ以外の方法ではアクセス不可能なファイルを削除することが出来ます。アプリケーションは、どちらのバージョンの rmtree() が利用されているかを知るために関数のデータ属性 rmtree.avoids_symlink_attacks を利用することができます。
onerror を指定する場合、 function, path, excinfo の3つの引数を受け取る呼び出し可能オブジェクトでなければなりません。
最初の引数 function は例外を送出した関数で、プラットフォームや実装に依存します。第二引数 path は function に渡されたパス名です。第三引数 excinfo は sys.exc_info() が返した例外の情報です。 onerror が送出した例外は捕捉されません。
バージョン 3.3 で変更: プラットフォームが fd ベースの関数をサポートする場合に自動的に使用されるシンボリックリンク攻撃に耐性のあるバージョンが追加されました。
rmtree.avoids_symlink_attacks
プラットフォームと実装がシンボリックリンク攻撃に耐性のあるバージョンの rmtree() を提供しているかどうかを示します。現在のところ、この属性は fd ベースのディレクトリアクセス関数をサポートしているプラットフォームでのみ真になります。
バージョン 3.3 で追加.
shutil.move(src, dst, copy_function=copy2)
ファイルまたはディレクトリ (src) を再帰的に別の場所 (dst) に移動して、移動先を返します。
移動先が存在するディレクトリの場合、 src はそのディレクトリの中へ移動します。移動先が存在していてそれがディレクトリでない場合、 os.rename() の動作によっては上書きされることがあります。
ターゲットが現在のファイルシステム上にある場合、 os.rename() が使用されます。 それ以外の場合 copy_function を使用して src を dst にコピーし、その後削除します。 シンボリックリンクの場合には、 src のターゲットを指す新しいシンボリックリンクが、 dst の中または dst として作成され、 src が削除されます。
バージョン 3.3 で変更: 異なるファイルシステムに対する明示的なシンボリックリンク処理が追加されました。これにより GNU mv の振る舞いに適応するようになります。 dst を返すようになりました。
バージョン 3.5 で変更: キーワード引数 copy_function が追加されました。
バージョン 3.3 で追加.
shutil.chown(path, user=None, group=None)
指定された path のオーナー user と/または group を変更します。
user はシステムのユーザー名か uid です。 group も同じです。少なくともどちらかの引数を指定する必要があります。
内部で利用している os.chown() も参照してください。
利用可能な環境: Unix。
バージョン 3.3 で追加.
shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None)
cmd を実行しようとした時に実行される実行ファイルのパスを返します。 cmd を呼び出せない場合は None を返します。
mode は os.access() に渡すパーミッションマスクで、デフォルトではファイルが存在して実行可能であることを確認します。
path が指定されなかった場合、 os.environ() が利用され、 "PATH" の値を返すか os.defpath にフォールバックします。
Windows では、 path を指定した場合もデフォルト値を使った場合も、カレントディレクトリが最初に探されます。これはコマンドシェルが実行ファイルを探すときの動作です。また、 cmd を path から検索するときに、 PATHEXT 環境変数も利用します。例えば、 shutil.which("python") を実行した場合、 which() は PATHEXT を参照して path ディレクトリから python.exe を探すべきだということを把握します。例えば、 Windows では:
>>>
>>> shutil.which("python")
'C:\\Python33\\python.EXE'
バージョン 3.3 で追加.
exception shutil.Error
この例外は複数ファイルの操作を行っているときに生じる例外をまとめたものです。 copytree() に対しては例外の引数は3つのタプル(srcname, dstname, exception)からなるリストです。
バージョン 3.8 で変更.
copytree の例
以下は前述の copytree() 関数のドキュメント文字列を省略した実装例です。本モジュールで提供される他の関数の使い方を示しています。
def copytree(src, dst, symlinks=False):
    names = os.listdir(src)
    os.makedirs(dst)
    errors = []
    for name in names:
        srcname = os.path.join(src, name)
        dstname = os.path.join(dst, name)
        try:
            if symlinks and os.path.islink(srcname):
                linkto = os.readlink(srcname)
                os.symlink(linkto, dstname)
            elif os.path.isdir(srcname):
                copytree(srcname, dstname, symlinks)
            else:
                copy2(srcname, dstname)
            # XXX What about devices, sockets etc.?
        except OSError as why:
            errors.append((srcname, dstname, str(why)))
        # catch the Error from the recursive copytree so that we can
        # continue with other files
        except Error as err:
            errors.extend(err.args[0])
    try:
        copystat(src, dst)
    except OSError as why:
        # can't copy file access times on Windows
        if why.winerror is None:
            errors.extend((src, dst, str(why)))
    if errors:
        raise Error(errors)
ignore_patterns() ヘルパ関数を利用する、もう1つの例です。
from shutil import copytree, ignore_patterns
copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))
この例では、 .pyc ファイルと、 tmp で始まる全てのファイルやディレクトリを除いて、全てをコピーします。
ignore 引数にロギングさせる別の例です。
from shutil import copytree
import logging
def _logpath(path, names):
    logging.info('Working in %s', path)
    return []   # nothing will be ignored
copytree(source, destination, ignore=_logpath)
rmtree の例
次の例は、Windows で一部のファイルが読み取り専用のビットセットを含む場合に、ディレクトリツリーを削除する方法を示します。onerror コールバックを使用して、読み取り専用のビットを消去し、削除を再試行します。結果として失敗が発生した場合、それらは伝搬されます:
import os, stat
import shutil
def remove_readonly(func, path, _):
    "Clear the readonly bit and reattempt the removal"
    os.chmod(path, stat.S_IWRITE)
    func(path)
shutil.rmtree(directory, onerror=remove_readonly)
アーカイブ化操作
バージョン 3.2 で追加.
バージョン 3.5 で変更: xztar 形式のサポートが追加されました。
圧縮とアーカイブ化されているファイルの読み書きの高水準なユーティリティも提供されています。これらは zipfile 、 tarfile モジュールに依拠しています。
shutil.make_archive(base_name, format[, root_dir[, base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])
アーカイブファイル (zip や tar) を作成してその名前を返します。
base_name は、作成するファイルの、パスを含み、フォーマットごとの拡張子を抜いた名前です。 format はアーカイブフォーマットで "zip" (zlib モジュールが利用可能な場合), "tar", "gztar" (zlib モジュールが利用可能な場合), "bztar" (bz2 モジュールが利用可能な場合), "xztar" (lzma モジュールが利用可能な場合) のいずれかです。
root_dir is a directory that will be the root directory of the archive, all paths in the archive will be relative to it; for example, we typically chdir into root_dir before creating the archive.
base_dir is the directory where we start archiving from; i.e. base_dir will be the common prefix of all files and directories in the archive. base_dir must be given relative to root_dir. See Archiving example with base_dir for how to use base_dir and root_dir together.
root_dir と base_dir のどちらも、デフォルトはカレントディレクトリです。
dry_run が真の場合、アーカイブは作成されませんが実行される操作は logger に記録されます。
owner と group は、tar アーカイブを作成するときに使われます。デフォルトでは、カレントのオーナーとグループを使います。
logger は PEP 282 に互換なオブジェクトでなければなりません。これは普通は logging.Logger のインスタンスです。
verbose 引数は使用されず、非推奨です。
shutil.get_archive_formats()
アーカイブ化をサポートしているフォーマットのリストを返します。返されるシーケンスのそれぞれの要素は、タプル (name, description) です。
デフォルトでは、 shutil は次のフォーマットを提供しています。
zip: ZIP ファイル (zlib モジュールが利用可能な場合)。
gztar: gzip で圧縮された tar ファイル (zlib モジュールが利用可能な場合)。
bztar: bzip2 で圧縮された tar ファイル (bz2 モジュールが利用可能な場合)。
xztar: xz で圧縮された tar ファイル (lzma モジュールが利用可能な場合)。
register_archive_format() を使って、新しいフォーマットを登録したり、既存のフォーマットに独自のアーカイバを提供したりできます。
shutil.register_archive_format(name, function[, extra_args[, description]])
アーカイバをフォーマット name に登録します。
function はアーカイブのアンパックに使用される呼び出し可能オブジェクトです。funciton は作成するファイルの base_name、続いてアーカイブを開始する元の base_dir (デフォルトは os.curdir) を受け取ります。さらなる引数は、次のキーワード引数として渡されます: owner, group, dry_run ならびに logger (make_archive() に渡されます)。
extra_args は、与えられた場合、 (name, value) の対のシーケンスで、アーカイバ呼び出し可能オブジェクトが使われるときに追加のキーワード引数として使われます。
description は、アーカイバのリストを返す get_archive_formats() で使われます。デフォルトでは空の文字列です。
shutil.unregister_archive_format(name)
アーカイブフォーマット name を、サポートされているフォーマットのリストから取り除きます。
shutil.unpack_archive(filename[, extract_dir[, format]])
アーカイブをアンパックします。 filename はアーカイブのフルパスです。
extract_dir はアーカイブをアンパックする先のディレクトリ名です。指定されなかった場合は現在の作業ディレクトリを利用します。
format はアーカイブフォーマットで、 "zip", "tar", "gztar", "bztar", "xztar" あるいは register_unpack_format() で登録したその他のフォーマットのどれかです。 指定されなかった場合、 unpack_archive() はアーカイブファイル名の拡張子に対して登録されたアンパッカーを利用します。 アンパッカーが見つからなかった場合、 ValueError を発生させます。
バージョン 3.7 で変更: filename と extract_dir が path-like object を受け付けるようになりました。
shutil.register_unpack_format(name, extensions, function[, extra_args[, description]])
アンパック用のフォーマットを登録します。 name はフォーマット名で、 extensions はそのフォーマットに対応する拡張子 (例えば Zip ファイルに対して .zip) のリストです。
function はアーカイブをアンパックするための呼び出し可能オブジェクトです。このオブジェクトはアーカイブのパスと、アーカイブを展開するディレクトリのパスを引数に受け取ります。
extra_args は省略可能な引数で、呼び出し可能オブジェクトに渡すキーワード引数を (name, value) というタプルのシーケンスにしたものです。
フォーマットの説明として description を指定することができます。これは get_unpack_formats() 関数によって返されます。
shutil.unregister_unpack_format(name)
アンパックフォーマットを登録解除します。 name はフォーマットの名前です。
shutil.get_unpack_formats()
登録されているすべてのアンパックフォーマットをリストで返します。戻り値のリストの各要素は (name, extensions, description) の形のタプルです。
デフォルトでは、 shutil は次のフォーマットを提供しています。
zip: ZIP ファイル (対応するモジュールが利用可能な場合にのみ圧縮ファイルはアンパックされます)。
tar: 圧縮されていない tar ファイル。
gztar: gzip で圧縮された tar ファイル (zlib モジュールが利用可能な場合)。
bztar: bzip2 で圧縮された tar ファイル (bz2 モジュールが利用可能な場合)。
xztar: xz で圧縮された tar ファイル (lzma モジュールが利用可能な場合)。
register_unpack_format() を使って新しいフォーマットや既存のフォーマットに対する別のアンパッカーを登録することができます。
アーカイブ化の例
この例では、ユーザの .ssh ディレクトリにあるすべてのファイルを含む、 gzip された tar ファイルアーカイブを作成します:
>>>
>>> from shutil import make_archive
>>> import os
>>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive'))
>>> root_dir = os.path.expanduser(os.path.join('~', '.ssh'))
>>> make_archive(archive_name, 'gztar', root_dir)
'/Users/tarek/myarchive.tar.gz'
結果のアーカイブは、以下のものを含みます:
$ tar -tzvf /Users/tarek/myarchive.tar.gz
drwx------ tarek/staff       0 2010-02-01 16:23:40 ./
-rw-r--r-- tarek/staff     609 2008-06-09 13:26:54 ./authorized_keys
-rwxr-xr-x tarek/staff      65 2008-06-09 13:26:54 ./config
-rwx------ tarek/staff     668 2008-06-09 13:26:54 ./id_dsa
-rwxr-xr-x tarek/staff     609 2008-06-09 13:26:54 ./id_dsa.pub
-rw------- tarek/staff    1675 2008-06-09 13:26:54 ./id_rsa
-rw-r--r-- tarek/staff     397 2008-06-09 13:26:54 ./id_rsa.pub
-rw-r--r-- tarek/staff   37192 2010-02-06 18:23:10 ./known_hosts
Archiving example with base_dir
$ tree tmp
tmp
└── root
    └── structure
        ├── content
            └── please_add.txt
        └── do_not_add.txt
>>>
>>> from shutil import make_archive
>>> import os
>>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive'))
>>> make_archive(
...     archive_name,
...     'tar',
...     root_dir='tmp/root',
...     base_dir='structure/content',
... )
'/Users/tarek/my_archive.tar'
Listing the files in the resulting archive gives us:
$ python -m tarfile -l /Users/tarek/myarchive.tar
structure/content/
structure/content/please_add.txt
出力ターミナルのサイズの取得
shutil.get_terminal_size(fallback=(columns, lines))
ターミナルウィンドウのサイズを取得します。
幅と高さについて、それぞれ COLUMNS と LINES という環境変数をチェックします。その変数が定義されていて値が正の整数であればそれを利用します。
典型的な COLUMNS や LINES が定義されていない場合には、 sys.__stdout__ に接続されているターミナルに os.get_terminal_size() を呼び出して問い合わせます。
システムが対応していない場合やターミナルに接続していないなどの理由でターミナルサイズの問い合わせに失敗した場合、 fallback 引数に与えられた値を利用します。 fallback のデフォルト値は (80, 24) で、これは多くのターミナルエミュレーターが利用しているデフォルトサイズです。
戻り値は os.terminal_size 型の名前付きタプルです。
バージョン 3.3 で追加.
struct --- バイト列をパックされたバイナリデータとして解釈する
ソースコード: Lib/struct.py
このモジュールは、 Python の値と Python bytes オブジェクトとして表される C の構造体データとの間の変換を実現します。このモジュールは特に、ファイルに保存されたり、ネットワーク接続を経由したバイナリデータを扱うときに使われます。このモジュールでは、C 構造体のレイアウトおよび Python の値との間で行いたい変換をコンパクトに表現するために、 書式文字列 を使います。
注釈 デフォルトでは、与えられた C の構造体をパックする際に、関連する C データ型を適切にアラインメント(alignment)するために数バイトのパディングを行うことがあります。この挙動が選択されたのは、パックされた構造体のバイト表現を対応する C 構造体のメモリレイアウトに正確に対応させるためです。プラットフォーム独立のデータフォーマットを扱ったり、隠れたパディングを排除したりするには、サイズ及びアラインメントとして native の代わりに standard を使うようにします: 詳しくは バイトオーダ、サイズ、アラインメント を参照して下さい。
いくつかの struct の関数 (および Struct のメソッド) は buffer 引数を取ります。 これは バッファプロトコル (buffer Protocol) を実装していて読み取り可能または読み書き可能なバッファを提供するオブジェクトのことです。この目的のために使われる最も一般的な型は bytes と bytearray ですが、バイトの配列とみなすことができるような他の多くの型がバッファプロトコルを実装しています。そのため、それらは bytes オブジェクトから追加のコピーなしで読み出しや書き込みができます。
関数と例外
このモジュールは以下の例外と関数を定義しています:
exception struct.error
様々な状況で送出される例外です。引数は何が問題なのかを記述する文字列です。
struct.pack(format, v1, v2, ...)
struct.pack_into(format, buffer, offset, v1, v2, ...)
struct.unpack(format, buffer)
struct.unpack_from(format, /, buffer, offset=0)
struct.iter_unpack(format, buffer)
イテレーション毎に書式文字列で指定されたタプルを yield します。
バージョン 3.4 で追加.
書式文字列
書式文字列はデータをパックしたりアンパックしたりするときの期待されるレイアウトを指定するためのメカニズムです。文字列はパック/アンパックされるデータの型を指定する 書式指定文字 から組み立てられます。さらに、 バイトオーダ、サイズ、アラインメント を制御するための特殊文字もあります。
バイトオーダ、サイズ、アラインメント
デフォルトでは、C での型はマシンのネイティブ (native) の形式およびバイトオーダ (byte order) で表され、適切にアラインメント (alignment) するために、必要に応じて数バイトのパディングを行ってスキップします (これは C コンパイラが用いるルールに従います)。
これに代わって、フォーマット文字列の最初の文字を使って、バイトオーダやサイズ、アラインメントを指定することができます。指定できる文字を以下のテーブルに示します:
文字
バイトオーダ
サイズ
アラインメント
@
native
native
native
=
native
standard
none
<
リトルエンディアン
standard
none
>
ビッグエンディアン
standard
none
!
ネットワーク (= ビッグエンディアン)
standard
none
フォーマット文字列の最初の文字が上のいずれかでない場合、'@' であるとみなされます。
ネイティブのバイトオーダはビッグエンディアンかリトルエンディアンで、ホスト計算機に依存します。例えば、Intel x86 および AMD64 (x86-64) はリトルエンディアンです。Motorola 68000 および PowerPC G5 はビッグエンディアンです。ARM および Intel Itanium はエンディアンを切り替えられる機能を備えています (バイエンディアン)。使っているシステムでのエンディアンは sys.byteorder を使って調べて下さい。
ネイティブのサイズおよびアラインメントは C コンパイラの sizeof 式で決定されます。ネイティブのサイズおよびアラインメントはネイティブのバイトオーダと同時に使われます。
標準のサイズはフォーマット文字だけで決まります。 書式指定文字 の表を参照して下さい。
'@' と '=' の違いに注意してください: 両方ともネイティブのバイトオーダですが、後者のバイトサイズとアラインメントは標準のものに合わせてあります。
バイトオーダに関して、「(強制的にバイトスワップを行う)ネイティブの逆」を指定する方法はありません。'<' または '>' のうちふさわしい方を選んでください。
注釈:
パディングは構造体のメンバの並びの中にだけ自動で追加されます。最初や最後にパディングが追加されることはありません。
ネイティブでないサイズおよびアラインメントが使われる場合にはパディングは行われません (たとえば '<', '>', '=', '!' を使った場合です)。
特定の型によるアラインメント要求に従うように構造体の末端をそろえるには、繰り返し回数をゼロにした特定の型でフォーマットを終端します。 使用例 を参照して下さい。
書式指定文字
フォーマット文字 (format character) は以下の意味を持っています; C と Python の間の変換では、値は正確に以下に指定された型でなくてはなりません: 「標準のサイズ」列は standard サイズ使用時にパックされた値が何バイトかを示します。つまり、フォーマット文字列が '<', '>', '!', '=' のいずれかで始まっている場合のものです。native サイズ使用時にはパックされた値の大きさはプラットフォーム依存です。
フォーマット
C の型
Python の型
標準のサイズ
注釈
x
パディングバイト
値なし
c
char
長さ 1 のバイト列
1
b
signed char
整数
1
(1), (2)
B
unsigned char
整数
1
(2)
?
_Bool
真偽値型(bool)
1
(1)
h
short
整数
2
(2)
H
unsigned short
整数
2
(2)
i
int
整数
4
(2)
I
unsigned int
整数
4
(2)
l
long
整数
4
(2)
L
unsigned long
整数
4
(2)
q
long long
整数
8
(2)
Q
unsigned long long
整数
8
(2)
n
ssize_t
整数
(3)
N
size_t
整数
(3)
e
(6)
浮動小数点数
2
(4)
f
float
浮動小数点数
4
(4)
d
double
浮動小数点数
8
(4)
s
char[]
bytes
p
char[]
bytes
P
void *
整数
(5)
バージョン 3.3 で変更: 'n' および 'N' フォーマットのサポートが追加されました。
バージョン 3.6 で変更: 'e' フォーマットのサポートが追加されました。
注釈:
'?' 変換コードは C99 で定義された _Bool 型に対応します。その型が利用できない場合は、 char で代用されます。標準モードでは常に1バイトで表現されます。
非整数を整数の変換コードを使ってパックしようとすると、非整数が __index__() メソッドを持っていた場合は、整数に変換するためにパックする前にそのメソッドが呼ばれます。
'n' および 'N' 変換コードは (デフォルトもしくはバイトオーダ文字 '@' 付きで選択される) native サイズ使用時のみ利用できます。standard サイズ使用時には、自身のアプリケーションに適する他の整数フォーマットを使うことができます。
'f' 、 'd' および 'e' 変換コードについて、パックされた表現は IEEE 754 binary32 ('f' の場合) 、 binary64 ('d' の場合) 、またはbinary16('e' の場合) フォーマットが、プラットフォームにおける浮動小数点数のフォーマットに関係なく使われます。
'P' フォーマット文字はネイティブバイトオーダでのみ利用可能です (デフォルトのネットワークバイトオーダに設定するか、'@' バイトオーダ指定文字を指定しなければなりません)。'=' を指定した場合、ホスト計算機のバイトオーダに基づいてリトルエンディアンとビッグエンディアンのどちらを使うかを決めます。struct モジュールはこの設定をネイティブのオーダ設定として解釈しないので、'P' を使うことはできません。
IEEE 754 の binary16 "半精度" 型は、 IEEE 754 standard の2008 年の改訂で導入されました。 半精度型は、符号 bit 、5 bit の指数部、 11 bit の精度 (明示的には 10 bit が保存される) を持ち、おおよそ 6.1e-05 から 6.5e+04 までの数を完全な精度で表現できます。 この型は C コンパイラでは広くはサポートされていません: たいていのマシンでは、保存するのに unsigned short が使えますが、数学の演算には使えません。 詳しいことは Wikipedia の half-precision floating-point format のページを参照してください。
フォーマット文字の前に整数をつけ、繰り返し回数 (count) を指定することができます。例えば、フォーマット文字列 '4h' は 'hhhh' と全く同じ意味です。
フォーマット文字間の空白文字は無視されます; count とフォーマット文字の間にはスペースを入れてはいけません。
's' フォーマット文字での繰り返し回数 (count) は、他のフォーマット文字のような繰り返し回数ではなく、バイト長として解釈されます。例えば、'10s' は単一の 10 バイトの文字列を意味し、'10c' は 10 個の文字を意味します。繰り返し回数が指定されなかった場合は、デフォルト値の 1 とみなされます。パックでは、文字列はサイズに合うように切り詰められたり null バイトで埋められたりします。アンパックでは、返されるバイトオブジェクトのバイト数は、正確に指定した通りになります。特殊な場合として、'0s' は単一の空文字列を意味し、'0c' は 0 個の文字を意味します。
整数フォーマット ('b', 'B', 'h', 'H', 'i', 'I', 'l', 'L', 'q', 'Q') のいずれかを使って値 x をパックするとき x がフォーマットの適切な値の範囲に無い場合、 struct.error が送出されます。
フォーマット文字 'p' は "Pascal 文字列 (pascal string)" をコードします。Pascal 文字列は count で与えられる 固定長のバイト列 に収められた短い可変長の文字列です。このデータの先頭の 1 バイトには文字列の長さか255 のうち、小さい方の数が収められます。その後に文字列のバイトデータが続きます。 pack() に渡された Pascal 文字列の長さが長すぎた (count-1 よりも長い) 場合、先頭の count-1 バイトが書き込まれます。文字列が count-1 よりも短い場合、指定した count バイトに達するまでの残りの部分はヌルで埋められます。 unpack() では、フォーマット文字 'p' は指定された count バイトだけデータを読み込みますが、返される文字列は決して 255 文字を超えることはないので注意してください。
'?' フォーマット文字では、返り値は True または False です。パックするときには、引数オブジェクトの論理値としての値が使われます。 0 または 1 のネイティブや標準の真偽値表現でパックされ、アンパックされるときはゼロでない値は True になります。
使用例
注釈 全ての例は、ビッグエンディアンのマシンで、ネイティブのバイトオーダ、サイズおよびアラインメントを仮定します。
基本的な例として、三つの整数をパック/アンパックします:
>>>
>>> from struct import *
>>> pack('hhl', 1, 2, 3)
b'\x00\x01\x00\x02\x00\x00\x00\x03'
>>> unpack('hhl', b'\x00\x01\x00\x02\x00\x00\x00\x03')
(1, 2, 3)
>>> calcsize('hhl')
8
アンパックした結果のフィールドは、変数に割り当てるか named tuple でラップすることによって名前を付けることができます:
>>>
>>> record = b'raymond   \x32\x12\x08\x01\x08'
>>> name, serialnum, school, gradelevel = unpack('<10sHHb', record)
>>> from collections import namedtuple
>>> Student = namedtuple('Student', 'name serialnum school gradelevel')
>>> Student._make(unpack('<10sHHb', record))
Student(name=b'raymond   ', serialnum=4658, school=264, gradelevel=8)
アラインメントの要求を満たすために必要なパディングが異なるという理由により、フォーマット文字の順番がサイズの違いを生み出すことがあります:
>>>
>>> pack('ci', b'*', 0x12131415)
b'*\x00\x00\x00\x12\x13\x14\x15'
>>> pack('ic', 0x12131415, b'*')
b'\x12\x13\x14\x15*'
>>> calcsize('ci')
8
>>> calcsize('ic')
5
以下のフォーマット 'llh0l' は、long 型が 4 バイトを境界としてそろえられていると仮定して、末端に 2 バイトをパディングします:
>>>
>>> pack('llh0l', 1, 2, 3)
b'\x00\x00\x00\x01\x00\x00\x00\x02\x00\x03\x00\x00'
この例はネイティブのサイズとアラインメントが使われているときだけ思った通りに動きます。標準のサイズとアラインメントはアラインメントの設定ではいかなるアラインメントも行いません。
参考
array モジュール
一様なデータ型からなるバイナリ記録データのパック。
xdrlib モジュール
XDR データのパックおよびアンパック。
クラス
struct モジュールは次の型を定義します:
class struct.Struct(format)
フォーマット文字列 format に従ってバイナリデータを読み書きする、新しい Struct オブジェクトを返します。 Struct オブジェクトを一度作ってからそのメソッドを使うと、フォーマット文字列のコンパイルが一度で済むので、 struct モジュールの関数を同じフォーマットで何度も呼び出すよりも効率的です。
コンパイルされた Struct オブジェクトは以下のメソッドと属性をサポートします:
pack(v1, v2, ...)
pack() 関数と同じ、コンパイルされたフォーマットを利用するメソッドです。 (len(result) は size と等しいでしょう)
pack_into(buffer, offset, v1, v2, ...)
pack_into() 関数と同じ、コンパイルされたフォーマットを利用するメソッドです。
unpack(buffer)
unpack() 関数と同じ、コンパイルされたフォーマットを利用するメソッドです。 (buffer のバイト数は size と等しくなければなりません)。
iter_unpack(buffer)
iter_unpack() 関数と同じ、コンパイルされたフォーマットを利用するメソッドです。 (buffer のバイト数は size の倍数でなければなりません)。
バージョン 3.4 で追加.
format
この Struct オブジェクトを作成する時に利用されたフォーマット文字列です。
size
format 属性に対応する構造体の (従って pack() メソッドによって作成されるバイト列オブジェクトの) サイズです。
codecs --- codec レジストリと基底クラス
ソースコード: Lib/codecs.py
このモジュールは、標準的な Python codec (エンコーダとデコーダ) 用の基底クラスを定義し、codec とエラー処理検索プロセスを管理する内部の Python codec レジストリへのアクセスを提供します。多くの codec はテキストをバイト形式にエンコードする テキストエンコーディング ですが、テキストをテキストに、またはバイトをバイトにエンコードする codec も提供されています。カスタムの codec は任意の型間でエンコードとデコードを行えますが、一部のモジュール機能は テキストエンコーディング か bytes へのエンコードのみに制限されています。
このモジュールでは、任意の codec でエンコードやデコードを行うための、以下の関数が定義されています。
codecs.encode(obj, encoding='utf-8', errors='strict')
encoding に記載された codec を使用して obj をエンコードします。
希望のエラー処理スキームを errors に設定することができます。デフォルトのエラーハンドラ (エラー処理関数) は 'strict' です。これはエンコードエラーは ValueError (もしくは UnicodeEncodeError のような、より codec に固有のサブクラス) を送出することを意味します。codec エラー処理についてのより詳しい情報は Codec 基底クラス を参照してください。
codecs.decode(obj, encoding='utf-8', errors='strict')
encoding に記載された codec を使用して obj をデコードします。
希望のエラー処理スキームを errors に設定することができます。デフォルトのエラーハンドラは 'strict' です。これはデコードエラーは ValueError (もしくは UnicodeDecodeError のような、より codec に固有のサブクラス) を送出することを意味します。codec エラー処理についてのより詳しい情報は Codec 基底クラス を参照してください。
各 codec についての詳細も、次のようにして直接調べることができます。
codecs.lookup(encoding)
Python codec レジストリから codec 情報を探し、以下で定義するような CodecInfo オブジェクトを返します。
エンコーディングの検索は、まずレジストリのキャッシュから行います。見つからなければ、登録されている検索関数のリストから探します。 CodecInfo オブジェクトが一つも見つからなければ LookupError を送出します。見つかったら、その CodecInfo オブジェクトはキャッシュに保存され、呼び出し側に返されます。
class codecs.CodecInfo(encode, decode, streamreader=None, streamwriter=None, incrementalencoder=None, incrementaldecoder=None, name=None)
codec レジストリ内を検索する場合の、codec の詳細です。コントラクタ引数は、次の同名の属性に保存されます。
name
エンコーディングの名前です。
encode
decode
ステートレスなエンコーディングとデコーディングの関数です。これらは、Codec インスタンスの encode() メソッドと decode() メソッドと同じインターフェースを持っている必要があります (see Codec のインターフェース を参照)。この関数またはメソッドは、ステートレスモードで動作することが想定されています。
incrementalencoder
incrementaldecoder
インクリメンタル・エンコーダとデコーダのクラスまたはファクトリ関数です。これらは、基底クラスの IncrementalEncoder と IncrementalDecoder が定義するインターフェースをそれぞれ提供する必要があります。インクリメンタルな codec は、ステート (内部状態) を保持することができます。
streamwriter
streamreader
ストリームライターとリーダーのクラスまたはファクトリ関数です。これらは、基底クラスの StreamWriter と StreamReader が定義するインターフェースをそれぞれ提供する必要があります。ストリーム codec は、ステートを保持することができます。
さまざまな codec 構成要素へのアクセスを簡便化するために、このモジュールは以下のような関数を提供しています。これらの関数は、 codec の検索に lookup() を使います:
codecs.getencoder(encoding)
与えられたエンコーディングに対する codec を検索し、エンコーダ関数を返します。
エンコーディングが見つからなければ LookupError を送出します。
codecs.getdecoder(encoding)
与えられたエンコーディングに対する codec を検索し、デコーダ関数を返します。
エンコーディングが見つからなければ LookupError を送出します。
codecs.getincrementalencoder(encoding)
与えられたエンコーディングに対する codec を検索し、インクリメンタル・エンコーダクラスまたはファクトリ関数を返します。
エンコーディングが見つからないか、 codec がインクリメンタル・エンコーダをサポートしなければ LookupError を送出します。
codecs.getincrementaldecoder(encoding)
与えられたエンコーディングに対する codec を検索し、インクリメンタル・デコーダクラスまたはファクトリ関数を返します。
エンコーディングが見つからないか、 codec がインクリメンタル・デコーダをサポートしなければ LookupError を送出します。
codecs.getreader(encoding)
与えられたエンコーディングに対する codec を検索し、StreamReader クラスまたはファクトリ関数を返します。
エンコーディングが見つからなければ LookupError を送出します。
codecs.getwriter(encoding)
与えられたエンコーディングに対する codec を検索し、StreamWriter クラスまたはファクトリ関数を返します。
エンコーディングが見つからなければ LookupError を送出します。
次のように、適切な codec 検索関数を登録することで、カスタムの codecs を利用することができます。
codecs.register(search_function)
codec 検索関数を登録します。検索関数は第 1 引数にすべてアルファベットの小文字から成るエンコーディング名を取り、CodecInfo オブジェクトを返します。検索関数が指定されたエンコーディングを見つけられない場合、None を返します。
注釈 現在、検索関数の登録は不可逆的です。このため、ユニットテストやモジュールの再ロード時などに問題が生じることがあります。
エンコードされたテキストファイルを処理する場合、組み込みの open() とそれに関連付けられた io モジュールの使用が推奨されていますが、このモジュールは追加のユーティリティ関数とクラスを提供し、バイナリファイルを処理する場合に幅広い codecs を利用できるようにします。
codecs.open(filename, mode='r', encoding=None, errors='strict', buffering=-1)
エンコードされたファイルを mode を使って開き、透過的なエンコード/デコードを提供する StreamReaderWriter のインスタンスを返します。デフォルトのファイルモードは 'r' 、つまり、読み出しモードでファイルを開きます。
注釈 下層のエンコードされたファイルは、常にバイナリモードで開きます。読み書き時に、 '\n' の自動変換は行われません。mode 引数は、組み込みの open() 関数が受け入れる任意のバイナリモードにすることができます。'b' が自動的に付加されます。
encoding は、そのファイルに対して使用されるエンコーディングを指定します。バイトにエンコードする、あるいはバイトからデコードするすべてのエンコーディングが許可されます。ファイルメソッドがサポートするデータ型は、使用される codec によって異なります。
エラーハンドリングのために errors を渡すことができます。これはデフォルトでは 'strict' で、エンコード時にエラーがあれば ValueError を送出します。
codecs.EncodedFile(file, data_encoding, file_encoding=None, errors='strict')
透過的なエンコード変換を行うファイルのラップされたバージョンである、StreamRecoder インスタンスを返します。元のファイルは、ラップされたバージョンが閉じられる時に、閉じられます。
ラップされたファイルに書き込まれたデータは、指定された data_encoding に従ってデコードされ、次に file_encoding を使用して元のファイルにバイトとして書き出されます。元のファイルから読み出されたバイトは、file_encoding に従ってデコードされ、結果は data_encoding を使用してエンコードされます。
file_encoding が与えられなければ、data_encoding がデフォルトになります。
エラーハンドリングのために errors を渡すことができます。これはデフォルトでは 'strict' で、エンコード時にエラーがあれば ValueError を送出します。
codecs.iterencode(iterator, encoding, errors='strict', **kwargs)
インクリメンタル・エンコーダを使って、 iterator から供給される入力を反復的にエンコードします。この関数は generator です。 errors 引数は (他のあらゆるキーワード引数と同様に) インクリメンタル・エンコーダにそのまま引き渡されます。
この関数では、コーデックはエンコードするテキストの str オブジェクトを受け付ける必要があります。 従って、 base64_codec のようなバイトからバイトへのエンコーダはサポートしていません。
codecs.iterdecode(iterator, encoding, errors='strict', **kwargs)
インクリメンタル・デコーダを使って、 iterator から供給される入力を反復的にデコードします。この関数は generator です。 errors 引数は (他のあらゆるキーワード引数と同様に) インクリメンタル・デコーダにそのまま引き渡されます。
この関数では、コーデックはエンコードする bytes オブジェクトを受け付ける必要があります。 従って、 rot_13 のようなテキストからテキストへのエンコーダが iterencode() で同等に使えるとしても、この関数ではサポートしていません。
このモジュールは以下のような定数も定義しています。プラットフォーム依存なファイルを読み書きするのに役立ちます:
codecs.BOM
codecs.BOM_BE
codecs.BOM_LE
codecs.BOM_UTF8
codecs.BOM_UTF16
codecs.BOM_UTF16_BE
codecs.BOM_UTF16_LE
codecs.BOM_UTF32
codecs.BOM_UTF32_BE
codecs.BOM_UTF32_LE
これらの定数は、いくつかのエンコーディングの Unicode のバイトオーダマーク (BOM) で、様々なバイトシーケンスを定義します。これらは、UTF-16 と UTF-32 のデータストリームで使用するバイトオーダを指定したり、 UTF-8 で Unicode シグネチャとして使われます。 BOM_UTF16 は、プラットフォームのネイティブバイトオーダによって BOM_UTF16_BE または BOM_UTF16_LE です。 BOM は BOM_UTF16 のエイリアスです。同様に、 BOM_LE は BOM_UTF16_LE の、 BOM_BE は BOM_UTF16_BE のエイリアスです。その他の定数は UTF-8 と UTF-32 エンコーディングの BOM を表します。
Codec 基底クラス
codecs モジュールは、 codec オブジェクトを操作するインターフェースを定義する一連の基底クラスを定義します。このモジュールは、カスタムの codec の実装の基礎として使用することもできます。
Python で codec として使えるようにするには、ステートレスエンコーダ、ステートレスデコーダ、ストリームリーダ、ストリームライタの 4 つのインタフェースを定義する必要があります。通常は、ストリームリーダとライタはステートレスエンコーダとデコーダを再利用して、ファイルプロトコルを実装します。codec の作者は、codec がエンコードとデコードのエラーの処理方法も定義する必要があります。
エラーハンドラ
値
意味
'strict'
'ignore'
以下のエラーハンドラは、 テキストエンコーディング にのみ適用されます。
値
意味
'replace'
'xmlcharrefreplace'
'backslashreplace'
バックスラッシュつきのエスケープシーケンスで置換します。 backslashreplace_errors() で実装されています。
'namereplace'
'surrogateescape'
さらに、次のエラーハンドラは与えられた codec に特有です:
値
Codecs
意味
'surrogatepass'
utf-8, utf-16, utf-32, utf-16-be, utf-16-le, utf-32-be, utf-32-le
バージョン 3.1 で追加: 'surrogateescape' および 'surrogatepass' エラーハンドラ。
バージョン 3.4 で変更: 'surrogatepass' エラーハンドラは utf-16* コーデックと utf-32* コーデックで動作するようになりました。
バージョン 3.5 で追加: 'namereplace' エラーハンドラです。
バージョン 3.5 で変更: 'backslashreplace' エラーハンドラは、デコード時と翻訳時に動作するようになりました。
次のように、名前付きの新しいエラーハンドラを登録することで、許可される値の集合を拡張することができます。
codecs.register_error(name, error_handler)
エラーハンドラ error_handler を名前 name で登録します。エンコード中およびデコード中にエラーが送出された場合、name が errors 引数として指定されていれば error_handler が呼び出されます。
デコードと翻訳の動作は似ていますが、エラーハンドラに渡されるのが UnicodeDecodeError か UnicodeTranslateError である点と、エラーハンドラの置換した内容が直接出力されるという点が異なります。
登録済みのエラーハンドラ (標準エラーハンドラを含む) は、次のようにその名前で検索することができます。
codecs.lookup_error(name)
名前 name で登録済みのエラーハンドラを返します。
エラーハンドラが見つからなければ LookupError を送出します。
以下の標準エラーハンドラも、モジュールレベルの関数として利用できます。
codecs.strict_errors(exception)
strict エラー処理を実装します。エンコードエラーまたはデコードエラーはそれぞれ UnicodeError を送出します。
codecs.replace_errors(exception)
'replace' エラー処理を実装します ( テキストエンコーディング のみ)。(codec によりエンコードする必要のある) エンコードエラーに対しては '?' に、デコードエラーに対しては '\ufffd' (Unicode 代替文字) に置き換えます。
codecs.ignore_errors(exception)
ignore エラー処理を実装します。不正な形式のデータは無視され、エンコードまたはデコードは何も通知することなく継続されます。
codecs.xmlcharrefreplace_errors(exception)
'xmlcharrefreplace' エラー処理を実装します ( テキストエンコーディング のエンコードのみ)。エンコードできない文字は、適切な XML 文字参照に置き換えます。
codecs.backslashreplace_errors(exception)
'backslashreplace' エラー処理を実装します ( テキストエンコーディング のエンコードのみ)。不正な形式のデータは、バックスラッシュ付きのエスケープシーケンスに置き換えます。
codecs.namereplace_errors(exception)
'namereplace' エラー処理を実装します ( テキストエンコーディング のエンコードのみ)。エンコードできない文字は、\N{...} エスケープシーケンスに置き換えます。
バージョン 3.5 で追加.
ステートレスなエンコードとデコード
基底の Codec クラスは以下のメソッドを定義します。これらのメソッドは、内部状態を持たないエンコーダ／デコーダ関数のインターフェースを定義します:
Codec.encode(input[, errors])
オブジェクト input エンコードし、(出力オブジェクト, 消費した長さ) のタプルを返します。例えば、 テキストエンコーディング は文字列オブジェクトを特有の文字セット (例えば cp1252 や iso-8859-1) を用いてバイト列オブジェクトに変換します。
errors 引数は適用するエラー処理を定義します。'strict' 処理がデフォルトです。
このメソッドは Codec に内部状態を保存してはなりません。効率よくエンコードするために状態を保持しなければならないような codecs には StreamWriter を使ってください。
エンコーダは長さが 0 の入力を処理できなければなりません。この場合、空のオブジェクトを出力オブジェクトとして返さなければなりません。
Codec.decode(input[, errors])
テキストエンコーディングとバイト列からバイト列への codec では、input は bytes オブジェクト、または読み出し専用のバッファインターフェースを提供するオブジェクトである必要があります。例えば、buffer オブジェクトやメモリマップドファイルでなければなりません。
errors 引数は適用するエラー処理を定義します。'strict' 処理がデフォルトです。
このメソッドは、 Codec インスタンスに内部状態を保存してはなりません。効率よくエンコード／デコードするために状態を保持しなければならないような codecs には StreamReader を使ってください。
デコーダは長さが 0 の入力を処理できなければなりません。この場合、空のオブジェクトを出力オブジェクトとして返さなければなりません。
インクリメンタルなエンコードとデコード
IncrementalEncoder クラスおよび IncrementalDecoder クラスはそれぞれインクリメンタル・エンコードおよびデコードのための基本的なインターフェースを提供します。エンコード／デコードは内部状態を持たないエンコーダ／デコーダを一度呼び出すことで行なわれるのではなく、インクリメンタル・エンコーダ／デコーダの encode()/decode() メソッドを複数回呼び出すことで行なわれます。インクリメンタル・エンコーダ／デコーダはメソッド呼び出しの間エンコード／デコード処理の進行を管理します。
encode()/decode() メソッド呼び出しの出力結果をまとめたものは、入力をひとまとめにして内部状態を持たないエンコーダ／デコーダでエンコード／デコードしたものと同じになります。
IncrementalEncoder オブジェクト
IncrementalEncoder クラスは入力を複数ステップでエンコードするのに使われます。全てのインクリメンタル・エンコーダが Python codec レジストリと互換性を持つために定義すべきメソッドとして、このクラスには以下のメソッドが定義されています。
class codecs.IncrementalEncoder(errors='strict')
IncrementalEncoder インスタンスのコンストラクタ。
全てのインクリメンタル・エンコーダはこのコンストラクタインターフェースを提供しなければなりません。さらにキーワード引数を付け加えるのは構いませんが、Python codec レジストリで利用されるのはここで定義されているものだけです。
IncrementalEncoder は、 errors キーワード引数を提供することで、様々なエラー取扱方法を実装することができます。取り得る値については エラーハンドラ を参照してください。
errors 引数は、同名の属性に代入されます。この属性を変更すると、 IncrementalEncoder オブジェクトが生きている間に、異なるエラー処理方法に切り替えることができるようになります。
encode(object[, final])
object を(エンコーダの現在の状態を考慮に入れて)エンコードし、得られたエンコードされたオブジェクトを返します。 encode() 呼び出しがこれで最後という時には final は真でなければなりません(デフォルトは偽です)。
reset()
エンコーダを初期状態にリセットします。出力は破棄されます。.encode(object, final=True) を呼び出して、必要に応じて空バイト列またはテキスト文字列を渡すことにより、エンコーダをリセットし、出力を取得します。
getstate()
setstate(state)
エンコーダの状態を state にセットします。 state は getstate() によって返されたエンコーダ状態でなければなりません。
IncrementalDecoder オブジェクト
IncrementalDecoder クラスは入力を複数ステップでデコードするのに使われます。全てのインクリメンタル・デコーダが Python codec レジストリと互換性を持つために定義すべきメソッドとして、このクラスには以下のメソッドが定義されています。
class codecs.IncrementalDecoder(errors='strict')
IncrementalDecoder インスタンスのコンストラクタ。
全てのインクリメンタル・デコーダはこのコンストラクタインターフェースを提供しなければなりません。さらにキーワード引数を付け加えるのは構いませんが、Python codec レジストリで利用されるのはここで定義されているものだけです。
IncrementalDecoder は、 errors キーワード引数を提供することで、様々なエラー取扱方法を実装することができます。取り得る値については エラーハンドラ を参照してください。
errors 引数は、同名の属性に代入されます。この属性を変更すると、 IncrementalDecoder オブジェクトが生きている間に、異なるエラー処理方法に切り替えることができるようになります。
decode(object[, final])
object を(デコーダの現在の状態を考慮に入れて)デコードし、得られたデコードされたオブジェクトを返します。 decode() 呼び出しがこれで最後という時には final は真でなければなりません(デフォルトは偽です)。もし final が真ならばデコーダは入力をデコードし切り全てのバッファをフラッシュしなければなりません。そうできない場合(たとえば入力の最後に不完全なバイト列があるから)、デコーダは内部状態を持たない場合と同じようにエラーの取り扱いを開始しなければなりません(例外を送出するかもしれません)。
reset()
デコーダを初期状態にリセットします。
getstate()
デコーダの現在の状態を返します。これは2要素を含むタプルでなければなりません。1番目はまだデコードされていない入力を含むバッファです。2番目は整数で、付加的な状態情報です (実装は 0 が最も一般的な付加的な状態情報であることを保証すべきです)。この付加的な状態情報が 0 である場合、デコーダを入力がバッファされていない状態に戻して、付加的な状態情報を 0 にセットすることが可能でなければなりません。その結果、以前バッファされた入力をデコーダに与えることで、何の出力もせずにデコーダを前の状態に戻します。 (整数より複雑な付加的な状態情報は、情報を marshal/pickle して、結果として生じる文字列のバイト列を整数にエンコードすることで、整数に変換することができます。)
setstate(state)
デコーダの状態を state にセットします。 state は getstate() によって返されたデコーダの状態でなければなりません。
ストリームのエンコードとデコード
StreamWriter と StreamReader クラスは、新しいエンコーディングサブモジュールを非常に簡単に実装するのに使用できる、一般的なインターフェイスを提供します。実装例は encodings.utf_8 をご覧ください。
StreamWriter オブジェクト
StreamWriter クラスは Codec のサブクラスで、以下のメソッドを定義しています。全てのストリームライタは、 Python の codec レジストリとの互換性を保つために、これらのメソッドを定義する必要があります。
class codecs.StreamWriter(stream, errors='strict')
StreamWriter インスタンスのコンストラクタです。
全てのストリームライタはコンストラクタとしてこのインターフェースを提供しなければなりません。キーワード引数を追加しても構いませんが、Python の codec レジストリはここで定義されている引数だけを使います。
stream 引数は、特定の codec に対応して、テキストまたはバイナリデータの書き込みが可能なファイルライクオブジェクトである必要があります。
StreamWriter は、 errors キーワード引数を提供することで、様々なエラー取扱方法を実装することができます。下層のストリーム codec がサポートできる標準エラーハンドラについては エラーハンドラ を参照してください。
errors 引数は、同名の属性に代入されます。この属性を変更すると、 StreamWriter オブジェクトが生きている間に、異なるエラー処理に変更できます。
write(object)
object の内容をエンコードしてストリームに書き出します。
writelines(list)
文字列からなるリストを連結して、ストリームに書き出します (可能な場合には write() を再利用します) 。バイト列からバイト列への標準 codecs は、このメソッドをサポートしません。
reset()
このメソッドが呼び出された場合、出力先データをきれいな状態にし、わざわざストリーム全体を再スキャンして状態を元に戻さなくても新しくデータを追加できるようにしなければなりません。
ここまでで挙げたメソッドの他にも、 StreamWriter では背後にあるストリームの他の全てのメソッドや属性を継承しなければなりません。
StreamReader オブジェクト
StreamReader クラスは Codec のサブクラスで、以下のメソッドを定義しています。全てのストリームリーダは、 Python の codec レジストリとの互換性を保つために、これらのメソッドを定義する必要があります。
class codecs.StreamReader(stream, errors='strict')
StreamReader インスタンスのコンストラクタです。
全てのストリームリーダはコンストラクタとしてこのインターフェースを提供しなければなりません。キーワード引数を追加しても構いませんが、Python の codec レジストリはここで定義されている引数だけを使います。
stream 引数は、特定の codec に対応して、テキストまたはバイナリデータの読み出しが可能なファイルライクオブジェクトである必要があります。
StreamReader は、 errors キーワード引数を提供することで、様々なエラー取扱方法を実装することができます。下層のストリーム codec がサポートできる標準エラーハンドラについては エラーハンドラ を参照してください。
errors 引数は、同名の属性に代入されます。この属性を変更すると、 StreamReader オブジェクトが生きている間に、異なるエラー処理に変更できます。
errors 引数に許される値の集合は register_error() で拡張できます。
read([size[, chars[, firstline]]])
ストリームからのデータをデコードし、デコード済のオブジェクトを返します。
chars 引数は、いくつのデコードされたコードポイントまたはバイト列を返すかを表します。 read() メソッドは、要求された数以上のデータを返すことはありませんが、データがそれより少ない場合には要求された数未満のデータを返す場合があります。
firstline フラグは、1行目さえ返せばその後の行でデコードエラーがあっても無視して十分だ、ということを示します。
このメソッドは貪欲な読み込み戦略を取るべきです。すなわち、エンコーディング定義と size の値が許す範囲で、できるだけ多くのデータを読むべきだということです。たとえば、ストリーム上にエンコーディングの終端や状態の目印があれば、それも読み込みます。
readline([size[, keepends]])
入力ストリームから1行読み込み、デコード済みのデータを返します。
size が与えられた場合、ストリームの read() メソッドに size 引数として渡されます。
keepends が偽の場合には行末の改行が削除された行が返ります。
readlines([sizehint[, keepends]])
入力ストリームから全ての行を読み込み、行のリストとして返します。
sizehint が与えられた場合、ストリームの read() メソッドに size 引数として渡されます。
reset()
ここまでで挙げたメソッドの他にも、 StreamReader では背後にあるストリームの他の全てのメソッドや属性を継承しなければなりません。
StreamReaderWriter オブジェクト
StreamReaderWriter は、読み書き両方に使えるストリームをラップできる便利なクラスです。
lookup() 関数が返すファクトリ関数を使って、インスタンスを生成するという設計です。
class codecs.StreamReaderWriter(stream, Reader, Writer, errors='strict')
StreamReaderWriter インスタンスを生成します。 stream はファイル類似のオブジェクトです。 Reader と Writer は、それぞれ StreamReader と StreamWriter インターフェースを提供するファクトリ関数かファクトリクラスでなければなりません。エラー処理は、ストリームリーダとライタで定義したものと同じように行われます。
StreamReaderWriter インスタンスは、 StreamReader クラスと StreamWriter クラスを合わせたインタフェースを継承します。元になるストリームからは、他のメソッドや属性を継承します。
StreamRecoder オブジェクト
StreamRecoder はデータをあるエンコーディングから別のエンコーディングに変換します。異なるエンコーディング環境を扱うとき、便利な場合があります。
lookup() 関数が返すファクトリ関数を使って、インスタンスを生成するという設計です。
class codecs.StreamRecoder(stream, encode, decode, Reader, Writer, errors='strict')
双方向変換を実装する StreamRecoder インスタンスを生成します。 encode と decode はフロントエンド (read() および write() を呼び出すコードから見えるデータ) ではたらき、 Reader と Writer はバックエンド (stream 内のデータ) ではたらきます。
stream 引数はファイルライクオブジェクトでなくてはなりません。
encode 引数と decode 引数は Codec のインターフェースに忠実でなくてはなりません。Reader と Writer は、それぞれ StreamReader と StreamWriter のインターフェースを提供するオブジェクトのファクトリ関数かクラスでなくてはなりません。
エラー処理はストリーム・リーダやライタで定義されている方法と同じように行われます。
StreamRecoder インスタンスは、 StreamReader と StreamWriter クラスを合わせたインターフェースを定義します。また、元のストリームのメソッドと属性も継承します。
エンコーディングと Unicode
最も単純なテキストエンコーディング ('latin-1' または 'iso-8859-1') では、0--255 の範囲にあるコードポイントを 0x0--0xff のバイトにマップします。 つまり、この codec では U+00FF 以上のコードポイントを含む文字列オブジェクトをエンコードすることはできません。 このようなエンコード処理をしようとすると、次のように UnicodeEncodeError が送出されます (エラーメッセージの細かところは異なる場合があります。): UnicodeEncodeError: 'latin-1' codec can't encode character '\u1234' in position 3: ordinal not in range(256) 。
他のエンコーディングの一群 (charmap エンコーディングと呼ばれます) があり、 Unicode コードポイントの別の部分集合と、それらから 0x0--0xff のバイトへの対応付けを選択したものです。 これがどのように行なわれるかを知るには、単にたとえば encodings/cp1252.py (主に Windows で使われるエンコーディングです) を開いてみてください。 256 文字のひとつの文字列定数があり、どの文字がどのバイト値へ対応付けられるかが示されています。
これらのエンコーディングはすべて、 Unicode に定義された 1114112 のコードポイントのうちの 256 だけをエンコードすることができます。 Unicode のすべてのコードポイントを格納するための単純で直接的な方法は、各コードポイントを連続する4バイトとして格納することです。これには2つの可能性があります: ビッグエンディアンまたはリトルエンディアンの順にバイトを格納することです。これら2つのエンコーディングはそれぞれ UTF-32-BE および UTF-32-LE と呼ばれます。それらのデメリットは、例えばリトルエンディアンのマシン上で UTF-32-BE を使用すると、エンコードでもデコードでも常にバイト順を交換する必要があることです。UTF-32 はこの問題を回避します: バイト順は、常に自然なエンディアンに従います。しかし、これらのバイト順が異なるエンディアン性を持つ CPU によって読まれる場合、結局バイト順を交換しなければなりません。UTF-16 あるいは UTF-32 バイト列のエンディアン性を検出する目的で、いわゆる BOM (「バイト・オーダー・マーク」) があります。これは Unicode 文字 U+FEFF です。この文字はすべての UTF-16 あるいは UTF-32 バイト列の前に置くことができます。この文字のバイトが交換されたバージョン (0xFFFE) は、 Unicode テキストに現われてはならない不正な文字です。したがって、UTF-16 あるいは UTF-32 バイト列中の最初の文字が U+FFFE であるように見える場合、デコードの際にバイトを交換しなければなりません。不運にも文字 U+FEFF は ZERO WIDTH NO-BREAK SPACE として別の目的を持っていました: 幅を持たず、単語を分割することを許容しない文字。それは、例えばリガチャアルゴリズムにヒントを与えるために使用することができます。 Unicode 4.0 で、ZERO WIDTH NO-BREAK SPACE としての U+FEFF の使用は廃止予定になりました (この役割は U+2060 (WORD JOINER) によって引き継がれました)。しかしながら、 Unicode ソフトウェアは、依然として両方の役割の U+FEFF を扱うことができなければなりません: BOM として、エンコードされたバイトのメモリレイアウトを決定する手段であり、一旦バイト列が文字列にデコードされたならば消えます; ZERO WIDTH NO-BREAK SPACE として、他の任意の文字のようにデコードされる通常の文字です。
さらにもう一つ Unicode 文字全てをエンコードできるエンコーディングがあり、UTF-8 と呼ばれています。UTF-8 は8ビットエンコーディングで、したがって UTF-8 にはバイト順の問題はありません。UTF-8 バイト列の各バイトは二つのパートから成ります。二つはマーカ(上位数ビット)とペイロードです。マーカは0ビットから4ビットの 1 の列に 0 のビットが一つ続いたものです。Unicode 文字は次のようにエンコードされます (x はペイロードを表わし、連結されると一つの Unicode 文字を表わします):
範囲
エンコーディング
U-00000000 ... U-0000007F
0xxxxxxx
U-00000080 ... U-000007FF
110xxxxx 10xxxxxx
U-00000800 ... U-0000FFFF
1110xxxx 10xxxxxx 10xxxxxx
U-00010000 ... U-0010FFFF
11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
Unicode 文字の最下位ビットとは最も右にある x のビットです。
UTF-8 は8ビットエンコーディングなので BOM は必要とせず、デコードされた文字列中の U+FEFF は(たとえ最初の文字であったとしても) ZERO WIDTH NO-BREAK SPACE として扱われます。
外部からの情報無しには、文字列のエンコーディングにどのエンコーディングが使われたのか信頼できる形で決定することは不可能です。どの charmap エンコーディングもどんなランダムなバイト列でもデコードできます。しかし UTF-8 ではそれは可能ではありません。任意のバイト列を許さないような構造を持っているからです。UTF-8 エンコーディングであることを検知する信頼性を向上させるために、Microsoft は Notepad プログラム用に UTF-8 の変種 (Python 2.5 では "utf-8-sig" と呼んでいます) を考案しました。Unicode 文字がファイルに書き込まれる前に UTF-8 でエンコードした BOM (バイト列では 0xef, 0xbb, 0xbf のように見えます) が書き込まれます。このようなバイト値で charmap エンコードされたファイルが始まることはほとんどあり得ない (たとえば iso-8859-1 では
標準エンコーディング
Python には数多くの codec が組み込みで付属します。これらは C 言語の関数、対応付けを行うテーブルの両方で提供されています。以下のテーブルでは codec と、いくつかの良く知られている別名と、エンコーディングが使われる言語を列挙します。別名のリスト、言語のリストともしらみつぶしに網羅されているわけではありません。大文字と小文字、またはアンダースコアの代りにハイフンにしただけの綴りも有効な別名です; そのため、例えば 'utf-8' は 'utf_8' codec の正当な別名です。
バージョン 3.6 で変更: us-ascii に対して最適化の機会が認識されるようになりました。
多くの文字セットは同じ言語をサポートしています。これらの文字セットは個々の文字 (例えば、EURO SIGN がサポートされているかどうか) や、文字のコード部分への割り付けが異なります。特に欧州言語では、典型的に以下の変種が存在します:
ISO 8859 コードセット
Microsoft Windows コードページで、8859 コード形式から導出されているが、制御文字を追加のグラフィック文字と置き換えたもの
IBM EBCDIC コードページ
ASCII 互換の IBM PC コードページ
Codec
別名
言語
ascii
646, us-ascii
英語
big5
big5-tw, csbig5
繁体字中国語
big5hkscs
big5-hkscs, hkscs
繁体字中国語
cp037
IBM037, IBM039
英語
cp273
273, IBM273, csIBM273
ドイツ語
バージョン 3.4 で追加.
cp424
EBCDIC-CP-HE, IBM424
ヘブライ語
cp437
437, IBM437
英語
cp500
EBCDIC-CP-BE, EBCDIC-CP-CH, IBM500
西ヨーロッパ言語
cp720
アラビア語
cp737
ギリシャ語
cp775
IBM775
バルト沿岸国
cp850
850, IBM850
西ヨーロッパ言語
cp852
852, IBM852
中央および東ヨーロッパ
cp855
855, IBM855
ブルガリア、ベラルーシ、マケドニア、ロシア、セルビア
cp856
ヘブライ語
cp857
857, IBM857
トルコ語
cp858
858, IBM858
西ヨーロッパ言語
cp860
860, IBM860
ポルトガル語
cp861
861, CP-IS, IBM861
アイスランド語
cp862
862, IBM862
ヘブライ語
cp863
863, IBM863
カナダ
cp864
IBM864
アラビア語
cp865
865, IBM865
デンマーク、ノルウェー
cp866
866, IBM866
ロシア語
cp869
869, CP-GR, IBM869
ギリシャ語
cp874
タイ語
cp875
ギリシャ語
cp932
932, ms932, mskanji, ms-kanji
日本語
cp949
949, ms949, uhc
韓国語
cp950
950, ms950
繁体字中国語
cp1006
Urdu
cp1026
ibm1026
トルコ語
cp1125
1125, ibm1125, cp866u, ruscii
ウクライナ語
バージョン 3.4 で追加.
cp1140
ibm1140
西ヨーロッパ言語
cp1250
windows-1250
中央および東ヨーロッパ
cp1251
windows-1251
ブルガリア、ベラルーシ、マケドニア、ロシア、セルビア
cp1252
windows-1252
西ヨーロッパ言語
cp1253
windows-1253
ギリシャ語
cp1254
windows-1254
トルコ語
cp1255
windows-1255
ヘブライ語
cp1256
windows-1256
アラビア語
cp1257
windows-1257
バルト沿岸国
cp1258
windows-1258
ベトナム
euc_jp
eucjp, ujis, u-jis
日本語
euc_jis_2004
jisx0213, eucjis2004
日本語
euc_jisx0213
eucjisx0213
日本語
euc_kr
euckr, korean, ksc5601, ks_c-5601, ks_c-5601-1987, ksx1001, ks_x-1001
韓国語
gb2312
chinese, csiso58gb231280, euc-cn, euccn, eucgb2312-cn, gb2312-1980, gb2312-80, iso-ir-58
簡体字中国語
gbk
936, cp936, ms936
Unified Chinese
gb18030
gb18030-2000
Unified Chinese
hz
hzgb, hz-gb, hz-gb-2312
簡体字中国語
iso2022_jp
csiso2022jp, iso2022jp, iso-2022-jp
日本語
iso2022_jp_1
iso2022jp-1, iso-2022-jp-1
日本語
iso2022_jp_2
iso2022jp-2, iso-2022-jp-2
日本語, 韓国語, 簡体字中国語, 西欧, ギリシャ語
iso2022_jp_2004
iso2022jp-2004, iso-2022-jp-2004
日本語
iso2022_jp_3
iso2022jp-3, iso-2022-jp-3
日本語
iso2022_jp_ext
iso2022jp-ext, iso-2022-jp-ext
日本語
iso2022_kr
csiso2022kr, iso2022kr, iso-2022-kr
韓国語
latin_1
iso-8859-1, iso8859-1, 8859, cp819, latin, latin1, L1
西ヨーロッパ言語
iso8859_2
iso-8859-2, latin2, L2
中央および東ヨーロッパ
iso8859_3
iso-8859-3, latin3, L3
エスペラント、マルタ
iso8859_4
iso-8859-4, latin4, L4
バルト沿岸国
iso8859_5
iso-8859-5, cyrillic
ブルガリア、ベラルーシ、マケドニア、ロシア、セルビア
iso8859_6
iso-8859-6, arabic
アラビア語
iso8859_7
iso-8859-7, greek, greek8
ギリシャ語
iso8859_8
iso-8859-8, hebrew
ヘブライ語
iso8859_9
iso-8859-9, latin5, L5
トルコ語
iso8859_10
iso-8859-10, latin6, L6
北欧語
iso8859_11
iso-8859-11, thai
タイ語
iso8859_13
iso-8859-13, latin7, L7
バルト沿岸国
iso8859_14
iso-8859-14, latin8, L8
ケルト語
iso8859_15
iso-8859-15, latin9, L9
西ヨーロッパ言語
iso8859_16
iso-8859-16, latin10, L10
南東ヨーロッパ
johab
cp1361, ms1361
韓国語
koi8_r
ロシア語
koi8_t
タジク
バージョン 3.5 で追加.
koi8_u
ウクライナ語
kz1048
kz_1048, strk1048_2002, rk1048
カザフ
バージョン 3.5 で追加.
mac_cyrillic
maccyrillic
ブルガリア、ベラルーシ、マケドニア、ロシア、セルビア
mac_greek
macgreek
ギリシャ語
mac_iceland
maciceland
アイスランド語
mac_latin2
maclatin2, maccentraleurope, mac_centeuro
中央および東ヨーロッパ
mac_roman
macroman, macintosh
西ヨーロッパ言語
mac_turkish
macturkish
トルコ語
ptcp154
csptcp154, pt154, cp154, cyrillic-asian
カザフ
shift_jis
csshiftjis, shiftjis, sjis, s_jis
日本語
shift_jis_2004
shiftjis2004, sjis_2004, sjis2004
日本語
shift_jisx0213
shiftjisx0213, sjisx0213, s_jisx0213
日本語
utf_32
U32, utf32
全ての言語
utf_32_be
UTF-32BE
全ての言語
utf_32_le
UTF-32LE
全ての言語
utf_16
U16, utf16
全ての言語
utf_16_be
UTF-16BE
全ての言語
utf_16_le
UTF-16LE
全ての言語
utf_7
U7, unicode-1-1-utf-7
全ての言語
utf_8
U8, UTF, utf8, cp65001
全ての言語
utf_8_sig
全ての言語
バージョン 3.4 で変更: utf-16* と utf-32* のエンコーダは、サロゲートコードポイント (U+D800--U+DFFF) がエンコードされることを許可しなくなりました。utf-32* デコーダは、サロゲートコードポイントに対応するバイト列をデコードしなくなりました。
バージョン 3.8 で変更: cp65001 is now an alias to utf_8.
Python 特有のエンコーディング
テキストエンコーディング
次の codec では、 Unicode におけるテキストエンコーディングと同様に、 str から bytes へのエンコードと、 bytes-like object から str へのデコードを提供します。
Codec
別名
意味
idna
mbcs
ansi, dbcs
oem
バージョン 3.6 で追加.
palmos
punycode
raw_unicode_escape
別のコードポイントに \uXXXX と \UXXXXXXXX を使用する Latin-1 エンコーディングです。既存のバックスラッシュは、いかなる方法でもエスケープされません。Python の pickle プロトコルで使用されます。
undefined
空文字列を含む全ての変換に対して例外を送出します。エラーハンドラは無視されます。
unicode_escape
バージョン 3.8 で変更: "unicode_internal" codec is removed.
バイナリ変換 (Binary Transforms)
Codec
別名
意味
エンコーダ / デコーダ
base64_codec 1
base64, base_64
バージョン 3.4 で変更: 任意の bytes-like object をエンコードとデコード用の入力として受け取ります。
base64.encodebytes() / base64.decodebytes()
bz2_codec
bz2
bz2.compress() / bz2.decompress()
hex_codec
hex
binascii.b2a_hex() / binascii.a2b_hex()
quopri_codec
quopri, quotedprintable, quoted_printable
quotetabs=True を指定した quopri.encode() / quopri.decode()
uu_codec
uu
uu.encode() / uu.decode()
zlib_codec
zip, zlib
zlib.compress() / zlib.decompress()
1
バイト様オブジェクト に加えて、'base64_codec' も str の ASCII のみのインスタンスをデコード用に受け入れるようになりました
バージョン 3.2 で追加: バイナリ変換が復活しました。(訳注: 2.x にはあったものが 3.0 で削除されていた。)
バージョン 3.4 で変更: バイナリ変換のエイリアスが復活しました。(訳注: 2.x にはあったエイリアス。3.2 でエイリアスは復活しなかった。)
テキスト変換 (Text Transforms)
Codec
別名
意味
rot_13
rot13
バージョン 3.2 で追加: rot_13 テキスト変換が復活しました。(訳注: 2.x にはあったものが 3.0 で削除されていた。)
バージョン 3.4 で変更: rot13 エイリアスが復活しました。(訳注: 2.x にはあったエイリアス。3.2 でエイリアスは復活しなかった。)
encodings.idna --- アプリケーションにおける国際化ドメイン名 (IDNA)
このモジュールでは RFC 3490 (アプリケーションにおける国際化ドメイン名、 IDNA: Internationalized Domain Names in Applications) および RFC 3492 (Nameprep: 国際化ドメイン名 (IDN) のための stringprep プロファイル) を実装しています。このモジュールは punycode エンコーディングおよび stringprep の上に構築されています。
これらの RFC はともに、非 ASCII 文字の入ったドメイン名をサポートするためのプロトコルを定義しています。 (www.Alliancefrançaise.nu のような) 非 ASCII 文字を含むドメイン名は、 ASCII と互換性のあるエンコーディング (ACE、 www.xn--alliancefranaise-npb.nu のような形式) に変換されます。ドメイン名の ACE 形式は、 DNS クエリ、 HTTP Host フィールドなどといった、プロトコル中で任意の文字を使えないような全ての局面で用いられます。この変換はアプリケーション内で行われます; 可能ならユーザからは不可視となります: アプリケーションは Unicode ドメインラベルをネットワークに載せる際に IDNA に、 ACE ドメインラベルをユーザに提供する前に Unicode に、それぞれ透過的に変換しなければなりません。
encodings.idna ではまた、 nameprep 手続きを実装しています。 nameprep はホスト名に対してある正規化を行って、国際化ドメイン名で大小文字を区別しないようにするとともに、類似の文字を一元化します。 nameprep 関数は必要なら直接使うこともできます。
encodings.idna.nameprep(label)
label を nameprep したバージョンを返します。現在の実装ではクエリ文字列を仮定しているので、AllowUnassigned は真です。
encodings.idna.ToASCII(label)
RFC 3490 仕様に従ってラベルを ASCIIに変換します。 UseSTD3ASCIIRules は偽であると仮定します。
encodings.idna.ToUnicode(label)
RFC 3490 仕様に従ってラベルを Unicode に変換します。
encodings.mbcs --- Windows ANSI コードページ
利用可能な環境: Windows のみ。
バージョン 3.3 で変更: 任意のエラーハンドラのサポート。
バージョン 3.2 で変更: 3.2 以前は errors 引数は無視されました; エンコードには常に 'replace' が、デコードには 'ignore' が使われました。
encodings.utf_8_sig --- BOM 印付き UTF-8
組み込み関数
Python インタプリタには数多くの関数と型が組み込まれており、いつでも利用できます。それらをここにアルファベット順に挙げます。
組み込み関数
abs()
delattr()
hash()
memoryview()
set()
all()
dict()
help()
min()
setattr()
any()
dir()
hex()
next()
slice()
ascii()
divmod()
id()
object()
sorted()
bin()
enumerate()
input()
oct()
staticmethod()
bool()
eval()
int()
open()
str()
breakpoint()
exec()
isinstance()
ord()
sum()
bytearray()
filter()
issubclass()
pow()
super()
bytes()
float()
iter()
print()
tuple()
callable()
format()
len()
property()
type()
chr()
frozenset()
list()
range()
vars()
classmethod()
getattr()
locals()
repr()
zip()
compile()
globals()
map()
reversed()
__import__()
complex()
hasattr()
max()
round()
abs(x)
all(iterable)
iterable の全ての要素が真ならば (もしくは iterable が空ならば) True を返します。以下のコードと等価です:
def all(iterable):
    for element in iterable:
        if not element:
            return False
    return True
any(iterable)
iterable のいずれかの要素が真ならば True を返します。iterable が空なら False を返します。以下のコードと等価です:
def any(iterable):
    for element in iterable:
        if element:
            return True
    return False
ascii(object)
repr() と同様、オブジェクトの印字可能な表現を含む文字列を返しますが、repr() によって返された文字列中の非 ASCII 文字は \x 、 \u 、 \U エスケープを使ってエスケープされます。これは Python 2 の repr() によって返されるのと同じ文字列を作ります。
bin(x)
整数を先頭に "0b" が付いた 2 進文字列に変換します。 結果は Python の式としても使える形式になります。
>>>
>>> bin(3)
'0b11'
>>> bin(-10)
'-0b1010'
先頭に "0b" が付いて欲しい、もしくは付いて欲しくない場合には、次の方法のどちらでも使えます。
>>>
>>> format(14, '#b'), format(14, 'b')
('0b1110', '1110')
>>> f'{14:#b}', f'{14:b}'
('0b1110', '1110')
より詳しいことは format() も参照してください。
class bool([x])
ブール値、即ち True または False のどちらかを返します。x は標準の 真理値判定手続き を用いて変換されます。x が偽または省略されている場合、この関数は False を返します。それ以外の場合、True を返します。bool クラスは int クラスの派生クラスです(数値型 int, float, complex を参照してください)。このクラスからさらに派生することはできません。ブール値のインスタンスは False と True のみです(ブール値 を参照してください)。
バージョン 3.7 で変更: x は位置専用引数になりました。
breakpoint(*args, **kws)
この関数により、呼び出された箇所からデバッガへ移行します。 特に、この関数は args および kws をそのまま sys.breakpointhook() に渡して呼び出します。 デフォルトでは、 sys.breakpointhook() は引数無しで pdb.set_trace() を呼び出します。 このケースでは、 pdb.set_trace() は単なる便利な関数なので、明示的に pdb をインポートしたり、デバッガに入るためにキーをたくさん打ち込む必要はありません。 ただし、 sys.breakpointhook() は他の関数を設定することもでき、 breakpoint() は自動的にその関数を呼び出します。これにより、最適なデバッガに移行できます。
引数 breakpointhook 付きで 監査イベント builtins.breakpoint を送出します。
バージョン 3.7 で追加.
class bytearray([source[, encoding[, errors]]])
新しいバイト配列を返します。bytearray クラスは0 <= x < 256の範囲の整数からなる変更可能な配列です。ミュータブルなシーケンス型 に記述されている変更可能な配列に対する普通のメソッドの大半を備えています。また、bytes 型が持つメソッドの大半も備えています（see bytes と bytearray の操作)。
オプションの source 引数は、配列を異なる方法で初期化するのに使われます:
文字列 の場合、 encoding (と、オプションの errors) 引数も与えなければなりません。このとき bytearray() は文字列を str.encode() でバイトに変換して返します。
整数 の場合、配列はそのサイズになり、null バイトで初期化されます。
イテラブル の場合、範囲 0 <= x < 256 内の整数のイテラブルでなければならず、それらが配列の初期の内容として使われます。
引数がなければ、長さ 0 の配列が生成されます。
バイナリシーケンス型 --- bytes, bytearray, memoryview と bytearray オブジェクト も参照してください。
class bytes([source[, encoding[, errors]]])
範囲 0 <= x < 256 の整数のイミュータブルなシーケンスである "bytes" オブジェクトを返します。 bytes は bytearray のイミュータブル版です。オブジェクトを変化させないようなメソッドや、インデクシングやスライシングのふるまいは、これと同様のものです。
従って、コンストラクタ引数は bytearray() のものと同様に解釈されます。
バイト列オブジェクトはリテラルでも生成できます。 文字列およびバイト列リテラル を参照してください。
バイナリシーケンス型 --- bytes, bytearray, memoryview, バイトオブジェクト, bytes と bytearray の操作 も参照してください。
callable(object)
object 引数が呼び出し可能オブジェクトであれば True を、そうでなければ False を返します。この関数が True を返しても、呼び出しは失敗する可能性がありますが、False であれば、 object の呼び出しは決して成功しません。なお、クラスは呼び出し可能 (クラスを呼び出すと新しいインスタンスを返します) です。また、インスタンスはクラスが __call__() メソッドを持つなら呼び出し可能です。
バージョン 3.2 で追加: この関数は Python 3.0 で一度取り除かれましたが、Python 3.2 で復活しました。
chr(i)
Unicode コードポイントが整数 i である文字を表す文字列を返します。例えば chr(97) は文字列 'a' を、 chr(8364) は文字列 '€' を返します。 ord() の逆です。
引数の有効な範囲は 0 から 1,114,111 (16 進数で 0x10FFFF) です。 i が範囲外の場合 ValueError が送出されます。
@classmethod
メソッドをクラスメソッドへ変換します。
クラスメソッドは、インスタンスメソッドが暗黙の第一引数としてインスタンスをとるように、第一引数としてクラスをとります。クラスメソッドを宣言するには、以下のイディオムを使います:
class C:
    @classmethod
    def f(cls, arg1, arg2, ...): ...
@classmethod 形式は関数 デコレータ です。詳しくは 関数定義 を参照してください。
クラスメソッドは、(C.f() のように) クラスから呼び出すことも、(C().f() のように) インスタンスから呼び出すこともできます。 インスタンスはそのクラスが何であるかを除いて無視されます。 クラスメソッドが派生クラスから呼び出される場合は、その派生クラスオブジェクトが暗黙の第一引数として渡されます。
compile(source, filename, mode, flags=0, dont_inherit=False, optimize=-1)
source をコードオブジェクト、もしくは、 AST オブジェクトにコンパイルします。 コードオブジェクトは exec() 文で実行したり、 eval() 呼び出しで評価できます。 source は通常の文字列、 バイト列、 AST オブジェクトのいずれでもかまいません。 AST オブジェクトへの、また、 AST オブジェクトからのコンパイルの方法は、 ast モジュールのドキュメントを参照してください。
filename 引数には、コードの読み出し元のファイルを与えなければなりません; ファイルから読み出されるのでなければ、認識可能な値を渡して下さい ('<string>' が一般的に使われます)。
mode 引数は、コンパイルされるコードの種類を指定します; source が一連の文から成るなら 'exec' 、単一の式から成るなら 'eval' 、単一の対話的文の場合 'single' です。(後者の場合、評価が None 以外である式文が印字されます)。
引数 optimize は、コンパイラの最適化レベルを指定します; デフォルトの値 -1 は、インタプリタの -O オプションで与えられるのと同じ最適化レベルを選びます。明示的なレベルは、 0 (最適化なし、 __debug__ は真)、 1 (assert は取り除かれ、 __debug__ は偽)、 2 (docstring も取り除かれる) です。
この関数は、コンパイルされたソースが不正である場合 SyntaxError を、ソースがヌルバイトを含む場合 ValueError を送出します。
Python コードをパースしてその AST 表現を得たいのであれば、 ast.parse() を参照してください。
引数 source, filename を指定して 監査イベント compile を送出します。
注釈 複数行に渡るコードの文字列を 'single' や 'eval' モードでコンパイルするとき、入力は一つ以上の改行文字で終端されなければなりません。これは、 code モジュールで不完全な文と完全な文を検知しやすくするためです。
警告 AST オブジェクトにコンパイルしているときに、十分に大きい文字列や複雑な文字列によって Python の抽象構文木コンパイラのスタックが深さの限界を越えることで、 Python インタプリタをクラッシュさせられます。
バージョン 3.2 で変更: Windows や Mac の改行も受け付けます。また 'exec' モードでの入力が改行で終わっている必要もありません。optimize 引数が追加されました。
バージョン 3.5 で変更: 以前は source にヌルバイトがあったときに TypeError を送出していました。
class complex([real[, imag]])
値 real + imag*1j の複素数を返すか、文字列や数を複素数に変換します。第一引数が文字列なら、それが複素数と解釈され、この関数は第二引数無しで呼び出されなければなりません。第二引数は文字列であってはなりません。それぞれの引数は (複素数を含む) 任意の数値型です。 imag が省略された場合、標準の値はゼロで、このコンストラクタは int や float のような数値変換としてはたらきます。両方の引数が省略された場合、 0j を返します。
注釈 文字列から変換するとき、その文字列は中央の + や - 演算子の周りに空白を含んではなりません。例えば、complex('1+2j') はいいですが、complex('1 + 2j') は ValueError を送出します。
複素数型については 数値型 int, float, complex に説明があります。
バージョン 3.6 で変更: コードリテラル中で桁をグループ化するのにアンダースコアを利用できます。
delattr(object, name)
setattr() の親戚です。引数はオブジェクトと文字列です。文字列はオブジェクトの属性のうち一つの名前でなければなりません。この関数は、オブジェクトが許すなら、指名された属性を削除します。例えば、 delattr(x, 'foobar') は del x.foobar と等価です。
class dict(**kwarg)
class dict(mapping, **kwarg)
class dict(iterable, **kwarg)
新しい辞書を作成します。 dict オブジェクトは辞書クラスです。このクラスに関するドキュメンテーションは dict と マッピング型 --- dict を参照してください。
他のコンテナについては、 ビルトインの list, set, tuple クラスおよび collections モジュールを参照してください。
dir([object])
引数がない場合、現在のローカルスコープにある名前のリストを返します。引数がある場合、そのオブジェクトの有効な属性のリストを返そうと試みます。
オブジェクトが __dir__() という名のメソッドを持つなら、そのメソッドが呼び出され、属性のリストを返さなければなりません。これにより、カスタムの __getattr__() や __getattribute__() 関数を実装するオブジェクトは、dir() が属性を報告するやり方をカスタマイズできます。
オブジェクトが __dir__() を提供していない場合、定義されていればオブジェクトの __dict__ 属性から、そして型オブジェクトから、情報を収集しようと試みます。結果のリストは完全であるとは限らず、また、カスタムの __getattr__() を持つ場合、不正確になるかもしれません。
デフォルトの dir() メカニズムは、完全というより最重要な情報を作成しようとするため、異なる型のオブジェクトでは異なって振る舞います:
オブジェクトがモジュールオブジェクトの場合、リストにはモジュールの属性の名前が含まれます。
オブジェクトが型オブジェクトやクラスオブジェクトの場合、リストにはその属性の名前と、再帰的にたどったその基底クラスの属性が含まれます。
それ以外の場合には、リストにはオブジェクトの属性名、クラス属性名、再帰的にたどった基底クラスの属性名が含まれます。
返されるリストはアルファベット順に並べられています。例えば:
>>>
>>> import struct
>>> dir()   # show the names in the module namespace  
['__builtins__', '__name__', 'struct']
>>> dir(struct)   # show the names in the struct module 
['Struct', '__all__', '__builtins__', '__cached__', '__doc__', '__file__',
 '__initializing__', '__loader__', '__name__', '__package__',
 '_clearcache', 'calcsize', 'error', 'pack', 'pack_into',
 'unpack', 'unpack_from']
>>> class Shape:
...     def __dir__(self):
...         return ['area', 'perimeter', 'location']
>>> s = Shape()
>>> dir(s)
['area', 'location', 'perimeter']
注釈 dir() は主に対話プロンプトでの使用に便利なように提供されているので、厳密性や一貫性を重視して定義された名前のセットというよりも、むしろ興味を引くような名前のセットを返そうとします。また、この関数の細かい動作はリリース間で変わる可能性があります。例えば、引数がクラスであるとき、メタクラス属性は結果のリストに含まれません。
divmod(a, b)
2 つの (複素数でない) 数を引数として取り、整数の除法を行ったときの商と剰余からなる対を返します。混合した被演算子型では、二項算術演算子での規則が適用されます。整数では、結果は (a // b, a % b) と同じです。浮動小数点数では、結果は (q, a % b) で、ここで q は通常 math.floor(a / b) ですが、それより 1 小さくなることもあります。いずれにせよ、q * b + a % b は a に非常に近く、a % b がゼロでなければその符号は b と同じで、0 <= abs(a % b) < abs(b) です。
enumerate(iterable, start=0)
enumerate オブジェクトを返します。 iterable は、シーケンスか iterator か、あるいはイテレーションをサポートするその他のオブジェクトでなければなりません。 enumerate() によって返されたイテレータの __next__() メソッドは、 (デフォルトでは 0 となる start からの) カウントと、 iterable 上のイテレーションによって得られた値を含むタプルを返します。
>>>
>>> seasons = ['Spring', 'Summer', 'Fall', 'Winter']
>>> list(enumerate(seasons))
[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]
>>> list(enumerate(seasons, start=1))
[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]
次と等価です:
def enumerate(sequence, start=0):
    n = start
    for elem in sequence:
        yield n, elem
        n += 1
eval(expression[, globals[, locals]])
文字列とオプションの引数 globals、locals をとります。globals を与える場合は辞書でなくてはなりません。locals を与える場合は任意のマッピングオブジェクトにできます。
expression 引数は Python 式 (技術的な言い方では、条件のリスト) として構文解析され評価されます。 このとき辞書 globals および locals はそれぞれグローバルおよびローカルな名前空間として使われます。 globals 辞書が与えられ、 __builtins__ をキーとする値が含まれていない場合、 expression が構文解析される前に、組み込みモジュール builtins の辞書への参照がキー __builtins__ の値として挿入されます。 よって、 expression は通常、標準の builtins モジュールへの完全なアクセスを有し、制限された環境は伝播します。 locals 辞書が省略された場合、デフォルトは globals 辞書です。 辞書が両方とも省略された場合、表現式は eval() が呼び出されている環境の globals 辞書と locals 辞書の下で実行されます。 eval() は、それが実行される環境の ネストされたスコープ (非ローカルのオブジェクト) を参照できないことに注意してください。
返される値は、式が評価された結果になります。構文エラーは例外として報告されます。例:
>>>
>>> x = 1
>>> eval('x+1')
2
この関数は (compile() で生成されるような) 任意のコードオブジェクトを実行するのにも利用できます。この場合、文字列の代わりにコードオブジェクトを渡します。このコードオブジェクトが、引数 mode を 'exec' としてコンパイルされている場合、 eval() が返す値は None になります。
ヒント: exec() 関数により文の動的な実行がサポートされています。globals() および locals() 関数は、それぞれ現在のグローバルおよびローカルな辞書を返すので、それらを eval() や exec() に渡して使うことができます。
リテラルだけを含む式の文字列を安全に評価できる関数、 ast.literal_eval() も参照してください。
引数 code_object を指定して 監査イベント exec を送出します。
globals 辞書がキー __builtins__ に対する値を含まなければ、そのキーに対して、組み込みモジュール builtins の辞書への参照が挿入されます。ですから、実行されるコードを exec() に渡す前に、 globals に自作の __builtins__ 辞書を挿入することで、コードがどの組み込みを利用できるか制御できます。
引数 code_object を指定して 監査イベント exec を送出します。
注釈 組み込み関数 globals() および locals() は、それぞれ現在のグローバルおよびローカルの辞書を返すので、それらを exec() の第二、第三引数にそのまま渡して使うと便利なことがあります。
注釈 標準では locals は後に述べる関数 locals() のように動作します: 標準の locals 辞書に対する変更を試みてはいけません。 exec() の呼び出しが返る時にコードが locals に与える影響を知りたいなら、明示的に locals 辞書を渡してください。
filter(function, iterable)
iterable の要素のうち function が真を返すものでイテレータを構築します。iterable はシーケンスか、反復をサポートするコンテナか、イテレータです。function が None なら、恒等関数を仮定します。すなわち、iterable の偽である要素がすべて除去されます。
なお、filter(function, iterable) は、関数が None でなければジェネレータ式 (item for item in iterable if function(item)) と同等で、関数が None なら (item for item in iterable if item) と同等です。
function が偽を返すような iterable の各要素を返す補完的関数は、 itertools.filterfalse() を参照してください。
class float([x])
数または文字列 x から生成された浮動小数点数を返します。
引数が文字列の場合、10進数を含んだ文字列にしてください。先頭に符号が付いていたり、空白中に埋め込まれていてもかまいません。符号として '+' か '-' を追加できます。'+' は、作られる値に何の影響も与えません。引数は NaN (not-a-number) や正負の無限大を表す文字列でもかまいません。正確には、入力は、前後の空白を取り除いた後に以下の文法に従う必要があります:
sign           ::=  "+" | "-"
infinity       ::=  "Infinity" | "inf"
nan            ::=  "nan"
numeric_value  ::=  floatnumber | infinity | nan
numeric_string ::=  [sign] numeric_value
ここで floatnumber は 浮動小数点数リテラル で記述されている Python の浮動小数点数リテラルです。大文字か小文字かは関係なく、例えば "inf"、 "Inf"、 "INFINITY" 、 "iNfINity" は全て正の無限大として使える綴りです。
一方で、引数が整数または浮動小数点数なら、(Python の浮動小数点数の精度で) 同じ値の浮動小数点数が返されます。引数が Python の浮動小数点数の範囲外なら、 OverflowError が送出されます。
引数が与えられなければ、0.0 が返されます。
例:
>>>
>>> float('+1.23')
1.23
>>> float('   -12345\n')
-12345.0
>>> float('1e-003')
0.001
>>> float('+1E6')
1000000.0
>>> float('-Infinity')
-inf
浮動小数点数型については、 数値型 int, float, complex も参照してください。
バージョン 3.6 で変更: コードリテラル中で桁をグループ化するのにアンダースコアを利用できます。
バージョン 3.7 で変更: x は位置専用引数になりました。
バージョン 3.8 で変更: __float__() が定義されていない場合、__index__() へフォールバックします。
format(value[, format_spec])
value を format_spec で制御される "書式化された" 表現に変換します。 format_spec の解釈は value 引数の型に依存しますが、ほとんどの組み込み型で使われる標準的な構文が存在します: 書式指定ミニ言語仕様 。
デフォルトの format_spec は空の文字列です。それは通常 str(value) の呼び出しと同じ結果になります。
format(value, format_spec) の呼び出しは、 type(value).__format__(value, format_spec) に翻訳され、これは value の __format__() メソッドの検索をするとき、インスタンス辞書を回避します。このメソッドの探索が object に到達しても format_spec が空にならなかったり、 format_spec や返り値が文字列でなかったりした場合、 TypeError が送出されます。
バージョン 3.4 で変更: format_spec が空の文字列でない場合 object().__format__(format_spec) は TypeError を送出します。
class frozenset([iterable])
新しい frozenset オブジェクトを返します。オプションで iterable から得られた要素を含みます。 frozenset はビルトインクラスです。このクラスに関するドキュメントは frozenset と set（集合）型 --- set, frozenset を参照してください。
他のコンテナについては、ビルトインクラス set, list, tuple, dict や collections モジュールを見てください。
getattr(object, name[, default])
object の指名された属性の値を返します。 name は文字列でなくてはなりません。文字列がオブジェクトの属性の一つの名前であった場合、戻り値はその属性の値になります。例えば、 getattr(x, 'foobar') は x.foobar と等価です。指名された属性が存在しない場合、 default が与えられていればそれが返され、そうでない場合には AttributeError が送出されます。
globals()
現在のグローバルシンボルテーブルを表す辞書を返します。これは常に現在のモジュール (関数やメソッドの中では、それを呼び出したモジュールではなく、それを定義しているモジュール) の辞書です。
hasattr(object, name)
引数はオブジェクトと文字列です。文字列がオブジェクトの属性名の一つであった場合 True を、そうでない場合 False を返します。 (この関数は、 getattr(object, name) を呼び出して AttributeError を送出するかどうかを見ることで実装されています。)
hash(object)
オブジェクトのハッシュ値を (存在すれば) 返します。ハッシュ値は整数です。これらは辞書を検索する際に辞書のキーを高速に比較するために使われます。等しい値となる数値は等しいハッシュ値を持ちます (1 と 1.0 のように型が異なっていてもです)。
注釈 独自の __hash__() メソッドを実装したオブジェクトを使う場合、hash() が実行するマシンのビット幅に合わせて戻り値を切り捨てることに注意してください。詳しくは __hash__() を参照してください。
help([object])
組み込みヘルプシステムを起動します。(この関数は対話的な使用のためのものです。) 引数が与えられていない場合、対話的ヘルプシステムはインタプリタコンソール上で起動します。引数が文字列の場合、文字列はモジュール、関数、クラス、メソッド、キーワード、またはドキュメントの項目名として検索され、ヘルプページがコンソール上に印字されます。引数がその他のオブジェクトの場合、そのオブジェクトに関するヘルプページが生成されます。
help() を呼び出したときに関数の引数リストにスラッシュ (/) が現れた場合は、スラッシュより前の引数が位置専用引数だという意味であることに注意してください。 より詳しいことは、 位置専用引数についての FAQ の記事 を参照してください。
この関数は、 site モジュールから、組み込みの名前空間に移されました。
バージョン 3.4 で変更: pydoc と inspect への変更により、呼び出し可能オブジェクトの報告されたシグニチャがより包括的で一貫性のあるものになりました。
hex(x)
>>>
>>> hex(255)
'0xff'
>>> hex(-42)
'-0x2a'
整数を大文字の 16 進文字列や小文字の 16 進文字列、先頭の "0x" 付きや "0x" 無しに変換したい場合は、次に挙げる方法が使えます:
>>>
>>> '%#x' % 255, '%x' % 255, '%X' % 255
('0xff', 'ff', 'FF')
>>> format(255, '#x'), format(255, 'x'), format(255, 'X')
('0xff', 'ff', 'FF')
>>> f'{255:#x}', f'{255:x}', f'{255:X}'
('0xff', 'ff', 'FF')
より詳しいことは format() も参照してください。
16を底として16進数文字列を整数に変換するには int() も参照してください。
注釈 浮動小数点数の16進文字列表記を得たい場合には、 float.hex() メソッドを使って下さい。
id(object)
オブジェクトの "識別値" を返します。この値は整数で、このオブジェクトの有効期間中は一意かつ定数であることが保証されています。有効期間が重ならない 2 つのオブジェクトは同じ id() 値を持つかもしれません。
input([prompt])
引数 prompt が存在すれば、それが末尾の改行を除いて標準出力に書き出されます。次に、この関数は入力から 1 行を読み込み、文字列に変換して (末尾の改行を除いて) 返します。 EOF が読み込まれたとき、 EOFError が送出されます。例:
>>>
>>> s = input('--> ')  
--> Monty Python's Flying Circus
>>> s  
"Monty Python's Flying Circus"
readline モジュールが読み込まれていれば、 input() はそれを使って精緻な行編集やヒストリ機能を提供します。
x が数値でない、あるいは base が与えられた場合、 x は文字列、 bytes インスタンス、 bytearray インスタンスのいずれかで、基数 base の 整数リテラル で表されたものでなければなりません。 オプションで、リテラルの前に + あるいは - を (中間のスペースなしで) 付けることができます。 また、リテラルは余白で囲むことができます。 基数 n のリテラルは、 0 から n-1 の数字に値 10-35 を持つ a から z (または A から Z) を加えたもので構成されます。 デフォルトの base は 10 です。 許される値は 0 と 2--36 です。 基数 2, 8, 16 のリテラルは、別の記法としてコード中の整数リテラルのように 0b/0B, 0o/0O, 0x/0X を前に付けることができます。 基数 0 はコードリテラルとして厳密に解釈することを意味します。 その結果、実際の基数は 2, 8, 10, 16 のどれかになります。 したがって int('010', 0) は有効ではありませんが、 int('010') や int('010', 8) は有効です。
整数型については、 数値型 int, float, complex も参照してください。
バージョン 3.4 で変更: base が int のインスタンスでなく、base オブジェクトが base.__index__ メソッドを持っている場合、そのメソッドを呼んで底に対する整数を得ることができます。以前のバージョンでは base.__index__ ではなく base.__int__ を使用していました。
バージョン 3.6 で変更: コードリテラル中で桁をグループ化するのにアンダースコアを利用できます。
バージョン 3.7 で変更: x は位置専用引数になりました。
isinstance(object, classinfo)
object 引数が classinfo 引数のインスタンスであるか、 (直接、間接、または 仮想) サブクラスのインスタンスの場合に True を返します。 object が与えられた型のオブジェクトでない場合、この関数は常に False を返します。 classinfo が型オブジェクトのタプル (あるいは再帰的に複数のタプル) の場合、 object がそれらのいずれかのインスタンスであれば True を返します。 classinfo が型や型からなるタプル、あるいは複数のタプルのいずれでもない場合、 TypeError 例外が送出されます。
issubclass(class, classinfo)
class が classinfo の (直接または間接的な、あるいは virtual) サブクラスである場合に True を返します。クラスはそれ自身のサブクラスとみなされます。 classinfo はクラスオブジェクトからなるタプルでもよく、この場合には classinfo のすべてのエントリが調べられます。その他の場合では、例外 TypeError が送出されます。
iter(object[, sentinel])
イテレータ オブジェクトを返します。 第二引数があるかどうかで、第一引数の解釈は大きく異なります。 第二引数がない場合、 object は反復プロトコル (__iter__() メソッド) か、シーケンスプロトコル (引数が 0 から開始する __getitem__() メソッド) をサポートする集合オブジェクトでなければなりません。これらのプロトコルが両方ともサポートされていない場合、 TypeError が送出されます。 第二引数 sentinel が与えられているなら、 object は呼び出し可能オブジェクトでなければなりません。この場合に生成されるイテレータは、 __next__() を呼ぶ毎に object を引数無しで呼び出します。返された値が sentinel と等しければ、 StopIteration が送出され、そうでなければ、戻り値がそのまま返されます。
イテレータ型 も見てください。
2引数形式の iter() の便利な利用方法の1つは、ブロックリーダーの構築です。 例えば、バイナリのデータベースファイルから固定幅のブロックをファイルの終端に到達するまで読み出すには次のようにします:
from functools import partial
with open('mydata.db', 'rb') as f:
    for block in iter(partial(f.read, 64), b''):
        process_block(block)
len(s)
オブジェクトの長さ (要素の数) を返します。引数はシーケンス (文字列、バイト列、タプル、リスト、range 等) かコレクション (辞書、集合、凍結集合等) です。
class list([iterable])
list は、実際には関数ではなくミュータブルなシーケンス型で、 リスト型 (list) と シーケンス型 --- list, tuple, range にドキュメント化されています。
locals()
現在のローカルシンボルテーブルを表す辞書を更新して返します。 関数ブロックで locals() を呼び出したときは自由変数が返されますが、クラスブロックでは返されません。 モジュールレベルでは、 locals() と globals() は同じ辞書であることに注意してください。
注釈 この辞書の内容は変更してはいけません; 変更しても、インタプリタが使うローカル変数や自由変数の値には影響しません。
map(function, iterable, ...)
function を、結果を返しながら iterable の全ての要素に適用するイテレータを返します。追加の iterable 引数が渡されたなら、 function はその数だけの引数を取らなければならず、全てのイテラブルから並行して取られた要素に適用されます。複数のイテラブルが与えられたら、このイテレータはその中の最短のイテラブルが尽きた時点で止まります。関数の入力がすでに引数タプルに配置されている場合は、 itertools.starmap() を参照してください。
max(iterable, *[, key, default])
max(arg1, arg2, *args[, key])
iterable の中で最大の要素、または2つ以上の引数の中で最大のものを返します。
位置引数が1つだけ与えられた場合、それはは空でない iterable でなくてはいけません。その iterable の最大の要素が返されます。2 つ以上のキーワード無しの位置引数が与えられた場合、その位置引数の中で最大のものが返されます。
任意のキーワード専用引数が 2 つあります。 key 引数は引数を 1 つ取る順序関数 (list.sort() のもののように) を指定します。 default 引数は与えられたイテラブルが空の場合に返すオブジェクトを指定します。 イテラブルが空で default が与えられていない場合 ValueError が送出されます。
最大の要素が複数あるとき、この関数はそのうち最初に現れたものを返します。これは、sorted(iterable, key=keyfunc, reverse=True)[0] や heapq.nlargest(1, iterable, key=keyfunc) のような、他のソート安定性を維持するツールと両立します。
バージョン 3.4 で追加: default キーワード専用引数。
バージョン 3.8 で変更: key 引数が None であることを許容します。
class memoryview(obj)
与えられたオブジェクトから作られた "メモリビュー" オブジェクトを返します。詳しくは メモリビュー を参照してください。
min(iterable, *[, key, default])
min(arg1, arg2, *args[, key])
iterable の中で最小の要素、または2つ以上の引数の中で最小のものを返します。
位置引数が1つだけ与えられた場合、それはは空でない iterable でなくてはいけません。その iterable の最小の要素が返されます。2 つ以上のキーワード無しの位置引数が与えられた場合、その位置引数の中で最小のものが返されます。
任意のキーワード専用引数が 2 つあります。 key 引数は引数を 1 つ取る順序関数 (list.sort() のもののように) を指定します。 default 引数は与えられたイテラブルが空の場合に返すオブジェクトを指定します。 イテラブルが空で default が与えられていない場合 ValueError が送出されます。
最小の要素が複数あるとき、この関数はそのうち最初に現れたものを返します。これは、sorted(iterable, key=keyfunc)[0] や heapq.nsmallest(1, iterable, key=keyfunc) のような、他のソート安定性を維持するツールと両立します。
バージョン 3.4 で追加: default キーワード専用引数。
バージョン 3.8 で変更: key 引数が None であることを許容します。
next(iterator[, default])
iterator の __next__() メソッドを呼び出すことにより、次の要素を取得します。イテレータが尽きている場合、 default が与えられていればそれが返され、そうでなければ StopIteration が送出されます。
class object
特徴を持たない新しいオブジェクトを返します。 object は全てのクラスの基底クラスです。これは、 Python のクラスの全てのインスタンスに共通のメソッド群を持ちます。この関数はいかなる引数も受け付けません。
注釈 object は __dict__ を 持たない ので、 object クラスのインスタンスに任意の属性を代入することはできません。
oct(x)
整数を先頭に "0o" が付いた 8 進文字列に変換します。 結果は Python の式としても使える形式になります。
>>>
>>> oct(8)
'0o10'
>>> oct(-56)
'-0o70'
整数を接頭辞の "0o" 付きや "0o" 無しの 8 進文字列に変換したい場合は、次に挙げる方法が使えます。
>>>
>>> '%#o' % 10, '%o' % 10
('0o12', '12')
>>> format(10, '#o'), format(10, 'o')
('0o12', '12')
>>> f'{10:#o}', f'{10:o}'
('0o12', '12')
より詳しいことは format() も参照してください。
open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)
file を開き、対応する ファイルオブジェクト を返します。ファイルを開くことができなければ、OSError が送出されます。 この関数の利用例について、 ファイルを読み書きする を参照してください。
file は path-like object で、開くファイルの (絶対または現在のワーキングディレクトリに対する相対) パス名を与えるものか、または、ラップするファイルの整数のファイルディスクリプタです。(ファイルディスクリプタが与えられた場合は、それは closefd が False に設定されていない限り、返された I/O オブジェクトが閉じられるときに閉じられます。)
mode はオプションの文字列で、ファイルが開かれるモードを指定します。デフォルトは 'r' で、読み込み用にテキストモードで開くという意味です。その他のよく使われる値は、書き込み (ファイルがすでに存在する場合はそのファイルを切り詰めます) 用の 'w'、排他的な生成用の 'x'、追記用の 'a' です (いくつかの Unix システムでは、全て の書き込みが現在のファイルシーク位置に関係なくファイルの末尾に追加されます)。テキストモードでは、encoding が指定されていない場合に使われるエンコーディングはプラットフォームに依存します:locale.getpreferredencoding(False) を使って現在のロケールエンコーディングを取得します。(rawバイト列の読み書きには、バイナリモードを使い、encoding は未指定のままとします) 指定可能なモードは次の表の通りです。
文字
意味
'r'
読み込み用に開く (デフォルト)
'w'
書き込み用に開き、まずファイルを切り詰める
'x'
排他的な生成に開き、ファイルが存在する場合は失敗する
'a'
書き込み用に開き、ファイルが存在する場合は末尾に追記する
'b'
バイナリモード
't'
テキストモード (デフォルト)
'+'
open for updating (reading and writing)
デフォルトのモードは 'r' (開いてテキストの読み込み、'rt' と同義) です。モード 'w+' と 'w+b' はファイルを開いて切り詰めます。モード 'r+' と 'r+b' はファイルを切り詰めずに開きます。
概要 で触れられているように、Python はバイナリとテキストの I/O を区別します。(mode 引数に 'b' を含めて) バイナリモードで開かれたファイルは、内容をいかなるデコーディングもせずに bytes オブジェクトとして返します。(デフォルトや、 mode 引数に 't' が含まれたときの) テキストモードでは、ファイルの内容は str として返され、バイト列はまず、プラットフォーム依存のエンコーディングか、encoding が指定された場合は指定されたエンコーディングを使ってデコードされます。
さらに 'U' という許可されているモード文字がありますが、これの効果は無くなっていて非推奨とされています。 以前はこのモード文字は、テキストモードでの universal newlines を有効にしていましたが、 Python 3.0 ではそれがデフォルトの挙動となりました。 より詳細なことは newline 引数のドキュメントを参照してください。
注釈 Python は、下層のオペレーティングシステムがテキストファイルをどう認識するかには依存しません; すべての処理は Python 自身で行われ、よってプラットフォーム非依存です。
buffering はオプションの整数で、バッファリングの方針を設定するのに使われます。バッファリングを無効にする (バイナリモードでのみ有効) には 0、行単位バッファリング (テキストモードでのみ有効) には 1、固定値のチャンクバッファの大きさをバイト単位で指定するには 1 以上の整数を渡してください。buffering 引数が与えられていないとき、デフォルトのバッファリング方針は以下のように動作します:
バイナリファイルは固定サイズのチャンクでバッファリングされます。バッファサイズは、下層のデバイスの「ブロックサイズ」を決定するヒューリスティックを用いて選択され、それが不可能な場合は代わりに io.DEFAULT_BUFFER_SIZE が使われます。多くのシステムでは、典型的なバッファサイズは 4096 か 8192 バイト長になるでしょう。
「対話的な」テキストファイル (isatty() が True を返すファイル) は行バッファリングを使用します。 その他のテキストファイルは、上で説明したバイナリファイル用の方針を使用します。
encoding はファイルのエンコードやデコードに使われる text encoding の名前です。このオプションはテキストモードでのみ使用してください。デフォルトエンコーディングはプラットフォーム依存 (locale.getpreferredencoding() が返すもの) ですが、Pythonでサポートされているエンコーディングはどれでも使えます。詳しくは codecs モジュール内のサポートしているエンコーディングのリストを参照してください。
errors はオプションの文字列で、エンコードやデコードでのエラーをどのように扱うかを指定するものです。バイナリモードでは使用できません。様々な標準のエラーハンドラが使用可能です (エラーハンドラ に列記されています) が、 codecs.register_error() に登録されているエラー処理の名前も使用可能です。標準のエラーハンドラの名前には、以下のようなものがあります:
'strict' はエンコーディングエラーがあると例外 ValueError を発生させます。デフォルト値である None も同じ効果です。
'ignore' はエラーを無視します。エンコーディングエラーを無視することで、データが失われる可能性があることに注意してください。
'replace' は、不正な形式のデータが存在した場所に('?' のような) 置換マーカーを挿入します。
'surrogateescape' は正しくないバイト列を、Unicode の Private Use Area (私用領域) にある U+DC80 から U+DCFF のコードポイントで示します。データを書き込む際に surrogateescape エラーハンドラが使われると、これらの私用コードポイントは元と同じバイト列に変換されます。これはエンコーディングが不明なファイルを処理するのに便利です。
'xmlcharrefreplace' はファイルへの書き込み時のみサポートされます。そのエンコーディングでサポートされない文字は、&#nnn; 形式の適切な XML 文字参照で置換されます。
'backslashreplace' は不正なデータを Python のバックスラッシュ付きのエスケープシーケンスで置換します。
'namereplace' (書き込み時のみサポートされています) はサポートされていない文字を \N{...} エスケープシーケンスで置換します。
newline は universal newlines モードの動作を制御します (テキストモードでのみ動作します)。None, '', '\n', '\r', '\r\n' のいずれかです。これは以下のように動作します:
ストリームからの入力の読み込み時、newline が None の場合、ユニバーサル改行モードが有効になります。入力中の行は '\n', '\r', または '\r\n' で終わり、呼び出し元に返される前に '\n' に変換されます。 '' の場合、ユニバーサル改行モードは有効になりますが、行末は変換されずに呼び出し元に返されます。その他の正当な値の場合、入力行は与えられた文字列でのみ終わり、行末は変換されずに呼び出し元に返されます。
ストリームへの出力の書き込み時、newline が None の場合、全ての '\n' 文字はシステムのデフォルトの行セパレータ os.linesep に変換されます。 newline が '' または '\n' の場合は変換されません。newline がその他の正当な値の場合、全ての '\n' 文字は与えられた文字列に変換されます。
closefd が False で、ファイル名ではなくてファイル記述子が与えられた場合、下層のファイル記述子はファイルが閉じられた後も開いたままとなります。 ファイル名が与えられた場合、closefd は True (デフォルト値) でなければなりません。 そうでない場合エラーが送出されます。
呼び出し可能オブジェクトを opener として与えることで、カスタムのオープナーが使えます。そしてファイルオブジェクトの下層のファイル記述子は、opener を (file, flags) で呼び出して得られます。opener は開いたファイル記述子を返さなければなりません。 (os.open を opener として渡すと、None を渡したのと同様の機能になります)。
新たに作成されたファイルは 継承不可 です。
次の例は os.open() 関数の dir_fd 引数を使い、与えられたディレクトリからの相対パスで指定されたファイルを開きます:
>>>
>>> import os
>>> dir_fd = os.open('somedir', os.O_RDONLY)
>>> def opener(path, flags):
...     return os.open(path, flags, dir_fd=dir_fd)
...
>>> with open('spamspam.txt', 'w', opener=opener) as f:
...     print('This will be written to somedir/spamspam.txt', file=f)
...
>>> os.close(dir_fd)  # don't leak a file descriptor
open() 関数が返す file object の型はモードに依存します。 open() をファイルをテキストモード ('w', 'r', 'wt', 'rt', など) で開くのに使ったときは io.TextIOBase (特に io.TextIOWrapper) のサブクラスを返します。 ファイルをバッファリング付きのバイナリモードで開くのに使ったときは io.BufferedIOBase のサブクラスを返します。 実際のクラスは様々です。 読み込みバイナリモードでは io.BufferedReader を返します。 書き込みバイナリモードや追記バイナリモードでは io.BufferedWriter を返します。 読み書きモードでは io.BufferedRandom を返します。 バッファリングが無効なときはrawストリーム、すなわち io.RawIOBase のサブクラスである io.FileIO を返します。
fileinput 、(open() が宣言された場所である) io 、 os 、 os.path 、 tempfile 、 shutil などの、ファイル操作モジュールも参照してください。
バージョン 3.3 で変更:
opener 引数を追加しました。
'x' モードを追加しました。
以前は IOError が送出されていました、それは現在 OSError のエイリアスになりました。
既存のファイルを 排他的生成モード('x')で開いた場合、 FileExistsError を送出するようになりました。
バージョン 3.4 で変更:
ファイルが継承不可になりました。
Deprecated since version 3.4, will be removed in version 3.10: 'U' モード。
バージョン 3.5 で変更:
システムコールが中断されシグナルハンドラが例外を送出しなかった場合、この関数は InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
'namereplace' エラーハンドラが追加されました。
バージョン 3.6 で変更:
os.PathLike を実装したオブジェクトを受け入れるようになりました。
Windowsでは、コンソールバッファのオープンは、io.FileIO ではなく、io.RawIOBase のサブクラスを返すでしょう。
ord(c)
1 文字の Unicode 文字を表す文字列に対し、その文字の Unicode コードポイントを表す整数を返します。例えば、 ord('a') は整数 97 を返し、 ord('€') (ユーロ記号) は 8364 を返します。これは chr() の逆です。
pow(base, exp[, mod])
base の exp 乗を返します; mod があれば、base の exp 乗に対する mod の剰余を返します (pow(base, exp) % mod より効率よく計算されます)。二引数の形式 pow(base, exp) は、冪乗演算子を使った base**exp と等価です。
引数は数値型でなくてはなりません。型混合の場合、二項算術演算における型強制規則が適用されます。 int 被演算子に対しては、第二引数が負でない限り、結果は (型強制後の) 被演算子と同じ型になります; 負の場合、全ての引数は浮動小数点に変換され、浮動小数点の結果が返されます。例えば、 10**2 は 100 を返しますが、 10**-2 は 0.01 を返します。
Here's an example of computing an inverse for 38 modulo 97:
>>>
>>> pow(38, -1, mod=97)
23
>>> 23 * 38 % 97 == 1
True
print(*objects, sep=' ', end='\n', file=sys.stdout, flush=False)
objects を sep で区切りながらテキストストリーム file に表示し、最後に end を表示します。sep 、 end 、 file 、 flush を与える場合、キーワード引数として与える必要があります。
キーワードなしの引数はすべて、 str() がするように文字列に変換され、 sep で区切られながらストリームに書き出され、最後に end が続きます。 sep と end の両方とも、文字列でなければなりません。これらを None にすると、デフォルトの値が使われます。 objects が与えられなければ、 print() は end だけを書き出します。
file 引数は、 write(string) メソッドを持つオブジェクトでなければなりません。指定されないか、 None である場合、 sys.stdout が使われます。表示される引数は全てテキスト文字列に変換されますから、 print() はバイナリモードファイルオブジェクトには使用できません。代わりに file.write(...) を使ってください。
出力がバッファ化されるかどうかは通常 file で決まりますが、flush キーワード引数が真ならストリームは強制的にフラッシュされます。
バージョン 3.3 で変更: キーワード引数 flush が追加されました。
class property(fget=None, fset=None, fdel=None, doc=None)
property 属性を返します。
fget は属性値を取得するための関数です。fset は属性値を設定するための関数です。fdel は属性値を削除するための関数です。doc は属性の docstring を作成します。
典型的な使用法は、属性 x の処理の定義です:
class C:
    def __init__(self):
        self._x = None
    def getx(self):
        return self._x
    def setx(self, value):
        self._x = value
    def delx(self):
        del self._x
    x = property(getx, setx, delx, "I'm the 'x' property.")
c が C のインスタンスならば、c.x は getter を呼び出し、c.x = value は setter を、del c.x は deleter を呼び出します。
doc は、与えられれば property 属性のドキュメント文字列になります。 与えられなければ、 property は fget のドキュメント文字列 (もしあれば) をコピーします。 そのため property() を デコレータ として使えば、読み出し専用 property を作るのは容易です:
class Parrot:
    def __init__(self):
        self._voltage = 100000
    @property
    def voltage(self):
        """Get the current voltage."""
        return self._voltage
@property デコレータは voltage() を同じ名前のまま 読み出し専用属性の "getter" にし、voltage のドキュメント文字列を "Get the current voltage." に設定します。
property オブジェクトは getter, setter, deleter メソッドを持っています。これらのメソッドをデコレータとして使うと、対応するアクセサ関数がデコレートされた関数に設定された、 property のコピーを作成できます。これを一番分かりやすく説明する例があります:
class C:
    def __init__(self):
        self._x = None
    @property
    def x(self):
        """I'm the 'x' property."""
        return self._x
    @x.setter
    def x(self, value):
        self._x = value
    @x.deleter
    def x(self):
        del self._x
このコードは最初の例と等価です。追加の関数には、必ず元の property と同じ名前 (この例では x) を与えて下さい。
返される property オブジェクトも、コンストラクタの引数に対応した fget, fset, および fdel 属性を持ちます。
バージョン 3.5 で変更: 属性オブジェクトのドックストリングが書き込み可能になりました。
class range(stop)
class range(start, stop[, step])
range は、実際には関数ではなくイミュータブルなシーケンス型で、 range と シーケンス型 --- list, tuple, range にドキュメント化されています。
repr(object)
オブジェクトの印字可能な表現を含む文字列を返します。この関数は多くの型について、 eval() に渡されたときと同じ値を持つようなオブジェクトを表す文字列を生成しようとします。そうでない場合は、山括弧に囲まれたオブジェクトの型の名前と追加の情報 (大抵の場合はオブジェクトの名前とアドレスを含みます) を返します。クラスは、 __repr__() メソッドを定義することで、この関数によりそのクラスのインスタンスが返すものを制御することができます。
reversed(seq)
要素を逆順に取り出すイテレータ (reverse iterator) を返します。 seq は __reversed__() メソッドを持つか、シーケンス型プロトコル (__len__() メソッド、および、 0 以上の整数を引数とする __getitem__() メソッド) をサポートするオブジェクトでなければなりません。
round(number[, ndigits])
number の小数部を ndigists 桁に丸めた値を返します。ndigits が省略されたり、None だった場合、入力値に最も近い整数を返します。
round() をサポートする組み込み型では、値は 10 のマイナス ndigits 乗の倍数の中で最も近いものに丸められます; 二つの倍数が同じだけ近いなら、偶数を選ぶ方に (そのため、例えば round(0.5) と round(-0.5) は両方とも 0 に、 round(1.5) は 2 に) 丸められます。 ndigits には任意の整数値が有効となります (正の整数、ゼロ、負の整数)。 返り値は ndigits が指定されていないか None の場合は整数、そうでなければ返り値は number と同じ型です。
一般的な Python オブジェクト number に対して、round は処理を number.__round__ に移譲します。
注釈 浮動小数点数に対する round() の振る舞いは意外なものかもしれません: 例えば、 round(2.675, 2) は予想通りの 2.68 ではなく 2.67 を与えます。これはバグではありません: これはほとんどの小数が浮動小数点数で正確に表せないことの結果です。詳しくは 浮動小数点演算、その問題と制限 を参照してください。
class set([iterable])
オプションで iterable の要素を持つ、新しい set オブジェクトを返します。 set は組み込みクラスです。このクラスについて詳しい情報は set や set（集合）型 --- set, frozenset を参照してください。
他のコンテナについては collections モジュールや組み込みの frozenset 、 list 、 tuple 、 dict クラスを参照してください。
setattr(object, name, value)
getattr() の相方です。引数はオブジェクト、文字列、それから任意の値です。文字列は既存の属性または新たな属性の名前にできます。この関数は指定したオブジェクトが許せば、値を属性に関連付けます。例えば、 setattr(x, 'foobar', 123) は x.foobar = 123 と等価です。
class slice(stop)
class slice(start, stop[, step])
range(start, stop, step) で指定されるインデクスの集合を表す、 スライス オブジェクトを返します。引数 start および step はデフォルトでは None です。スライスオブジェクトは読み出し専用の属性 start、stop および step を持ち、これらは単に引数で使われた 値 (またはデフォルト値) を返します。これらの値には、その他のはっきりと した機能はありません。しかしながら、これらの値は Numerical Python および、その他のサードパーティによる拡張で利用されています。スライスオブジェクトは拡張されたインデクス指定構文が使われる際にも生成されます。例えば a[start:stop:step] や a[start:stop, i] です。この関数の代替となるイテレータを返す関数、itertools.islice() も参照してください。
sorted(iterable, *, key=None, reverse=False)
iterable の要素を並べ替えた新たなリストを返します。
2 つのオプション引数があり、これらはキーワード引数として指定されなければなりません。
key には 1 引数関数を指定します。これは iterable の各要素から比較キーを展開するのに使われます (例えば、 key=str.lower のように指定します)。 デフォルト値は None です (要素を直接比較します)。
reverse は真偽値です。 True がセットされた場合、リストの要素は個々の比較が反転したものとして並び替えられます。
旧式の cmp 関数を key 関数に変換するには functools.cmp_to_key() を使用してください。
組み込みの sort() 関数は安定なことが保証されています。同等な要素の相対順序を変更しないことが保証されていれば、ソートは安定です。これは複数のパスでソートを行なうのに役立ちます（例えば部署でソートしてから給与の等級でソートする場合）。
ソートの例と簡単なチュートリアルは ソート HOW TO を参照して下さい。
@staticmethod
メソッドを静的メソッドへ変換します。
静的メソッドは暗黙の第一引数を受け取りません。静的メソッドを宣言するには、このイディオムを使ってください:
class C:
    @staticmethod
    def f(arg1, arg2, ...): ...
@staticmethod 形式は関数 デコレータ です。詳しくは 関数定義 を参照してください。
静的メソッドは (C.f() のよう) クラスから呼び出したり、 (C().f() のように) インスタンスから呼び出したりできます。
Python における静的メソッドは Java や C++ における静的メソッドと類似しています。クラスコンストラクタの代替を生成するのに役立つ変種、 classmethod() も参照してください。
あらゆるデコレータと同じく、 staticmethod は普通の関数のように呼べ、その返り値で処理が行えます。 この機能は、クラス本体から関数を参照する必要があり、かつ、インスタンスメソッドに自動変換されるのを避けたいケースで必要になります。 そのようなケースでは、このイディオムが使えます:
class C:
    builtin_open = staticmethod(open)
静的メソッドについて詳しい情報は 標準型の階層 を参照してください。
class str(object='')
class str(object=b'', encoding='utf-8', errors='strict')
object の str 版を返します。詳細は str() を参照してください。
str は組み込みの文字列 クラス です。文字列に関する一般的な情報は、テキストシーケンス型 --- str を参照してください。
sum(iterable, /, start=0)
start と iterable の要素を左から右へ合計し、総和を返します。 iterable の要素は通常は数値で、start の値は文字列であってはなりません。
使う場面によっては、 sum() よりもいい選択肢があります。文字列からなるシーケンスを結合する高速かつ望ましい方法は ''.join(sequence) を呼ぶことです。浮動小数点数値を拡張された精度で加算するには、 math.fsum() を参照してください。一連のイテラブルを連結するには、 itertools.chain() の使用を考えてください。
バージョン 3.8 で変更: start パラメータをキーワード引数として指定することができるようになりました。
第 2 引数が省かれたなら、返されるスーパーオブジェクトは束縛されません。第 2 引数がオブジェクトであれば、 isinstance(obj, type) は真でなければなりません。第 2 引数が型であれば、 issubclass(type2, type) は真でなければなりません (これはクラスメソッドに役に立つでしょう)。
super の典型的な用途は 2 つあります。第一に、単継承のクラス階層構造で super は名前を明示することなく親クラスを参照するのに使え、それゆえコードをメンテナンスしやすくなります。この用途は他のプログラミング言語で見られる super の用途によく似ています。
2 つ目の用途は、動的な実行環境下で協調的な多重継承をサポートすることです。この用途は Python に特有で、静的にコンパイルされる言語や、単継承のみをサポートする言語では見られないものです。この機能により、複数の基底クラスが同じメソッドを実装する "diamond diagram" を実装できます。このメソッドをあらゆる場合に同じ形式で呼び出せるようにするのが、良い設計です (理由は、呼び出しの順序が実行時に決定されること、呼び出しの順序がクラス階層の変更に対応すること、呼び出しの順序に実行時まで未知の兄弟クラスが含まれる場合があることです)。
両方の用途において、典型的なスーパークラスの呼び出しは次のようになります:
class C(B):
    def method(self, arg):
        super().method(arg)    # This does the same thing as:
                               # super(C, self).method(arg)
なお、super() は super().__getitem__(name) のような明示的なドット表記属性探索の束縛処理の一部として実装されています。これは、 __getattribute__() メソッドを予測可能な順序でクラスを検索するように実装し、協調的な多重継承をサポートすることで実現されています。従って、 super() は文や super()[name] のような演算子を使った暗黙の探索向けには定義されていません。
また、 super() の使用は引数無しの形式を除きメソッド内部に限定されないことにも注目して下さい。2引数の形式は、必要な要素を正確に指定するので、適当な参照を作ることができます。クラス定義中における引数無しの形式は、定義されているクラスを取り出すのに必要な詳細を、通常の方法で現在のインスタンスにアクセスするようにコンパイラが埋めるのではたらきます。
super() を用いて協調的なクラスを設計する方法の実践的な提案は、 guide to using super() を参照してください。
class tuple([iterable])
tuple は、実際は関数ではなくイミュータブルなシーケンス型で、タプル型 (tuple) と シーケンス型 --- list, tuple, range にドキュメント化されています。
class type(object)
class type(name, bases, dict)
引数が1つだけの場合、object の型を返します。返り値は型オブジェクトで、一般に object.__class__ によって返されるのと同じオブジェクトです。
オブジェクトの型の判定には、 isinstance() 組み込み関数を使うことが推奨されます。これはサブクラスを考慮するからです。
>>>
>>> class X:
...     a = 1
...
>>> X = type('X', (), dict(a=1))
型オブジェクト も参照してください。
バージョン 3.6 で変更: type.__new__ をオーバーライドしていない type のサブクラスは、オブジェクトの型を得るのに１引数形式を利用することができません。
vars([object])
モジュール、クラス、インスタンス、あるいはそれ以外の __dict__ 属性を持つオブジェクトの、 __dict__ 属性を返します。
モジュールやインスタンスのようなオブジェクトは、更新可能な __dict__ 属性を持っています。ただし、それ以外のオブジェクトでは __dict__ 属性への書き込みが制限されている場合があります。書き込みに制限がある例としては、辞書を直接更新されることを防ぐために types.MappingProxyType を使っているクラスがあります。
引数がなければ、vars() は locals() のように振る舞います。ただし、辞書 locals への更新は無視されるため、辞書 locals は読み出し時のみ有用であることに注意してください。
zip(*iterables)
それぞれのイテラブルから要素を集めたイテレータを作ります。
この関数はタプルのイテレータを返し、その i 番目のタプルは引数シーケンスまたはイテラブルそれぞれの i 番目の要素を含みます。このイテレータは、入力イテラブルの中で最短のものが尽きたときに止まります。単一のイテラブル引数が与えられたときは、1 要素のタプルからなるイテレータを返します。引数がなければ、空のイテレータを返します。次と等価です:
def zip(*iterables):
    # zip('ABCD', 'xy') --> Ax By
    sentinel = object()
    iterators = [iter(it) for it in iterables]
    while iterators:
        result = []
        for it in iterators:
            elem = next(it, sentinel)
            if elem is sentinel:
                return
            result.append(elem)
        yield tuple(result)
イテラブルの左から右への評価順序は保証されています。そのため zip(*[iter(s)]*n) を使ってデータ系列を長さ n のグループにクラスタリングするイディオムが使えます。これは、各出力タプルがイテレータを n 回呼び出した結果となるよう、 同じ イテレータを n 回繰り返します。これは入力を長さ n のチャンクに分割する効果があります。
zip() は、長い方のイテラブルの終端にある対にならない値を考慮したい場合は、等しくない長さの入力に対して使うべきではありません。そのような値が重要な場合、代わりに itertools.zip_longest() を使ってください。
zip() に続けて * 演算子を使うと、zip したリストを元に戻せます:
>>>
>>> x = [1, 2, 3]
>>> y = [4, 5, 6]
>>> zipped = zip(x, y)
>>> list(zipped)
[(1, 4), (2, 5), (3, 6)]
>>> x2, y2 = zip(*zip(x, y))
>>> x == list(x2) and y == list(y2)
True
__import__(name, globals=None, locals=None, fromlist=(), level=0)
注釈 これは importlib.import_module() とは違い、日常の Python プログラミングでは必要ない高等な関数です。
この関数は import 文により呼び出されます。 (builtins モジュールをインポートして builtins.__import__ に代入することで) この関数を置き換えて import 文のセマンティクスを変更することができますが、同様のことをするのに通常はインポートフック (PEP 302 参照) を利用する方が簡単で、かつデフォルトのインポート実装が使用されていることを仮定するコードとの間で問題が起きないので、このやり方は 強く 推奨されません。 __import__() を直接使用することも推奨されず、 importlib.import_module() の方が好まれます。
この関数は、モジュール name をインポートし、 globals と locals が与えられれば、パッケージのコンテキストで名前をどう解釈するか決定するのに使います。 fromlist は name で与えられるモジュールからインポートされるべきオブジェクトまたはサブモジュールの名前を与ます。標準の実装では locals 引数はまったく使われず、 globals は import 文のパッケージコンテキストを決定するためにのみ使われます。
level は絶対と相対どちらのインポートを使うかを指定します。 0 (デフォルト) は絶対インポートのみ実行します。正の level の値は、 __import__() を呼び出したディレクトリから検索対象となる親ディレクトリの数を示します (詳細は PEP 328 を参照してください)。
name 変数が package.module 形式であるとき、通常は、name で指名されたモジュール ではなく、最上位のパッケージ (最初のドットまでの名前) が返されます。しかしながら、空でない fromlist 引数が与えられると、 name で指名されたモジュールが返されます。
例えば、文 import spam は、以下のコードのようなバイトコードに帰結します:
spam = __import__('spam', globals(), locals(), [], 0)
文 import spam.ham は、この呼び出しになります:
spam = __import__('spam.ham', globals(), locals(), [], 0)
ここで __import__() がどのように最上位モジュールを返しているかに注意して下さい。 import 文により名前が束縛されたオブジェクトになっています。
一方で、文 from spam.ham import eggs, sausage as saus は、以下となります
_temp = __import__('spam.ham', globals(), locals(), ['eggs', 'sausage'], 0)
eggs = _temp.eggs
saus = _temp.sausage
ここで、__import__() から spam.ham モジュールが返されます。このオブジェクトから、インポートされる名前が取り出され、それぞれの名前として代入されます。
単純に名前からモジュール (パッケージの範囲内であるかも知れません) をインポートしたいなら、 importlib.import_module() を使ってください。
バージョン 3.3 で変更: 負の level の値はサポートされなくなりました (デフォルト値の 0 に変更されます)。
バージョン 3.9 で変更: コマンドラインオプション -E or -I が指定された場合、環境変数 PYTHONCASEOK は無視されるようになりました。
組み込み定数
組み込み名前空間にはいくつかの定数があります。定数の一覧:
False
bool 型の偽値です。False への代入は不正で、SyntaxError を送出します。
True
bool 型の真値です。True への代入は不正で、SyntaxError を送出します。
None
型 NoneType の唯一の値です。 None は、関数にデフォルト引数が渡されなかったときなどに、値の非存在を表すのに頻繁に用いられます。 None への代入は不正で、SyntaxError を送出します。
注釈 二項演算の (あるいはインプレースの) メソッドが NotImplemented を返した場合、インタープリタはもう一方の型で定義された対の演算で代用を試みます (あるいは演算によっては他の代替手段も試みます)。試行された演算全てが NotImplemented を返した場合、インタープリタは適切な例外を送出します。 NotImplemented を正しく返さないと、誤解を招きかねないエラーメッセージになったり、 NotImplemented が Python コードに返されるようなことになります。
例として 算術演算の実装 を参照してください。
注釈 NotImplementedError と NotImplemented は、似たような名前と目的を持っていますが、相互に変換できません。 利用する際には、 NotImplementedError を参照してください。
Ellipsis
Ellipsis リテラル "..." と同じです。 主に拡張スライス構文やユーザ定義のコンテナデータ型において使われる特殊な値です。
__debug__
この定数は、Python が -O オプションを有効にして開始されたのでなければ真です。 assert 文も参照して下さい。
注釈 名前 None 、 False 、 True 、 __debug__ は再代入できない (これらに対する代入は、たとえ属性名としてであっても SyntaxError が送出されます) ので、これらは「真の」定数であると考えられます。
site モジュールで追加される定数
site モジュール (-S コマンドラインオプションが指定されない限り、スタートアップ時に自動的にインポートされます) は組み込み名前空間にいくつかの定数を追加します。それらは対話的インタープリタシェルで有用ですが、プログラム中では使うべきではありません。
quit(code=None)
exit(code=None)
表示されたときに "Use quit() or Ctrl-D (i.e. EOF) to exit" のようなメッセージを表示し、呼び出されたときには指定された終了コードを伴って SystemExit を送出するオブジェクトです。
copyright
credits
表示あるいは呼び出されたときに、それぞれ著作権あるいはクレジットのテキストが表示されるオブジェクトです。
license
表示されたときに "Type license() to see the full license text" というメッセージを表示し、呼び出されたときには完全なライセンスのテキストをページャのような形式で (1画面分づつ) 表示するオブジェクトです。
組み込み型
以下のセクションでは、インタプリタに組み込まれている標準型について記述します。
主要な組み込み型は、数値、シーケンス、マッピング、クラス、インスタンス、および例外です。
コレクションクラスには、ミュータブルなものがあります。コレクションのメンバをインプレースに足し、引き、または並べ替えて、特定の要素を返さないメソッドは、コレクション自身ではなく None を返します。
演算には、複数の型でサポートされているものがあります; 特に、ほぼ全てのオブジェクトは、等価比較でき、真理値を判定でき、 (repr() 関数や、わずかに異なる str() 関数によって) 文字列に変換できます。オブジェクトが print() 関数で印字されるとき、文字列に変換する関数が暗黙に使われます。
真理値判定
どのようなオブジェクトでも真理値として判定でき、 if や while の条件あるいは以下のブール演算の被演算子として使えます。
オブジェクトは、デフォルトでは真と判定されます。ただしそのクラスが __bool__() メソッドを定義していて、それが False を返す場合、または __len__() メソッドを定義していて、それが 0 を返す場合は偽と判定されます。 1 主な組み込みオブジェクトで偽と判定されるものを次に示します:
偽であると定義されている定数: None と False
数値型におけるゼロ: 0, 0.0, 0j, Decimal(0), Fraction(0, 1)
空のシーケンスまたはコレクション: '', (), [], {}, set(), range(0)
ブール値の結果を返す演算および組み込み関数は、特に注釈のない限り常に偽値として 0 または False を返し、真値として 1 または True を返します。 (重要な例外: ブール演算 or および and は常に被演算子のうちの一つを返します。)
ブール演算 --- and, or, not
以下にブール演算を、優先順位が低い順に示します:
演算
結果
注釈
x or y
x が偽なら y, そうでなければ x
(1)
x and y
x が偽なら x, そうでなければ y
(2)
not x
x が偽なら True, そうでなければ False
(3)
注釈:
この演算子は短絡評価されます。つまり第一引数が偽のときにのみ、第二引数が評価されます。
この演算子は短絡評価されます。つまり第一引数が真のときにのみ、第二引数が評価されます。
not は非ブール演算子よりも優先度が低いので、 not a == b は not (a == b) と解釈され、 a == not b は構文エラーです。
比較
Python には 8 種の比較演算があります。比較演算の優先順位は全て同じです (ブール演算より高い優先順位です)。比較は任意に連鎖できます; 例えば、 x < y <= z は x < y and y <= z とほぼ等価ですが、この y は一度だけしか評価されません (どちらにしても、 x < y が偽となれば z は評価されません)。
以下の表に比較演算をまとめます:
演算
意味
<
より小さい
<=
以下
>
より大きい
>=
以上
==
等しい
!=
等しくない
is
同一のオブジェクトである
is not
同一のオブジェクトでない
あるクラスの同一でないインスタンスは、通常等価でないとされますが、そのクラスが __eq__() メソッドを定義している場合は除きます。
クラスのインスタンスは、そのクラスがメソッド __lt__() 、 __le__() 、 __gt__() 、 __ge__() のうち十分なものを定義していない限り、同じクラスの別のインスタンスや他の型のオブジェクトとは順序付けできません (一般に、比較演算子の通常の意味を求めるなら、 __lt__() と __eq__() だけで十分です)。
is および is not 演算子の振る舞いはカスタマイズできません。また、これらはいかなる 2 つのオブジェクトにも適用でき、決して例外を送出しません。
in と not in という構文上で同じ優先度を持つ演算子がさらに 2 つあり、 iterable または __contains__() を実装した型でサポートされています。
数値型 int, float, complex
数値型には 3 種類あります: 整数 、 浮動小数点数 、 複素数 です。さらに、ブール型は整数のサブタイプです。整数には精度の制限がありません。浮動小数点型はたいていは C の double を使って実装されています; あなたのプログラムが動作するマシンでの浮動小数点型の精度と内部表現は、 sys.float_info から利用できます。複素数は実部と虚部を持ち、それぞれ浮動小数点数です。複素数 z から実部および虚部を取り出すには、 z.real および z.imag を使ってください。 (標準ライブラリには、さらに分数のための数値型 fractions.Fraction や、ユーザによる精度の定義が可能な浮動小数点数のための decimal.Decimal があります。)
数値は、数値リテラルによって、あるいは組み込み関数や演算子の戻り値として生成されます。 (十六進、八進、二進数を含む) 修飾のない整数リテラルは、整数を与えます。小数点または指数表記を含む数値リテラルは浮動小数点数を与えます。数値リテラルに 'j' または 'J' をつけると虚数 (実部がゼロの複素数) を与え、それに整数や浮動小数点数を加えて実部と虚部を持つ複素数を得られます。
Python は型混合の算術演算に完全に対応しています: ある二項算術演算子の被演算子の数値型が互いに異なるとき、"より狭い方" の型の被演算子はもう片方の型に合わせて広げられます。ここで整数は浮動小数点数より狭く、浮動小数点数は複素数より狭いです。 たくさんの異なる型の数値間での比較は、それらの厳密な数で比較したかのように振る舞います。 2
コンストラクタ int() 、 float() 、 complex() で、特定の型の数を生成できます。
全ての (複素数を除く) 組み込み数値型は以下の演算に対応しています (演算の優先順位については、 演算子の優先順位 を参照してください):
演算
結果
注釈
完全なドキュメント
x + y
x と y の和
x - y
x と y の差
x * y
x と y の積
x / y
x と y の商
x // y
x と y の商を切り下げたもの
(1)
x % y
x / y の剰余
(2)
-x
x の符号反転
+x
x そのまま
abs(x)
x の絶対値または大きさ
abs()
int(x)
x の整数への変換
(3)(6)
int()
float(x)
x の浮動小数点数への変換
(4)(6)
float()
complex(re, im)
実部 re, 虚部 im の複素数。 im の既定値はゼロ。
(6)
complex()
c.conjugate()
複素数 c の共役複素数
divmod(x, y)
(x // y, x % y) からなるペア
(2)
divmod()
pow(x, y)
x の y 乗
(5)
pow()
x ** y
x の y 乗
(5)
注釈:
整数の除算とも呼ばれます。結果の型は整数型とは限りませんが、結果の値は整数です。結果は常に負の無限大の方向に丸められます: 1//2 は 0 、 (-1)//2 は -1 、 1//(-2) は -1 、そして (-1)//(-2) は 0 です。
複素数型には使えません。適用可能な場合には代わりに abs() で浮動小数点型に変換してください。
浮動小数点数から整数への変換はC言語と同様の方法で丸め、または切り捨てられます; より明確に定義された変換を行う場合は、 math.floor() と math.ceil() を参照してください。
浮動小数点数は、文字列 "nan" と "inf" を、オプションの接頭辞 "+" または "-" と共に、非数 (Not a Number (NaN)) や正、負の無限大として受け付けます。
Python は、プログラム言語一般でそうであるように、 pow(0, 0) および 0 ** 0 を 1 と定義します。
受け付けられる数値リテラルは数字 0 から 9 または等価な Unicode (Nd プロパティを持つコードポイント) を含みます。
全ての numbers.Real 型 (int 、 float) は以下の演算も含みます:
演算
結果
math.trunc(x)
x を Integral (整数) に切り捨てます
round(x[, n])
x を n 桁に丸めます。丸め方は偶数丸めです。 n が省略されれば 0 がデフォルトとなります。
math.floor(x)
x 以下の最大の Integral (整数) を返します
math.ceil(x)
x 以上の最小の Integral (整数) を返します
その他の数値演算は、 math や cmath モジュールをご覧ください。
整数型におけるビット単位演算
ビット単位演算は整数についてのみ意味を持ちます。 ビット単位演算の結果は、あたかも両方の値の先頭を無限個の符号ビットで埋めたものに対して計算したかのような値になります。
二項ビット単位演算の優先順位は全て、数値演算よりも低く、比較よりも高くなっています; 単項演算 ~ の優先順位は他の単項数値演算 (+ および -) と同じです。
以下の表では、ビット単位演算を優先順位が低い順に並べています:
演算
結果
注釈
x | y
x と y のビット単位 論理和
(4)
x ^ y
x と y のビット単位 排他的論理和
(4)
x & y
x と y のビット単位 論理積
(4)
x << n
x の n ビット左シフト
(1)(2)
x >> n
x の n ビット右シフト
(1)(3)
~x
x のビット反転
注釈:
負値のシフト数は不正であり、 ValueError が送出されます。
n ビットの左シフトは、 pow(2, n) による乗算と等価です。
n ビットの右シフトは、 pow(2, n) による切り捨て除算と等価です。
桁の長い方の値に少なくとも 1 つ余計に符号ビットを付け加えた幅 (計算するビット幅は 1 + max(x.bit_length(), y.bit_length()) かそれ以上) でこれらの計算を行えば、無限個の符号ビットがあるかのように計算したのと同じ結果を得るのに十分です。
整数型における追加のメソッド
整数型は numbers.Integral 抽象基底クラス を実装します。さらに、追加のメソッドをいくつか提供します:
int.bit_length()
整数を、符号と先頭の 0 は除いて二進法で表すために必要なビットの数を返します:
>>>
>>> n = -37
>>> bin(n)
'-0b100101'
>>> n.bit_length()
6
正確には、 x が非 0 なら、 x.bit_length() は 2**(k-1) <= abs(x) < 2**k を満たす唯一の正の整数 k です。同様に、 abs(x) が十分小さくて対数を適切に丸められるとき、 k = 1 + int(log(abs(x), 2)) です。 x が 0 なら、 x.bit_length() は 0 を返します。
次と等価です:
def bit_length(self):
    s = bin(self)       # binary representation:  bin(-37) --> '-0b100101'
    s = s.lstrip('-0b') # remove leading zeros and minus sign
    return len(s)       # len('100101') --> 6
バージョン 3.1 で追加.
int.to_bytes(length, byteorder, *, signed=False)
整数を表すバイト列を返します。
>>>
>>> (1024).to_bytes(2, byteorder='big')
b'\x04\x00'
>>> (1024).to_bytes(10, byteorder='big')
b'\x00\x00\x00\x00\x00\x00\x00\x00\x04\x00'
>>> (-1024).to_bytes(10, byteorder='big', signed=True)
b'\xff\xff\xff\xff\xff\xff\xff\xff\xfc\x00'
>>> x = 1000
>>> x.to_bytes((x.bit_length() + 7) // 8, byteorder='little')
b'\xe8\x03'
整数は length バイトで表されます。整数が与えられた数のバイトで表せなければ、 OverflowError が送出されます。
byteorder 引数は、整数を表すのに使われるバイトオーダーを決定します。 byteorder が "big" なら、最上位のバイトがバイト配列の最初に来ます。 byteorder が "little" なら、最上位のバイトがバイト配列の最後に来ます。ホストシステムにネイティブのバイトオーダーを要求するには、 sys.byteorder をバイトオーダーの値として使ってください。
signed 引数は、整数を表すのに 2 の補数を使うかどうかを決定します。 signed が False で、負の整数が与えられたなら、 OverflowError が送出されます。 signed のデフォルト値は False です。
バージョン 3.2 で追加.
classmethod int.from_bytes(bytes, byteorder, *, signed=False)
与えられたバイト列の整数表現を返します。
>>>
>>> int.from_bytes(b'\x00\x10', byteorder='big')
16
>>> int.from_bytes(b'\x00\x10', byteorder='little')
4096
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=True)
-1024
>>> int.from_bytes(b'\xfc\x00', byteorder='big', signed=False)
64512
>>> int.from_bytes([255, 0, 0], byteorder='big')
16711680
引数 bytes は bytes-like object か、または bytes を生成する iterable でなければなりません。
byteorder 引数は、整数を表すのに使われるバイトオーダーを決定します。 byteorder が "big" なら、最上位のバイトがバイト配列の最初に来ます。 byteorder が "little" なら、最上位のバイトがバイト配列の最後に来ます。ホストシステムにネイティブのバイトオーダーを要求するには、 sys.byteorder をバイトオーダーの値として使ってください。
signed 引数は、整数を表すのに 2 の補数を使うかどうかを決定します。
バージョン 3.2 で追加.
バージョン 3.8 で追加.
浮動小数点数に対する追加のメソッド
浮動小数点数型は、 numbers.Real 抽象基底クラス を実装しています。浮動小数点型はまた、以下の追加のメソッドを持ちます。
float.as_integer_ratio()
比が元の浮動小数点数とちょうど同じで分母が正である、一対の整数を返します。無限大に対しては OverflowError を、非数 (NaN) に対しては ValueError を送出します。
float.is_integer()
浮動小数点数インスタンスが有限の整数値なら True を、そうでなければ False を返します:
>>>
>>> (-2.0).is_integer()
True
>>> (3.2).is_integer()
False
16 進表記の文字列へ、または、 16 進表記からの変換をサポートする二つのメソッドがあります。 Python の浮動小数点数は内部的には2進数で保持されるので、浮動小数点数の 10進数 へまたは 10進数 からの変換には若干の丸め誤差があります。それに対し、16 進表記では、浮動小数点数を正確に表現できます。これはデバッグのときや、数学的な用途 (numerical work) に便利でしょう。
float.hex()
浮動小数点数の 16 進文字列表現を返します。有限の浮動小数点数に対し、この表現は常に 0x で始まり p と指数が続きます。
classmethod float.fromhex(s)
16 進文字列表現 s で表される、浮動小数点数を返すクラスメソッドです。文字列 s は、前や後にホワイトスペースを含んでいても構いません。
float.fromhex() はクラスメソッドですが、 float.hex() はインスタンスメソッドであることに注意して下さい。
16 進文字列表現は以下の書式となります:
[sign] ['0x'] integer ['.' fraction] ['p' exponent]
sign は必須ではなく、 + と - のどちらかです。 integer と fraction は 16 進数の文字列で、 exponent は 10 進数で符号もつけられます。大文字・小文字は区別されず、最低でも 1 つの 16 進数文字を整数部もしくは小数部に含む必要があります。この制限は C99 規格のセクション 6.4.4.2 で規定されていて、 Java 1.5 以降でも使われています。特に、 float.hex() の出力は C や Java コード中で、浮動小数点数の 16 進表記として役に立つでしょう。また、 C の %a 書式や、 Java の Double.toHexString で書きだされた文字列は float.fromhex() で受け付けられます。
なお、指数部は 16 進数ではなく 10 進数で書かれ、係数に掛けられる 2 の累乗を与えます。例えば、16 進文字列 0x3.a7p10 は浮動小数点数 (3 + 10./16 + 7./16**2) * 2.0**10 すなわち 3740.0 を表します:
>>>
>>> float.fromhex('0x3.a7p10')
3740.0
逆変換を 3740.0 に適用すると、同じ数を表す異なる 16 進文字列表現を返します:
>>>
>>> float.hex(3740.0)
'0x1.d380000000000p+11'
数値型のハッシュ化
数 x と y に対して、型が異なっていたとしても、 x == y であれば必ず hash(x) == hash(y) であることが要請されます (詳細は __hash__() メソッドドキュメントを参照してください)。実装の簡単さと 複数の数値型 (int 、 float 、 decimal.Decimal 、 fractions.Fraction を含みます) 間の効率のため、Python の 数値型に対するハッシュ値はある単一の数学的関数に基づいていて、 その関数はすべての有理数に対し定義されているため、 int と fractions.Fraction のすべてのインスタンスと、 float と decimal.Decimal のすべての有限なインスタンスに 対して適用されます。本質的には、この関数は定数の素数 P に対して P を法とする還元で与えられます。 値 P は、 sys.hash_info の modulus 属性として Python で利用できます。
CPython implementation detail: 現在使われている素数は、32 bit C long のマシンでは P = 2**31 - 1 、 64-bit C long のマシンでは P = 2**61 - 1 です。
詳細な規則はこうです:
x = m / n が非負の有理数で、 n が P で割り切れないなら、 invmod(n, P) を n を P で割った剰余の (剰余演算の意味での) 逆数を与えるものとして、 hash(x) を m * invmod(n, P) % P と定義します。
x = m / n が非負の有理数で、 n が P で割り切れる (が m は割り切れない) なら、 n は P で割った余りの逆数を持たず、上の規則は適用できません。この場合、 hash(x) を定数 sys.hash_info.inf と定義します。
x = m / n が負の有理数なら、 hash(x) を -hash(-x) と定義します。その結果のハッシュが -1 なら、 -2 に置き換えます。
特定の値 sys.hash_info.inf 、 -sys.hash_info.inf 、 sys.hash_info.nan は、正の無限大、負の無限大、nan を (それぞれ) 表すのに使われます。(すべてのハッシュ可能な nan は同じハッシュ値を持ちます。)
複素 (complex) 数 z に対して、実部と虚部のハッシュ値は、 hash(z.real) + sys.hash_info.imag * hash(z.imag) の 2**sys.hash_info.width を法とする還元を計算することにより組み合わせられ、よってこれは range(-2**(sys.hash_info.width - 1), 2**(sys.hash_info.width - 1)) に収まります。再び、結果が -1 なら、 -2 で置き換えられます。
上述の規則をわかりやすくするため、有理数 float や、 complex のハッシュを計算する組み込みのハッシュと等価な Python コードの例を挙げます:
import sys, math
def hash_fraction(m, n):
    """Compute the hash of a rational number m / n.
    Assumes m and n are integers, with n positive.
    Equivalent to hash(fractions.Fraction(m, n)).
    """
    P = sys.hash_info.modulus
    # Remove common factors of P.  (Unnecessary if m and n already coprime.)
    while m % P == n % P == 0:
        m, n = m // P, n // P
    if n % P == 0:
        hash_value = sys.hash_info.inf
    else:
        # Fermat's Little Theorem: pow(n, P-1, P) is 1, so
        # pow(n, P-2, P) gives the inverse of n modulo P.
        hash_value = (abs(m) % P) * pow(n, P - 2, P) % P
    if m < 0:
        hash_value = -hash_value
    if hash_value == -1:
        hash_value = -2
    return hash_value
def hash_float(x):
    """Compute the hash of a float x."""
    if math.isnan(x):
        return sys.hash_info.nan
    elif math.isinf(x):
        return sys.hash_info.inf if x > 0 else -sys.hash_info.inf
    else:
        return hash_fraction(*x.as_integer_ratio())
def hash_complex(z):
    """Compute the hash of a complex number z."""
    hash_value = hash_float(z.real) + sys.hash_info.imag * hash_float(z.imag)
    # do a signed reduction modulo 2**sys.hash_info.width
    M = 2**(sys.hash_info.width - 1)
    hash_value = (hash_value & (M - 1)) - (hash_value & M)
    if hash_value == -1:
        hash_value = -2
    return hash_value
イテレータ型
Python はコンテナでの反復処理の概念をサポートしています。この概念は 2 つの別々のメソッドを使って実装されています; これらのメソッドを使ってユーザ定義のクラスで反復を行えるようにできます。後に詳しく述べるシーケンスは、必ず反復処理メソッドをサポートしています。
コンテナオブジェクトに反復処理をサポートさせるためには、以下のメソッドを定義しなければなりません:
container.__iter__()
イテレータオブジェクトを返します。オブジェクトは後述するイテレータプロトコルをサポートする必要があります。もしコンテナが異なる型の反復処理をサポートするなら、それらの反復処理毎に追加のメソッドを提供しても構いません (複数の形式の反復処理を提供するオブジェクトの例として、幅優先探索と深さ優先探索をサポートする木構造が挙げられます)。このメソッドは Python/C API での Python オブジェクトの型構造体の tp_iter スロットに対応します。
イテレータオブジェクト自体は以下の 2 つのメソッドをサポートする必要があります。これらのメソッドは 2 つ合わせて iterator protocol: (イテレータプロトコル) を成します:
iterator.__iter__()
イテレータオブジェクト自体を返します。このメソッドはコンテナとイテレータの両方を for および in 文で使えるようにするために必要です。このメソッドは Python/C API において Python オブジェクトを表す型構造体の tp_iter スロットに対応します。
iterator.__next__()
コンテナの次のアイテムを返します。もしそれ以上アイテムが無ければ StopIteration 例外を送出します。 このメソッドは Python/C APIでのPythonオブジェクトの型構造体の tp_iternext スロットに対応します。
Python では、いくつかのイテレータオブジェクトを定義して、一般のシーケンス型、特殊なシーケンス型、辞書型、その他の特殊な形式に渡って反復をサポートしています。特殊型は、イテレータプロトコルの実装以外では重要ではありません。
イテレータの __next__() メソッドが一旦 StopIteration を送出したなら、以降の呼び出しでも例外を送出し続けなければなりません。この特性に従わない実装は壊れているとみなされます。
ジェネレータ型
Python における generator (ジェネレータ) は、イテレータプロトコルを実装する便利な方法を提供します。コンテナオブジェクトの __iter__() メソッドがジェネレータとして実装されていれば、そのメソッドは __iter__() および __next__() メソッドを提供するイテレータオブジェクト (厳密にはジェネレータオブジェクト) を自動的に返します。ジェネレータに関する詳細な情報は、 yield 式のドキュメント にあります。
シーケンス型 --- list, tuple, range
基本的なシーケンス型は 3 つあります: リスト、タプル、range オブジェクトです。バイナリデータ や テキスト文字列 を処理するように仕立てられたシーケンス型は、セクションを割いて解説します。
共通のシーケンス演算
以下の表にある演算は、ほとんどのミュータブル、イミュータブル両方のシーケンスでサポートされています。カスタムのシーケンス型にこれらの演算を完全に実装するのが簡単になるように、 collections.abc.Sequence ABC が提供されています。
以下のテーブルで、シーケンス演算を優先順位が低い順に挙げます。表内で、 s と t は同じ型のシーケンス、 n、 i、 j 、 k は整数、x は s に課された型と値の条件を満たす任意のオブジェクトです。
in および not in 演算の優先順位は比較演算と同じです。+ (結合) および * (繰り返し)の優先順位は対応する数値演算と同じです。 3
演算
結果
注釈
x in s
s のある要素が x と等しければ True , そうでなければ False
(1)
x not in s
s のある要素が x と等しければ False, そうでなければ True
(1)
s + t
s と t の結合
(6)(7)
s * n または n * s
s 自身を n 回足すのと同じ
(2)(7)
s[i]
s の 0 から数えて i 番目の要素
(3)
s[i:j]
s の i から j までのスライス
(3)(4)
s[i:j:k]
s の i から j まで、 k 毎のスライス
(3)(5)
len(s)
s の長さ
min(s)
s の最小の要素
max(s)
s の最大の要素
s.index(x[, i[, j]])
s 中で x が最初に出現するインデックス (インデックス i 以降からインデックス j までの範囲)
(8)
s.count(x)
s 中に x が出現する回数
同じ型のシーケンスは比較もサポートしています。特に、タプルとリストは対応する要素を比較することで辞書式順序で比較されます。つまり、等しいとされるためには、すべての要素が等しく、両シーケンスの型も長さも等しくなければなりません。(完全な詳細は言語リファレンスの 比較 を参照してください。)
注釈:
in および not in 演算は、一般に単純な包含判定にのみ使われますが、(str, bytes, bytearray のような) 特殊なシーケンスでは部分シーケンス判定にも使われます:
>>>
>>> "gg" in "eggs"
True
0 未満の値 n は 0 として扱われます (これは s と同じ型の空のシーケンスを表します)。シーケンス s の要素はコピーされないので注意してください; コピーではなく要素に対する参照カウントが増えます。これは Python に慣れていないプログラマをよく悩ませます。例えば以下のコードを考えます:
>>>
>>> lists = [[]] * 3
>>> lists
[[], [], []]
>>> lists[0].append(3)
>>> lists
[[3], [3], [3]]
ここで、[[]] が空リストを含む 1 要素のリストなので、[[]] * 3 の 3 要素はこの一つの空リスト (への参照) です。lists のいずれかの要素を変更すると、その一つのリストが変更されます。別々のリストのリストを作るにはこうします:
>>>
>>> lists = [[] for i in range(3)]
>>> lists[0].append(3)
>>> lists[1].append(5)
>>> lists[2].append(7)
>>> lists
[[3], [5], [7]]
別の説明が FAQ エントリ 多次元のリストを作るにはどうしますか？ にあります。
i または j が負の数の場合、インデックスはシーケンスの末端からの相対インデックスになります: len(s) + i または len(s) + j が代わりに使われます。 ただし -0 はやはり 0 であることに注意してください。
s の i から j へのスライスは i <= k < j となるようなインデックス k を持つ要素からなるシーケンスとして定義されます。 i または j が len(s) よりも大きい場合、 len(s) を使います。 i が省略されるか None だった場合、 0 を使います。 j が省略されるか None だった場合、 len(s) を使います。 i が j 以上の場合、スライスは空のシーケンスになります。
s の「 i から j まででステップが k のスライス」は、インデックス x = i + n*k （ただし n は 0 <= n < (j-i)/k を満たす任意の整数）を持つ要素からなるシーケンスとして定義されます。言い換えるとインデックスは i, i+k, i+2*k, i+3*k と続き、 j に達したところでストップします (ただし j は含みません)。 k が正の数である場合、 i または j が len(s) より大きければ len(s) を代わりに使用します。 k が負の数である場合、 i または j が len(s) - 1 より大きければ len(s) - 1 を代わりに使用します。 i または j を省略または None を指定すると、 "端" (どちらの端かは k の符号に依存) の値を代わりに使用します。なお k はゼロにできないので注意してください。また k に None を指定すると、 1 が指定されたものとして扱われます。
イミュータブルなシーケンスの結合は、常に新しいオブジェクトを返します。これは、結合の繰り返しでシーケンスを構築する実行時間コストがシーケンスの長さの合計の二次式になることを意味します。実行時間コストを線形にするには、代わりに以下のいずれかにしてください:
str オブジェクトを結合するには、リストを構築して最後に str.join() を使うか、 io.StringIO インスタンスに書き込んで完成してから値を取得してください
bytes オブジェクトを結合するなら、同様に bytes.join() や io.BytesIO を使うか、 bytearray オブジェクトでインプレースに結合できます。 bytearray オブジェクトはミュータブルで、効率のいい割り当て超過機構を備えています
tuple オブジェクトを結合するなら、代わりに list を拡張してください
その他の型については、関連するクラスのドキュメントを調べてください
シーケンス型には、 (range のように) 特殊なパターンに従う項目のシーケンスのみをサポートするものがあり、それらはシーケンスの結合や繰り返しをサポートしません。
index は x が s 中に見つからないとき ValueError を送出します。追加の引数 i と j は、すべての実装がサポートしているわけではありません。追加の引数を渡すのは、おおよそ s[i:j].index(x) を使うのと等価ですが、データをコピーしなくて済むし、返されるのはスライスの最初ではなくシーケンスの最初からの相対インデクスです。
イミュータブルなシーケンス型
イミュータブルなシーケンス型が一般に実装している演算のうち、ミュータブルなシーケンス型がサポートしていないのは、組み込みの hash() だけです。
このサポートにより、tuple インスタンスのようなイミュータブルなシーケンスは、 dict のキーとして使え、 set や frozenset インスタンスに保存できます。
ハッシュ不可能な値を含むイミュータブルなシーケンスをハッシュ化しようとすると、 TypeError となります。
ミュータブルなシーケンス型
以下のテーブルにある演算は、ほとんどのミュータブルなシーケンスでサポートされています。カスタムのシーケンス型にこれらの演算を完全に実装するのが簡単になるように、 collections.abc.MutableSequence ABC が提供されています。
このテーブルで、 s はミュータブルなシーケンス型のインスタンス、 t は任意のイテラブルオブジェクト、 x は s に課された型と値の条件を満たす任意のオブジェクト (例えば、 bytearray は値の制限 0 <= x <= 255 に合う整数のみを受け付けます) です。
演算
結果
注釈
s[i] = x
s の要素 i を x と入れ替えます
s[i:j] = t
s の i から j 番目までのスライスをイテラブル t の内容に入れ替えます
del s[i:j]
s[i:j] = [] と同じです
s[i:j:k] = t
s[i:j:k] の要素を t の要素と入れ替えます
(1)
del s[i:j:k]
リストから s[i:j:k] の要素を削除します
s.append(x)
x をシーケンスの最後に加えます (s[len(s):len(s)] = [x] と同じ)
s.clear()
s から全ての要素を取り除きます (del s[:] と同じ)
(5)
s.copy()
s の浅いコピーを作成します (s[:] と同じ)
(5)
s.extend(t) または s += t
s を t の内容で拡張します (ほとんど s[len(s):len(s)] = t と同じ)
s *= n
s をその内容を n 回繰り返したもので更新
(6)
s.insert(i, x)
s の i で与えられたインデックスに x を挿入します。 (s[i:i] = [x] と同じ)
s.pop([i])
s から i 番目の要素を取り出し、また取り除きます
(2)
s.remove(x)
s から s[i] が x が等価となる最初の要素を取り除きます
(3)
s.reverse()
s をインプレースに逆転させます
(4)
注釈:
t は置き換えるスライスと同じ長さでなければいけません。
オプションの引数 i は標準で -1 なので、標準では最後の要素をリストから除去して返します。
remove() は s に x が見つからなければ ValueError を送出します。
reverse() メソッドは、大きなシーケンスを反転するときの容量の節約のため、シーケンスをインプレースに変化させます。副作用としてこの演算が行われることをユーザに気づかせるために、これは反転したシーケンスを返しません。
clear() および copy() は、スライシング操作をサポートしないミュータブルなコンテナ (dict や set など) のインタフェースとの一貫性のために含まれています。 copy() は collections.abc.MutableSequence ABC の一部ではありませんが、ほとんどのミュータブルなシーケンスクラスが提供しています。
バージョン 3.3 で追加: clear() および copy() メソッド。
値 n は整数であるか、__index__() を実装したオブジェクトです。 n の値がゼロまたは負数の場合、シーケンスをクリアします。共通のシーケンス演算 で s * n について説明したとおり、シーケンスの要素はコピーされないので注意してください; コピーではなく要素に対する参照カウントが増えます。
リスト型 (list)
リストはミュータブルなシーケンスで、一般的に同種の項目の集まりを格納するために使われます (厳密な類似の度合いはアプリケーションによって異なる場合があります)。
class list([iterable])
リストの構成にはいくつかの方法があります:
角括弧の対を使い、空のリストを表す: []
角括弧を使い、項目をカンマで区切る: [a]、[a, b, c]
リスト内包表記を使う: [x for x in iterable]
型コンストラクタを使う: list() または list(iterable)
コンストラクタは、 iterable の項目と同じ項目で同じ順のリストを構築します。 iterable は、シーケンス、イテレートをサポートするコンテナ、またはイテレータオブジェクトです。 iterable が既にリストなら、 iterable[:] と同様にコピーが作られて返されます。例えば、 list('abc') は ['a', 'b', 'c'] を、 list( (1, 2, 3) ) は [1, 2, 3] を返します。引数が与えられなければ、このコンストラクタは新しい空のリスト [] を作成します。
リストを作る方法は、他にも組み込み関数 sorted() などいろいろあります。
リストは 共通の および ミュータブルの シーケンス演算をすべて実装します。リストは、更に以下のメソッドも提供します:
sort(*, key=None, reverse=False)
このメソッドは、項目間の < 比較のみを用いてリストをインプレースにソートします。例外は抑制されません。比較演算がどこかで失敗したら、ソート演算自体が失敗します (そしてリストは部分的に変更された状態で残されるでしょう)。
sort() は、キーワードでしか渡せない 2 つの引数 (キーワード専用引数) を受け付けます:
key は一引数をとる関数を指定し、リストのそれぞれの要素から比較キーを取り出すのに使います (例えば、 key=str.lower)。それぞれの項目に対応するキーは一度計算され、ソート処理全体に使われます。デフォルトの値 None は、別のキー値を計算せず、リストの値が直接ソートされることを意味します。
2.x 形式の cmp 関数を key 関数に変換するために、functools.cmp_to_key() ユーティリティが利用できます。
reverse は真偽値です。 True がセットされた場合、リストの要素は個々の比較が反転したものとして並び替えられます。
このメソッドは、大きなシーケンスをソートするときの容量の節約のため、シーケンスをインプレースに変化させます。副作用としてこの演算が行われることをユーザに気づかせるために、これはソートしたシーケンスを返しません (新しいリストインスタンスを明示的に要求するには sorted() を使ってください)。
sort() メソッドは安定していることが保証されています。ソートは、等しい要素の相対順序が変更されないことが保証されていれば、安定しています。これは複数パスのソートを行なう (例えば部署でソートして、それから給与の等級でソートする) のに役立ちます。
ソートの例と簡単なチュートリアルは ソート HOW TO を参照して下さい。
CPython implementation detail: リストがソートされている間、または変更しようとする試みの影響中、あるいは検査中でさえ、リストは未定義です。Python の C 実装では、それらが続いている間、リストは空として出力され、リストがソート中に変更されていることを検知できたら ValueError を送出します。
タプル型 (tuple)
タプルはイミュータブルなシーケンスで、一般的に異種のデータの集まり (組み込みの enumerate() で作られた 2-タプルなど) を格納するために使われます。タプルはまた、同種のデータのイミュータブルなシーケンスが必要な場合 (set インスタンスや dict インスタンスに保存できるようにするためなど) にも使われます。
class tuple([iterable])
タプルの構成にはいくつかの方法があります:
丸括弧の対を使い、空のタプルを表す: ()
カンマを使い、単要素のタプルを表す: a, または (a,)
項目をカンマで区切る: a, b, c または (a, b, c)
組み込みの tuple() を使う: tuple() または tuple(iterable)
コンストラクタは、 iterable の項目と同じ項目で同じ順のタプルを構築します。 iterable は、シーケンス、イテレートをサポートするコンテナ、またはイテレータオブジェクトです。 iterable が既にタプルなら、そのまま返されます。例えば、 tuple('abc') は ('a', 'b', 'c') を、 tuple( [1, 2, 3] ) は (1, 2, 3) を返します。引数が与えられなければ、このコンストラクタは新しい空のタプル () を作成します。
なお、タプルを作るのはカンマであり、丸括弧ではありません。丸括弧は省略可能ですが、空のタプルの場合や構文上の曖昧さを避けるのに必要な時は例外です。例えば、 f(a, b, c) は三引数の関数呼び出しですが、f((a, b, c)) は 3-タプルを唯一の引数とする関数の呼び出しです。
タプルは 共通の シーケンス演算をすべて実装します。
異種のデータの集まりで、インデックスによってアクセスするよりも名前によってアクセスしたほうが明確になるものには、単純なタプルオブジェクトよりも collections.namedtuple() が向いているかもしれません。
range
range 型は、数のイミュータブルなシーケンスを表し、一般に for ループにおいて特定の回数のループに使われます。
class range(stop)
class range(start, stop[, step])
range コンストラクタの引数は整数 (組み込みの int または __index__ 特殊メソッドを実装するオブジェクト) でなければなりません。step 引数が省略された場合のデフォルト値は 1 です。start 引数が省略された場合のデフォルト値は 0 です。 step が 0 の場合、ValueError が送出されます。
step が正の場合、range r の内容は式 r[i] = start + step*i で決定されます。ここで、 i >= 0 かつ r[i] < stop です。
step が負の場合も、range r の内容は式 r[i] = start + step*i で決定されます。ただし、制約条件は i >= 0 かつ r[i] > stop です。
r[0] が値の制約を満たさない場合、range オブジェクトは空になります。range は負のインデックスをサポートしますが、これらは正のインデックスにより決定されるシーケンスの末尾からのインデックス指定として解釈されます。
range は sys.maxsize より大きい絶対値を含むことができますが、いくつかの機能 (len() など) は OverflowError を送出することがあります。
range の例:
>>>
>>> list(range(10))
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> list(range(1, 11))
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
>>> list(range(0, 30, 5))
[0, 5, 10, 15, 20, 25]
>>> list(range(0, 10, 3))
[0, 3, 6, 9]
>>> list(range(0, -10, -1))
[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
>>> list(range(0))
[]
>>> list(range(1, 0))
[]
range は 共通の シーケンス演算を、結合と繰り返し以外すべて実装します (range オブジェクトは厳格なパターンに従うシーケンスのみを表せ、繰り返しと結合はたいていそのパターンを破るという事実によります)。
start
引数 start の値 (この引数が与えられていない場合は 0)
stop
引数 stop の値
step
引数 step の値 (この引数が与えられていない場合は 1)
range 型が通常の list や tuple にまさる点は、range オブジェクトがサイズや表す範囲にかかわらず常に一定の (小さな) 量のメモリを使うことです (start、stop、step の値のみを保存し、後は必要に応じて個々の項目や部分 range を計算するためです)。
range オブジェクトは collections.abc.Sequence ABC を実装し、包含判定、要素インデックス検索、スライシングのような機能を提供し、負のインデックスをサポートします (シーケンス型 --- list, tuple, range を参照):
>>>
>>> r = range(0, 20, 2)
>>> r
range(0, 20, 2)
>>> 11 in r
False
>>> 10 in r
True
>>> r.index(10)
5
>>> r[5]
10
>>> r[:5]
range(0, 10, 2)
>>> r[-1]
18
== および != による range オブジェクトの等価性の判定は、これらをシーケンスとして比較します。つまり、二つの range オブジェクトは同じ値のシーケンスを表すなら等しいとみなされます。(なお、二つの等しいとされる range オブジェクトが異なる start, stop および step 属性を持つことがあります。例えば range(0) == range(2, 1, 3) や range(0, 3, 2) == range(0, 4, 2)。)
バージョン 3.2 で変更: シーケンス ABC を実装。スライスと負のインデックスのサポート。int オブジェクトの帰属判定を、すべてのアイテムをイテレートする代わりに、定数時間で行います。
バージョン 3.3 で変更: (オブジェクトの同一性に基づいて比較する代わりに) range オブジェクトをそれらが定義する値のシーケンスに基づいて比較するように '==' と '!=' を定義しました。
バージョン 3.3 で追加: 属性 start, stop および step。
参考
linspace レシピ には、遅延評価される浮動小数点版の range の実装方法が載っています。
テキストシーケンス型 --- str
Python のテキストデータは str オブジェクト、すなわち 文字列 として扱われます。文字列は Unicode コードポイントのイミュータブルな シーケンス です。文字列リテラルには様々な記述方法があります:
シングルクォート: '"ダブル" クォートを埋め込むことができます'
ダブルクォート: "'シングル' クォートを埋め込むことができます"。
三重引用符: '''三つのシングルクォート''', """三つのダブルクォート"""
三重引用符文字列は、複数行に分けることができます。関連付けられる空白はすべて文字列リテラルに含まれます。
単式の一部であり間に空白のみを含む文字列リテラルは、一つの文字列リテラルに暗黙に変換されます。つまり、("spam " "eggs") == "spam eggs" です。
エスケープシーケンスを含む文字列や、ほとんどのエスケープシーケンス処理を無効にする r ("raw") 接頭辞などの、文字列リテラルの様々な形式は、文字列およびバイト列リテラル を参照してください。
文字列は他のオブジェクトに str コンストラクタを使うことでも生成できます。
"character" 型が特別に用意されているわけではないので、文字列のインデックス指定を行うと長さ 1 の文字列を作成します。つまり、空でない文字列 s に対し、s[0] == s[0:1] です。
ミュータブルな文字列型もありませんが、ミュータブルな断片から効率よく文字列を構成するのに str.join() や io.StringIO が使えます。
バージョン 3.3 で変更: Python 2 シリーズとの後方互換性のため、文字列リテラルの u 接頭辞が改めて許可されました。それは文字列リテラルとしての意味には影響がなく、 r 接頭辞と結合することはできません。
class str(object='')
class str(object=b'', encoding='utf-8', errors='strict')
object の 文字列 版を返します。 object が与えられなかった場合、空文字列が返されます。それ以外の場合 str() の動作は、 encoding や errors が与えられたかどうかによって次のように変わります。
encoding も errors も与えられない場合、 str(object) は object.__str__() の結果を返します。これは "略式の" つまり読み易い object の文字列表現です。文字列オブジェクトに対してはその文字列自体を返します。 object が __str__() メソッドを持たない場合、str() は代わりに repr(object) の結果を返します。
encoding か errors の少なくとも一方が与えられた場合、 object は bytes-like object (たとえば bytes や bytearray) でなくてはなりません。object が bytes (もしくは bytearray) オブジェクトである場合は、 str(bytes, encoding, errors) は bytes.decode(encoding, errors) と等価です。そうでない場合は、 bytes.decode() が呼ばれる前に buffer オブジェクトの下層にある bytes オブジェクトが取得されます。 buffer オブジェクトについて詳しい情報は、 バイナリシーケンス型 --- bytes, bytearray, memoryview や バッファプロトコル (buffer Protocol) を参照してください。
encoding 引数や errors 引数無しに bytes オブジェクトを str() に渡すと、略式の文字列表現を返す 1 つ目の場合に該当します。(Python のコマンドラインオプション -b も参照してください) 例えば:
>>>
>>> str(b'Zoot!')
"b'Zoot!'"
str クラスとそのメソッドについて詳しくは、 テキストシーケンス型 --- str や 文字列メソッド の節を参照してください。フォーマットされた文字列を出力するには、 フォーマット済み文字列リテラル と カスタムの文字列書式化 の節を参照してください。加えて、 テキスト処理サービス の節も参照してください。
文字列メソッド
文字列は 共通の シーケンス演算全てに加え、以下に述べるメソッドを実装します。
文字列は、二形式の文字列書式化をサポートします。一方は柔軟さが高くカスタマイズできます (str.format()、 書式指定文字列の文法 、および カスタムの文字列書式化 を参照してください)。他方は C 言語の printf 形式の書式化に基づいてより狭い範囲と型を扱うもので、正しく扱うのは少し難しいですが、扱える場合ではたいていこちらのほうが高速です (printf 形式の文字列書式化)。
標準ライブラリの テキスト処理サービス 節は、その他テキストに関する様々なユーティリティ (re モジュールによる正規表現サポートなど) を提供するいくつかのモジュールをカバーしています。
str.capitalize()
最初の文字を大文字にし、残りを小文字にした文字列のコピーを返します。
バージョン 3.8 で変更: 最初の文字が大文字ではなくタイトルケースに置き換えられるようになりました。つまり二重音字のような文字はすべての文字が大文字にされるのではなく、最初の文字だけ大文字にされるようになります。
str.casefold()
文字列の casefold されたコピーを返します。casefold された文字列は、大文字小文字に関係ないマッチに使えます。
casefold は、小文字化と似ていますが、より積極的です。これは文字列の大文字小文字の区別をすべて取り去ることを意図しているためです。例えば、ドイツ語の小文字 'ß' は "ss" と同じです。これは既に小文字なので、lower() は 'ß' に何もしませんが、casefold() はこれを "ss" に変換します。
casefold のアルゴリズムは Unicode Standard のセクション 3.13 に記述されています。
バージョン 3.3 で追加.
str.center(width[, fillchar])
width の長さをもつ中央寄せされた文字列を返します。パディングには fillchar で指定された値 (デフォルトでは ASCII スペース) が使われます。 width が len(s) 以下なら元の文字列が返されます。
str.count(sub[, start[, end]])
[start, end] の範囲に、部分文字列 sub が重複せず出現する回数を返します。オプション引数 start および end はスライス表記と同じように解釈されます。
str.encode(encoding="utf-8", errors="strict")
文字列のエンコードされたバージョンをバイト列オブジェクトとして返します。標準のエンコーディングは 'utf-8' です。標準とは異なるエラー処理を行うために errors を与えることができます。標準のエラー処理は 'strict' で、エンコードに関するエラーは UnicodeError を送出します。他に利用できる値は 'ignore', 'replace', 'xmlcharrefreplace', 'backslashreplace' および関数 codecs.register_error() によって登録された名前です。これについてはセクション エラーハンドラ を参照してください。利用可能なエンコーディングの一覧は、セクション 標準エンコーディング を参照してください。
バージョン 3.1 で変更: キーワード引数のサポートが追加されました。
バージョン 3.9 で変更: The errors is now checked in development mode and in debug mode.
str.endswith(suffix[, start[, end]])
文字列が指定された suffix で終わるなら True を、そうでなければ False を返します。 suffix は見つけたい複数の接尾語のタプルでも構いません。オプションの start があれば、その位置から判定を始めます。オプションの end があれば、その位置で比較を止めます。
str.expandtabs(tabsize=8)
文字列内の全てのタブ文字が 1 つ以上のスペースで置換された、文字列のコピーを返します。スペースの数は現在の桁 (column) 位置と tabsize に依存します。タブ位置は tabsize 文字毎に存在します (デフォルト値である 8 の場合、タブ位置は 0, 8, 16 などになります)。文字列を展開するため、まず現桁位置がゼロにセットされ、文字列が 1 文字ずつ調べられます。文字がタブ文字 (\t) であれば、現桁位置が次のタブ位置と一致するまで、1 つ以上のスペースが結果の文字列に挿入されます。(タブ文字自体はコピーされません。) 文字が改行文字 (\n もしくは \r) の場合、文字がコピーされ、現桁位置は 0 にリセットされます。その他の文字は変更されずにコピーされ、現桁位置は、その文字の表示のされ方 (訳注: 全角、半角など) に関係なく、1 ずつ増加します。
>>>
>>> '01\t012\t0123\t01234'.expandtabs()
'01      012     0123    01234'
>>> '01\t012\t0123\t01234'.expandtabs(4)
'01  012 0123    01234'
str.find(sub[, start[, end]])
文字列のスライス s[start:end] に部分文字列 sub が含まれる場合、その最小のインデックスを返します。オプション引数 start および end はスライス表記と同様に解釈されます。 sub が見つからなかった場合 -1 を返します。
注釈 find() メソッドは、 sub の位置を知りたいときにのみ使うべきです。 sub が部分文字列であるかどうかのみを調べるには、 in 演算子を使ってください:
>>>
>>> 'Py' in 'Python'
True
str.format(*args, **kwargs)
文字列の書式化操作を行います。このメソッドを呼び出す文字列は通常の文字、または、 {} で区切られた置換フィールドを含みます。それぞれの置換フィールドは位置引数のインデックスナンバー、または、キーワード引数の名前を含みます。返り値は、それぞれの置換フィールドが対応する引数の文字列値で置換された文字列のコピーです。
>>>
>>> "The sum of 1 + 2 is {0}".format(1+2)
'The sum of 1 + 2 is 3'
書式指定のオプションについては、書式指定文字列を規定する 書式指定文字列の文法 を参照してください。
注釈 数値 (int, float, complex, decimal.Decimal とサブクラス) を n の整数表現型 (例: '{:n}'.format(1234)) でフォーマットするとき、LC_CTYPE ロケールと LC_NUMERIC ロケールの一方または両方が 1 バイトより長い非 ASCII 文字であると同時に異なる値である場合、この関数は localeconv() の decimal_point と thousands_sep フィールドを読み取るため一時的に LC_CTYPE ロケールに LC_NUMERIC のロケール値を設定します。この一時的な変更は他のスレッドの動作に影響します。
バージョン 3.7 で変更: 数値を n の整数表現型でフォーマットするとき、この関数は一時的に LC_CTYPE ロケールに LC_NUMERIC のロケール値を設定する場合があります。
str.format_map(mapping)
str.format(**mapping) と似ていますが、 mapping は dict にコピーされず、直接使われます。これは例えば mapping が dict のサブクラスであるときに便利です:
>>>
>>> class Default(dict):
...     def __missing__(self, key):
...         return key
...
>>> '{name} was born in {country}'.format_map(Default(name='Guido'))
'Guido was born in country'
バージョン 3.2 で追加.
str.index(sub[, start[, end]])
find() と同様ですが、部分文字列が見つからなかったとき ValueError を送出します。
str.isalnum()
文字列中の全ての文字が英数字で、かつ 1 文字以上あるなら True を、そうでなければ False を返します。文字 c は以下のいずれかが True を返せば英数字です: c.isalpha() 、 c.isdecimal() 、 c.isdigit() 、 c.isnumeric() 。
str.isalpha()
文字列中の全ての文字が英字で、かつ 1 文字以上あるなら True を、そうでなければ False を返します。英字は、Unicode 文字データベースで "Letter" として定義されているもので、すなわち、一般カテゴリプロパティ "Lm"、 "Lt"、 "Lu"、 "Ll"、 "Lo" のいずれかをもつものです。なお、これは Unicode 標準で定義されている "Alphabetic" プロパティとは異なるものです。
str.isascii()
文字列が空であるか、文字列の全ての文字が ASCII である場合に True を、それ以外の場合に False を返します。 ASCII 文字のコードポイントは U+0000-U+007F の範囲にあります。
バージョン 3.7 で追加.
str.isdecimal()
文字列中の全ての文字が十進数字で、かつ 1 文字以上あるなら True を、そうでなければ False を返します。十進数字とは十進数を書くのに使われる文字のことで、たとえば U+0660 (ARABIC-INDIC DIGIT ZERO) なども含みます。正式には、Unicode の一般カテゴリ "Nd" に含まれる文字を指します。
str.isdigit()
文字列中の全ての文字が数字で、かつ 1 文字以上あるなら True を、そうでなければ False を返します。ここでの数字とは、十進数字に加えて、互換上付き数字のような特殊操作を必要とする数字を含みます。また 10 を基数とした表現ができないカローシュティー数字のような体系の文字も含みます。正式には、数字とは、プロパティ値 Numeric_Type=Digit または Numeric_Type=Decimal を持つ文字です。
str.isidentifier()
文字列が、 識別子 (identifier) およびキーワード (keyword) 節の言語定義における有効な識別子であれば True を返します。
文字列 s が def や class のような予約済みの識別子か判定するには keyword.iskeyword() を呼び出してください。
例:
>>>
>>> from keyword import iskeyword
>>> 'hello'.isidentifier(), iskeyword('hello')
True, False
>>> 'def'.isidentifier(), iskeyword('def')
True, True
str.islower()
文字列中の大小文字の区別のある文字 4 全てが小文字で、かつ大小文字の区別のある文字が 1 文字以上あるなら True を、そうでなければ False を返します。
str.isnumeric()
文字列中の全ての文字が数を表す文字で、かつ 1 文字以上あるなら True を、そうでなければ False を返します。数を表す文字は、数字と、Unicode の数値プロパティを持つ全ての文字を含みます。たとえば U+2155 (VULGAR FRACTION ONE FIFTH)。正式には、数を表す文字は、プロパティ値 Numeric_Type=Digit、 Numeric_Type=Decimal または Numeric_Type=Numeric を持つものです。
str.isprintable()
文字列中のすべての文字が印字可能であるか、文字列が空であれば True を、そうでなければ False を返します。非印字可能文字は、 Unicode 文字データベースで "Other" または "Separator" と定義されている文字の、印字可能と見なされる ASCII space (0x20) 以外のものです。(なお、この文脈での印字可能文字は、文字列に repr() が呼び出されるときにエスケープすべきでない文字のことです。これは sys.stdout や sys.stderr に書き込まれる文字列の操作とは関係ありません。)
str.isspace()
文字列が空白文字だけからなり、かつ 1 文字以上ある場合には True を返し、そうでない場合は False を返します。
Unicode 文字データベース (unicodedata を参照) で一般カテゴリが Zs ("Seperator, space") であるか、 双方向クラスが　WS、B、 S のいずれかである場合、その文字は 空白文字(whitespace) です。
str.istitle()
文字列がタイトルケース文字列であり、かつ 1 文字以上ある場合、例えば大文字は大小文字の区別のない文字の後にのみ続き、小文字は大小文字の区別のある文字の後ろにのみ続く場合には True を返します。そうでない場合は False を返します。
str.isupper()
文字列中の大小文字の区別のある文字 4 全てが大文字で、かつ大小文字の区別のある文字が 1 文字以上あるなら True を、そうでなければ False を返します。
>>>
>>> 'BANANA'.isupper()
True
>>> 'banana'.isupper()
False
>>> 'baNana'.isupper()
False
>>> ' '.isupper()
False
str.join(iterable)
iterable 中の文字列を結合した文字列を返します。 iterable に bytes オブジェクトのような非文字列の値が存在するなら、 TypeError が送出されます。要素間のセパレータは、このメソッドを提供する文字列です。
str.ljust(width[, fillchar])
長さ width の左揃えした文字列を返します。パディングは指定された fillchar (デフォルトでは ASCII スペース) を使って行われます。 width が len(s) 以下ならば、元の文字列が返されます。
str.lower()
全ての大小文字の区別のある文字 4 が小文字に変換された、文字列のコピーを返します。
使われる小文字化のアルゴリズムは Unicode Standard のセクション 3.13 に記述されています。
str.lstrip([chars])
文字列の先頭の文字を除去したコピーを返します。引数 chars は除去される文字の集合を指定する文字列です。 chars が省略されるか None の場合、空白文字が除去されます。 chars 文字列は接頭辞ではなく、その値に含まれる文字の組み合わせ全てがはぎ取られます:
>>>
>>> '   spacious   '.lstrip()
'spacious   '
>>> 'www.example.com'.lstrip('cmowz.')
'example.com'
See str.removeprefix() for a method that will remove a single prefix string rather than all of a set of characters. For example:
>>>
>>> 'Arthur: three!'.lstrip('Arthur: ')
'ee!'
>>> 'Arthur: three!'.removeprefix('Arthur: ')
'three!'
static str.maketrans(x[, y[, z]])
この静的メソッドは str.translate() に使える変換テーブルを返します。
引数を 1 つだけ与える場合、それは Unicode 序数 (整数) または文字 (長さ 1 の文字列) を、Unicode 序数、(任意長の) 文字列、または None に対応づける辞書でなければなりません。このとき、文字で指定したキーは序数に変換されます。
引数を 2 つ指定する場合、それらは同じ長さの文字列である必要があり、結果の辞書では、x のそれぞれの文字が y の同じ位置の文字に対応付けられます。第 3 引数を指定する場合、文字列を指定する必要があり、それに含まれる文字が None に対応付けられます。
str.partition(sep)
文字列を sep の最初の出現位置で区切り、 3 要素のタプルを返します。タプルの内容は、区切りの前の部分、区切り文字列そのもの、そして区切りの後ろの部分です。もし区切れなければ、タプルには元の文字列そのものとその後ろに二つの空文字列が入ります。
str.removeprefix(prefix, /)
文字列が prefix で始まる場合、 string[len(prefix):] を返します。それ以外の場合、元の文字列のコピーを返します:
>>>
>>> 'TestHook'.removeprefix('Test')
'Hook'
>>> 'BaseTestCase'.removeprefix('Test')
'BaseTestCase'
バージョン 3.9 で追加.
str.removesuffix(suffix, /)
文字列が suffix で終わる場合、 string[:-len(suffix)] を返します。それ以外の場合、元の文字列のコピーを返します:
>>>
>>> 'MiscTests'.removesuffix('Tests')
'Misc'
>>> 'TmpDirMixin'.removesuffix('Tests')
'TmpDirMixin'
バージョン 3.9 で追加.
str.replace(old, new[, count])
文字列をコピーし、現れる部分文字列 old 全てを new に置換して返します。オプション引数 count が与えられている場合、先頭から count 個の old だけを置換します。
str.rfind(sub[, start[, end]])
文字列中の領域 s[start:end] に sub が含まれる場合、その最大のインデックスを返します。オプション引数 start および end はスライス表記と同様に解釈されます。 sub が見つからなかった場合 -1 を返します。
str.rindex(sub[, start[, end]])
rfind() と同様ですが、 sub が見つからなかった場合 ValueError を送出します。
str.rjust(width[, fillchar])
width の長さをもつ右寄せした文字列を返します。パディングには fillchar で指定された文字(デフォルトでは ASCII スペース)が使われます。 width が len(s) 以下の場合、元の文字列が返されます。
str.rpartition(sep)
文字列を sep の最後の出現位置で区切り、 3 要素のタプルを返します。タプルの内容は、区切りの前の部分、区切り文字列そのもの、そして区切りの後ろの部分です。もし区切れなければ、タプルには二つの空文字列とその後ろに元の文字列そのものが入ります。
str.rsplit(sep=None, maxsplit=-1)
sep を区切り文字とした、文字列中の単語のリストを返します。 maxsplit が与えられた場合、文字列の 右端 から最大 maxsplit 回分割を行います。sep が指定されていない、あるいは None のとき、全ての空白文字が区切り文字となります。右から分割していくことを除けば、 rsplit() は後ほど詳しく述べる split() と同様に振る舞います。
str.rstrip([chars])
文字列の末尾部分を除去したコピーを返します。引数 chars は除去される文字集合を指定する文字列です。 chars が省略されるか None の場合、空白文字が除去されます。 chars 文字列は接尾語ではなく、そこに含まれる文字の組み合わせ全てがはぎ取られます:
>>>
>>> '   spacious   '.rstrip()
'   spacious'
>>> 'mississippi'.rstrip('ipz')
'mississ'
See str.removesuffix() for a method that will remove a single suffix string rather than all of a set of characters. For example:
>>>
>>> 'Monty Python'.rstrip(' Python')
'M'
>>> 'Monty Python'.removesuffix(' Python')
'Monty'
str.split(sep=None, maxsplit=-1)
文字列を sep をデリミタ文字列として区切った単語のリストを返します。maxsplit が与えられていれば、最大で maxsplit 回分割されます (つまり、リストは最大 maxsplit+1 要素になります)。 maxsplit が与えられないか -1 なら、分割の回数に制限はありません (可能なだけ分割されます)。
sep が与えられた場合、連続した区切り文字はまとめられず、空の文字列を区切っていると判断されます(例えば '1,,2'.split(',') は ['1', '', '2'] を返します)。引数 sep は複数の文字にもできます (例えば '1<>2<>3'.split('<>') は ['1', '2', '3'] を返します)。区切り文字を指定して空の文字列を分割すると、 [''] を返します。
例えば:
>>>
>>> '1,2,3'.split(',')
['1', '2', '3']
>>> '1,2,3'.split(',', maxsplit=1)
['1', '2,3']
>>> '1,2,,3,'.split(',')
['1', '2', '', '3', '']
sep が指定されていないか None の場合、異なる分割アルゴリズムが適用されます。連続する空白文字はひとつのデリミタとみなされます。また、文字列の先頭や末尾に空白があっても、結果の最初や最後に空文字列は含まれません。よって、空文字列や空白だけの文字列を None デリミタで分割すると [] が返されます。
例えば:
>>>
>>> '1 2 3'.split()
['1', '2', '3']
>>> '1 2 3'.split(maxsplit=1)
['1', '2 3']
>>> '   1   2   3   '.split()
['1', '2', '3']
str.splitlines([keepends])
文字列を改行部分で分解し、各行からなるリストを返します。 keepends に真が与えらない限り、返されるリストに改行は含まれません。
このメソッドは以下の行境界で分解します。特に、以下の境界は universal newlines のスーパーセットです。
表現
説明
\n
改行
\r
復帰
\r\n
改行 + 復帰
\v or \x0b
垂直タブ
\f or \x0c
改ページ
\x1c
ファイル区切り
\x1d
グループ区切り
\x1e
レコード区切り
\x85
改行 (C1 制御コード)
\u2028
行区切り
\u2029
段落区切り
バージョン 3.2 で変更: \v と \f が行境界のリストに追加されました。
例えば:
>>>
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines()
['ab c', '', 'de fg', 'kl']
>>> 'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
['ab c\n', '\n', 'de fg\r', 'kl\r\n']
split() とは違って、デリミタ文字列 sep が与えられたとき、このメソッドは空文字列に空リストを返し、終末の改行は結果に行を追加しません:
>>>
>>> "".splitlines()
[]
>>> "One line\n".splitlines()
['One line']
比較のために split('\n') は以下のようになります:
>>>
>>> ''.split('\n')
['']
>>> 'Two lines\n'.split('\n')
['Two lines', '']
str.startswith(prefix[, start[, end]])
文字列が指定された prefix で始まるなら True を、そうでなければ False を返します。 prefix は見つけたい複数の接頭語のタプルでも構いません。オプションの start があれば、その位置から判定を始めます。オプションの end があれば、その位置で比較を止めます。
str.strip([chars])
文字列の先頭および末尾部分を除去したコピーを返します。引数 chars は除去される文字集合を指定する文字列です。 chars が省略されるか None の場合、空白文字が除去されます。 chars 文字列は接頭語でも接尾語でもなく、そこに含まれる文字の組み合わせ全てがはぎ取られます:
>>>
>>> '   spacious   '.strip()
'spacious'
>>> 'www.example.com'.strip('cmowz.')
'example'
文字列の最も外側の先頭および末尾から、引数 chars 値がはぎ取られます。文字列の先頭から chars の文字集合に含まれない文字に達するまで、文字が削除されます。文字列の末尾に対しても同様の操作が行われます。例えば、次のようになります:
>>>
>>> comment_string = '#....... Section 3.2.1 Issue #32 .......'
>>> comment_string.strip('.#! ')
'Section 3.2.1 Issue #32'
str.swapcase()
大文字が小文字に、小文字が大文字に変換された、文字列のコピーを返します。なお、 s.swapcase().swapcase() == s が真であるとは限りません。
str.title()
文字列を、単語ごとに大文字から始まり、残りの文字のうち大小文字の区別があるものは全て小文字にする、タイトルケースにして返します。
例えば:
>>>
>>> 'Hello world'.title()
'Hello World'
このアルゴリズムは、連続した文字の集まりという、言語から独立した単純な単語の定義を使います。この定義は多くの状況ではうまく機能しますが、短縮形や所有格のアポストロフィが単語の境界になってしまい、望みの結果を得られない場合があります:
>>>
>>> "they're bill's friends from the UK".title()
"They'Re Bill'S Friends From The Uk"
正規表現を使うことでアポストロフィに対応できます:
>>>
>>> import re
>>> def titlecase(s):
...     return re.sub(r"[A-Za-z]+('[A-Za-z]+)?",
...                   lambda mo: mo.group(0).capitalize(),
...                   s)
...
>>> titlecase("they're bill's friends.")
"They're Bill's Friends."
str.translate(table)
与えられた変換テーブルに基づいて文字列を構成する各文字をマッピングし、マッピング後の文字列のコピーを返します。変換テーブルは、__getitem__() によるインデックス指定を実装するオブジェクトである必要があります。一般的には、 mapping または sequence です。Unicode 序数 (整数) でインデックス指定する場合、変換テーブルのオブジェクトは次のいずれも行うことができます。Unicode 序数または文字列を返して文字を 1 文字以上の別の文字にマッピングすること、None を返して返り値の文字列から指定した文字を削除すること、例外 LookupError を送出して文字をその文字自身にマッピングすること。
文字から文字への異なる形式のマッピングから変換マップを作成するために、 str.maketrans() が使えます。
文字のマッピングを好みに合わせてより柔軟に変更する方法については、codecs モジュールも参照してください。
str.upper()
全ての大小文字の区別のある文字 4 が大文字に変換された、文字列のコピーを返します。なお s.upper().isupper() は、 s が大小文字の区別のある文字を含まなかったり、結果の文字の Unicode カテゴリが "Lu" ではなく例えば "Lt" (Letter, titlecase) などであったら、 False になりえます。
使われる大文字化のアルゴリズムは Unicode Standard のセクション 3.13 に記述されています。
str.zfill(width)
長さが width になるよう ASCII '0' で左詰めした文字列のコピーを返します。先頭が符号接頭辞 ('+'/'-') だった場合、 '0' は符号の前ではなく 後 に挿入されます。width が len(s) 以下の場合元の文字列を返します。
例えば:
>>>
>>> "42".zfill(5)
'00042'
>>> "-42".zfill(5)
'-0042'
printf 形式の文字列書式化
注釈 ここで解説されているフォーマット操作には、(タプルや辞書を正しく表示するのに失敗するなどの) よくある多くの問題を引き起こす、様々な欠陥が出現します。 新しい フォーマット済み文字列リテラル や str.format() インターフェースや テンプレート文字列 が、これらの問題を回避する助けになるでしょう。 これらの代替手段には、それ自身に、トレードオフや、簡潔さ、柔軟さ、拡張性といった利点があります。
文字列オブジェクトには固有の操作: % 演算子 (モジュロ) があります。この演算子は文字列 書式化 または 補間 演算子とも呼ばれます。format % values (format は文字列) とすると、format 中の % 変換指定は values 中のゼロ個またはそれ以上の要素で置換されます。この動作は C 言語における sprintf() に似ています。
format が単一の引数しか要求しない場合、 values はタプルでない単一のオブジェクトでもかまいません。 5 それ以外の場合、 values はフォーマット文字列中で指定された項目と正確に同じ数の要素からなるタプルか、単一のマップオブジェクトでなければなりません。
一つの変換指定子は 2 またはそれ以上の文字を含み、その構成要素は以下からなりますが、示した順に出現しなければなりません:
指定子の開始を示す文字 '%' 。
マップキー (オプション)。丸括弧で囲った文字列からなります (例えば (somename)) 。
変換フラグ (オプション)。一部の変換型の結果に影響します。
最小のフィールド幅 (オプション)。 '*' (アスタリスク) を指定した場合、実際の文字列幅が values タプルの次の要素から読み出されます。タプルには最小フィールド幅やオプションの精度指定の後に変換したいオブジェクトがくるようにします。
精度 (オプション)。 '.' (ドット) とその後に続く精度で与えられます。 '*' (アスタリスク) を指定した場合、精度の桁数は values タプルの次の要素から読み出されます。タプルには精度指定の後に変換したい値がくるようにします。
精度長変換子 (オプション)。
変換型。
% 演算子の右側の引数が辞書の場合 (またはその他のマップ型の場合), 文字列中のフォーマットには、辞書に挿入されているキーを丸括弧で囲い、文字 '%' の直後にくるようにしたものが含まれていなければ なりません 。マップキーはフォーマット化したい値をマップから選び出します。例えば:
>>>
>>> print('%(language)s has %(number)03d quote types.' %
...       {'language': "Python", "number": 2})
この場合、 * 指定子をフォーマットに含めてはいけません (* 指定子は順番付けされたパラメタのリストが必要だからです)。
変換フラグ文字を以下に示します:
Flag
意味
'#'
値の変換に (下で定義されている) "別の形式" を使います。
'0'
数値型に対してゼロによるパディングを行います。
'-'
変換された値を左寄せにします ('0' と同時に与えた場合、 '0' を上書きします) 。
' '
(スペース) 符号付きの変換で正の数の場合、前に一つスペースを空けます (そうでない場合は空文字になります) 。
'+'
変換の先頭に符号文字 ('+' または '-') を付けます("スペース" フラグを上書きします) 。
精度長変換子(h, l,または L) を使うことができますが、 Python では必要ないため無視されます。 -- つまり、例えば %ld は %d と等価です。
変換型を以下に示します:
変換
意味
注釈
'd'
符号付き 10 進整数。
'i'
符号付き 10 進整数。
'o'
符号付き 8 進数。
(1)
'u'
旧式の型 -- 'd' と同じです。
(6)
'x'
符号付き 16 進数 (小文字)。
(2)
'X'
符号付き 16 進数 (大文字)。
(2)
'e'
指数表記の浮動小数点数 (小文字)。
(3)
'E'
指数表記の浮動小数点数 (大文字)。
(3)
'f'
10 進浮動小数点数。
(3)
'F'
10 進浮動小数点数。
(3)
'g'
浮動小数点数。指数部が -4 以上または精度以下の場合には小文字指数表記、それ以外の場合には10進表記。
(4)
'G'
浮動小数点数。指数部が -4 以上または精度以下の場合には大文字指数表記、それ以外の場合には10進表記。
(4)
'c'
文字一文字 (整数または一文字からなる文字列を受理します)。
'r'
文字列 (Python オブジェクトを repr() で変換します)。
(5)
's'
文字列 (Python オブジェクトを str() で変換します)。
(5)
'a'
文字列 (Python オブジェクトを ascii() で変換します)。
(5)
'%'
引数を変換せず、返される文字列中では文字 '%' になります。
注釈:
別の形式を指定（訳注: 変換フラグ # を使用）すると 8 進数を表す接頭辞 ('0o') が最初の数字の前に挿入されます。
別の形式を指定（訳注: 変換フラグ # を使用）すると 16 進数を表す接頭辞 '0x' または '0X' (使用するフォーマット文字が 'x' か 'X' に依存します) が最初の数字の前に挿入されます。
この形式にした場合、変換結果には常に小数点が含まれ、それはその後ろに数字が続かない場合にも適用されます。
指定精度は小数点の後の桁数を決定し、そのデフォルトは 6 です。
この形式にした場合、変換結果には常に小数点が含まれ他の形式とは違って末尾の 0 は取り除かれません。
指定精度は小数点の前後の有効桁数を決定し、そのデフォルトは 6 です。
精度が N なら、出力は N 文字に切り詰められます。
PEP 237 を参照してください。
Python 文字列には明示的な長さ情報があるので、 %s 変換において '\0' を文字列の末端と仮定したりはしません。
バージョン 3.1 で変更: 絶対値が 1e50 を超える数値の %f 変換が %g 変換に置き換えられなくなりました。
バイナリシーケンス型 --- bytes, bytearray, memoryview
バイナリデータを操作するためのコア組み込み型は bytes および bytearray です。これらは、別のバイナリオブジェクトのメモリにコピーを作成すること無くアクセスするための バッファプロトコル を利用する memoryview でサポートされています。
array モジュールは、32 ビット整数や IEEE754 倍精度浮動小数点値のような基本データ型の、効率的な保存をサポートしています。
バイトオブジェクト
bytes はバイトの不変なシーケンスです。多くのメジャーなプロトコルがASCIIテキストエンコーディングをベースにしているので、 bytes オブジェクトは ASCII 互換のデータに対してのみ動作する幾つかのメソッドを提供していて、文字列オブジェクトと他の多くの点で近いです。
class bytes([source[, encoding[, errors]]])
まず、 bytes リテラルの構文は文字列リテラルとほぼ同じで、 b というプリフィックスを付けます:
シングルクォート: b'still allows embedded "double" quotes'
ダブルクォート: b"still allows embedded 'single' quotes".
3重クォート: b'''3 single quotes''', b"""3 double quotes"""
bytes リテラルでは (ソースコードのエンコーディングに関係なく) ASCII文字のみが許可されています。 127より大きい値を bytes リテラルに記述する場合は適切なエスケープシーケンスを書く必要があります。
文字列リテラルと同じく、 bytes リテラルでも r プリフィックスを用いてエスケープシーケンスの処理を無効にすることができます。 bytes リテラルの様々な形式やサポートされているエスケープシーケンスについては 文字列およびバイト列リテラル を参照してください。
bytesリテラルと repr 出力は ASCII テキストをベースにしたものですが、 bytes オブジェクトは、各値が 0 <= x < 256 の範囲に収まるような整数 (この制限に違反しようとすると ValueError が発生します) の不変なシーケンスとして振る舞います。多くのバイナリフォーマットがASCIIテキストを元にした要素を持っていたり何らかのテキスト操作アルゴリズムによって操作されるものの、任意のバイナリデータが一般にテキストになっているわけではないことを強調するためにこのように設計されました (何も考えずにテキスト操作アルゴリズムをASCII非互換なバイナリデータフォーマットに対して行うとデータを破壊することがあります)。
リテラル以外に、幾つかの方法で bytes オブジェクトを作ることができます:
指定された長さの、0で埋められた bytes オブジェクト: bytes(10)
整数の iterable から: bytes(range(20))
既存のバイナリデータからバッファプロトコルでコピーする: bytes(obj)
bytes ビルトイン関数も参照してください。
16 進数で 2 桁の数は正確に 1 バイトに相当するため、16 進整はバイナリデータを表現する形式として広く使われています。 従って、 bytes 型にはその形式でデータを読み取るための追加のクラスメソッドがあります。
classmethod fromhex(string)
この bytes のクラスメソッドは、与えられた文字列オブジェクトをデコードして bytes オブジェクトを返します。それぞれのバイトを 16 進数 2 桁で表現した文字列を指定しなければなりません。ASCII 空白文字は無視されます。
>>>
>>> bytes.fromhex('2Ef0 F1f2  ')
b'.\xf0\xf1\xf2'
バージョン 3.7 で変更: bytes.fromhex() は文字列にある空白だけでなく、 ASCII の空白文字全てをスキップするようになりました。
bytes オブジェクトをその 16 進表記に変換するための、反対向きの変換関数があります。
hex([sep[, bytes_per_sep]])
インスタンス内の 1 バイトにつき 2 つの 16 進数を含む、文字列オブジェクトを返します。
>>>
>>> b'\xf0\xf1\xf2'.hex()
'f0f1f2'
>>>
>>> value = b'\xf0\xf1\xf2'
>>> value.hex('-')
'f0-f1-f2'
>>> value.hex('_', 2)
'f0_f1f2'
>>> b'UUDDLRLRAB'.hex(' ', -4)
'55554444 4c524c52 4142'
バージョン 3.5 で追加.
バージョン 3.8 で変更: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output.
bytes オブジェクトは (タプルに似た) 整数のシーケンスなので、 bytes オブジェクト b について、 b[0] は整数になり、 b[0:1] は長さ 1 の bytes オブジェクトになります。 (この動作は、文字列に対するインデックス指定もスライスも長さ 1 の文字列を返すのと対照的です。)
bytes オブジェクトの repr 出力はリテラル形式 (b'...') になります。 bytes([46, 46, 46]) などの形式よりも便利な事が多いからです。 bytes オブジェクトはいつでも list(b) で整数のリストに変換できます。
注釈 Python 2.x ユーザーへ: Python 2.x では多くの場面で 8bit 文字列 (2.x が提供しているビルトインのバイナリデータ型) と Unicode 文字列の間の暗黙の変換が許可されていました。これは Python がもともと 8bit 文字列しか持っていなくて、あとから Unicode テキストが追加されたので、後方互換性を維持するためのワークアラウンドでした。 Python 3.x ではこれらの暗黙の変換はなくなりました。 8-bit バイナリデータと Unicode テキストは明確に違うもので、 bytes オブジェクトと文字列オブジェクトを比較すると常に等しくなりません。
bytearray オブジェクト
bytearray オブジェクトは bytes オブジェクトの可変なバージョンです。
class bytearray([source[, encoding[, errors]]])
bytearray に専用のリテラル構文はないので、コンストラクタを使って作成します:
空のインスタンスを作る: bytearray()
指定された長さの0で埋められたインスタンスを作る: bytearray(10)
整数の iterable から: bytearray(range(20))
既存のバイナリデータからバッファプロトコルを通してコピーする: bytearray(b'Hi!')
bytearray オブジェクトは可変なので、 bytes と bytearray の操作 で解説されている bytes オブジェクトと共通の操作に加えて、 mutable シーケンス操作もサポートしています。
bytearray ビルトイン関数も参照してください。
16 進数で 2 桁の数は正確に 1 バイトに相当するため、16 進整はバイナリデータを表現する形式として広く使われています。 従って、 bytearray 型にはその形式でデータを読み取るための追加のクラスメソッドがあります。
classmethod fromhex(string)
この bytearray のクラスメソッドは、与えられた文字列オブジェクトをデコードして bytearray オブジェクトを返します。それぞれのバイトを 16 進数 2 桁で表現した文字列を指定しなければなりません。ASCII 空白文字は無視されます。
>>>
>>> bytearray.fromhex('2Ef0 F1f2  ')
bytearray(b'.\xf0\xf1\xf2')
バージョン 3.7 で変更: bytearray.fromhex() は文字列にある空白だけでなく、 ASCII の空白文字全てをスキップするようになりました。
bytearray オブジェクトをその 16 進表記に変換するための、反対向きの変換関数があります。
hex([sep[, bytes_per_sep]])
インスタンス内の 1 バイトにつき 2 つの 16 進数を含む、文字列オブジェクトを返します。
>>>
>>> bytearray(b'\xf0\xf1\xf2').hex()
'f0f1f2'
バージョン 3.5 で追加.
バージョン 3.8 で変更: Similar to bytes.hex(), bytearray.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output.
bytearray オブジェクトは整数のシーケンス (リストのようなもの) なので、 bytearray オブジェクト b について、 b[0] は整数になり、 b[0:1] は長さ 1 の bytearray オブジェクトになります。(これは、文字列においてインデックス指定もスライスも長さ 1 の文字列を返すのと対照的です。)
bytearray オブジェクトの表記はバイトのリテラル形式 (bytearray(b'...')) を使用します。これは bytearray([46, 46, 46]) などの形式よりも便利な事が多いためです。 bytearray オブジェクトはいつでも list(b) で整数のリストに変換できます。
bytes と bytearray の操作
bytes と bytearray は両方共 一般のシーケンス操作 をサポートしています。また、両方とも bytes-like object をサポートしている任意のオブジェクトを対象に操作することもできます。この柔軟性により bytes と bytearray を自由に混ぜてもエラーを起こすことなく扱うことができます。ただし、操作の結果のオブジェクトはその操作の順序に依存することになります。
注釈 文字列のメソッドが引数として bytes を受け付けないのと同様、bytes オブジェクトと bytearray オブジェクトのメソッドは引数として文字列を受け付けません。例えば、以下のように書かなければなりません:
a = "abc"
b = a.replace("a", "f")
および:
a = b"abc"
b = a.replace(b"a", b"f")
いくつかの bytes と bytearray の操作は ASCII と互換性のあるバイナリフォーマットが使われていると仮定していますので、フォーマットの不明なバイナリデータに対して使うことは避けるべきです。こうした制約については以下で説明します。
注釈 これらの ASCII ベースの演算を使って ASCII ベースではないバイナリデータを操作すると、データを破壊する恐れがあります。
以下の bytes および bytearray オブジェクトのメソッドは、任意のバイナリデータに対して使用できます。
bytes.count(sub[, start[, end]])
bytearray.count(sub[, start[, end]])
[start, end] の範囲に、部分シーケンス sub が重複せず出現する回数を返します。オプション引数 start および end はスライス表記と同じように解釈されます。
検索対象の部分シーケンスは、任意の bytes-like object または 0 から 255 の範囲の整数にできます。
バージョン 3.3 で変更: 部分シーケンスとして 0 から 255 の範囲の整数も受け取れるようになりました。
bytes.removeprefix(prefix, /)
bytearray.removeprefix(prefix, /)
If the binary data starts with the prefix string, return bytes[len(prefix):]. Otherwise, return a copy of the original binary data:
>>>
>>> b'TestHook'.removeprefix(b'Test')
b'Hook'
>>> b'BaseTestCase'.removeprefix(b'Test')
b'BaseTestCase'
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
バージョン 3.9 で追加.
bytes.removesuffix(suffix, /)
bytearray.removesuffix(suffix, /)
If the binary data ends with the suffix string and that suffix is not empty, return bytes[:-len(suffix)]. Otherwise, return a copy of the original binary data:
>>>
>>> b'MiscTests'.removesuffix(b'Tests')
b'Misc'
>>> b'TmpDirMixin'.removesuffix(b'Tests')
b'TmpDirMixin'
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
バージョン 3.9 で追加.
bytes.decode(encoding="utf-8", errors="strict")
bytearray.decode(encoding="utf-8", errors="strict")
与えられたバイト列からデコードされた文字列を返します。デフォルトのエンコーディングは 'utf-8' です。 errors を与えて異なるエラー処理法を設定できます。 errors のデフォルトは 'strict' で、エンコーディングエラーが UnicodeError を送出します。設定できる他の値は、 'ignore' 、 'replace' 、その他の codecs.register_error() を通して登録された名前で、節 エラーハンドラ を参照してください。可能なエンコーディングのリストは、 標準エンコーディング を参照してください。
注釈 引数 encoding を str に渡すと bytes-like object を直接デコードすることができます。つまり、一時的な bytes や bytearray オブジェクトを作成する必要はありません。
バージョン 3.1 で変更: キーワード引数のサポートが追加されました。
bytes.endswith(suffix[, start[, end]])
bytearray.endswith(suffix[, start[, end]])
バイナリデータが指定された suffix で終わる場合は True を、そうでなければ False を返します。 suffix は見つけたい複数の接尾語のタプルでも構いません。オプションの start が指定されている場合、その位置から判定を開始します。オプションの end が指定されている場合、その位置で比較を終了します。
検索対象の接尾語 (複数も可) は、任意の bytes-like object にできます。
bytes.find(sub[, start[, end]])
bytearray.find(sub[, start[, end]])
スライス s[start:end] に部分シーケンス sub が含まれる場合、データ中のその sub の最小のインデックスを返します。オプション引数 start および end はスライス表記と同様に解釈されます。 sub が見つからなかった場合、 -1 を返します。
検索対象の部分シーケンスは、任意の bytes-like object または 0 から 255 の範囲の整数にできます。
注釈 find() メソッドは、 sub の位置を知りたいときにのみ使うべきです。 sub が部分文字列 (訳注: おそらく原文の誤り、正しくは部分シーケンス) であるかどうかのみを調べるには、 in 演算子を使ってください:
>>>
>>> b'Py' in b'Python'
True
バージョン 3.3 で変更: 部分シーケンスとして 0 から 255 の範囲の整数も受け取れるようになりました。
bytes.index(sub[, start[, end]])
bytearray.index(sub[, start[, end]])
find() と同様ですが、部分シーケンスが見つからなかった場合 ValueError を送出します。
検索対象の部分シーケンスは、任意の bytes-like object または 0 から 255 の範囲の整数にできます。
バージョン 3.3 で変更: 部分シーケンスとして 0 から 255 の範囲の整数も受け取れるようになりました。
bytes.join(iterable)
bytearray.join(iterable)
iterable 中のバイナリデータを結合した bytes または bytearray オブジェクトを返します。 iterable に str オブジェクトなど bytes-like objects ではない値が含まれている場合、 TypeError が送出されます。なお要素間のセパレータは、このメソッドを提供する bytes または bytearray オブジェクトとなります。
static bytes.maketrans(from, to)
static bytearray.maketrans(from, to)
この静的メソッドは、 bytes.translate() に渡すのに適した変換テーブルを返します。このテーブルは、 from 中の各バイトを to の同じ位置にあるバイトにマッピングします。 from と to は両方とも同じ長さの bytes-like objects でなければなりません。
バージョン 3.1 で追加.
bytes.partition(sep)
bytearray.partition(sep)
区切り sep が最初に出現する位置でシーケンスを分割し、 3 要素のタプルを返します。タプルの内容は、区切りの前の部分、その区切りオブジェクトまたはその bytearray 型のコピー、そして区切りの後ろの部分です。もし区切れなければ、タプルには元のシーケンスのコピーと、その後ろに二つの空の bytes または bytearray オブジェクトが入ります。
検索する区切りとしては、任意の bytes-like object を指定できます。
bytes.replace(old, new[, count])
bytearray.replace(old, new[, count])
部分シーケンス old を全て new に置換したシーケンスを返します。オプション引数 count が与えられている場合、先頭から count 個の old だけを置換します。
検索する部分シーケンスおよび置換後の部分シーケンスとしては、任意の bytes-like object を指定できます。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.rfind(sub[, start[, end]])
bytearray.rfind(sub[, start[, end]])
シーケンス中の領域 s[start:end] に sub が含まれる場合、その最大のインデックスを返します。オプション引数 start および end はスライス表記と同様に解釈されます。 sub が見つからなかった場合 -1 を返します。
検索対象の部分シーケンスは、任意の bytes-like object または 0 から 255 の範囲の整数にできます。
バージョン 3.3 で変更: 部分シーケンスとして 0 から 255 の範囲の整数も受け取れるようになりました。
bytes.rindex(sub[, start[, end]])
bytearray.rindex(sub[, start[, end]])
rfind() と同様ですが、部分シーケンス sub が見つからなかった場合 ValueError を送出します。
検索対象の部分シーケンスは、任意の bytes-like object または 0 から 255 の範囲の整数にできます。
バージョン 3.3 で変更: 部分シーケンスとして 0 から 255 の範囲の整数も受け取れるようになりました。
bytes.rpartition(sep)
bytearray.rpartition(sep)
検索する区切りとしては、任意の bytes-like object を指定できます。
bytes.startswith(prefix[, start[, end]])
bytearray.startswith(prefix[, start[, end]])
バイナリデータが指定された prefix で始まる場合は True を、そうでなければ False を返します。 prefix は見つけたい複数の接頭語のタプルでも構いません。オプションの start が指定されている場合、その位置から判定を開始します。オプションの end が指定されている場合、その位置で比較を終了します。
検索対象の接頭語 (複数も可) は、任意の bytes-like object にできます。
bytes.translate(table, /, delete=b'')
bytearray.translate(table, /, delete=b'')
オプション引数 delete に現れるすべてのバイトを除去し、残ったバイトを与えられた変換テーブルに従ってマップした、バイト列やバイト配列オブジェクトのコピーを返します。変換テーブルは長さ 256 のバイト列オブジェクトでなければなりません。
変換テーブルの作成に、 bytes.maketrans() メソッドを使うこともできます。
文字を削除するだけの変換には、 table 引数を None に設定してください:
>>>
>>> b'read this short text'.translate(None, b'aeiou')
b'rd ths shrt txt'
バージョン 3.6 で変更: delete はキーワード引数として指定可能になりました。
以下の bytes および bytearray オブジェクトのメソッドは、 ASCII と互換性のあるバイナリフォーマットが使われていると仮定していますが、適切な引数を指定すれば任意のバイナリデータに使用できます。なお、このセクションで紹介する bytearray のメソッドはすべてインプレースで動作 せず 、新しいオブジェクトを生成します。
bytes.center(width[, fillbyte])
bytearray.center(width[, fillbyte])
長さ width の中央寄せされたシーケンスのコピーを返します。パディングには fillbyte で指定された値 (デフォルトでは ASCII スペース) が使われます。 bytes オブジェクトの場合、 width が len(s) 以下なら元のシーケンスが返されます。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.ljust(width[, fillbyte])
bytearray.ljust(width[, fillbyte])
長さ width の左寄せされたシーケンスのコピーを返します。パディングには fillbyte で指定された値 (デフォルトでは ASCII スペース) が使われます。 bytes オブジェクトの場合、 width が len(s) 以下なら元のシーケンスが返されます。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.lstrip([chars])
bytearray.lstrip([chars])
先頭から特定のバイト値を除去したコピーを返します。引数 chars は除去されるバイト値の集合を指定するバイナリシーケンスです － この名前は、このメソッドが通常は ASCII 文字列に対して使われることに由来しています。 chars が省略されるか None の場合、 ASCII の空白文字（訳注: 半角スペース）が除去されます。なお chars 引数と一致する接頭辞が除去されるのではなく、それに含まれるバイトの組み合わせ全てが除去されます:
>>>
>>> b'   spacious   '.lstrip()
b'spacious   '
>>> b'www.example.com'.lstrip(b'cmowz.')
b'example.com'
>>>
>>> b'Arthur: three!'.lstrip(b'Arthur: ')
b'ee!'
>>> b'Arthur: three!'.removeprefix(b'Arthur: ')
b'three!'
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.rjust(width[, fillbyte])
bytearray.rjust(width[, fillbyte])
長さ width の右寄せされたシーケンスのコピーを返します。パディングには fillbyte で指定された値 (デフォルトでは ASCII スペース) が使われます。 bytes オブジェクトの場合、 width が len(s) 以下なら元のシーケンスが返されます。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.rsplit(sep=None, maxsplit=-1)
bytearray.rsplit(sep=None, maxsplit=-1)
sep を区切りとして、同じ型の部分シーケンスに分割します。 maxsplit が与えられた場合、シーケンスの 右端 から最大 maxsplit 回だけ分割を行います。 sep が指定されていないか None のとき、 ASCII 空白文字の組み合わせで作られる部分シーケンスすべてが区切りとなります。右から分割していくことを除けば、 rsplit() は後ほど詳しく述べる split() と同様に振る舞います。
bytes.rstrip([chars])
bytearray.rstrip([chars])
末尾から特定のバイト値を除去したコピーを返します。引数 chars は除去されるバイト値の集合を指定するバイナリシーケンスです － この名前は、このメソッドが通常は ASCII 文字列に対して使われることに由来しています。 chars が省略されるか None の場合、 ASCII の空白文字（訳注: 半角スペース）が除去されます。なお chars 引数と一致する接尾辞が除去されるのではなく、それに含まれるバイトの組み合わせ全てが除去されます:
>>>
>>> b'   spacious   '.rstrip()
b'   spacious'
>>> b'mississippi'.rstrip(b'ipz')
b'mississ'
>>>
>>> b'Monty Python'.rstrip(b' Python')
b'M'
>>> b'Monty Python'.removesuffix(b' Python')
b'Monty'
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.split(sep=None, maxsplit=-1)
bytearray.split(sep=None, maxsplit=-1)
sep を区切りとして、同じ型の部分シーケンスに分割します。 maxsplit が与えられ、かつ負の数でない場合、シーケンスの 左端 から最大 maxsplit 回だけ分割を行います (したがって結果のリストの要素数は最大で maxsplit+1 になります)。 maxsplit が指定されていないか -1 のとき、分割の回数に制限はありません (可能なだけ分割されます)。
sep が与えられた場合、連続した区切り用バイト値はまとめられず、空の部分シーケンスを区切っていると判断されます(例えば b'1,,2'.split(b',') は [b'1', b'', b'2'] を返します)。引数 sep は複数バイトのシーケンスにもできます (例えば b'1<>2<>3'.split(b'<>') は [b'1', b'2', b'3'] を返します)。空のシーケンスを分割すると、分割するオブジェクトの型によって [b''] または [bytearray(b'')] が返ります。引数 sep には、あらゆる bytes-like object を指定できます。
例えば:
>>>
>>> b'1,2,3'.split(b',')
[b'1', b'2', b'3']
>>> b'1,2,3'.split(b',', maxsplit=1)
[b'1', b'2,3']
>>> b'1,2,,3,'.split(b',')
[b'1', b'2', b'', b'3', b'']
sep が指定されていないか None の場合、異なる分割アルゴリズムが適用されます。連続する ASCII 空白文字はひとつの区切りとみなされ、またシーケンスの先頭や末尾に空白があっても、結果の最初や最後に空のシーケンスは含まれません。したがって区切りを指定せずに空のシーケンスや ASCII 空白文字だけのシーケンスを分割すると、 [] が返されます。
例えば:
>>>
>>> b'1 2 3'.split()
[b'1', b'2', b'3']
>>> b'1 2 3'.split(maxsplit=1)
[b'1', b'2 3']
>>> b'   1   2   3   '.split()
[b'1', b'2', b'3']
bytes.strip([chars])
bytearray.strip([chars])
先頭および末尾から特定のバイト値を除去したコピーを返します。引数 chars は除去されるバイト値の集合を指定するバイナリシーケンスです － この名前は、このメソッドが通常は ASCII 文字列に対して使われることに由来しています。 chars が省略されるか None の場合、 ASCII の空白文字（訳注: 半角スペース）が除去されます。なお chars 引数と一致する接頭辞および接尾辞が除去されるのではなく、それに含まれるバイトの組み合わせ全てが除去されます:
>>>
>>> b'   spacious   '.strip()
b'spacious'
>>> b'www.example.com'.strip(b'cmowz.')
b'example'
除去対象のバイト値を含むバイナリシーケンスには、任意の bytes-like object を指定できます。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
以下の bytes および bytearray オブジェクトのメソッドは、 ASCII と互換性のあるバイナリフォーマットが使われていると仮定しており、任意のバイナリデータに対して使用すべきではありません。なお、このセクションで紹介する bytearray のメソッドはすべてインプレースで動作 せず 、新しいオブジェクトを生成します。
bytes.capitalize()
bytearray.capitalize()
各バイトを ASCII 文字と解釈して、最初のバイトを大文字にし、残りを小文字にしたシーケンスのコピーを返します。 ASCII 文字と解釈できないバイト値は、変更されません。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.expandtabs(tabsize=8)
bytearray.expandtabs(tabsize=8)
桁 (column) 位置と指定されたタブ幅 (tab size) に応じて、全ての ASCII タブ文字を 1 つ以上の ASCII スペース文字に置換したシーケンスのコピーを返します。ここで tabsize バイトごとの桁位置をタブ位置とします (デフォルト値である 8 の場合、タブ位置は 0 桁目、 8 桁目、 16 桁目、と続いていきます)。シーケンスを展開するにあたって、まず現桁位置をゼロに設定し、シーケンスを 1 バイトずつ調べていきます。もしバイト値が ASCII タブ文字 (b'\t') であれば、現桁位置が次のタブ位置と一致するまで 1 つ以上の ASCII スペース文字を結果のシーケンスに挿入していきます（ASCII タブ文字自体はコピーしません）。もしバイト値が ASCII 改行文字 (b'\n' もしくは b'\r') であれば、そのままコピーした上で現桁位置を 0 にリセットします。その他のバイト値については変更せずにコピーし、そのバイト値の表示のされ方（訳注: 全角、半角など）に関わらず現桁位置を 1 つ増加させます:
>>>
>>> b'01\t012\t0123\t01234'.expandtabs()
b'01      012     0123    01234'
>>> b'01\t012\t0123\t01234'.expandtabs(4)
b'01  012 0123    01234'
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.isalnum()
bytearray.isalnum()
シーケンスが空でなく、かつ全てのバイト値が ASCII 文字のアルファベットまたは数字である場合は True を、そうでなければ False を返します。ここでの ASCII 文字のアルファベットとはシーケンス b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。 ASCII 文字の数字とは b'0123456789' に含まれるバイト値です。
例えば:
>>>
>>> b'ABCabc1'.isalnum()
True
>>> b'ABC abc1'.isalnum()
False
bytes.isalpha()
bytearray.isalpha()
シーケンスが空でなく、かつ全てのバイト値が ASCII 文字のアルファベットである場合は True を、そうでなければ False を返します。ここでの ASCII 文字のアルファベットとはシーケンス b'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。
例えば:
>>>
>>> b'ABCabc'.isalpha()
True
>>> b'ABCabc1'.isalpha()
False
bytes.isascii()
bytearray.isascii()
シーケンスが空であるか、シーケンスの全てのバイトが ASCII である場合に True を、それ以外の場合に False を返します。 ASCII バイトは 0-0x7F の範囲にあります。
バージョン 3.7 で追加.
bytes.isdigit()
bytearray.isdigit()
シーケンスが空でなく、かつ全てのバイト値が ASCII 文字の数字である場合は True を、そうでなければ False を返します。ここでの ASCII 文字の数字とは b'0123456789' に含まれるバイト値です。
例えば:
>>>
>>> b'1234'.isdigit()
True
>>> b'1.23'.isdigit()
False
bytes.islower()
bytearray.islower()
シーケンス中に小文字アルファベットの ASCII 文字が一つ以上あり、かつ大文字アルファベットの ASCII 文字が一つも無い場合に True を返します。そうでなければ False を返します。
例えば:
>>>
>>> b'hello world'.islower()
True
>>> b'Hello world'.islower()
False
ここでの小文字の ASCII 文字とは b'abcdefghijklmnopqrstuvwxyz' に含まれるバイト値です。また大文字の ASCII 文字とは b'ABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。
bytes.isspace()
bytearray.isspace()
シーケンスが空でなく、かつ全てのバイト値が ASCII 空白文字である場合は True を、そうでなければ False を返します。ここでの ASCII 空白文字とはシーケンス b' \t\n\r\x0b\f' に含まれるバイト値です (半角スペース、タブ、ラインフィード、キャリッジリターン、垂直タブ、フォームフィード) 。
bytes.istitle()
bytearray.istitle()
シーケンスが空でなく、かつ ASCII のタイトルケース文字列になっている場合は True を、そうでなければ False を返します。「タイトルケース文字列」の定義については bytes.title() を参照してください。
例えば:
>>>
>>> b'Hello World'.istitle()
True
>>> b'Hello world'.istitle()
False
bytes.isupper()
bytearray.isupper()
シーケンス中に大文字アルファベットの ASCII 文字が一つ以上あり、かつ小文字アルファベットの ASCII 文字が一つも無い場合に True を返します。そうでなければ False を返します。
例えば:
>>>
>>> b'HELLO WORLD'.isupper()
True
>>> b'Hello world'.isupper()
False
ここでの小文字の ASCII 文字とは b'abcdefghijklmnopqrstuvwxyz' に含まれるバイト値です。また大文字の ASCII 文字とは b'ABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。
bytes.lower()
bytearray.lower()
シーケンスに含まれる大文字アルファベットの ASCII 文字を全て小文字アルファベットに変換したシーケンスのコピーを返します。
例えば:
>>>
>>> b'Hello World'.lower()
b'hello world'
ここでの小文字の ASCII 文字とは b'abcdefghijklmnopqrstuvwxyz' に含まれるバイト値です。また大文字の ASCII 文字とは b'ABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.splitlines(keepends=False)
bytearray.splitlines(keepends=False)
バイナリシーケンスを ASCII の改行コードで分割し、各行をリストにして返します。このメソッドは universal newlines アプローチで行を分割します。 keepends 引数に真を与えた場合を除き、改行コードは結果のリストに含まれません。
例えば:
>>>
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines()
[b'ab c', b'', b'de fg', b'kl']
>>> b'ab c\n\nde fg\rkl\r\n'.splitlines(keepends=True)
[b'ab c\n', b'\n', b'de fg\r', b'kl\r\n']
split() とは違って、空シーケンスに対して区切り sep を与えて呼び出すと空のリストを返します。またシーケンス末尾に改行コードがある場合、（訳註: その後ろに空行があるとは判断せず）余分な行を生成することはありません:
>>>
>>> b"".split(b'\n'), b"Two lines\n".split(b'\n')
([b''], [b'Two lines', b''])
>>> b"".splitlines(), b"One line\n".splitlines()
([], [b'One line'])
bytes.swapcase()
bytearray.swapcase()
シーケンスに含まれる小文字アルファベットの ASCII 文字を全て大文字アルファベットに変換し、さらに大文字アルファベットを同様に小文字アルファベットに変換したシーケンスのコピーを返します。
例えば:
>>>
>>> b'Hello World'.swapcase()
b'hELLO wORLD'
ここでの小文字の ASCII 文字とは b'abcdefghijklmnopqrstuvwxyz' に含まれるバイト値です。また大文字の ASCII 文字とは b'ABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。
str.swapcase() とは違い、バイナリバージョンのこちらでは bin.swapcase().swapcase() == bin が常に成り立ちます。一般的に Unicode 文字の大文字小文字変換は対称的ではありませんが、 ASCII 文字の場合は対称的です。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.title()
bytearray.title()
タイトルケース化したバイナリシーケンスを返します。具体的には、各単語が大文字アルファベットの ASCII 文字で始まり、かつ残りの文字が小文字アルファベットになっているシーケンスが返ります。大文字小文字の区別が無いバイト値については変更されずそのままになります。
例えば:
>>>
>>> b'Hello world'.title()
b'Hello World'
ここでの小文字の ASCII 文字とは b'abcdefghijklmnopqrstuvwxyz' に含まれるバイト値です。また大文字の ASCII 文字とは b'ABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。その他のバイト値については、大文字小文字の区別はありません。
このアルゴリズムは、連続した文字の集まりという、言語から独立した単純な単語の定義を使います。この定義は多くの状況ではうまく機能しますが、短縮形や所有格のアポストロフィが単語の境界になってしまい、望みの結果を得られない場合があります:
>>>
>>> b"they're bill's friends from the UK".title()
b"They'Re Bill'S Friends From The Uk"
正規表現を使うことでアポストロフィに対応できます:
>>>
>>> import re
>>> def titlecase(s):
...     return re.sub(rb"[A-Za-z]+('[A-Za-z]+)?",
...                   lambda mo: mo.group(0)[0:1].upper() +
...                              mo.group(0)[1:].lower(),
...                   s)
...
>>> titlecase(b"they're bill's friends.")
b"They're Bill's Friends."
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.upper()
bytearray.upper()
シーケンスに含まれる小文字アルファベットの ASCII 文字を全て大文字アルファベットに変換したシーケンスのコピーを返します。
例えば:
>>>
>>> b'Hello World'.upper()
b'HELLO WORLD'
ここでの小文字の ASCII 文字とは b'abcdefghijklmnopqrstuvwxyz' に含まれるバイト値です。また大文字の ASCII 文字とは b'ABCDEFGHIJKLMNOPQRSTUVWXYZ' に含まれるバイト値です。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
bytes.zfill(width)
bytearray.zfill(width)
長さが width になるよう ASCII b'0' で左詰めしたシーケンスのコピーを返します。先頭が符号接頭辞 (b'+'/b'-') だった場合、 b'0' は符号の前ではなく 後 に挿入されます。 bytes オブジェクトの場合、 width が len(seq) 以下であれば元のシーケンスが返ります。
例えば:
>>>
>>> b"42".zfill(5)
b'00042'
>>> b"-42".zfill(5)
b'-0042'
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
printf 形式での bytes の書式化
注釈 ここで述べる書式化演算には様々な癖があり、よく間違いの元になっています (タプルや辞書を正しく表示できないなど)。もし表示する値がタプルや辞書かもしれない場合、それをタプルに包むようにしてください。
bytes オブジェクト (bytes/bytearray) には固有の操作: % 演算子 (モジュロ) があります。この演算子は bytes の 書式化 または 補間 演算子とも呼ばれます。format % values (format は bytes オブジェクト) とすると、format 中の % 変換指定は values 中のゼロ個またはそれ以上の要素で置換されます。この動作は C 言語における sprintf() に似ています。
format が単一の引数しか要求しない場合、 values はタプルではない単一のオブジェクトで問題ありません。 5 それ以外の場合、 values は書式シーケンス（訳註: 先の例での format ）中で指定された項目と正確に同じ数の要素を含むタプルか、単一のマッピング型のオブジェクト (たとえば辞書) でなければなりません。
一つの変換指定子は 2 またはそれ以上の文字を含み、その構成要素は以下からなりますが、示した順に出現しなければなりません:
指定子の開始を示す文字 '%' 。
マップキー (オプション)。丸括弧で囲った文字列からなります (例えば (somename)) 。
変換フラグ (オプション)。一部の変換型の結果に影響します。
最小のフィールド幅 (オプション)。 '*' (アスタリスク) を指定した場合、実際の文字列幅が values タプルの次の要素から読み出されます。タプルには最小フィールド幅やオプションの精度指定の後に変換したいオブジェクトがくるようにします。
精度 (オプション)。 '.' (ドット) とその後に続く精度で与えられます。 '*' (アスタリスク) を指定した場合、精度の桁数は values タプルの次の要素から読み出されます。タプルには精度指定の後に変換したい値がくるようにします。
精度長変換子 (オプション)。
変換型。
% 演算子の右側の引数が辞書の場合 (またはその他のマッピング型の場合) 、 bytes オブジェクト中のフォーマットには、辞書のキーを丸括弧で囲って文字 '%' の直後に書いたものが含まれていなければ なりません 。マップキーは書式化したい値をマッピングから選び出します。例えば:
>>>
>>> print(b'%(language)s has %(number)03d quote types.' %
...       {b'language': b"Python", b"number": 2})
b'Python has 002 quote types.'
この場合、 * 指定子をフォーマットに含めてはいけません (* 指定子は順番付けされたパラメタのリストが必要だからです)。
変換フラグ文字を以下に示します:
Flag
意味
'#'
値の変換に (下で定義されている) "別の形式" を使います。
'0'
数値型に対してゼロによるパディングを行います。
'-'
変換された値を左寄せにします ('0' と同時に与えた場合、 '0' を上書きします) 。
' '
(スペース) 符号付きの変換で正の数の場合、前に一つスペースを空けます (そうでない場合は空文字になります) 。
'+'
変換の先頭に符号文字 ('+' または '-') を付けます("スペース" フラグを上書きします) 。
精度長変換子(h, l,または L) を使うことができますが、 Python では必要ないため無視されます。 -- つまり、例えば %ld は %d と等価です。
変換型を以下に示します:
変換
意味
注釈
'd'
符号付き 10 進整数。
'i'
符号付き 10 進整数。
'o'
符号付き 8 進数。
(1)
'u'
旧式の型 -- 'd' と同じです。
(8)
'x'
符号付き 16 進数 (小文字)。
(2)
'X'
符号付き 16 進数 (大文字)。
(2)
'e'
指数表記の浮動小数点数 (小文字)。
(3)
'E'
指数表記の浮動小数点数 (大文字)。
(3)
'f'
10 進浮動小数点数。
(3)
'F'
10 進浮動小数点数。
(3)
'g'
浮動小数点数。指数部が -4 以上または精度以下の場合には小文字指数表記、それ以外の場合には10進表記。
(4)
'G'
浮動小数点数。指数部が -4 以上または精度以下の場合には大文字指数表記、それ以外の場合には10進表記。
(4)
'c'
1 バイト (整数または要素 1 つの bytes/bytearray オブジェクトを受理します)
'b'
バイナリシーケンス (buffer protocol をサポートするか、 __bytes__() メソッドがあるオブジェクト)
(5)
's'
's' は 'b' の別名です。Python 2/3 の両方を対象としたコードでのみ使用すべきです。
(6)
'a'
バイナリシーケンス (Python オブジェクトを repr(obj).encode('ascii','backslashreplace) で変換します)。
(5)
'r'
'r' は 'a' の別名です。Python 2/3 の両方を対象としたコードでのみ使用すべきです。
(7)
'%'
引数を変換せず、返される文字列中では文字 '%' になります。
注釈:
別の形式を指定（訳注: 変換フラグ # を使用）すると 8 進数を表す接頭辞 ('0o') が最初の数字の前に挿入されます。
別の形式を指定（訳注: 変換フラグ # を使用）すると 16 進数を表す接頭辞 '0x' または '0X' (使用するフォーマット文字が 'x' か 'X' に依存します) が最初の数字の前に挿入されます。
この形式にした場合、変換結果には常に小数点が含まれ、それはその後ろに数字が続かない場合にも適用されます。
指定精度は小数点の後の桁数を決定し、そのデフォルトは 6 です。
この形式にした場合、変換結果には常に小数点が含まれ他の形式とは違って末尾の 0 は取り除かれません。
指定精度は小数点の前後の有効桁数を決定し、そのデフォルトは 6 です。
精度が N なら、出力は N 文字に切り詰められます。
b'%s' は非推奨ですが、3.x 系では削除されません。
b'%r' は非推奨ですが、3.x 系では削除されません。
PEP 237 を参照してください。
注釈 bytearray のこのメソッドはインプレースでは動作 しません -- 一切変化が無い場合でも、常に新しいオブジェクトを生成します。
参考 PEP 461 - bytes と bytearray への % 書式化の追加
バージョン 3.5 で追加.
メモリビュー
memoryview オブジェクトは、Python コードが バッファプロトコル をサポートするオブジェクトの内部データへ、コピーすることなくアクセスすることを可能にします。
class memoryview(obj)
obj を参照する memoryview を作成します。 obj はバッファプロトコルをサポートしていなければなりません。バッファプロトコルをサポートする組み込みオブジェクトには、 bytes 、 bytearray などがあります。
memoryview は元となるオブジェクト obj が扱うメモリーの最小単位を 要素 として扱います。多くの単純なオブジェクト、例えば bytes や bytearray では、要素は単バイトになりますが、他の array.array 等の型では、要素はより大きくなりえます。
メモリビューの長さ len(view) は、 tolist で得られるリストの長さとなります。view.ndim = 0 なら、長さは 1 です。view.ndim = 1 なら、長さはビューの要素数と等しいです。より高次元では、長さはビューのネストされたリスト表現の長さと等しいです。要素一つあたりのバイト数は itemsize 属性から取得できます。
memoryview はスライスおよびインデックス指定で内容を取得できます。一次元のスライスは部分ビューになります:
>>>
>>> v = memoryview(b'abcefg')
>>> v[1]
98
>>> v[-1]
103
>>> v[1:4]
<memory at 0x7f3ddc9f4350>
>>> bytes(v[1:4])
b'bce'
もしメモリビューの format が struct モジュールによって定義されているネイティブのフォーマット指定子であれば、整数または整数のタプルでのインデックス指定により適切な型の 要素1つ を得ることができます。一次元のメモリビューでは、整数または整数 1 つのタプルでインデックス指定できます。多次元のメモリビューでは、その次元数を ndim としたとき、ちょうど ndim 個の整数からなるタプルでインデックス指定できます。ゼロ次元のメモリビューでは、空のタプルでインデックス指定できます。
format が単バイト単位ではない例を示します:
>>>
>>> import array
>>> a = array.array('l', [-11111111, 22222222, -33333333, 44444444])
>>> m = memoryview(a)
>>> m[0]
-11111111
>>> m[-1]
44444444
>>> m[::2].tolist()
[-11111111, -33333333]
メモリビューの参照しているオブジェクトが書き込み可能であれば、一次元スライスでの代入が可能です。ただしサイズの変更はできません:
>>>
>>> data = bytearray(b'abcefg')
>>> v = memoryview(data)
>>> v.readonly
False
>>> v[0] = ord(b'z')
>>> data
bytearray(b'zbcefg')
>>> v[1:4] = b'123'
>>> data
bytearray(b'z123fg')
>>> v[2:3] = b'spam'
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: memoryview assignment: lvalue and rvalue have different structures
>>> v[2:6] = b'spam'
>>> data
bytearray(b'z1spam')
'B', 'b', 'c' いずれかのフォーマットのハッシュ可能な (読み出し専用の) 型の1次元メモリビューもまた、ハッシュ可能です。ハッシュは hash(m) == hash(m.tobytes()) として定義されています:
>>>
>>> v = memoryview(b'abcefg')
>>> hash(v) == hash(b'abcefg')
True
>>> hash(v[2:4]) == hash(b'ce')
True
>>> hash(v[::-2]) == hash(b'abcefg'[::-2])
True
バージョン 3.3 で変更: 1 次元のメモリビューがスライス可能になりました。 'B', 'b', 'c' いずれかのフォーマットの 1 次元のメモリビューがハッシュ可能になりました。
バージョン 3.4 で変更: memoryview は自動的に collections.abc.Sequence へ登録されるようになりました。
バージョン 3.5 で変更: メモリビューは整数のタプルでインデックス指定できるようになりました。
memoryview にはいくつかのメソッドがあります:
__eq__(exporter)
memoryview と PEP 3118 エクスポーターは、 shape が同じで、 struct のフォーマットで解釈したときの値が同じ場合に同値になります。
tolist() がサポートしている struct フォーマットの一部では、 v.tolist() == w.tolist() が成り立つときに v == w になります:
>>>
>>> import array
>>> a = array.array('I', [1, 2, 3, 4, 5])
>>> b = array.array('d', [1.0, 2.0, 3.0, 4.0, 5.0])
>>> c = array.array('b', [5, 3, 1])
>>> x = memoryview(a)
>>> y = memoryview(b)
>>> x == a == y == b
True
>>> x.tolist() == a.tolist() == y.tolist() == b.tolist()
True
>>> z = y[::-2]
>>> z == c
True
>>> z.tolist() == c.tolist()
True
どちらかの書式文字列が struct モジュールにサポートされていなければ、 (書式文字列とバッファの内容が同一でも) オブジェクトは常に等しくないものとして比較されます:
>>>
>>> from ctypes import BigEndianStructure, c_long
>>> class BEPoint(BigEndianStructure):
...     _fields_ = [("x", c_long), ("y", c_long)]
...
>>> point = BEPoint(100, 200)
>>> a = memoryview(point)
>>> b = memoryview(point)
>>> a == point
False
>>> a == b
False
浮動小数点数の場合と同様 memoryview オブジェクトに対する v is w は v == w を意味しないことに注意してください。
バージョン 3.3 で変更: 以前のバージョンは、要素フォーマットと論理的な配列構造を無視して生のメモリを比較していました。
tobytes(order=None)
バッファ中のデータをバイト文字列として返します。これはメモリビューに対して bytes コンストラクタを呼び出すのと同等です。
>>>
>>> m = memoryview(b"abc")
>>> m.tobytes()
b'abc'
>>> bytes(m)
b'abc'
連続でない配列については、結果はすべての要素がバイトに変換されたものを含むフラットなリスト表現に等しくなります。 tobytes() は、 struct モジュール文法にないものを含むすべての書式文字列をサポートします。
バージョン 3.8 で追加: order can be {'C', 'F', 'A'}. When order is 'C' or 'F', the data of the original array is converted to C or Fortran order. For contiguous views, 'A' returns an exact copy of the physical memory. In particular, in-memory Fortran order is preserved. For non-contiguous views, the data is converted to C first. order=None is the same as order='C'.
hex([sep[, bytes_per_sep]])
バッファ中の各バイトを 2 つの 16 進数で表した文字列を返します:
>>>
>>> m = memoryview(b"abc")
>>> m.hex()
'616263'
バージョン 3.5 で追加.
バージョン 3.8 で変更: Similar to bytes.hex(), memoryview.hex() now supports optional sep and bytes_per_sep parameters to insert separators between bytes in the hex output.
tolist()
バッファ中のデータを要素のリストとして返します。
>>>
>>> memoryview(b'abc').tolist()
[97, 98, 99]
>>> import array
>>> a = array.array('d', [1.1, 2.2, 3.3])
>>> m = memoryview(a)
>>> m.tolist()
[1.1, 2.2, 3.3]
バージョン 3.3 で変更: tolist() が struct モジュール文法に含まれるすべての単一文字の native フォーマットと多次元の表現をサポートするようになりました。
toreadonly()
>>>
>>> m = memoryview(bytearray(b'abc'))
>>> mm = m.toreadonly()
>>> mm.tolist()
[89, 98, 99]
>>> mm[0] = 42
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: cannot modify read-only memory
>>> m[0] = 43
>>> mm.tolist()
[43, 98, 99]
バージョン 3.8 で追加.
release()
memoryview オブジェクトによって晒されている、元になるバッファを解放します。多くのオブジェクトはビューに支配されているときに特殊なふるまいをします (例えば、 bytearray は大きさの変更を一時的に禁止します)。ですから、release() を呼び出すことは、これらの制約をできるだけ早く取り除く (そしてぶら下がったリソースをすべて解放する) のに便利です。
このメソッドが呼ばれた後、このビュー上のそれ以上の演算は ValueError を送出します (複数回呼ばれえる release() 自身は除きます):
>>>
>>> m = memoryview(b'abc')
>>> m.release()
>>> m[0]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: operation forbidden on released memoryview object
コンテキストマネージャプロトコルは、 with 文を使って同様の効果を得るのに使えます:
>>>
>>> with memoryview(b'abc') as m:
...     m[0]
...
97
>>> m[0]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: operation forbidden on released memoryview object
バージョン 3.2 で追加.
cast(format[, shape])
memoryview を新しいフォーマットか shape にキャストします。 shape はデフォルトで [byte_length//new_itemsize] で、 1次元配列になります。戻り値は memoryview ですが、バッファー自体はコピーされません。サポートされている変換は 1次元配列 -> C言語型の連続配列 と C言語型の連続配列 -> 1次元配列 です（参考: contiguous）。
キャスト後のフォーマットは struct 文法の単一要素ネイティブフォーマットに制限されます。フォーマットのうちの一つはバイトフォーマット ('B', 'b', 'c') でなければなりません。結果のバイト長はオリジナルの長さと同じでなければなりません。
1次元 long から 1次元 unsigned byte へのキャスト:
>>>
>>> import array
>>> a = array.array('l', [1,2,3])
>>> x = memoryview(a)
>>> x.format
'l'
>>> x.itemsize
8
>>> len(x)
3
>>> x.nbytes
24
>>> y = x.cast('B')
>>> y.format
'B'
>>> y.itemsize
1
>>> len(y)
24
>>> y.nbytes
24
1次元 unsigned byte から 1次元 char へのキャスト:
>>>
>>> b = bytearray(b'zyz')
>>> x = memoryview(b)
>>> x[0] = b'a'
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: memoryview: invalid value for format "B"
>>> y = x.cast('c')
>>> y[0] = b'a'
>>> b
bytearray(b'ayz')
1次元 byte から 3次元 int へ、そして 1次元 signed char へのキャスト:
>>>
>>> import struct
>>> buf = struct.pack("i"*12, *list(range(12)))
>>> x = memoryview(buf)
>>> y = x.cast('i', shape=[2,2,3])
>>> y.tolist()
[[[0, 1, 2], [3, 4, 5]], [[6, 7, 8], [9, 10, 11]]]
>>> y.format
'i'
>>> y.itemsize
4
>>> len(y)
2
>>> y.nbytes
48
>>> z = y.cast('b')
>>> z.format
'b'
>>> z.itemsize
1
>>> len(z)
48
>>> z.nbytes
48
1次元 unsigned long から 2次元 unsigned long へのキャスト:
>>>
>>> buf = struct.pack("L"*6, *list(range(6)))
>>> x = memoryview(buf)
>>> y = x.cast('L', shape=[2,3])
>>> len(y)
2
>>> y.nbytes
48
>>> y.tolist()
[[0, 1, 2], [3, 4, 5]]
バージョン 3.3 で追加.
バージョン 3.5 で変更: 単バイトのビューへキャストする場合、キャスト元のフォーマットについて制約は無くなりました。
読み出し専用の属性もいくつか使えます:
obj
memoryview が参照しているオブジェクト:
>>>
>>> b  = bytearray(b'xyz')
>>> m = memoryview(b)
>>> m.obj is b
True
バージョン 3.3 で追加.
nbytes
nbytes == product(shape) * itemsize == len(m.tobytes()). その配列が連続表現において利用するスペースです。これは len(m) と一致するとは限りません:
>>>
>>> import array
>>> a = array.array('i', [1,2,3,4,5])
>>> m = memoryview(a)
>>> len(m)
5
>>> m.nbytes
20
>>> y = m[::2]
>>> len(y)
3
>>> y.nbytes
12
>>> len(y.tobytes())
12
多次元配列:
>>>
>>> import struct
>>> buf = struct.pack("d"*12, *[1.5*x for x in range(12)])
>>> x = memoryview(buf)
>>> y = x.cast('d', shape=[3,4])
>>> y.tolist()
[[0.0, 1.5, 3.0, 4.5], [6.0, 7.5, 9.0, 10.5], [12.0, 13.5, 15.0, 16.5]]
>>> len(y)
3
>>> y.nbytes
96
バージョン 3.3 で追加.
readonly
メモリが読み出し専用かどうかを示す真偽値です。
format
ビューの中の各要素に対する (struct モジュールスタイルの) フォーマットを含む文字列。 memoryview は、任意のフォーマット文字列を使ってエクスポーターから作成することができます。しかし、いくつかのメソッド(例えば tolist()) はネイティブの単一要素フォーマットに制限されます。
バージョン 3.3 で変更: フォーマット 'B' は struct モジュール構文で扱われるようになりました。これは memoryview(b'abc')[0] == b'abc'[0] == 97 ということを意味します。
itemsize
memoryview の各要素のバイト単位の大きさ:
>>>
>>> import array, struct
>>> m = memoryview(array.array('H', [32000, 32001, 32002]))
>>> m.itemsize
2
>>> m[0]
32000
>>> struct.calcsize('H') == m.itemsize
True
ndim
メモリが表す多次元配列が何次元かを示す整数です。
shape
メモリが表している N 次元配列の形状を表す、長さ ndim の整数のタプルです。
バージョン 3.3 で変更: ndim = 0 の場合は None ではなく空のタプルとなるよう変更されました。
strides
配列のそれぞれの次元に対して、それぞれの要素にアクセスするのに必要なバイト数を表す、長さ ndim の整数のタプルです。
バージョン 3.3 で変更: ndim = 0 の場合は None ではなく空のタプルとなるよう変更されました。
suboffsets
PILスタイルの配列の内部で利用している値。この値はただの情報として公開されています。
c_contiguous
メモリーが C 形式の順序で連続しているかどうかを示す真偽値（参考: contiguous ）。
バージョン 3.3 で追加.
f_contiguous
メモリーがFortran形式の順序で連続しているかどうかを示す真偽値（参考: contiguous ）。
バージョン 3.3 で追加.
contiguous
メモリーが連続しているかどうかを示す真偽値（参考: contiguous ）。
バージョン 3.3 で追加.
set（集合）型 --- set, frozenset
set オブジェクトは、固有の hashable オブジェクトの順序なしコレクションです。通常の用途には、帰属テスト、シーケンスからの重複除去、積集合、和集合、差集合、対称差 (排他的論理和) のような数学的演算の計算が含まれます。(他のコンテナについては組み込みの dict, list, tuple クラスや collections モジュールを参照してください。)
集合は、他のコレクションと同様、 x in set, len(set), for x in set をサポートします。コレクションには順序がないので、集合は挿入の順序や要素の位置を記録しません。従って、集合はインデクシング、スライシング、その他のシーケンス的な振舞いをサポートしません。
set および frozenset という、2つの組み込みの集合型があります。 set はミュータブルで、add() や remove() のようなメソッドを使って内容を変更できます。ミュータブルなため、ハッシュ値を持たず、また辞書のキーや他の集合の要素として用いることができません。一方、frozenset 型はイミュータブルで、ハッシュ可能 です。作成後に内容を改変できないため、辞書のキーや他の集合の要素として用いることができます。
空でない set (frozenset ではない) は、set コンストラクタに加え、要素を波括弧中にカンマで区切って列挙することでも生成できます。例: {'jack', 'sjoerd'}。
どちらのクラスのコンストラクタも同様に働きます:
class set([iterable])
class frozenset([iterable])
iterable から要素を取り込んだ、新しい set もしくは frozenset オブジェクトを返します。 集合の要素は ハッシュ可能 なものでなくてはなりません。集合の集合を表現するためには、内側の集合は frozenset オブジェクトでなくてはなりません。iterable が指定されない場合、新しい空の集合が返されます。
Sets can be created by several means:
Use a comma-separated list of elements within braces: {'jack', 'sjoerd'}
Use a set comprehension: {c for c in 'abracadabra' if c not in 'abc'}
Use the type constructor: set(), set('foobar'), set(['a', 'b', 'foo'])
set および frozenset のインスタンスは以下の操作を提供します:
len(s)
集合 s の要素数 (s の濃度) を返します。
x in s
x が s のメンバーに含まれるか判定します。
x not in s
x が s のメンバーに含まれていないことを判定します。
isdisjoint(other)
集合が other と共通の要素を持たないとき、True を返します。集合はそれらの積集合が空集合となるときのみ、互いに素 (disjoint) となります。
issubset(other)
set <= other
set の全ての要素が other に含まれるか判定します。
set < other
set が other の真部分集合であるかを判定します。つまり、 set <= other and set != other と等価です。
issuperset(other)
set >= other
other の全ての要素が set に含まれるか判定します。
set > other
set が other の真上位集合であるかを判定します。つまり、 set >= other and set != other と等価です。
union(*others)
set | other | ...
set と全ての other の要素からなる新しい集合を返します。
intersection(*others)
set & other & ...
set と全ての other に共通する要素を持つ、新しい集合を返します。
difference(*others)
set - other - ...
set に含まれて、かつ、全ての other に含まれない要素を持つ、新しい集合を返します。
symmetric_difference(other)
set ^ other
set と other のいずれか一方だけに含まれる要素を持つ新しい集合を返します。
copy()
集合の浅いコピーを返します。
なお、演算子でない版の union(), intersection(), difference(), symmetric_difference(), issubset(), issuperset() メソッドは、任意のイテラブルを引数として受け付けます。対して、演算子を使う版では、引数は集合でなくてはなりません。これは、set('abc') & 'cbs' のような誤りがちな構文を予防し、より読みやすい set('abc').intersection('cbs') を支持します。
set と frozenset のどちらも、集合同士の比較をサポートします。二つの集合は、それぞれの集合の要素全てが他方にも含まれている (互いに他方の部分集合である) とき、かつそのときに限り等しいです。一方の集合が他方の集合の真部分集合である (部分集合であるが等しくない) とき、かつそのときに限り一方の集合は他方の集合より小さいです。一方の集合が他方の集合の真上位集合である (上位集合であるが等しくない) とき、かつそのときに限り一方の集合は他方の集合より大きいです。
set のインスタンスは、 frozenset のインスタンスと、要素に基づいて比較されます。例えば、 set('abc') == frozenset('abc') や set('abc') in set([frozenset('abc')]) は True を返します。
部分集合と等価性の比較は全順序付けを行う関数へと一般化することはできません。例えば、互いに素である二つの非空集合は、等しくなく、他方の部分集合でもありませんから、以下の すべて に False を返します: a<b, a==b, そして a>b.
集合は半順序（部分集合関係）しか定義しないので、集合のリストにおける list.sort() メソッドの出力は未定義です。
集合の要素は、辞書のキーのように、 ハッシュ可能 でなければなりません。
set インスタンスと frozenset インスタンスを取り混ぜての二項演算は、第一被演算子の型を返します。例えば: frozenset('ab') | set('bc') は frozenset インスタンスを返します。
以下の表に挙げる演算は set に適用されますが、frozenset のイミュータブルなインスタンスには適用されません:
update(*others)
set |= other | ...
全ての other の要素を追加し、 set を更新します。
intersection_update(*others)
set &= other & ...
元の set と全ての other に共通する要素だけを残して set を更新します。
difference_update(*others)
set -= other | ...
other に含まれる要素を取り除き、 set を更新します。
symmetric_difference_update(other)
set ^= other
どちらかにのみ含まれて、共通には持たない要素のみで set を更新します。
add(elem)
要素 elem を set に追加します。
remove(elem)
要素 elem を set から取り除きます。elem が set に含まれていなければ KeyError を送出します。
discard(elem)
要素 elem が set に含まれていれば、取り除きます。
pop()
s から任意の要素を取り除き、それを返します。集合が空の場合、 KeyError を送出します
clear()
set の全ての要素を取り除きます。
なお、演算子でない版の update(), intersection_update(), difference_update(), および symmetric_difference_update() メソッドは、任意のイテラブルを引数として受け付けます。
__contains__(), remove(), discard() メソッドの引数 elem は集合かもしれないことに注意してください。 その集合と等価な frozenset の検索をサポートするために、 elem から一時的な frozenset を作成します。
マッピング型 --- dict
マッピング オブジェクトは、 ハッシュ可能 な値を任意のオブジェクトに対応付けます。マッピングはミュータブルなオブジェクトです。現在、標準のマッピング型は辞書 (dictionary) だけです。 (他のコンテナについては組み込みの list, set, および tuple クラスと、 collections モジュールを参照してください。)
辞書のキーは ほぼ 任意の値です。 ハッシュ可能 でない値、つまり、リストや辞書その他のミュータブルな型 (オブジェクトの同一性ではなく値で比較されるもの) はキーとして使用できません。キーとして使われる数値型は通常の数値比較のルールに従います: もしふたつの数値が (例えば 1 と 1.0 のように) 等しければ、同じ辞書の項目として互換的に使用できます。 (ただし、コンピュータは浮動小数点数を近似値として保管するので、辞書型のキーとして使用するのはたいてい賢くありません。)
辞書は key: value 対のカンマ区切りのリストを波括弧でくくることで作成できます。例えば: {'jack': 4098, 'sjoerd': 4127} あるいは {4098: 'jack', 4127: 'sjoerd'} 。あるいは、 dict コンストラクタでも作成できます。
class dict(**kwarg)
class dict(mapping, **kwarg)
class dict(iterable, **kwarg)
オプションの位置引数と空の可能性もあるキーワード引数の集合により初期化された新しい辞書を返します。
Dictionaries can be created by several means:
Use a comma-separated list of key: value pairs within braces: {'jack': 4098, 'sjoerd': 4127} or {4098: 'jack', 4127: 'sjoerd'}
Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}
Use the type constructor: dict(), dict([('foo', 100), ('bar', 200)]), dict(foo=100, bar=200)
位置引数が何も与えられなかった場合、空の辞書が作成されます。位置引数が与えられ、それがマッピングオブジェクトだった場合、そのマッピングオブジェクトと同じキーと値のペアを持つ辞書が作成されます。それ以外の場合、位置引数は iterable オブジェクトでなければなりません。iterable のそれぞれの要素自身は、ちょうど 2 個のオブジェクトを持つイテラブルでなければなりません。それぞれの要素の最初のオブジェクトは新しい辞書のキーになり、2 番目のオブジェクトはそれに対応する値になります。同一のキーが 2 回以上現れた場合は、そのキーの最後の値が新しい辞書での対応する値になります。
キーワード引数が与えられた場合、キーワード引数とその値が位置引数から作られた辞書に追加されます。既に存在しているキーが追加された場合、キーワード引数の値は位置引数の値を置き換えます。
例を出すと、次の例は全て {"one": 1, "two": 2, "three": 3} に等しい辞書を返します:
>>>
>>> a = dict(one=1, two=2, three=3)
>>> b = {'one': 1, 'two': 2, 'three': 3}
>>> c = dict(zip(['one', 'two', 'three'], [1, 2, 3]))
>>> d = dict([('two', 2), ('one', 1), ('three', 3)])
>>> e = dict({'three': 3, 'one': 1, 'two': 2})
>>> f = dict({'one': 1, 'three': 3}, two=2)
>>> a == b == c == d == e == f
True
最初の例のようにキーワード引数を与える方法では、キーは有効な Python の識別子でなければなりません。それ以外の方法では、辞書のキーとして有効などんなキーでも使えます。
以下は辞書型がサポートする操作です (それゆえ、カスタムのマップ型もこれらの操作をサポートするべきです):
list(d)
辞書 d で使われている全てのキーのリストを返します。
len(d)
辞書 d の項目数を返します。
d[key]
d のキー key の項目を返します。マップに key が存在しなければ、 KeyError を送出します。
辞書のサブクラスが __missing__() メソッドを定義していて、 key が存在しない場合、 d[key] 演算はこのメソッドをキー key を引数として呼び出します。 d[key] 演算は、 __missing__(key) の呼び出しによって返された値をそのまま返すか、送出されたものをそのまま送出します。他の演算やメソッドは __missing__() を呼び出しません。 __missing__() が定義されていない場合、 KeyError が送出されます。 __missing__() はメソッドでなければならず、インスタンス変数であってはなりません:
>>>
>>> class Counter(dict):
...     def __missing__(self, key):
...         return 0
>>> c = Counter()
>>> c['red']
0
>>> c['red'] += 1
>>> c['red']
1
ここでお見せした例は collections.Counter 実装の一部です。これとは違った __missing__ が collections.defaultdict で使われています。
d[key] = value
d[key] に value を設定します。
del d[key]
d から d[key] を削除します。マップに key が存在しなければ、 KeyError を送出します。
key in d
d がキー key を持っていれば True を、そうでなければ、 False を返します。
key not in d
not key in d と等価です。
iter(d)
辞書のキーに渡るイテレータを返します。これは iter(d.keys()) へのショートカットです。
clear()
辞書の全ての項目を消去します。
copy()
辞書の浅いコピーを返します。
classmethod fromkeys(iterable[, value])
iterable からキーを取り、値を value に設定した、新しい辞書を作成します。
get(key[, default])
key が辞書にあれば key に対する値を、そうでなければ default を返します。 default が与えられなかった場合、デフォルトでは None となります。そのため、このメソッドは KeyError を送出することはありません。
items()
辞書の項目 ((key, value) 対) の新しいビューを返します。ビューオブジェクトのドキュメント を参照してください。
keys()
辞書のキーの新しいビューを返します。ビューオブジェクトのドキュメント を参照してください。
pop(key[, default])
key が辞書に存在すればその値を辞書から消去して返し、そうでなければ default を返します。 default が与えらず、かつ key が辞書に存在しなければ KeyError を送出します。
popitem()
任意の (key, value) 対を辞書から消去して返します。 対は LIFO の順序で返却されます。
集合のアルゴリズムで使われるのと同じように、 popitem() は辞書に繰り返し適用して消去するのに便利です。辞書が空であれば、 popitem() の呼び出しは KeyError を送出します。
バージョン 3.7 で変更: LIFO 順序が保証されるようになりました。 以前のバージョンでは、 popitem() は任意の key/value 対を返していました。
reversed(d)
バージョン 3.8 で追加.
setdefault(key[, default])
もし、 key が辞書に存在すれば、その値を返します。そうでなければ、値を default として key を挿入し、 default を返します。 default のデフォルトは None です。
update([other])
辞書の内容を other のキーと値で更新します。既存のキーは上書きされます。返り値は None です。
update() は、他の辞書オブジェクトでもキー/値の対のイテラブル (タプル、もしくは、長さが2のイテラブル) でも、どちらでも受け付けます。キーワード引数が指定されれば、そのキー/値の対で辞書を更新します: d.update(red=1, blue=2)。
values()
辞書の値の新しいビューを返します。ビューオブジェクトのドキュメント を参照してください。
>>>
>>> d = {'a': 1}
>>> d.values() == d.values()
False
d | other
バージョン 3.9 で追加.
d |= other
バージョン 3.9 で追加.
辞書は挿入順序を保存するようになりました。 キーの更新は順序には影響が無いことに注意してください。 いったん削除されてから再度追加されたキーは末尾に挿入されます。:
>>>
>>> d = {"one": 1, "two": 2, "three": 3, "four": 4}
>>> d
{'one': 1, 'two': 2, 'three': 3, 'four': 4}
>>> list(d)
['one', 'two', 'three', 'four']
>>> list(d.values())
[1, 2, 3, 4]
>>> d["one"] = 42
>>> d
{'one': 42, 'two': 2, 'three': 3, 'four': 4}
>>> del d["two"]
>>> d["two"] = None
>>> d
{'one': 42, 'three': 3, 'four': 4, 'two': None}
バージョン 3.7 で変更: 辞書の順序が挿入順序であることが保証されるようになりました。この振る舞いは CPython 3.6 の実装詳細でした。
>>>
>>> d = {"one": 1, "two": 2, "three": 3, "four": 4}
>>> d
{'one': 1, 'two': 2, 'three': 3, 'four': 4}
>>> list(reversed(d))
['four', 'three', 'two', 'one']
>>> list(reversed(d.values()))
[4, 3, 2, 1]
>>> list(reversed(d.items()))
[('four', 4), ('three', 3), ('two', 2), ('one', 1)]
参考 dict の読み出し専用ビューを作るために types.MappingProxyType を使うことができます。
辞書ビューオブジェクト
dict.keys(), dict.values(), dict.items() によって返されるオブジェクトは、 ビューオブジェクト です。これらは、辞書の項目の動的なビューを提供し、辞書が変更された時、ビューはその変更を反映します。
辞書ビューは、イテレートすることで対応するデータを yield できます。また、帰属判定をサポートします:
len(dictview)
辞書の項目数を返します。
iter(dictview)
辞書のキー、値、または ((key, value) のタプルとして表される) 項目に渡るイテレータを返します。
キーと値は挿入順序で反復されます。 これにより、 (value, key) の対の列を pairs = zip(d.values(), d.keys()) のように zip() で作成できます。 同じリストを作成する他の方法は、 pairs = [(v, k) for (k, v) in d.items()] です。
辞書の項目の追加や削除中にビューをイテレートすると、 RuntimeError を送出したり、すべての項目に渡ってイテレートできなかったりします。
バージョン 3.7 で変更: 辞書の順序が挿入順序であると保証されるようになりました。
x in dictview
x が元の辞書のキー、値、または項目 (項目の場合、 x は (key, value) タプルです) にあるとき True を返します。
reversed(dictview)
キーのビューは、項目が一意的でハッシュ可能であるという点で、集合に似ています。すべての値がハッシュ可能なら、 (key, value) 対も一意的でハッシュ可能なので、要素のビューも集合に似ています。(値のビューは、要素が一般に一意的でないことから、集合に似ているとは考えられません。) 集合に似ているビューに対して、抽象基底クラス collections.abc.Set で定義されている全ての演算 (例えば、 ==、<、^) が利用できます。
辞書ビューの使用法の例:
>>>
>>> dishes = {'eggs': 2, 'sausage': 1, 'bacon': 1, 'spam': 500}
>>> keys = dishes.keys()
>>> values = dishes.values()
>>> # iteration
>>> n = 0
>>> for val in values:
...     n += val
>>> print(n)
504
>>> # keys and values are iterated over in the same order (insertion order)
>>> list(keys)
['eggs', 'sausage', 'bacon', 'spam']
>>> list(values)
[2, 1, 1, 500]
>>> # view objects are dynamic and reflect dict changes
>>> del dishes['eggs']
>>> del dishes['sausage']
>>> list(keys)
['bacon', 'spam']
>>> # set operations
>>> keys & {'eggs', 'bacon', 'salad'}
{'bacon'}
>>> keys ^ {'sausage', 'juice'}
{'juice', 'sausage', 'bacon', 'spam'}
コンテキストマネージャ型
Python の with 文は、コンテキストマネージャによって定義される実行時コンテキストの概念をサポートします。これは、文の本体が実行される前に進入し文の終わりで脱出する実行時コンテキストを、ユーザ定義クラスが定義できるようにする一対のメソッドで実装されます:
contextmanager.__enter__()
実行時コンテキストに入り、このオブジェクトまたは他の実行時コンテキストに関連したオブジェクトを返します。このメソッドが返す値はこのコンテキストマネージャを使う with 文の as 節の識別子に束縛されます。
自分自身を返すコンテキストマネージャの例として ファイルオブジェクト があります。ファイルオブジェクトは __enter__() から自分自身を返し、 open() が with 文のコンテキスト式として使われるようにします。
関連オブジェクトを返すコンテキストマネージャの例としては decimal.localcontext() が返すものがあります。このマネージャはアクティブな10進数コンテキストをオリジナルのコンテキストのコピーにセットしてそのコピーを返します。こうすることで, with 文の本体の内部で、外側のコードに影響を与えずに、 10進数コンテキストを変更できます。
contextmanager.__exit__(exc_type, exc_val, exc_tb)
実行時コンテキストから抜け、(発生していた場合) 例外を抑制するかどうかを示すブール値フラグを返します。 with 文の本体の実行中に例外が発生した場合、引数にはその例外の型と値とトレースバック情報を渡します。そうでない場合、引数は全て None となります。
このメソッドから真値が返されると with 文は例外の発生を抑え、 with 文の直後の文に実行を続けます。そうでなければ、このメソッドの実行を終えると例外の伝播が続きます。このメソッドの実行中に起きた例外は with 文の本体の実行中に起こった例外を置き換えてしまいます。
渡された例外を明示的に再送出すべきではありません。その代わりに、このメソッドが偽の値を返すことでメソッドの正常終了と送出された例外を抑制しないことを伝えるべきです。このようにすればコンテキストマネージャは __exit__() メソッド自体が失敗したのかどうかを簡単に見分けることができます。
Python は、易しいスレッド同期、ファイルなどのオブジェクトの即時クローズ、アクティブな小数算術コンテキストの単純な操作をサポートするために、いくつかのコンテキストマネージャを用意しています。各型はコンテキスト管理プロトコルを実装しているという以上の特別の取り扱いを受けるわけではありません。例については contextlib モジュールを参照してください。
Python の ジェネレータ と contextlib.contextmanager デコレータ はこのプロトコルの簡便な実装方法を提供します。ジェネレータ関数を contextlib.contextmanager デコレータでデコレートすると、デコレートされないジェネレータ関数が作成するイテレータの代わりに、必要な __enter__() および __exit__() メソッドを実装したコンテキストマネージャを返すようになります。
これらのメソッドのために Python/C API の中の Python オブジェクトの型構造体に特別なスロットが作られたわけではないことに注意してください。これらのメソッドを定義したい拡張型はこれらを通常の Python からアクセスできるメソッドとして提供しなければなりません。実行時コンテキストを準備するオーバーヘッドに比べたら、一回のクラス辞書の探索のオーバーヘッドは無視できます。
def average(values: list[float]) -> float:
    return sum(values) / len(values)
def send_post_request(url: str, body: dict[str, int]) -> None:
    ...
The builtin functions isinstance() and issubclass() do not accept GenericAlias types for their second argument:
>>>
>>> isinstance([1, 2], list[str])
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: isinstance() argument 2 cannot be a parameterized generic
>>>
>>> t = list[str]
>>> t([1, 2, 3])
[1, 2, 3]
Furthermore, parameterized generics erase type parameters during object creation:
>>>
>>> t = list[str]
>>> type(t)
<class 'types.GenericAlias'>
>>> l = t()
>>> type(l)
<class 'list'>
Calling repr() or str() on a generic shows the parameterized type:
>>>
>>> repr(list[int])
'list[int]'
>>> str(list[int])
'list[int]'
The __getitem__() method of generics will raise an exception to disallow mistakes like dict[str][str]:
>>>
>>> dict[str][str]
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: There are no type variables left in dict[str]
>>>
>>> from typing import TypeVar
>>> Y = TypeVar('Y')
>>> dict[str, Y][int]
dict[str, int]
Standard Generic Collections
tuple
list
dict
set
frozenset
type
collections.deque
collections.defaultdict
collections.OrderedDict
collections.Counter
collections.ChainMap
’’collections.abc.Awaitable
collections.abc.Coroutine
collections.abc.AsyncIterable
collections.abc.AsyncIterator
collections.abc.AsyncGenerator
collections.abc.Iterable
collections.abc.Iterator
collections.abc.Generator
collections.abc.Reversible
collections.abc.Container
collections.abc.Collection
collections.abc.Callable
collections.abc.Set
collections.abc.MutableSet
collections.abc.Mapping
collections.abc.MutableMapping
collections.abc.Sequence
collections.abc.MutableSequence
collections.abc.ByteString
collections.abc.MappingView
collections.abc.KeysView
collections.abc.ItemsView
collections.abc.ValuesView
contextlib.AbstractContextManager
contextlib.AbstractAsyncContextManager
re.Pattern
re.Match
Special Attributes of Generic Alias
genericalias.__origin__
This attribute points at the non-parameterized generic class:
>>>
>>> list[int].__origin__
<class 'list'>
genericalias.__args__
This attribute is a tuple (possibly of length 1) of generic types passed to the original __class_getitem__() of the generic container:
>>>
>>> dict[str, list[int]].__args__
(<class 'str'>, list[int])
genericalias.__parameters__
This attribute is a lazily computed tuple (possibly empty) of unique type variables found in __args__:
>>>
>>> from typing import TypeVar
>>> T = TypeVar('T')
>>> list[T].__parameters__
(~T,)
参考
PEP 585 -- "Type Hinting Generics In Standard Collections"
__class_getitem__() -- Used to implement parameterized generics.
ジェネリクス -- typing モジュールのジェネリクス。
バージョン 3.9 で追加.
その他の組み込み型
インタプリタは、その他いくつかの種類のオブジェクトをサポートしています。これらのほとんどは 1 つまたは 2 つの演算だけをサポートしています。
モジュール (module)
モジュールに対する唯一の特殊な演算は属性アクセス: m.name です。ここで m はモジュールで、 name は m のシンボルテーブル上に定義された名前にアクセスします。モジュール属性に代入することもできます。 (なお、import 文は、厳密にいえば、モジュールオブジェクトに対する演算ではありません; import foo は foo と名づけられたモジュールオブジェクトの存在を必要とはせず、foo と名づけられたモジュールの (外部の) 定義 を必要とします。)
全てのモジュールにある特殊属性が __dict__ です。これはモジュールのシンボルテーブルを含む辞書です。この辞書を書き換えると実際にモジュールのシンボルテーブルを変更することができますが、__dict__ 属性を直接代入することはできません (m.__dict__['a'] = 1 と書いて m.a を 1 に定義することはできますが、m.__dict__ = {} と書くことはできません)。 __dict__ を直接書き換えることは推奨されません。
インタプリタ内に組み込まれたモジュールは、 <module 'sys' (built-in)> のように書かれます。ファイルから読み出された場合、 <module 'os' from '/usr/local/lib/pythonX.Y/os.pyc'> と書かれます。
クラスおよびクラスインスタンス
これらについては オブジェクト、値、および型 および クラス定義 を参照してください。
関数
関数オブジェクトは関数定義によって生成されます。関数オブジェクトに対する唯一の操作は、それを呼び出すことです: func(argument-list) 。
関数オブジェクトには実際には二種類あります: 組み込み関数とユーザ定義関数です。どちらも同じ操作 (関数の呼び出し) をサポートしますが、実装は異なるので、オブジェクトの型も異なります。
詳細は、 関数定義 を参照してください。
メソッド
メソッドは属性表記を使って呼び出される関数です。メソッドには二種類あります: (リストの append() のような) 組み込みメソッドと、クラスインスタンスのメソッドです。組み込みメソッドは、それをサポートする型と一緒に記述されています。
インスタンスを通してメソッド (クラスの名前空間内で定義された関数) にアクセスすると、特殊なオブジェクトが得られます。それは束縛メソッド (bound method) オブジェクトで、インスタンスメソッド (instance method) とも呼ばれます。呼び出された時、引数リストに self 引数が追加されます。束縛メソッドには 2 つの特殊読み出し専用属性があります。 m.__self__ はそのメソッドが操作するオブジェクトで、 m.__func__ はそのメソッドを実装している関数です。 m(arg-1, arg-2, ..., arg-n) の呼び出しは、 m.__func__(m.__self__, arg-1, arg-2, ..., arg-n) の呼び出しと完全に等価です。
関数オブジェクトと同様に、メソッドオブジェクトは任意の属性の取得をサポートしています。しかし、メソッド属性は実際には下層の関数オブジェクト (meth.__func__) に記憶されているので、バインドされるメソッドにメソッド属性を設定することは許されていません。メソッドに属性を設定しようとすると AttributeError が送出されます。メソッドの属性を設定するためには、次のようにその下層の関数オブジェクトに明示的に設定する必要があります:
>>>
>>> class C:
...     def method(self):
...         pass
...
>>> c = C()
>>> c.method.whoami = 'my name is method'  # can't set on the method
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'method' object has no attribute 'whoami'
>>> c.method.__func__.whoami = 'my name is method'
>>> c.method.whoami
'my name is method'
詳細は、 標準型の階層 を参照してください。
コードオブジェクト
コードオブジェクトは、関数本体のような "擬似コンパイルされた" Python の実行可能コードを表すために実装系によって使われます。コードオブジェクトはグローバルな実行環境への参照を持たない点で関数オブジェクトとは異なります。コードオブジェクトは組み込み関数 compile() によって返され、また関数オブジェクトの __code__ 属性として取り出せます。 code モジュールも参照してください。
コードオブジェクトは、組み込み関数 exec() や eval() に (ソース文字列の代わりに) 渡すことで、実行や評価できます。
詳細は、 標準型の階層 を参照してください。
型オブジェクト
型オブジェクトは様々なオブジェクト型を表します。オブジェクトの型は組み込み関数 type() でアクセスされます。型オブジェクトには特有の操作はありません。標準モジュール types には全ての組み込み型名が定義されています。
型はこのように書き表されます: <class 'int'> 。
ヌルオブジェクト
このオブジェクトは明示的に値を返さない関数によって返されます。このオブジェクトには特有の操作はありません。ヌルオブジェクトは一つだけで、 None (組み込み名) と名づけられています。 type(None)() は同じシングルトンを作成します。
None と書き表されます。
Ellipsis オブジェクト
このオブジェクトは一般にスライシングによって使われます (スライス表記 (slicing) を参照してください)。特殊な演算は何もサポートしていません。Ellipsis オブジェクトは一つだけで、その名前は Ellipsis (組み込み名) です。type(Ellipsis)() は単一の Ellipsis を作成します。
Ellipsis または ... と書き表されます。
NotImplemented オブジェクト
このオブジェクトは、対応していない型に対して比較演算や二項演算が求められたとき、それらの演算から返されます。詳細は 比較 を参照してください。 NotImplemented オブジェクトは一つだけです。 type(NotImplemented)() はこの単一のインスタンスを作成します。
NotImplemented と書き表されます。
ブール値
ブール値は二つの定数オブジェクト False および True です。これらは真理値を表すのに使われます (ただし他の値も偽や真とみなされます)。 数値処理のコンテキスト (例えば算術演算子の引数として使われた場合) では、これらはそれぞれ 0 および 1 と同様に振舞います。任意の値に対して、真理値と解釈できる場合、組み込み関数 bool() は値をブール値に変換するのに使われます (上述の 真理値判定 の節を参照してください)。
それぞれ False および True と書き表されます。
内部オブジェクト
この情報は 標準型の階層 を参照してください。スタックフレームオブジェクト、トレースバックオブジェクト、スライスオブジェクトについて記述されています。
特殊属性
実装は、いくつかのオブジェクト型に対して、適切な場合には特殊な読み出し専用の属性を追加します。そのうちいくつかは dir() 組込み関数で報告されません。
object.__dict__
オブジェクトの (書き込み可能な) 属性を保存するために使われる辞書またはその他のマッピングオブジェクトです。
instance.__class__
クラスインスタンスが属しているクラスです。
class.__bases__
クラスオブジェクトの基底クラスのタプルです。
definition.__name__
クラス、関数、メソッド、デスクリプタ、ジェネレータインスタンスの名前です。
definition.__qualname__
クラス、関数、メソッド、デスクリプタ、ジェネレータインスタンスの 修飾名 です。
バージョン 3.3 で追加.
class.__mro__
この属性はメソッドの解決時に基底クラスを探索するときに考慮されるクラスのタプルです。
class.mro()
このメソッドは、メタクラスによって、そのインスタンスのメソッド解決の順序をカスタマイズするために、上書きされるかも知れません。このメソッドはクラスのインスタンス化時に呼ばれ、その結果は __mro__ に格納されます。
class.__subclasses__()
>>>
>>> int.__subclasses__()
[<class 'bool'>]
組み込み例外
Python において、すべての例外は BaseException から派生したクラスのインスタンスでなければなりません。特定のクラスを言及する except 節を伴う try 文において、その節はそのクラスから派生した例外クラスも処理しますが、そのクラスの派生 元 の例外クラスは処理しません。サブクラス化の関係にない 2 つの例外クラスは、それらが同じ名前だった場合でも等しくなりえません。
以下に挙げる組み込み例外は、インタプリタや組み込み関数によって生成されます。特に注記しないかぎり、これらはエラーの詳しい原因を示す "関連値 (associated value)" を持ちます。この値は、複数の情報 (エラーコードや、そのコードを説明する文字列など) の文字列かタプルです。関連値は通常、例外クラスのコンストラクタに引数として渡されます。
ユーザによるコードも組み込み例外を送出できます。これを使って、例外ハンドラをテストしたり、インタプリタが同じ例外を送出する状況と "ちょうど同じような" エラー条件であることを報告したりできます。しかし、ユーザのコードが適切でないエラーを送出するのを妨げる方法はないので注意してください。
組み込み例外クラスは新たな例外を定義するためにサブクラス化することができます。新しい例外は、Exception クラスかそのサブクラスの一つから派生することをお勧めします。 BaseException からは派生しないで下さい。例外を定義する上での詳しい情報は、 Python チュートリアルの ユーザー定義例外 の項目にあります。
except または finally 節内で例外を送出 (または再送出) するとき、__context__ は自動的に最後に捕まった例外に設定されます。新しい例外が処理されなければ、最終的に表示されるトレースバックは先に起きた例外も最後の例外も含みます。
現在処理中の例外を raise を使って再送出するのではなく新規に例外を送出する場合、raise と一緒に from を使うことで暗黙の例外コンテキストを捕捉することができます:
raise new_exc from original_exc
from に続く式は例外か None でなくてはなりません。 式は送出される例外の __cause__ として設定されます。 __cause__ を設定することは、 __suppress_context__ 属性を暗黙的に True に設定することにもなるので、 raise new_exc from None を使うことで効率的に古い例外を新しいもので置き換えて表示する (例えば、 KeyError を AttributeError に置き換え)、古い例外はデバッグ時の調査で使えるよう __context__ に残すことができます。
デフォルトの traceback 表示コードは、例外自体の traceback に加え、これらの連鎖された例外を表示します。__cause__ で明示的に連鎖させた例外は、存在するならば常に表示されます。__context__ で暗黙に連鎖させた例外は、__cause__ が None かつ __suppress_context__ が false の場合にのみ表示されます。
いずれにせよ、連鎖された例外に続いて、その例外自体は常に表示されます。そのため、traceback の最終行には、常に送出された最後の例外が表示されます。
基底クラス
以下の例外は、主に他の例外の基底クラスとして使われます。
exception BaseException
全ての組み込み例外の基底クラスです。ユーザ定義の例外に直接継承されることは意図されていません (継承には Exception を使ってください)。このクラスのインスタンスに str() が呼ばれた場合、インスタンスへの引数の表現か、引数が無い場合には空文字列が返されます。
args
例外コンストラクタに与えられた引数のタプルです。組み込み例外は普通、エラーメッセージを与える一つの文字列だけを引数として呼ばれますが、中には (OSError など) いくつかの引数を必要とし、このタプルの要素に特別な意味を込めるものもあります。
with_traceback(tb)
このメソッドは tb を例外の新しいトレースバックとして設定し、例外オブジェクトを返します。これは通常次のような例外処理コードに使われます:
try:
    ...
except SomeException:
    tb = sys.exc_info()[2]
    raise OtherException(...).with_traceback(tb)
exception Exception
システム終了以外の全ての組み込み例外はこのクラスから派生しています。全てのユーザ定義例外もこのクラスから派生させるべきです。
exception ArithmeticError
算術上の様々なエラーに対して送出される組み込み例外 OverflowError, ZeroDivisionError, FloatingPointError の基底クラスです。
exception BufferError
バッファ に関連する操作が行えなかったときに送出されます。
exception LookupError
マッピングまたはシーケンスで使われたキーやインデクスが無効な場合に送出される例外 IndexError および KeyError の基底クラスです。 codecs.lookup() によって直接送出されることもあります。
具象例外
以下の例外は、通常送出される例外です。
exception AssertionError
assert 文が失敗した場合に送出されます。
exception AttributeError
属性参照 (属性参照 を参照) や代入が失敗した場合に送出されます (オブジェクトが属性の参照や属性の代入をまったくサポートしていない場合には TypeError が送出されます)。
exception EOFError
input() が何もデータを読まずに end-of-file (EOF) に達した場合に送出されます。(注意: io.IOBase.read() と io.IOBase.readline() メソッドは、EOF に達すると空文字列を返します。)
exception FloatingPointError
現在は使われていません。
exception GeneratorExit
ジェネレータ や コルーチン が閉じられたときに送出されます。 generator.close() と coroutine.close() を参照してください。この例外は厳密に言えばエラーではないので、 Exception ではなく BaseException を直接継承しています。
exception ImportError
import 文でモジュールをロードしようとして問題が発生すると送出されます。 from ... import の中の"from list" (訳注：... の部分)の名前が見つからないときにも送出されます。
コンストラクタのキーワード専用引数を使って name および path 属性を設定できます。設定された場合、インポートを試みられたモジュールの名前と、例外を引き起こしたファイルへのパスとを、それぞれ表します。
バージョン 3.3 で変更: name および path 属性が追加されました。
exception ModuleNotFoundError
ImportError のサブクラスで、import 文でモジュールが見つからない場合に送出されます。また、 sys.modules に None が含まれる場合にも送出されます。
バージョン 3.6 で追加.
exception IndexError
シーケンスの添字が範囲外の場合に送出されます。 (スライスのインデクスはシーケンスの範囲に収まるように暗黙のうちに調整されます; インデクスが整数でない場合、 TypeError が送出されます。)
exception KeyError
マッピング (辞書) のキーが、既存のキーの集合内に見つからなかった場合に送出されます。
exception KeyboardInterrupt
ユーザが割り込みキー (通常は Control-C または Delete) を押した場合に送出されます。実行中、割り込みは定期的に監視されます。Exception を捕捉するコードに誤って捕捉されてインタプリタの終了が阻害されないように、この例外は BaseException を継承しています。
exception MemoryError
ある操作中にメモリが不足したが、その状況は (オブジェクトをいくつか消去することで) まだ復旧可能かもしれない場合に送出されます。この例外の関連値は、メモリ不足になった (内部) 操作の種類を示す文字列です。下層のメモリ管理アーキテクチャ (C の malloc() 関数) のために、インタプリタが現状から完璧に復旧できるとはかぎらないので注意してください。それでも、プログラムの暴走が原因の場合に備えて実行スタックのトレースバックを出力できるように、例外が送出されます。
exception NameError
ローカルまたはグローバルの名前が見つからなかった場合に送出されます。これは非修飾の (訳注: spam.egg ではなく単に egg のような) 名前のみに適用されます。関連値は見つからなかった名前を含むエラーメッセージです。
exception NotImplementedError
この例外は RuntimeError から派生しています。ユーザ定義の基底クラスにおいて、抽象メソッドが派生クラスでオーバライドされることを要求する場合にこの例外を送出しなくてはなりません。またはクラスは実装中であり本来の実装を追加する必要があることを示します。
注釈 演算子やメソッドがサポートされていないことを示す目的でこの例外を使用するべきではありません。そのようなケースではオペレータやメソッドを未定義のままとするか、サブクラスの場合は None を設定してください。
注釈 NotImplementedError と NotImplemented は、似たような名前と目的を持っていますが、相互に変換できません。 利用する際には、 NotImplemented を参照してください。
exception OSError([arg])
exception OSError(errno, strerror[, filename[, winerror[, filename2]]])
この例外はシステム関数がシステム関連のエラーを返した場合に送出されます。例えば "file not found" や "disk full" のような I/O の失敗が発生したときです (引数の型が不正な場合や、他の偶発的なエラーは除きます)。
コンストラクタの2番目の形式は下記の対応する属性を設定します。指定されなかった場合属性はデフォルトで None です。後方互換性のために、引数が3つ渡された場合、args 属性は最初の2つの要素のみからなるタプルを持ちます。
コンストラクタは実際には、 OS exceptions で述べられている OSError のサブクラスを返すことがよくあります。特定のサブクラスは最終的な errno 値によります。この挙動は OSError を直接またはエイリアスで構築し、サブクラス化時に継承されなかった場合にのみ発生します。
errno
C 変数 errno に由来する数値エラーコードです。
winerror
Windows において、ネイティブ Windows エラーコードを与えます。そして errno 属性は POSIX でいうネイティブエラーコードへのおよその翻訳です。
Windows では、winerror コンストラクタ引数が整数の場合 errno 属性は Windows エラーコードから決定され、errno 引数は無視されます。他のプラットフォームでは winerror 引数は無視され、 winerror 属性は存在しません。
strerror
OS が提供するような、対応するエラーメッセージです。 POSIX では perror() で、Windows では FormatMessage() で体裁化されます。
filename
filename2
ファイルシステムパスが1つ関与する例外 (例えば open() や os.unlink()) の場合、filename は関数に渡されたファイル名です。 ファイルシステムパスが2つ関与する関数 (例えば os.rename()) の場合、filename2 は関数に渡された2つ目のファイル名です。
バージョン 3.3 で変更: EnvironmentError, IOError, WindowsError, socket.error, select.error, mmap.error が OSError に統合されました。コンストラクタはサブクラスを返すかもしれません。
バージョン 3.4 で変更: filename 属性がファイルシステムのエンコーディングでエンコードやデコードされた名前から、関数に渡された元々のファイル名になりました。 また、filename2 コンストラクタ引数が追加されました。
exception OverflowError
算術演算の結果が表現できない大きな値になった場合に送出されます。これは整数では起こりません (むしろ MemoryError が送出されることになるでしょう)。しかし、歴史的な理由のため、要求された範囲の外の整数に対して OverflowError が送出されることがあります。C の浮動小数点演算の例外処理は標準化されていないので、ほとんどの浮動小数点演算もチェックされません。
exception RecursionError
この例外は RuntimeError を継承しています。インタープリタが最大再帰深度 (sys.getrecursionlimit() を参照) の超過を検出すると送出されます。
バージョン 3.5 で追加: 以前は RuntimeError をそのまま送出していました。
exception ReferenceError
weakref.proxy() によって生成された弱参照 (weak reference) プロキシを使って、ガーベジコレクションによって回収された後の参照対象オブジェクトの属性にアクセスした場合に送出されます。弱参照については weakref モジュールを参照してください。
exception RuntimeError
他のカテゴリに分類できないエラーが検出された場合に送出されます。関連値は、何が問題だったのかをより詳細に示す文字列です。
exception StopIteration
組込み関数 next() と iterator の __next__() メソッドによって、そのイテレータが生成するアイテムがこれ以上ないことを伝えるために送出されます。
この例外オブジェクトには一つの属性 value があり、例外を構成する際に引数として与えられ、デフォルトは None です。
generator や coroutine 関数が返るとき、新しい StopIteration インスタンスが送出されます。 関数の返り値は例外のコンストラクタの value 引数として使われます。
ジェネレータのコードが直接的あるいは間接的に StopIteration を送出する場合は、 RuntimeError に変換されます (StopIteration は変換後の例外の原因として保持されます)。
バージョン 3.3 で変更: value 属性とジェネレータ関数が値を返すためにそれを使う機能が追加されました。
バージョン 3.5 で変更: from __future__ import generator_stop による RuntimeError への変換が導入されました。 PEP 479 を参照してください。
バージョン 3.7 で変更: PEP 479 が全てのコードでデフォルトで有効化されました: ジェネレータから送出された StopIteration は RuntimeError に変換されます。
exception StopAsyncIteration
イテレーションを停止するために、 asynchronous iterator オブジェクトの __anext__() メソッドによって返される必要があります。
バージョン 3.5 で追加.
exception SyntaxError
パーザが構文エラーに遭遇した場合に送出されます。この例外は import 文、組み込み関数 exec() や eval() 、初期化スクリプトの読み込みや標準入力で (対話的な実行時にも) 起こる可能性があります。
このクラスのインスタンスは、例外の詳細に簡単にアクセスできるようにするために、属性 filename, lineno, offset, text を持ちます。例外インスタンスに対する str() はメッセージのみを返します。
exception IndentationError
正しくないインデントに関する構文エラーの基底クラスです。これは SyntaxError のサブクラスです。
exception TabError
タブとスペースを一貫しない方法でインデントに使っているときに送出されます。これは IndentationError のサブクラスです。
exception SystemError
インタプリタが内部エラーを発見したが、状況は全ての望みを棄てさせるほど深刻ではないと思われる場合に送出されます。関連値は (下位層で) どの動作が失敗したかを示す文字列です。
使用中の Python インタプリタの作者または保守担当者にこのエラーを報告してください。このとき、Python インタプリタのバージョン (sys.version 。Python の対話的セッションを開始した際にも出力されます)、正確なエラーメッセージ (例外の関連値) を忘れずに報告してください。可能な場合にはエラーを引き起こしたプログラムのソースコードも報告してください。
exception SystemExit
この例外は sys.exit() 関数から送出されます。Exception をキャッチするコードに誤ってキャッチされないように、Exception ではなく BaseException を継承しています。これにより例外は上の階層に適切に伝わり、インタープリタを終了させます。この例外が処理されなかった場合はスタックのトレースバックを表示せずに Python インタープリタは終了します。コンストラクタは sys.exit() に渡されるオプション引数と同じものを受け取ります。値が整数の場合、システムの終了ステータス (C 言語の exit() 関数に渡すもの)を指定します。値が None の場合、終了ステータスは 0 です。それ以外の型の場合 (例えば str)、 オブジェクトの値が表示され、終了ステータスは 1 です。
sys.exit() は、クリーンアップのための処理 (try 文の finally 節) が実行されるようにするため、またデバッガが制御不能になるリスクを冒さずにスクリプトを実行できるようにするために例外に変換されます。即座に終了することが真に強く必要であるとき (例えば、os.fork() を呼んだ後の子プロセス内) には os._exit() 関数を使うことができます。
code
コンストラクタに渡された終了ステータス又はエラーメッセージ。(デフォルトは None)
exception TypeError
組み込み演算または関数が適切でない型のオブジェクトに対して適用された際に送出されます。関連値は型の不整合に関して詳細を述べた文字列です。
この例外は、そのオブジェクトで実行しようとした操作がサポートされておらず、その予定もない場合にユーザーコードから送出されるかもしれません。オブジェクトでその操作をサポートするつもりだが、まだ実装を提供していないのであれば、送出する適切な例外は NotImplementedError です。
誤った型の引数が渡された場合は (例えば、int が期待されるのに、list が渡された) TypeError となるべきです。しかし、誤った値(例えば、期待する範囲外の数)が引数として渡された場合は、 ValueError となるべきです。
exception UnboundLocalError
関数やメソッド内のローカルな変数に対して参照を行ったが、その変数には値が代入されていなかった場合に送出されます。 NameError のサブクラスです。
exception UnicodeError
Unicode に関するエンコードまたはデコードのエラーが発生した際に送出されます。 ValueError のサブクラスです。
UnicodeError はエンコードまたはデコードのエラーの説明を属性として持っています。例えば、 err.object[err.start:err.end] は、無効な入力のうちコーデックが処理に失敗した箇所を表します。
encoding
エラーを送出したエンコーディングの名前です。
reason
そのコーデックエラーを説明する文字列です。
object
コーデックがエンコードまたはデコードしようとしたオブジェクトです。
start
object の最初の無効なデータのインデクスです。
end
object の最後の無効なデータの次のインデクスです。
exception UnicodeEncodeError
Unicode 関連のエラーがエンコード中に発生した際に送出されます。 UnicodeError のサブクラスです。
exception UnicodeDecodeError
Unicode 関連のエラーがデコード中に発生した際に送出されます。 UnicodeError のサブクラスです。
exception UnicodeTranslateError
Unicode 関連のエラーが変換中に発生した際に送出されます。 UnicodeError のサブクラスです。
exception ValueError
演算子や関数が、正しい型だが適切でない値を持つ引数を受け取ったときや、 IndexError のようなより詳細な例外では記述できない状況で送出されます。
exception ZeroDivisionError
除算や剰余演算の第二引数が 0 であった場合に送出されます。関連値は文字列で、その演算における被演算子と演算子の型を示します。
以下の例外は、過去のバージョンとの後方互換性のために残されています; Python 3.3 より、これらは OSError のエイリアスです。
exception EnvironmentError
exception IOError
exception WindowsError
Windows でのみ利用できます。
OS 例外
以下の例外は OSError のサブクラスで、システムエラーコードに依存して送出されます。
exception BlockingIOError
ある操作が、ノンブロッキング操作に設定されたオブジェクト (例えばソケット) をブロックしそうになった場合に送出されます。errno EAGAIN, EALREADY, EWOULDBLOCK および EINPROGRESS に対応します。
BlockingIOError は、 OSError の属性に加えて一つの属性を持ちます:
characters_written
ストリームがブロックされるまでに書き込まれた文字数を含む整数です。この属性は io からのバッファ I/O クラスを使っているときに利用できます。
exception ChildProcessError
子プロセスの操作が失敗した場合に送出されます。errno ECHILD に対応します。
exception ConnectionError
コネクション関係の問題の基底クラス。
サブクラスは BrokenPipeError, ConnectionAbortedError, ConnectionRefusedError, ConnectionResetError です。
exception BrokenPipeError
ConnectionError のサブクラスで、もう一方の端が閉じられたパイプに書き込こもうとするか、書き込みのためにシャットダウンされたソケットに書き込こもうとした場合に発生します。 errno EPIPE と ESHUTDOWN に対応します。
exception ConnectionAbortedError
ConnectionError のサブクラスで、接続の試行が通信相手によって中断された場合に発生します。 errno ECONNABORTED に対応します。
exception ConnectionRefusedError
ConnectionError のサブクラスで、接続の試行が通信相手によって拒否された場合に発生します。 errno ECONNREFUSED に対応します。
exception ConnectionResetError
ConnectionError のサブクラスで、接続が通信相手によってリセットされた場合に発生します。 errno ECONNRESET に対応します。
exception FileExistsError
すでに存在するファイルやディレクトリを作成しようとした場合に送出されます。errno EEXIST に対応します。
exception FileNotFoundError
要求されたファイルやディレクトリが存在しない場合に送出されます。errno ENOENT に対応します。
exception InterruptedError
システムコールが入力信号によって中断された場合に送出されます。errno EINTR に対応します。
バージョン 3.5 で変更: シグナルハンドラが例外を送出せず、システムコールが信号で中断された場合 Python は InterruptedError を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください) 。
exception IsADirectoryError
ディレクトリに (os.remove() などの) ファイル操作が要求された場合に送出されます。errno EISDIR に対応します。
exception NotADirectoryError
ディレクトリ以外のものに (os.listdir() などの) ディレクトリ操作が要求された場合に送出されます。errno ENOTDIR に対応します。
exception PermissionError
十分なアクセス権、例えばファイルシステム権限のない操作が試みられた場合に送出されます。errno EACCES および EPERM に対応します。
exception ProcessLookupError
与えられたプロセスが存在しない場合に送出されます。errno ESRCH に対応します。
exception TimeoutError
システム関数がシステムレベルでタイムアウトした場合に送出されます。errno ETIMEDOUT に対応します。
バージョン 3.3 で追加: 上記のすべての OSError サブクラスが追加されました。
参考 PEP 3151 - OS および IO 例外階層の手直し
警告
次の例外は警告カテゴリとして使われます。詳細については 警告カテゴリ のドキュメントを参照してください。
exception Warning
警告カテゴリの基底クラスです。
exception UserWarning
ユーザコードによって生成される警告の基底クラスです。
exception DeprecationWarning
他の Python 開発者へ向けて警告を発するときの、廃止予定の機能についての警告の基底クラスです。
exception PendingDeprecationWarning
古くなって将来的に廃止される予定だが、今のところは廃止されていない機能についての警告の基底クラスです。
近々起こる可能性のある機能廃止について警告を発することはまれなので、このクラスはめったに使われず、既に決まっている廃止については DeprecationWarning が望ましいです。
exception SyntaxWarning
曖昧な構文に対する警告の基底クラスです。
exception RuntimeWarning
あいまいなランタイム挙動に対する警告の基底クラスです。
exception FutureWarning
Python で書かれたアプリケーションのエンドユーザーへ向けて警告を発するときの、廃止予定の機能についての警告の基底クラスです。
exception ImportWarning
モジュールインポートの誤りと思われるものに対する警告の基底クラスです。
exception UnicodeWarning
Unicode に関連した警告の基底クラスです。
exception BytesWarning
bytes や bytearray に関連した警告の基底クラスです。
exception ResourceWarning
リソースの使用に関連した警告の基底クラスです。
バージョン 3.2 で追加.
例外のクラス階層
組み込み例外のクラス階層は以下のとおりです:
zlib --- gzip 互換の圧縮
zlib の関数にはたくさんのオプションがあり、場合によっては特定の順番で使わなければなりません。このドキュメントではそれら順番についてすべてを説明しようとはしていません。詳細は公式サイト http://www.zlib.net/manual.html にある zlib のマニュアルを参照してください。
.gz ファイルの読み書きのためには、 gzip モジュールを参照してください。
このモジュールで利用可能な例外と関数を以下に示します:
exception zlib.error
圧縮および展開時のエラーによって送出される例外です。
zlib.adler32(data[, value])
data の Adler-32 チェックサムを計算します (Adler-32 チェックサムは、おおむね CRC32 と同等の信頼性を持ちながら、はるかに高速に計算できます)。結果は、符号のない 32 ビットの整数です。 value が与えられている場合、チェックサム計算の初期値として使われます。与えられていない場合、デフォルト値の 1 が使われます。 value を与えることで、複数の入力を結合したデータ全体にわたり、通しのチェックサムを計算できます。このアルゴリズムは暗号論的には強力ではなく、認証やデジタル署名などに用いるべきではありません。また、チェックサムアルゴリズムとして設計されているため、汎用のハッシュアルゴリズムには向きません。
バージョン 3.0 で変更: 常に符号のない値を返します。すべてのバージョンとプラットフォームの Python に渡って同一の数値を生成するには、 adler32(data) & 0xffffffff を使用します。
zlib.compress(data, /, level=-1)
バージョン 3.6 で変更: level can now be used as a keyword parameter.
zlib.compressobj(level=-1, method=DEFLATED, wbits=MAX_WBITS, memLevel=DEF_MEM_LEVEL, strategy=Z_DEFAULT_STRATEGY[, zdict])
一度にメモリ上に置くことができないようなデータストリームを圧縮するための圧縮オブジェクトを返します。
memLevel 引数は内部圧縮状態用に使用されるメモリ量を制御します。有効な値は 1 から 9 です。大きい値ほど多くのメモリを消費しますが、より速く、より小さな出力を作成します。
zdict は定義済み圧縮辞書です。これは圧縮されるデータ内で繰り返し現れると予想されるサブシーケンスを含む (bytes オブジェクトのような) バイト列のシーケンスです。最も一般的と思われるサブシーケンスは辞書の末尾に来なければなりません。
バージョン 3.3 で変更: zdict パラメータとキーワード引数のサポートが追加されました。
zlib.crc32(data[, value])
data の CRC (Cyclic Redundancy Check, 巡回冗長検査) チェックサムを計算します。結果は、符号のない 32 ビットの整数です。 value が与えられている場合、チェックサム計算の初期値として使われます。与えられていない場合、デフォルト値の 1 が使われます。 value を与えることで、複数の入力を結合したデータ全体にわたり、通しのチェックサムを計算できます。このアルゴリズムは暗号論的には強力ではなく、認証やデジタル署名などに用いるべきではありません。また、チェックサムアルゴリズムとして設計されているため、汎用のハッシュアルゴリズムには向きません。
バージョン 3.0 で変更: 常に符号のない値を返します。すべてのバージョンとプラットフォームの Python に渡って同一の数値を生成するには、crc32(data) & 0xffffffff を使用します。
zlib.decompressobj(wbits=MAX_WBITS[, zdict])
一度にメモリ上に置くことができないようなデータストリームを展開するための展開オブジェクトを返します。
zdict パラメータには定義済み圧縮辞書を指定します。このパラメータを指定する場合、展開するデータを圧縮した際に使用した辞書と同じものでなければなりません。
注釈 zdict が (bytearray のような) 変更可能オブジェクトの場合、decompressobj() の呼び出しとデコンプレッサの decompress() メソッドの最初の呼び出しの間に辞書の内容を変更してはいけません。
バージョン 3.3 で変更: パラメータに zdict を追加しました。
圧縮オブジェクトは以下のメソッドをサポートしています:
Compress.compress(data)
data を圧縮し、圧縮されたデータを含むバイト列オブジェクトを返します。この文字列は少なくとも data の一部分のデータに対する圧縮データを含みます。このデータは以前に呼んだ compress() が返した出力と結合することができます。入力の一部は以後の処理のために内部バッファに保存されることもあります。
Compress.flush([mode])
Compress.copy()
圧縮オブジェクトのコピーを返します。これを使うと先頭部分が共通している複数のデータを効率的に圧縮することができます。
バージョン 3.8 で変更: Added copy.copy() and copy.deepcopy() support to compression objects.
展開オブジェクトは以下のメソッドと属性をサポートしています:
Decompress.unused_data
圧縮データの末尾より後のバイト列が入ったバイト列オブジェクトです。すなわち、この値は圧縮データの入っているバイト列の最後の文字が利用可能になるまでは b"" のままとなります。入力バイト文字列すべてが圧縮データを含んでいた場合、この属性は b"" 、すなわち空バイト列になります。
Decompress.unconsumed_tail
展開されたデータを収めるバッファの長さ制限を超えたために、直近の decompress() 呼び出しで処理しきれなかったデータを含むバイト列オブジェクトです。このデータはまだ zlib 側からは見えていないので、正しい展開出力を得るには以降の decompress() メソッド呼び出しに (場合によっては後続のデータが追加された) データを差し戻さなければなりません。
Decompress.eof
圧縮データストリームの終了に達したかどうかを示すブール値です。
これは、正常な形式の圧縮ストリームと、不完全あるいは切り詰められたストリームとを区別することを可能にします。
バージョン 3.3 で追加.
Decompress.decompress(data, max_length=0)
data を展開し、少なくとも string の一部分に対応する展開されたデータを含むバイト列オブジェクトを返します。このデータは以前に decompress() メソッドを呼んだ時に返された出力と結合することができます。入力データの一部分が以後の処理のために内部バッファに保存されることもあります。
バージョン 3.6 で変更: max_length can be used as a keyword argument.
Decompress.flush([length])
未処理の入力データをすべて処理し、最終的に圧縮されなかった残りの出力バイト列オブジェクトを返します。flush() を呼んだ後、decompress() を再度呼ぶべきではありません。このときできる唯一の現実的な操作はオブジェクトの削除だけです。
オプション引数 length には出力バッファの初期サイズを指定します。
Decompress.copy()
展開オブジェクトのコピーを返します。これを使うとデータストリームの途中にある展開オブジェクトの状態を保存でき、未来のある時点で行なわれるストリームのランダムなシークをスピードアップするのに利用できます。
バージョン 3.8 で変更: Added copy.copy() and copy.deepcopy() support to decompression objects.
使用している zlib ライブラリのバージョン情報を以下の定数で確認できます:
zlib.ZLIB_VERSION
モジュールのビルド時に使用された zlib ライブラリのバージョン文字列です。これは ZLIB_RUNTIME_VERSION で確認できる、実行時に使用している実際の zlib ライブラリのバージョンとは異なる場合があります。
zlib.ZLIB_RUNTIME_VERSION
インタプリタが読み込んだ実際の zlib ライブラリのバージョン文字列です。
バージョン 3.3 で追加.
参考
gzip モジュール
gzip 形式ファイルへの読み書きを行うモジュール。
http://www.zlib.net
zlib ライブラリホームページ。
http://www.zlib.net/manual.html
zlib ライブラリの多くの関数の意味と使い方を解説したマニュアル。
gzip --- gzip ファイルのサポート
ソースコード: Lib/gzip.py
このモジュールは、GNU の gzip や gunzip のようにファイルを圧縮、展開するシンプルなインターフェイスを提供しています。
データ圧縮は zlib モジュールで提供されています。
gzip は GzipFile クラスと、簡易関数 open()、compress()、および decompress() を提供しています。GzipFile クラスは通常の ファイルオブジェクト と同様に gzip 形式のファイルを読み書きし、データを自動的に圧縮または展開します。
compress や pack 等によって作成され、gzip や gunzip が展開できる他のファイル形式についてはこのモジュールは対応していないので注意してください。
このモジュールは以下の項目を定義しています:
gzip.open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)
gzip 圧縮ファイルをバイナリまたはテキストモードで開き、ファイルオブジェクト を返します。
引数 filename には実際のファイル名 (str または bytes オブジェクト) か、既存のファイルオブジェクトを指定します。
引数 mode には、バイナリモード用に 'r'、'rb'、'a'、'ab'、'w'、'wb'、'x'、または 'xb'、テキストモード用に 'rt'、'at'、'wt'、または 'xt' を指定できます。デフォルトは 'rb' です。
引数 compresslevel は GzipFile コンストラクタと同様に 0 から 9 の整数を取ります。
バイナリモードでは、この関数は GzipFile コンストラクタ GzipFile(filename, mode, compresslevel) と等価です。この時、引数 encoding、errors、および newline を指定してはいけません。
テキストモードでは、GzipFile オブジェクトが作成され、指定されたエンコーディング、エラーハンドラの挙動、および改行文字で io.TextIOWrapper インスタンスにラップされます。
バージョン 3.3 で変更: filename にファイルオブジェクト指定のサポート、テキストモードのサポート、および引数に encoding、errors、および newline を追加しました。
バージョン 3.4 で変更: Added support for the 'x', 'xb' and 'xt' modes.
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
exception gzip.BadGzipFile
バージョン 3.8 で追加.
class gzip.GzipFile(filename=None, mode=None, compresslevel=9, fileobj=None, mtime=None)
GzipFile クラスのコンストラクタです。GzipFile オブジェクトは truncate() メソッドを除くほとんどの ファイルオブジェクト のメソッドをシミュレートします。少なくとも fileobj および filename は有効な値でなければなりません。
クラスの新しいインスタンスは、 fileobj に基づいて作成されます。 fileobj は通常のファイル、 io.BytesIO オブジェクト、 そしてその他ファイルをシミュレートできるオブジェクトでかまいません。 値はデフォルトでは None で、その場合ファイルオブジェクトを生成するために filename を開きます。
fileobj が None でない場合、filename 引数は gzip ファイルヘッダにインクルードされることのみに使用されます。gzip ファイルヘッダは圧縮されていないファイルの元の名前をインクルードするかもしれません。認識可能な場合、規定値は fileobj のファイル名です。そうでない場合、規定値は空の文字列で、元のファイル名はヘッダにはインクルードされません。
ファイルは常にバイナリモードで開かれることに注意してください。圧縮ファイルをテキストモードで開く場合、open() (または GzipFile を io.TextIOWrapper でラップしたオブジェクト) を使ってください。
引数 compresslevel は 0 から 9 の整数を取り、圧縮レベルを制御します; 1 は最も高速で最小限の圧縮を行い、9 は最も低速ですが最大限の圧縮を行います。0 は圧縮しません。デフォルトは 9 です。
mtime 引数は、圧縮時にストリームの最終更新日時フィールドに書き込まれるオプションの数値のタイムスタンプです。これは、圧縮モードでのみ提供することができます。省略された場合か None である場合、現在時刻が使用されます。詳細については、 mtime 属性を参照してください。
圧縮したデータの後ろにさらに何か追加したい場合もあるので、GzipFile オブジェクトの close() メソッド呼び出しは fileobj を閉じません。 このため、書き込みのためにオープンした io.BytesIO オブジェクトを fileobj として渡し、(GzipFile を close() した後に) io.BytesIO オブジェクトの getvalue() メソッドを使って書き込んだデータの入っているメモリバッファを取得することができます。
GzipFile は、イテレーションと with 文を含む io.BufferedIOBase インターフェイスをサポートしています。truncate() メソッドのみ実装されていません。
GzipFile は以下のメソッドと属性も提供しています:
peek(n)
ファイル内の位置を移動せずに展開した n バイトを読み込みます。呼び出し要求を満たすために、圧縮ストリームに対して最大 1 回の単一読み込みが行われます。返されるバイト数はほぼ要求した値になります。
注釈 peek() の呼び出しでは GzipFile のファイル位置は変わりませんが、下層のファイルオブジェクトの位置が変わる惧れがあります。(e.g. GzipFile が fileobj 引数で作成された場合)
バージョン 3.2 で追加.
mtime
展開時に、最後に読み取られたヘッダーの最終更新日時フィールドの値は、この属性から整数として読み取ることができます。ヘッダーを読み取る前の初期値は None です。
gzip で圧縮されたすべてのストリームは、このタイムスタンプフィールドを含む必要があります。gunzip などの一部のプログラムがこのタイムスタンプを使用します。形式は、 time.time() の返り値や、os.stat() が返すオブジェクトの st_mtime 属性と同一です。
バージョン 3.1 で変更: with 文がサポートされました。mtime コンストラクタ引数と mtime 属性が追加されました。
バージョン 3.2 で変更: ゼロパディングされたファイルやシーク出来ないファイルがサポートされました。
バージョン 3.3 で変更: io.BufferedIOBase.read1() メソッドを実装しました。
バージョン 3.4 で変更: 'x' ならびに 'xb' モードがサポートされました。
バージョン 3.5 で変更: 任意の バイトライクオブジェクト の書き込みがサポートされました。 read() メソッドが None を引数として受け取るようになりました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
gzip.compress(data, compresslevel=9, *, mtime=None)
バージョン 3.2 で追加.
gzip.decompress(data)
data を展開し、展開データを含む bytes オブジェクトを返します。
バージョン 3.2 で追加.
使い方の例
圧縮されたファイルを読み込む例:
import gzip
with gzip.open('/home/joe/file.txt.gz', 'rb') as f:
    file_content = f.read()
GZIP 圧縮されたファイルを作成する例:
import gzip
content = b"Lots of content here"
with gzip.open('/home/joe/file.txt.gz', 'wb') as f:
    f.write(content)
既存のファイルを GZIP 圧縮する例:
import gzip
import shutil
with open('/home/joe/file.txt', 'rb') as f_in:
    with gzip.open('/home/joe/file.txt.gz', 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)
バイナリ文字列を GZIP 圧縮する例:
import gzip
s_in = b"Lots of content here"
s_out = gzip.compress(s_in)
参考
zlib モジュール
gzip ファイル形式のサポートを行うために必要な基本ライブラリモジュール。
-h, --help
ヘルプメッセージを出力します
bz2 --- bzip2 圧縮のサポート
ソースコード: Lib/bz2.py
このモジュールは、bzip2 アルゴリズムを用いて圧縮・展開を行う包括的なインターフェイスを提供します。
bz2 モジュールには以下のクラスや関数があります:
圧縮ファイルを読み書きするための open() 関数と BZ2File クラス。
インクリメンタルにデータを圧縮・展開するための BZ2Compressor および BZ2Decompressor クラス。
一度に圧縮・展開を行う compress() および decompress() 関数。
このモジュールのクラスはすべて、複数のスレッドから安全にアクセスできます。
ファイルの圧縮/解凍
bz2.open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)
bzip2 圧縮されたファイルを、バイナリモードかテキストモードでオープンし、ファイルオブジェクト を返します。
BZ2File のコンストラクタと同様に、引数 filename には実際のファイル名 (str または bytes オブジェクト) か、読み書きする既存のファイルオブジェクトを指定します。
引数 mode には、バイナリモード用に 'r'、'rb'、'w'、'wb'、'x'、'xb'、'a'、あるいは 'ab'、テキストモード用に 'rt'、'wt'、'xt'、あるいは 'at' を指定できます。デフォルトは 'rb' です。
引数 compresslevel には BZ2File コンストラクタと同様に 1 から 9 の整数を指定します。
バイナリモードでは、この関数は BZ2File コンストラクタ BZ2File(filename, mode, compresslevel=compresslevel) と等価です。この時、引数 encoding、errors、および newline を指定してはいけません。
テキストモードでは、BZ2File オブジェクトが作成され、指定されたエンコーディング、エラーハンドラの挙動、および改行文字で io.TextIOWrapper にラップされます。
バージョン 3.3 で追加.
バージョン 3.4 で変更: 'x' (排他的作成) モードが追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
class bz2.BZ2File(filename, mode='r', *, compresslevel=9)
bzip2 圧縮ファイルをバイナリモードでオープンします。
filename が str あるいは bytes オブジェクトの場合、それを名前とするファイルを直接開きます。そうでない場合、filename は圧縮データを読み書きする ファイルオブジェクト でなくてはなりません。
引数 mode は読み込みモードの 'r' (デフォルト)、上書きモードの 'w'、排他的作成モードの 'x'、あるいは追記モードの 'a' のいずれかを指定できます。これらはそれぞれ 'rb'、'wb'、'xb' および 'ab' と等価です。
filename が (実際のファイル名でなく) ファイルオブジェクトの場合、'w' はファイルを上書きせず、'a' と等価になります。
mode が 'w' あるいは 'a' の場合、compresslevel に圧縮レベルを 1 から 9 の整数で指定できます。 圧縮率は 1 が最低で、9 (デフォルト値) が最高です。
mode の値が 'r' の場合、入力ファイルは複数の圧縮ストリームでも構いません。
BZ2File には、 io.BufferedIOBase で規定されているメソッドや属性のうち、 detach() と truncate() を除くすべてが備わっています。イテレーションと with 文をサポートしています。
BZ2File は以下のメソッドも提供しています:
peek([n])
ファイル上の現在位置を変更せずにバッファのデータを返します。このメソッドは少なくとも 1 バイトのデータを返します (EOF の場合を除く)。返される正確なバイト数は規定されていません。
注釈 peek() の呼び出しでは BZ2File のファイル位置は変わりませんが、下層のファイルオブジェクトの位置が変わる惧れがあります(e.g. BZ2File を filename にファイルオブジェクトを渡して作成した場合)。
バージョン 3.3 で追加.
バージョン 3.1 で変更: with 構文のサポートが追加されました。
バージョン 3.3 で変更: fileno() 、 readable() 、 seekable() 、 writable() 、 read1() 、 readinto() メソッドが追加されました。
バージョン 3.3 で変更: filename が実際のファイル名でなく ファイルオブジェクト だった場合のサポートが追加されました。
バージョン 3.3 で変更: 'a' (追記) モードが追加され、複数のストリームの読み込みがサポートされました。
バージョン 3.4 で変更: 'x' (排他的作成) モードが追加されました。
バージョン 3.5 で変更: read() メソッドが None を引数として受け取るようになりました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
逐次圧縮および展開
class bz2.BZ2Compressor(compresslevel=9)
新しくコンプレッサオブジェクトを作成します。このオブジェクトはデータの逐次的な圧縮に使用できます。一度に圧縮したい場合は、compress() 関数を使ってください。
引数 compresslevel を指定する場合は、1 から 9 までの整数を与えてください。 デフォルト値は 9 です。
compress(data)
データをコンプレッサオブジェクトに渡します。戻り値は圧縮されたデータですが、圧縮データを返すことができない場合は空のバイト文字列を返します。
コンプレッサオブジェクトにデータをすべて渡し終えたら、flush() メソッドを呼び出し、圧縮プロセスを完了させてください。
flush()
圧縮プロセスを完了させ、内部バッファに残っている圧縮済みデータを返します。
このメソッドを呼び出すと、それ以後コンプレッサオブジェクトは使用できなくなります。
class bz2.BZ2Decompressor
新しくデコンプレッサオブジェクトを作成します。このオブジェクトは逐次的なデータ展開に使用できます。一度に展開したい場合は、decompress() 関数を使ってください。
注釈 このクラスは、decompress() や BZ2File とは異なり、複数の圧縮レベルが混在しているデータを透過的に扱うことができません。 BZ2Decompressor クラスを用いて、複数のストリームからなるデータを展開する場合は、それぞれのストリームについてデコンプレッサオブジェクトを用意してください。
decompress(data, max_length=-1)
data (bytes-like object) を展開し、未圧縮のデータを bytes で返します。 data の一部は、後で decompress() の呼び出しに使用するため内部でバッファされている場合があります。 返されたデータは、以前の decompress() の呼び出しの出力に連結する必要があります。
max_length が非負の場合、最大 max_length バイトの展開データを返します。この制限に達して、出力がさらに生成できる場合、 needs_input が False に設定されます。この場合、 decompress() を次に呼び出すと、data を b'' として提供し、出力をさらに取得することができます。
入力データの全てが圧縮され返された (max_length バイトより少ないためか max_length が負のため) 場合、 needs_input 属性は True になります。
ストリームの終端に到達した後にデータを展開しようとすると EOFError が送出されます。 ストリームの終端の後ろの全てのデータは無視され、その部分は unused_data 属性に保存されます。
バージョン 3.5 で変更: max_length パラメータが追加されました。
eof
ストリーム終端記号に到達した場合 True を返します。
バージョン 3.3 で追加.
unused_data
圧縮ストリームの末尾以降に存在したデータを表します。
ストリームの末尾に達する前には、この属性には b'' という値が収められています。
needs_input
decompress() メソッドが、新しい非圧縮入力を必要とせずにさらに展開データを提供できる場合、 False です。
バージョン 3.5 で追加.
一括圧縮/解凍
bz2.compress(data, compresslevel=9)
バイト類オブジェクト の data を圧縮します。
引数 compresslevel を指定する場合は、1 から 9 までの整数を与えてください。 デフォルト値は 9 です。
逐次的にデータを圧縮したい場合は、BZ2Compressor を使ってください。
bz2.decompress(data)
バイト類オブジェクト の data を展開します。
data が複数の圧縮ストリームから成る場合、そのすべてを展開します。
逐次的に展開を行う場合は、BZ2Decompressor を使ってください。
バージョン 3.3 で変更: 複数ストリームの入力をサポートしました。
使い方の例
以下は、典型的な bz2 モジュールの利用方法です。
compress() と decompress() を使い、圧縮して展開する実演をしています:
>>>
import bz2
data = b"""\
Donec rhoncus quis sapien sit amet molestie. Fusce scelerisque vel augue
nec ullamcorper. Nam rutrum pretium placerat. Aliquam vel tristique lorem,
sit amet cursus ante. In interdum laoreet mi, sit amet ultrices purus
pulvinar a. Nam gravida euismod magna, non varius justo tincidunt feugiat.
Aliquam pharetra lacus non risus vehicula rutrum. Maecenas aliquam leo
felis. Pellentesque semper nunc sit amet nibh ullamcorper, ac elementum
dolor luctus. Curabitur lacinia mi ornare consectetur vestibulum."""
c = bz2.compress(data)
len(data) / len(c)  # Data compression ratio
1.513595166163142
d = bz2.decompress(c)
data == d  # Check equality to original object after round-trip
True
BZ2Compressor を使い、逐次圧縮をしています:
>>>
import bz2
def gen_data(chunks=10, chunksize=1000):
    """Yield incremental blocks of chunksize bytes."""
    for _ in range(chunks):
        yield b"z" * chunksize
comp = bz2.BZ2Compressor()
out = b""
for chunk in gen_data():
    # Provide data to the compressor object
    out = out + comp.compress(chunk)
# Finish the compression process.  Call this once you have
# finished providing data to the compressor.
out = out + comp.flush()
上の例は、非常に "ランダムでない" データストリーム (チャンク b"z" のストリーム) です。 ランダムなデータは圧縮率が低い傾向にある一方、揃っていて、繰り返しのあるデータは通常は高い圧縮率を叩き出します。
bzip2 圧縮されたファイルをバイナリモードで読み書きしています:
>>>
import bz2
data = b"""\
Donec rhoncus quis sapien sit amet molestie. Fusce scelerisque vel augue
nec ullamcorper. Nam rutrum pretium placerat. Aliquam vel tristique lorem,
sit amet cursus ante. In interdum laoreet mi, sit amet ultrices purus
pulvinar a. Nam gravida euismod magna, non varius justo tincidunt feugiat.
Aliquam pharetra lacus non risus vehicula rutrum. Maecenas aliquam leo
felis. Pellentesque semper nunc sit amet nibh ullamcorper, ac elementum
dolor luctus. Curabitur lacinia mi ornare consectetur vestibulum."""
with bz2.open("myfile.bz2", "wb") as f:
    # Write compressed data to file
    unused = f.write(data)
with bz2.open("myfile.bz2", "rb") as f:
    # Decompress data from file
    content = f.read()
content == data  # Check equality to original object after round-trip
True
lzma --- LZMA アルゴリズムを使用した圧縮
バージョン 3.3 で追加.
ソースコード: Lib/lzma.py
このモジュールは LZMA 圧縮アルゴリズムを使用したデータ圧縮および展開のためのクラスや便利な関数を提供しています。また、xz ユーティリティを使用した .xz およびレガシーな .lzma ファイル形式へのファイルインターフェイスの他、RAW 圧縮ストリームもサポートしています。
このモジュールが提供するインターフェイスは bz2 モジュールと非常によく似ています。ただし、LZMAFile は (bz2.BZ2File と異なり) スレッドセーフではない点に注意してください。単一の LZMAFile インスタンスを複数スレッドから使用する場合は、ロックで保護する必要があります。
exception lzma.LZMAError
この例外は圧縮あるいは展開中にエラーが発生した場合、または圧縮/展開状態の初期化中に送出されます。
圧縮ファイルへの読み書き
lzma.open(filename, mode="rb", *, format=None, check=-1, preset=None, filters=None, encoding=None, errors=None, newline=None)
LZMA 圧縮ファイルをバイナリまたはテキストモードでオープンし、ファイルオブジェクト を返します。
filename 引数には、ファイルをオープンする際には実際のファイル名 (str、 bytes、または path-like オブジェクトとして指定します)か、読み込みまたは書き込むためであれば、すでに存在するファイルオブジェクトを指定できます。
引数 mode は、バイナリモードでは "r"、"rb"、"w"、"wb"、"x"、"xb"、"a"、あるいは "ab" の、テキストモードでは "rt"、"wt"、"xt"、あるいは "at" のいずれかになります。デフォルトは "rb" です。
読み込み用にファイルをオープンした場合、引数 format および filters は LZMADecompressor と同じ意味になります。この時、引数 check および preset は使用しないでください。
書き出し用にオープンした場合、引数 format、check、preset、および filters は LZMACompressor と同じ意味になります。
バイナリモードでは、この関数は LZMAFile コンストラクタと等価になります (LZMAFile(filename, mode, ...))。この場合、引数 encoding、errors、および newline を指定しなければなりません。
テキストモードでは、LZMAFile オブジェクトが生成され、指定したエンコーディング、エラーハンドラの挙動、および改行コードで io.TextIOWrapper にラップされます。
バージョン 3.4 で変更: "x", "xb", "xt" モードのサポートが追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
class lzma.LZMAFile(filename=None, mode="r", *, format=None, check=-1, preset=None, filters=None)
LZMA 圧縮ファイルをバイナリモードで開きます。
LZMAFile はすでにオープンしている file object をラップ、または名前付きファイルを直接操作できます。引数 filename にはラップするファイルオブジェクトかオープンするファイル名 (str オブジェクトま、bytes オブジェクト、または path-like オブジェクト) を指定します。既存のファイルオブジェクトをラップした場合、LZMAFile をクローズしてもラップしたファイルはクローズされません。
引数 mode は読み込みモードの "r" (デフォルト)、上書きモードの "w"、排他的生成モードの "x"、あるいは追記モードの "a" のいずれかを指定できます。これらはそれぞれ "rb"、"wb"、"xb"、および "ab" と等価です。
filename が (実際のファイル名でなく) ファイルオブジェクトの場合、"w" モードはファイルを上書きせず、"a" と等価になります。
読み込みモードでファイルをオープンした時、入力ファイルは複数に分割された圧縮ストリームを連結したものでもかまいません。これらは透過的に単一論理ストリームとしてデコードされます。
読み込み用にファイルをオープンした場合、引数 format および filters は LZMADecompressor と同じ意味になります。この時、引数 check および preset は使用しないでください。
書き出し用にオープンした場合、引数 format、check、preset、および filters は LZMACompressor と同じ意味になります。
LZMAFile は io.BufferedIOBase で規定されているメンバのうち、detach() と truncate() を除くすべてをサポートします。イテレーションと with 文をサポートしています。
次のメソッドを提供しています:
peek(size=-1)
ファイル上の現在位置を変更せずにバッファのデータを返します。EOF に達しない限り、少なくとも 1 バイトが返されます。返される正確なバイト数は規定されていません (引数 size は無視されます)。
注釈 peek() の呼び出しでは LZMAFile のファイル位置は変わりませんが、下層のファイルオブジェクトの位置が変わる惧れがあります。(e.g. LZMAFile を filename にファイルオブジェクトを渡して作成した場合)
バージョン 3.4 で変更: 'x', 'xb' モードがサポートが追加されました。
バージョン 3.5 で変更: read() メソッドが None を引数として受け取るようになりました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
メモリ上での圧縮と展開
class lzma.LZMACompressor(format=FORMAT_XZ, check=-1, preset=None, filters=None)
データをインクリメンタルに圧縮する圧縮オブジェクトを作成します。
大量の単一データを圧縮する、より便利な方法については compress() を参照してください。
引数 format には使用するコンテナフォーマットを指定します。以下の値が指定できます:
FORMAT_XZ: The .xz コンテナフォーマット。
デフォルトのフォーマットです。
FORMAT_ALONE: レガシーな .lzma コンテナフォーマット。
このフォーマットは .xz より制限があります -- インテグリティチェックや複数フィルタをサポートしていません。
FORMAT_RAW: 特定のコンテナフォーマットを使わない、生のデータストリーム。
このフォーマット指定子はインテグリティチェックをサポートしておらず、(圧縮および展開双方のために) 常にカスタムフィルタチェインを指定する必要があります。さらに、この方法で圧縮されたデータは FORMAT_AUTO を使っても展開できません (LZMADecompressor を参照)。
引数 check には圧縮データに組み込むインテグリティチェックのタイプを指定します。このチェックは展開時に使用され、データが破損していないことを保証します。以下の値が指定できます:
CHECK_NONE: インテグリティチェックなし。FORMAT_ALONE および FORMAT_RAW のデフォルト (かつ唯一指定可能な値) です。
CHECK_CRC32: 32-bit 巡回冗長検査。
CHECK_CRC64: 64-bit 巡回冗長検査。FORMAT_XZ のデフォルトです。
CHECK_SHA256: 256-bit セキュアハッシュアルゴリズム (SHA)。
指定したチェック方法がサポートされていない場合、LZMAError が送出されます。
圧縮設定はプリセット圧縮レベル (引数 preset で指定) またはカスタムフィルタチェイン (引数 filters で指定) のどちらかを指定します。
引数 preset を指定する場合、0 から 9 までの整数値でなければならず、オプションで定数 PRESET_EXTREME を論理和指定できます。preset も filters も指定されなかった場合、デフォルトの挙動として PRESET_DEFAULT (プリセットレベル 6) が使用されます。高いプリセット値を指定すると圧縮率が上がりますが、圧縮にかかる時間が長くなります。
注釈 CPU の使用量が多いのに加えて、高いプリセットで圧縮を行うには、メモリをずっと多く必要とします (さらに、生成される出力も展開により多くのメモリを必要とします)。例えば、プリセットが 9 の場合、LZMACompressor オブジェクトのオーバーヘッドは 800 MiB にまで高くなる場合があります。このため、通常はデフォルトのプリセットを使用するのがよいでしょう。
引数 filters を指定する場合、フィルタチェイン指定子でなければなりません。詳しくは カスタムフィルタチェインの指定 を参照してください。
compress(data)
data (bytes オブジェクト) を圧縮し、少なくともその一部が圧縮されたデータを格納する bytes オブジェクトを返します。data の一部は、後で compress() および flush() の呼び出しに使用するため内部でバッファされている場合があります。返すデータは以前の compress() 呼び出しの出力を連結したものです。
flush()
圧縮処理を終了し、コンプレッサの内部バッファにあるあらゆるデータを格納する bytes オブジェクトを返します。
コンプレッサはこのメソッドが呼び出された後は使用できません。
class lzma.LZMADecompressor(format=FORMAT_AUTO, memlimit=None, filters=None)
データをインクリメンタルに展開するために使用できる展開オブジェクトを作成します。
圧縮されたストリーム全体を一度に展開にする、より便利な方法については、decompress() を参照してください。
引数 format には使用するコンテナフォーマットを指定します。デフォルトは FORMAT_AUTO で、.xz および .lzma ファイルを展開できます。その他に指定できる値は、FORMAT_XZ、FORMAT_ALONE、および FORMAT_RAW です。
引数 memlimit にはデコンプレッサが使用できるメモリ量をバイトで指定します。この引数を指定した場合、そのメモリ量で展開ができないと LZMAError を送出します。
引数 filters には展開されるストリームの作成に使用するフィルタチェインを指定します。この引数を使用する際は、引数 format に FORMAT_RAW を指定しなければなりません。フィルタチェインについての詳細は カスタムフィルタチェインの指定 を参照してください。
注釈 このクラスは decompress() および LZMAFile と異なり、複数の圧縮ストリームを含む入力を透過的に扱いません。 LZMADecompressor で複数ストリーム入力を展開するには、各ストリームごとに新しいデコンプレッサを作成しなければなりません。
decompress(data, max_length=-1)
data (bytes-like object) を展開し、未圧縮のデータを bytes で返します。 data の一部は、後で decompress() の呼び出しに使用するため内部でバッファされている場合があります。 返すデータは以前の decompress() 呼び出しの出力を全て連結したものです。
max_length が非負の場合、最大 max_length バイトの展開データを返します。この制限に達して、出力がさらに生成できる場合、 needs_input が False に設定されます。この場合、 decompress() を次に呼び出すと、data を b'' として提供し、出力をさらに取得することができます。
入力データの全てが圧縮され返された (max_length バイトより少ないためか max_length が負のため) 場合、 needs_input 属性は True になります。
ストリームの終端に到達した後にデータを展開しようとすると EOFError が送出されます。 ストリームの終端の後ろの全てのデータは無視され、その部分は unused_data 属性に保存されます。
バージョン 3.5 で変更: max_length パラメータが追加されました。
check
入力ストリームに使用されるインテグリティチェックの ID です。これは何のインテグリティチェックが使用されているか決定するために十分な入力がデコードされるまでは CHECK_UNKNOWN になることがあります。
eof
ストリーム終端記号に到達した場合 True を返します。
unused_data
圧縮ストリームの末尾以降に存在したデータを表します。
ストリームの末尾に達する前は、これは b"" になります。
needs_input
decompress() メソッドが、新しい非圧縮入力を必要とせずにさらに展開データを提供できる場合、 False です。
バージョン 3.5 で追加.
lzma.compress(data, format=FORMAT_XZ, check=-1, preset=None, filters=None)
data (bytes オブジェクト) を圧縮し、圧縮データを bytes オブジェクトとして返します。
引数 format、check、preset、および filters についての説明は上記の LZMACompressor を参照してください。
lzma.decompress(data, format=FORMAT_AUTO, memlimit=None, filters=None)
data (bytes オブジェクト) を展開し、展開データを bytes オブジェクトとして返します。
data が複数の明確な圧縮ストリームの連結だった場合、すべてのストリームを展開し、結果の連結を返します。
引数 format、memlimit、および filters の説明は、上記 LZMADecompressor を参照してください。
その他
lzma.is_check_supported(check)
指定したインテグリティチェックがシステムでサポートされていれば True を返します。
CHECK_NONE および CHECK_CRC32 は常にサポートされています。CHECK_CRC64 および CHECK_SHA256 は liblzma が機能制限セットでコンパイルされている場合利用できないことがあります。
カスタムフィルタチェインの指定
フィルタチェイン指定子は、辞書のシーケンスで、各辞書は ID と単一フィルタのオプションからなります。各辞書はキー "id" を持たなければならず、フィルタ依存のオプションを指定する追加キーを持つ場合もあります。有効なフィルタ ID は以下のとおりです:
圧縮フィルタ:
FILTER_LZMA1 (FORMAT_ALONE と共に使用)
FILTER_LZMA2 (FORMAT_XZ および FORMAT_RAW と共に使用)
デルタフィルター:
FILTER_DELTA
ブランチコールジャンプ (BCJ) フィルター:
FILTER_X86
FILTER_IA64
FILTER_ARM
FILTER_ARMTHUMB
FILTER_POWERPC
FILTER_SPARC
一つのフィルタチェインは 4 個までのフィルタを定義することができ、空にはできません。チェインの最後は圧縮フィルタでなくてはならず、その他のフィルタはデルタまたは BCJ フィルタでなければなりません。
圧縮フィルタは以下のオプション (追加エントリとしてフィルタを表す辞書に指定) をサポートしています:
preset: 明示されていないオプションのデフォルト値のソースとして使用する圧縮プリセット。
dict_size: 辞書のサイズのバイト数。これは、 4 KiB から 1.5 GiB の間にしてください (両端を含みます)。
lc: リテラルコンテキストビットの数。
lp: リテラル位置ビットの数。lc + lp で最大 4 までです。
pb: 位置ビットの数。最大で 4 までです。
mode: MODE_FAST または MODE_NORMAL。
nice_len: マッチに "良い" とみなす長さ。273 以下でなければなりません。
mf: 使用するマッチファインダ -- MF_HC3、MF_HC4、MF_BT2、MF_BT3、または MF_BT4。
depth: マッチファインダが使用する検索の最大深度。0 (デフォルト) では他のフィルタオプションをベースに自動選択します。
デルタフィルターは、バイト間の差異を保存し、特定の状況で、コンプレッサーに対してさらに反復的な入力を生成します。 デルタフィルターは、1 つのオプション dist のみをサポートします。 これは差し引くバイトどうしの距離を示します。 デフォルトは 1 で、隣接するバイトの差異を扱います。
使用例
圧縮ファイルからの読み込み:
import lzma
with lzma.open("file.xz") as f:
    file_content = f.read()
圧縮ファイルの作成:
import lzma
data = b"Insert Data Here"
with lzma.open("file.xz", "w") as f:
    f.write(data)
メモリ上でデータを圧縮:
import lzma
data_in = b"Insert Data Here"
data_out = lzma.compress(data_in)
逐次圧縮:
import lzma
lzc = lzma.LZMACompressor()
out1 = lzc.compress(b"Some data\n")
out2 = lzc.compress(b"Another piece of data\n")
out3 = lzc.compress(b"Even more data\n")
out4 = lzc.flush()
# Concatenate all the partial results:
result = b"".join([out1, out2, out3, out4])
すでにオープンしているファイルへの圧縮データの書き出し:
import lzma
with open("file.xz", "wb") as f:
    f.write(b"This data will not be compressed\n")
    with lzma.open(f, "w") as lzf:
        lzf.write(b"This *will* be compressed\n")
    f.write(b"Not compressed\n")
カスタムフィルタチェインを使った圧縮ファイルの作成:
import lzma
my_filters = [
    {"id": lzma.FILTER_DELTA, "dist": 5},
    {"id": lzma.FILTER_LZMA2, "preset": 7 | lzma.PRESET_EXTREME},
]
with lzma.open("file.xz", "w", filters=my_filters) as f:
    f.write(b"blah blah blah")
zipfile --- ZIP アーカイブの処理
ソースコード: Lib/zipfile.py
ZIP は一般によく知られているアーカイブ (書庫化) および圧縮の標準ファイルフォーマットです。このモジュールでは ZIP 形式のファイルの作成、読み書き、追記、書庫内のファイル一覧の作成を行うためのツールを提供します。より高度な使い方でこのモジュールを利用したいのであれば、 PKZIP Application Note に定義されている ZIP ファイルフォーマットの理解が必要になるでしょう。
このモジュールは現在マルチディスク ZIP ファイルを扱うことはできません。ZIP64 拡張を利用する ZIP ファイル (サイズが 4 GiB を超えるような ZIP ファイル) は扱えます。このモジュールは暗号化されたアーカイブの復号をサポートしますが、現在暗号化ファイルを作成することはできません。C 言語ではなく、Python で実装されているため、復号は非常に遅くなっています。
このモジュールは以下の項目を定義しています:
exception zipfile.BadZipFile
正常ではない ZIP ファイルに対して送出されるエラーです。
バージョン 3.2 で追加.
exception zipfile.BadZipfile
BadZipFile の別名です。過去のバージョンの Python との互換性のために用意されています。
バージョン 3.2 で非推奨.
exception zipfile.LargeZipFile
ZIP ファイルが ZIP64 の機能を必要としているが、その機能が有効化されていない場合に送出されるエラーです。
class zipfile.ZipFile
ZIP ファイルの読み書きのためのクラスです。コンストラクタの詳細については、ZipFile オブジェクト 節を参照してください。
class zipfile.Path
バージョン 3.8 で追加.
class zipfile.PyZipFile
Python ライブラリを含む、ZIP アーカイブを作成するためのクラスです。
class zipfile.ZipInfo(filename='NoName', date_time=(1980, 1, 1, 0, 0, 0))
アーカイブ内の 1 個のメンバの情報を取得するために使うクラスです。このクラスのインスタンスは ZipFile オブジェクトの getinfo() および infolist() メソッドによって返されます。ほとんどの zipfile モジュールの利用者はこのクラスのインスタンスを作成する必要はなく、このモジュールによって作成されたものを使用できます。filename はアーカイブメンバのフルネームでなければならず、date_time はファイルが最後に変更された日時を表す 6 個のフィールドのタプルでなければなりません; フィールドは ZipInfo オブジェクト 節で説明されています。
zipfile.is_zipfile(filename)
filename が正しいマジックナンバをもつ ZIP ファイルの時に True を返し、そうでない場合 False を返します。filename にはファイルやファイルライクオブジェクトを渡すこともできます。
バージョン 3.1 で変更: ファイルおよびファイルライクオブジェクトをサポートしました。
zipfile.ZIP_STORED
アーカイブメンバを圧縮しない (複数ファイルを一つにまとめるだけ) ことを表す数値定数です。
zipfile.ZIP_DEFLATED
通常の ZIP 圧縮方法を表す数値定数です。これには zlib モジュールが必要です。
zipfile.ZIP_BZIP2
BZIP2 圧縮方法を表す数値定数です。これには bz2 モジュールが必要です。
バージョン 3.3 で追加.
zipfile.ZIP_LZMA
LZMA 圧縮方法を表す数値定数です。これには lzma モジュールが必要です。
バージョン 3.3 で追加.
注釈 ZIP ファイルフォーマット仕様は 2001 年より bzip2 圧縮を、2006 年より LZMA 圧縮をサポートしていますが、(過去の Python リリースを含む) 一部のツールはこれら圧縮方式をサポートしていないため、ZIP ファイルの処理を全く受け付けないか、あるいは個々のファイルの抽出に失敗する場合があります。
参考
PKZIP Application Note
ZIP ファイルフォーマットおよびアルゴリズムを作成した Phil Katz によるドキュメント。
Info-ZIP Home Page
Info-ZIP プロジェクトによる ZIP アーカイブプログラムおよびプログラム開発ライブラリに関する情報。
ZipFile オブジェクト
class zipfile.ZipFile(file, mode='r', compression=ZIP_STORED, allowZip64=True, compresslevel=None, *, strict_timestamps=True)
ファイルがモード 'w'、 'x' または 'a' で作成され、その後そのアーカイブにファイルを追加することなく クローズ された場合、空のアーカイブのための適切な ZIP 構造がファイルに書き込まれます。
ZipFile is also a context manager and therefore supports the with statement. In the example, myzip is closed after the with statement's suite is finished---even if an exception occurs:
with ZipFile('spam.zip', 'w') as myzip:
    myzip.write('eggs.txt')
バージョン 3.2 で追加: ZipFile をコンテキストマネージャとして使用できるようになりました。
バージョン 3.3 で変更: bzip2 および lzma 圧縮をサポートしました。
バージョン 3.4 で変更: ZIP64 拡張がデフォルトで有効になりました。
バージョン 3.5 で変更: seek 出来ないストリームのサポートが追加されました。'x' モードのサポートが追加されました。
バージョン 3.6 で変更: Previously, a plain RuntimeError was raised for unrecognized compression values.
バージョン 3.6.2 で変更: The file parameter accepts a path-like object.
バージョン 3.7 で変更: Add the compresslevel parameter.
バージョン 3.8 で追加: The strict_timestamps keyword-only argument
ZipFile.close()
アーカイブファイルをクローズします。close() はプログラムを終了する前に必ず呼び出さなければなりません。さもないとアーカイブ上の重要なレコードが書き込まれません。
ZipFile.getinfo(name)
アーカイブメンバ name に関する情報を持つ ZipInfo オブジェクトを返します。アーカイブに含まれないファイル名に対して getinfo() を呼び出すと、KeyError が送出されます。
ZipFile.infolist()
アーカイブに含まれる各メンバの ZipInfo オブジェクトからなるリストを返します。既存のアーカイブファイルを開いている場合、リストの順番は実際の ZIP ファイル中のメンバの順番と同じになります。
ZipFile.namelist()
アーカイブメンバの名前のリストを返します。
ZipFile.open(name, mode='r', pwd=None, *, force_zip64=False)
open() はコンテキストマネージャでもあるので with 文をサポートしています:
with ZipFile('spam.zip') as myzip:
    with myzip.open('eggs.txt') as myfile:
        print(myfile.read())
注釈 open()、read()、および extract() メソッドには、ファイル名または ZipInfo オブジェクトを指定できます。これは重複する名前のメンバを含む ZIP ファイルを読み込むときにそのメリットを享受できるでしょう。
バージョン 3.6 で変更: Removed support of mode='U'. Use io.TextIOWrapper for reading compressed text files in universal newlines mode.
バージョン 3.6 で変更: open() can now be used to write files into the archive with the mode='w' option.
バージョン 3.6 で変更: Calling open() on a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
ZipFile.extract(member, path=None, pwd=None)
メンバをアーカイブから現在の作業ディレクトリに展開します。member は展開するファイルのフルネームまたは ZipInfo オブジェクトでなければなりません。ファイル情報は可能な限り正確に展開されます。path は展開先のディレクトリを指定します。member はファイル名または ZipInfo オブジェクトです。pwd は暗号化ファイルに使われるパスワードです。
作成された (ディレクトリか新ファイルの) 正規化されたパスを返します。
注釈 メンバのファイル名が絶対パスなら、ドライブ/UNC sharepoint および先頭の (バック) スラッシュは取り除かれます。例えば、Unix で ///foo/bar は foo/bar となり、Window で C:\foo\bar は foo\bar となります。また、メンバのファイル名に含まれる全ての ".." は取り除かれます。例えば、../../foo../../ba..r は foo../ba..r となります。Windows では、不正な文字 (:, <, >, |, ", ?, および *) はアンダースコア (_) で置き換えられます。
バージョン 3.6 で変更: Calling extract() on a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
バージョン 3.6.2 で変更: path パラメタが path-like object を受け付けるようになりました。
ZipFile.extractall(path=None, members=None, pwd=None)
すべてのメンバをアーカイブから現在の作業ディレクトリに展開します。path は展開先のディレクトリを指定します。members は、オプションで、namelist() で返されるリストの部分集合でなければなりません。pwd は、暗号化ファイルに使われるパスワードです。
警告 信頼できないソースからきた Zip ファイルを、事前に中身をチェックせずに展開してはいけません。ファイルを path の外側に作成することができるからです。例えば、 "/" で始まる絶対パスを持ったメンバーや、 2 つのドット ".." を持つファイル名などの場合です。このモジュールはそれを避けようとします。 extract() の注釈を参照してください。
バージョン 3.6 で変更: Calling extractall() on a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
バージョン 3.6.2 で変更: path パラメタが path-like object を受け付けるようになりました。
ZipFile.printdir()
アーカイブの内容の一覧を sys.stdout に出力します。
ZipFile.setpassword(pwd)
pwd を展開する圧縮ファイルのデフォルトパスワードとして指定します。
ZipFile.read(name, pwd=None)
バージョン 3.6 で変更: Calling read() on a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
ZipFile.testzip()
バージョン 3.6 で変更: Calling testzip() on a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
ZipFile.write(filename, arcname=None, compress_type=None, compresslevel=None)
注釈 アーカイブ名はアーカイブルートに対する相対パスでなければなりません。言い換えると、アーカイブ名はパスセパレータで始まってはいけません。
注釈 もし、arcname (arcname が与えられない場合は、filename) が null byte を含むなら、アーカイブ中のファイルのファイル名は、null byte までで切り詰められます。
バージョン 3.6 で変更: Calling write() on a ZipFile created with mode 'r' or a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
ZipFile.writestr(zinfo_or_arcname, data, compress_type=None, compresslevel=None)
注釈 ZipInfo インスタンスを引数 zinfo_or_arcname として与えた場合、与えられた ZipInfo インスタンスのメンバーである compress_type で指定された圧縮方法が使われます。デフォルトでは、ZipInfo コンストラクターが、このメンバーを ZIP_STORED に設定します。
バージョン 3.2 で変更: 引数 compress_type を追加しました。
バージョン 3.6 で変更: Calling writestr() on a ZipFile created with mode 'r' or a closed ZipFile will raise a ValueError. Previously, a RuntimeError was raised.
以下のデータ属性も利用することができます:
ZipFile.filename
ZIP ファイルの名前です。
ZipFile.debug
使用するデバッグ出力レベルです。この属性は 0 (デフォルト、何も出力しない) から 3 (最も多く出力する) までの値に設定することができます。デバッグ情報は sys.stdout に出力されます。
ZipFile.comment
ZIP ファイルに bytes オブジェクトとして関連付けられたコメントです。モード 'w' 、 'x' または 'a' で作成された ZipFile インスタンスへコメントを割り当てる場合、文字列長は 65535 バイトまでにしてください。その長さを超えたコメントは切り捨てられます。
Path オブジェクト
class zipfile.Path(root, at='')
at specifies the location of this Path within the zipfile, e.g. 'dir/file.txt', 'dir/', or ''. Defaults to the empty string, indicating the root.
Path objects expose the following features of pathlib.Path objects:
Path.name
Path.open(mode='r', *, pwd, **)
バージョン 3.9 で変更: Added support for text and binary modes for open. Default mode is now text.
Path.iterdir()
Path.is_dir()
Path.is_file()
Path.exists()
Path.read_text(*, **)
Path.read_bytes()
PyZipFile オブジェクト
PyZipFile コンストラクタは ZipFile コンストラクタと同じパラメータに加え、optimize パラメータをとります。
class zipfile.PyZipFile(file, mode='r', compression=ZIP_STORED, allowZip64=True, optimize=-1)
バージョン 3.2 で追加: パラメータに optimize を追加しました。
バージョン 3.4 で変更: ZIP64 拡張がデフォルトで有効になりました。
インスタンスは ZipFile オブジェクトのメソッドの他に、追加のメソッドを 1 個持ちます:
writepy(pathname, basename='', filterfunc=None)
*.py ファイルを探し、一致するファイルをアーカイブに追加します。
PyZipFile に optimize 引数が与えられない場合、あるいは -1 が指定された場合、対応するファイルは *.pyc ファイルで、必要に応じてコンパイルします。
PyZipFile の optimize パラメータが 0、1、あるいは 2 の場合、それを最適化レベル (compile() 参照) とするファイルのみが、必要に応じてコンパイルされアーカイブに追加されます。
basename は内部が使用するためだけのものです。
filterfunc を与える場合、単一の文字列引数を取る関数を渡してください。これには(個々のフルパスを含む)それぞれのパスがアーカイブに加えられる前に渡されます。 filterfunc が偽を返せば、そのパスはアーカイブに追加されず、ディレクトリだった場合はその中身が無視されます。例として、私たちのテストファイルが全て test ディレクトリの中にあるか、 test 文字列で始まるとしましょう。 filterfunc を使ってそれらを除外出来ます:
>>>
>>> zf = PyZipFile('myprog.zip')
>>> def notests(s):
...     fn = os.path.basename(s)
...     return (not (fn == 'test' or fn.startswith('test_')))
>>> zf.writepy('myprog', filterfunc=notests)
writepy() メソッドは以下のようなファイル名でアーカイブを作成します:
string.pyc                   # Top level name
test/__init__.pyc            # Package directory
test/testall.pyc             # Module test.testall
test/bogus/__init__.pyc      # Subpackage directory
test/bogus/myfile.pyc        # Submodule test.bogus.myfile
バージョン 3.4 で追加: filterfunc パラメータ。
バージョン 3.6.2 で変更: The pathname parameter accepts a path-like object.
バージョン 3.7 で変更: Recursion sorts directory entries.
ZipInfo オブジェクト
ZipInfo クラスのインスタンスは、ZipFile オブジェクトの getinfo() および infolist() メソッドによって返されます。各オブジェクトは ZIP アーカイブ内の 1 個のメンバに関する情報を格納します。
There is one classmethod to make a ZipInfo instance for a filesystem file:
classmethod ZipInfo.from_file(filename, arcname=None, *, strict_timestamps=True)
filename should be the path to a file or directory on the filesystem.
バージョン 3.6 で追加.
バージョン 3.6.2 で変更: The filename parameter accepts a path-like object.
バージョン 3.8 で追加: The strict_timestamps keyword-only argument
Instances have the following methods and attributes:
ZipInfo.is_dir()
バージョン 3.6 で追加.
ZipInfo.filename
アーカイブ中のファイル名。
ZipInfo.date_time
アーカイブメンバの最終更新日時。6 つの値からなるタプルになります:
インデックス
値
0
西暦年 (>= 1980)
1
月 (1 から始まる)
2
日 (1 から始まる)
3
時 (0 から始まる)
4
分 (0 から始まる)
5
秒 (0 から始まる)
注釈 ZIP ファイルフォーマットは 1980 年より前のタイムスタンプをサポートしていません。
ZipInfo.compress_type
アーカイブメンバの圧縮形式。
ZipInfo.comment
ZipInfo.extra
ZipInfo.create_system
ZIP アーカイブを作成したシステムを記述する文字列。
ZipInfo.create_version
このアーカイブを作成した PKZIP のバージョン。
ZipInfo.extract_version
このアーカイブを展開する際に必要な PKZIP のバージョン。
ZipInfo.reserved
予約領域。ゼロでなくてはなりません。
ZipInfo.flag_bits
ZIP フラグビット列。
ZipInfo.volume
ファイルヘッダのボリューム番号。
ZipInfo.internal_attr
内部属性。
ZipInfo.external_attr
外部ファイル属性。
ZipInfo.header_offset
ファイルヘッダへのバイトオフセット。
ZipInfo.CRC
圧縮前のファイルの CRC-32 チェックサム。
ZipInfo.compress_size
圧縮後のデータのサイズ。
ZipInfo.file_size
圧縮前のファイルのサイズ。
コマンドラインインターフェイス
zipfile モジュールは、 ZIP アーカイブを操作するための簡単なコマンドラインインターフェースを提供しています。
ZIP アーカイブを新規に作成したい場合、-c オプションの後にまとめたいファイルを列挙してください:
$ python -m zipfile -c monty.zip spam.txt eggs.txt
ディレクトリを渡すこともできます:
$ python -m zipfile -c monty.zip life-of-brian_1979/
ZIP アーカイブを特定のディレクトリに展開したい場合、-e オプションを使用してください:
$ python -m zipfile -e monty.zip target-dir/
ZIP アーカイブ内のファイル一覧を表示するには -l を使用してください:
$ python -m zipfile -l monty.zip
コマンドラインオプション
-l <zipfile>
--list <zipfile>
zipfile 内のファイル一覧を表示します。
-c <zipfile> <source1> ... <sourceN>
--create <zipfile> <source1> ... <sourceN>
ソースファイルから zipfile を作成します。
-e <zipfile> <output_dir>
--extract <zipfile> <output_dir>
zipfile を対象となるディレクトリに展開します。
-t <zipfile>
--test <zipfile>
zipfile が有効かどうか調べます。
Decompression pitfalls
From file itself
File System limitations
Resources limitations
Interruption
Default behaviors of extraction
tarfile --- tar アーカイブファイルの読み書き
ソースコード: Lib/tarfile.py
tarfile モジュールは、gzip、bz2、および lzma 圧縮されたものを含む、tar アーカイブを読み書きできます。.zip ファイルの読み書きには zipfile モジュールか、あるいは shutil の高水準関数を使用してください。
いくつかの事実と形態:
モジュールが利用可能な場合、gzip、bz2 ならびに lzma で圧縮されたアーカイブを読み書きします。
POSIX.1-1988 (ustar) フォーマットの読み書きをサポートしています。
longname および longlink 拡張を含む GNU tar フォーマットの読み書きをサポートしています。スパースファイルの復元を含む sparse 拡張は読み込みのみサポートしています。
POSIX.1-2001 (pax) フォーマットの読み書きをサポートしています。
ディレクトリ、一般ファイル、ハードリンク、シンボリックリンク、fifo、キャラクターデバイスおよびブロックデバイスを処理します。また、タイムスタンプ、アクセス許可や所有者のようなファイル情報の取得および保存が可能です。
バージョン 3.3 で変更: lzma 圧縮をサポートしました。
tarfile.open(name=None, mode='r', fileobj=None, bufsize=10240, **kwargs)
パス名 name の TarFile オブジェクトを返します。TarFile オブジェクトと、利用できるキーワード引数に関する詳細な情報については、TarFile オブジェクト 節を参照してください。
mode は 'filemode[:compression]' の形式をとる文字列でなければなりません。デフォルトの値は 'r' です。以下に mode のとりうる組み合わせすべてを示します:
mode
action
'r' または 'r:*'
圧縮方法に関して透過的に、読み込み用にオープンします (推奨)。
'r:'
非圧縮で読み込み用に排他的にオープンします。
'r:gz'
gzip 圧縮で読み込み用にオープンします。
'r:bz2'
bzip2 圧縮で読み込み用にオープンします。
'r:xz'
lzma 圧縮で読み込み用にオープンします。
'x' or 'x:'
圧縮せずに tarfile を排他的に作成します。tarfile が既存の場合 FileExistsError 例外を送出します。
'x:gz'
gzip 圧縮で tarfile を作成します。tarfile が既存の場合 FileExistsError 例外を送出します。
'x:bz2'
bzip2 圧縮で tarfile を作成します。tarfile が既存の場合 FileExistsError 例外を送出します。
'x:xz'
lzma 圧縮で tarfile を作成します。tarfile が既存の場合 FileExistsError 例外を送出します。
'a' または 'a:'
非圧縮で追記用にオープンします。ファイルが存在しない場合は新たに作成されます。
'w' または 'w:'
非圧縮で書き込み用にオープンします。
'w:gz'
gzip 圧縮で書き込み用にオープンします。
'w:bz2'
bzip2 圧縮で書き込み用にオープンします。
'w:xz'
lzma 圧縮で書き込み用にオープンします。
'a:gz'、'a:bz2'、'a:xz' は利用できないことに注意して下さい。もし mode が、ある (圧縮した) ファイルを読み込み用にオープンするのに適していないなら、ReadError が送出されます。これを防ぐには mode 'r' を使って下さい。もし圧縮方式がサポートされていなければ、CompressionError が送出されます。
もし fileobj が指定されていれば、それは name でバイナリモードでオープンされた ファイルオブジェクト の代替として使うことができます。そのファイルオブジェクトの位置が 0 であることを前提に動作します。
'w:gz'、'r:gz'、'w:bz2'、'r:bz2', 'x:gz', 'x:bz2' モードの場合、tarfile.open() はファイルの圧縮レベルを指定するキーワード引数 compresslevel (デフォルトは 9) を受け付けます。
特別な目的のために、mode には 2 番目の形式: 'ファイルモード|[圧縮]' があります。この形式を使うと、tarfile.open() が返すのは、データをブロックからなるストリームとして扱う TarFile オブジェクトになります。この場合、ファイルに対してランダムなシークが行えなくなります。fileobj を指定する場合、 read() および write() メソッドを持つ (mode に依存した) 任意のオブジェクトにできます。bufsize にはブロックサイズを指定します。デフォルトは 20 * 512 バイトです。sys.stdin、ソケット file object、あるいはテープデバイスと組み合わせる場合にはこの形式を使ってください。ただし、このような TarFile オブジェクトにはランダムアクセスを行えないという制限があります。使用例 節を参照してください。現在可能なモードは以下のとおりです。
モード
動作
'r|*'
tar ブロックの stream を圧縮方法に関して透過的に読み込み用にオープンします。
'r|'
非圧縮 tar ブロックの stream を読み込み用にオープンします。
'r|gz'
gzip 圧縮の stream を読み込み用にオープンします。
'r|bz2'
bzip2 圧縮の stream を読み込み用にオープンします。
'r|xz'
lzma 圧縮の stream を読み込み用にオープンします。
'w|'
非圧縮の stream を書き込み用にオープンします。
'w|gz'
gzip 圧縮の stream を書き込み用にオープンします。
'w|bz2'
bzip2 圧縮の stream を書き込み用にオープンします。
'w|xz'
lzma 圧縮の stream を書き込み用にオープンします。
バージョン 3.5 で変更: 'x' (排他的作成) モードが追加されました。
バージョン 3.6 で変更: name パラメタが path-like object を受け付けるようになりました。
class tarfile.TarFile
tar アーカイブを読み書きするためのクラスです。このクラスを直接使わないこと: 代わりに tarfile.open() を使ってください。TarFile オブジェクト を参照してください。
tarfile.is_tarfile(name)
バージョン 3.9 で変更: ファイルおよびファイルライクオブジェクトをサポートしました。
tarfile モジュールは以下の例外を定義しています:
exception tarfile.TarError
すべての tarfile 例外のための基本クラスです。
exception tarfile.ReadError
tar アーカイブがオープンされた時、tarfile モジュールで操作できないか、あるいは何か無効であるとき送出されます。
exception tarfile.CompressionError
圧縮方法がサポートされていないか、あるいはデータを正しくデコードできない時に送出されます。
exception tarfile.StreamError
ストリームのような TarFile オブジェクトで典型的な制限のために送出されます。
exception tarfile.ExtractError
TarFile.extract() を使った時に 致命的でない エラーに対して送出されます。ただし TarFile.errorlevel== 2 の場合に限ります。
exception tarfile.HeaderError
TarInfo.frombuf() メソッドが取得したバッファーが不正だったときに送出されます。
モジュールレベルで以下の定数が利用できます。
tarfile.ENCODING
既定の文字エンコーディング。Windows では 'utf-8' 、それ以外では sys.getfilesystemencoding() の返り値です。
以下の各定数は、tarfile モジュールが作成できる tar アーカイブフォーマットを定義しています。詳細は、サポートしている tar フォーマット を参照してください。
tarfile.USTAR_FORMAT
POSIX.1-1988 (ustar) フォーマット。
tarfile.GNU_FORMAT
GNU tar フォーマット。
tarfile.PAX_FORMAT
POSIX.1-2001 (pax) フォーマット。
tarfile.DEFAULT_FORMAT
バージョン 3.8 で変更: The default format for new archives was changed to PAX_FORMAT from GNU_FORMAT.
参考
zipfile モジュール
zipfile 標準モジュールのドキュメント。
アーカイブ化操作
shutil が提供するより高水準のアーカイブ機能についてのドキュメント。
GNU tar manual, Basic Tar Format
GNU tar 拡張機能を含む、tar アーカイブファイルのためのドキュメント。
TarFile オブジェクト
TarFile オブジェクトは、tar アーカイブへのインターフェースを提供します。tar アーカイブは一連のブロックです。アーカイブメンバー (保存されたファイル) は、ヘッダーブロックとそれに続くデータブロックで構成されています。一つの tar アーカイブにファイルを何回も保存することができます。各アーカイブメンバーは、TarInfo オブジェクトで確認できます。詳細については TarInfo オブジェクト を参照してください。
TarFile オブジェクトは with 文のコンテキストマネージャーとして利用できます。with ブロックが終了したときにオブジェクトはクローズされます。例外が発生した時、内部で利用されているファイルオブジェクトのみがクローズされ、書き込み用にオープンされたアーカイブのファイナライズは行われないことに注意してください。使用例 節のユースケースを参照してください。
バージョン 3.2 で追加: コンテキスト管理のプロトコルがサポートされました。
class tarfile.TarFile(name=None, mode='r', fileobj=None, format=DEFAULT_FORMAT, tarinfo=TarInfo, dereference=False, ignore_zeros=False, encoding=ENCODING, errors='surrogateescape', pax_headers=None, debug=0, errorlevel=0)
以下のすべての引数はオプションで、インスタンス属性としてもアクセスできます。
name はアーカイブのパス名です。name は path-like object でも構いません。fileobj が渡された場合は省略可能です。その場合、ファイルオブジェクトに name 属性があれば、それを利用します。
mode は、既存のアーカイブから読み込むための 'r'、既存のアーカイブに追記するための 'a'、既存のファイルがあれば上書きして新しいファイルを作成する 'w' 、あるいは存在しない場合にのみ新しいファイルを作成する 'x' のいずれかです。
fileobj が与えられていれば、それを使ってデータを読み書きします。もしそれが決定できれば、mode は fileobj のモードで上書きされます。fileobj は位置 0 から利用されます。
注釈 TarFile をクローズした時、fileobj はクローズされません。
format controls the archive format for writing. It must be one of the constants USTAR_FORMAT, GNU_FORMAT or PAX_FORMAT that are defined at module level. When reading, format will be automatically detected, even if different formats are present in a single archive.
tarinfo 引数を利用して、デフォルトの TarInfo クラスを別のクラスで置き換えることができます。
dereference が False だった場合、シンボリックリンクやハードリンクがアーカイブに追加されます。True だった場合、リンクのターゲットとなるファイルの内容がアーカイブに追加されます。シンボリックリンクをサポートしていないシステムでは効果がありません。
ignore_zeros が False だった場合、空ブロックをアーカイブの終端として扱います。True だった場合、空の (無効な) ブロックをスキップして、可能な限り多くのメンバーを取得しようとします。このオプションは、連結されたり、壊れたアーカイブファイルを扱うときにのみ、意味があります。
debug は 0 (デバッグメッセージ無し) から 3 (全デバッグメッセージ) まで設定できます。このメッセージは sys.stderr に書き込まれます。
errorlevel が 0 の場合、TarFile.extract() 使用時にすべてのエラーが無視されます。エラーが無視された場合でも、debug が有効であれば、エラーメッセージは出力されます。1 の場合、すべての 致命的な(fatal) エラーは OSError を送出します。2 の場合、すべての 致命的でない(non-fatal) エラーも TarError 例外として送出されます。
引数 encoding および errors にはアーカイブの読み書きやエラー文字列の変換に使用する文字エンコーディングを指定します。ほとんどのユーザーはデフォルト設定のままで動作します。詳細に関しては Unicode に関する問題 節を参照してください。
引数 pax_headers は、オプションの文字列辞書で、format が PAX_FORMAT だった場合に pax グローバルヘッダーに追加されます。
バージョン 3.2 で変更: 引数 errors のデフォルトが 'surrogateescape' になりました。
バージョン 3.5 で変更: 'x' (排他的作成) モードが追加されました。
バージョン 3.6 で変更: name パラメタが path-like object を受け付けるようになりました。
classmethod TarFile.open(...)
代替コンストラクターです。モジュールレベルでの tarfile.open() 関数は、実際はこのクラスメソッドへのショートカットです。
TarFile.getmember(name)
メンバー name に対する TarInfo オブジェクトを返します。name がアーカイブに見つからなければ、KeyError が送出されます。
注釈 アーカイブ内にメンバーが複数ある場合は、最後に出現するものが最新のバージョンとみなされます。
TarFile.getmembers()
TarInfo アーカイブのメンバーをオブジェクトのリストとして返します。このリストはアーカイブ内のメンバーと同じ順番です。
TarFile.getnames()
メンバーをその名前のリストを返します。これは getmembers() で返されるリストと同じ順番です。
TarFile.list(verbose=True, *, members=None)
内容の一覧を sys.stdout に出力します。verbose が False の場合、メンバー名のみ表示します。True の場合、 ls -l に似た出力を生成します。オプションの members を与える場合、 getmembers() が返すリストのサブセットである必要があります。
バージョン 3.5 で変更: members 引数が追加されました。.
TarFile.next()
TarFile が読み込み用にオープンされている時、アーカイブの次のメンバーを TarInfo オブジェクトとして返します。もしそれ以上利用可能なものがなければ、None を返します。
TarFile.extractall(path=".", members=None, *, numeric_owner=False)
すべてのメンバーをアーカイブから現在の作業ディレクトリまたは path に抽出します。オプションの members が与えられるときには、getmembers() で返されるリストの一部でなければなりません。所有者、変更時刻、アクセス権限のようなディレクトリ情報はすべてのメンバーが抽出された後にセットされます。これは二つの問題を回避するためです。一つはディレクトリの変更時刻はその中にファイルが作成されるたびにリセットされるということ、もう一つはディレクトリに書き込み許可がなければその中のファイル抽出は失敗してしまうということです。
numeric_owner が True の場合、tarfile の uid と gid 数値が抽出されたファイルのオーナー/グループを設定するために使用されます。False の場合、tarfile の名前付きの値が使用されます。
警告 内容を信頼できない tar アーカイブを、事前の内部チェック前に展開してはいけません。ファイルが path の外側に作られる可能性があります。例えば、"/" で始まる絶対パスのファイル名や、2 重ドット ".." で始まるパスのファイル名です。
バージョン 3.5 で変更: numeric_owner 引数が追加されました。
バージョン 3.6 で変更: path パラメタが path-like object を受け付けるようになりました。
TarFile.extract(member, path="", set_attrs=True, *, numeric_owner=False)
アーカイブからメンバーの完全な名前を使って、現在のディレクトリに展開します。ファイル情報はできる限り正確に展開されます。 member はファイル名もしくは TarInfo オブジェクトです。 path を使って別のディレクトリを指定することもできます。 path は　path-like object でも構いません。set_attrs が false でない限り、ファイルの属性 (所有者、最終更新時刻、モード) は設定されます。
numeric_owner が True の場合、tarfile の uid と gid 数値が抽出されたファイルのオーナー/グループを設定するために使用されます。False の場合、tarfile の名前付きの値が使用されます。
注釈 extract() メソッドはいくつかの展開に関する問題を扱いません。ほとんどの場合、extractall() メソッドの利用を考慮するべきです。
警告 extractall() の警告を参してください。
バージョン 3.2 で変更: パラメーターに set_attrs を追加しました。
バージョン 3.5 で変更: numeric_owner 引数が追加されました。
バージョン 3.6 で変更: path パラメタが path-like object を受け付けるようになりました。
TarFile.extractfile(member)
バージョン 3.3 で変更: 戻り値が io.BufferedReader オブジェクトになりました。
TarFile.add(name, arcname=None, recursive=True, *, filter=None)
ファイル name をアーカイブに追加します。 name は、任意のファイルタイプ (ディレクトリ、fifo、シンボリックリンク等)です。 arcname が与えられている場合は、それはアーカイブ内のファイルの代替名を指定します。 デフォルトではディレクトリは再帰的に追加されます。 これは、 recursive を False に設定すると避けられます。 再帰処理はソートされた順序でエントリーを追加します。 filter が与えられた場合、それは TarInfo オブジェクトを引数として受け取り、操作した TarInfo オブジェクトを返す関数でなければなりません。 代わりに None を返した場合、 TarInfo オブジェクトはアーカイブから除外されます。 使用例 にある例を参照してください。
バージョン 3.2 で変更: filter パラメータが追加されました。
バージョン 3.7 で変更: 再帰処理はソートされた順序でエントリーを追加するようになりました。
TarFile.addfile(tarinfo, fileobj=None)
TarInfo オブジェクト tarinfo をアーカイブに追加します。fileobj を与える場合、binary file にしなければならず、 tarinfo.size バイトがそれから読まれ、アーカイブに追加されます。TarInfo オブジェクトを直接作成するか、gettarinfo() を使って作成することができます。
TarFile.gettarinfo(name=None, arcname=None, fileobj=None)
os.stat() の結果か、既存のファイルに相当するものから、TarInfo オブジェクトを作成します。このファイルは、name で名付けられるか、ファイル記述子を持つ file object fileobj として指定されます。name は:term:path-like object でも構いません。 arcname が与えられた場合、アーカイブ内のファイルに対して代替名を指定します。与えられない場合、名前は fileobj の name 属性 name 属性から取られます。名前はテキスト文字列にしてください。
TarInfo の属性の一部は、addfile() を使用して追加する前に修正できます。ファイルオブジェクトが、ファイルの先頭にある通常のファイルオブジェクトでない場合、 size などの属性は修正が必要かもしれません。これは、 GzipFile などの属性に当てはまります。name も修正できるかもしれず、この場合、arcname はダミーの文字列にすることができます。
バージョン 3.6 で変更: name パラメタが path-like object を受け付けるようになりました。
TarFile.close()
TarFile をクローズします。書き込みモードでは、完了ゼロブロックが 2 個アーカイブに追加されます。
TarFile.pax_headers
pax グローバルヘッダーに含まれる key-value ペアの辞書です。
TarInfo オブジェクト
TarInfo オブジェクトは TarFile の一つのメンバーを表します。ファイルに必要なすべての属性 (ファイルタイプ、ファイルサイズ、時刻、アクセス権限、所有者等のような) を保存する他に、そのタイプを決定するのに役に立ついくつかのメソッドを提供します。これにはファイルのデータそのものは 含まれません 。
TarInfo オブジェクトは TarFile のメソッド getmember()、 getmembers() および gettarinfo() によって返されます。
class tarfile.TarInfo(name="")
TarInfo オブジェクトを作成します。
classmethod TarInfo.frombuf(buf, encoding, errors)
TarInfo オブジェクトを文字列バッファー buf から作成して返します。
バッファーが不正な場合 HeaderError を送出します。
classmethod TarInfo.fromtarfile(tarfile)
TarFile オブジェクトの tarfile から、次のメンバーを読み込んで、それを TarInfo オブジェクトとして返します。
TarInfo.tobuf(format=DEFAULT_FORMAT, encoding=ENCODING, errors='surrogateescape')
TarInfo オブジェクトから文字列バッファーを作成します。引数についての情報は、TarFile クラスのコンストラクターを参照してください。
バージョン 3.2 で変更: 引数 errors のデフォルトが 'surrogateescape' になりました。
TarInfo オブジェクトには以下のデータ属性があります:
TarInfo.name
アーカイブメンバーの名前。
TarInfo.size
バイト単位でのサイズ。
TarInfo.mtime
最後に変更された時刻。
TarInfo.mode
許可ビット。
TarInfo.type
ファイルタイプ。type は通常、定数 REGTYPE、AREGTYPE、LNKTYPE、SYMTYPE、DIRTYPE、FIFOTYPE、CONTTYPE、CHRTYPE、BLKTYPE、あるいは GNUTYPE_SPARSE のいずれかです。TarInfo オブジェクトのタイプをもっと簡単に解決するには、下記の is*() メソッドを使って下さい。
TarInfo.linkname
リンク先ファイルの名前。これはタイプ LNKTYPE と SYMTYPE の TarInfo オブジェクトにだけ存在します。
TarInfo.uid
ファイルメンバーを保存した元のユーザーのユーザー ID。
TarInfo.gid
ファイルメンバーを保存した元のユーザーのグループ ID。
TarInfo.uname
ファイルメンバーを保存した元のユーザーのユーザー名。
TarInfo.gname
ファイルメンバーを保存した元のユーザーのグループ名。
TarInfo.pax_headers
pax 拡張ヘッダーに関連付けられた、key-value ペアの辞書。
TarInfo オブジェクトは便利な照会用のメソッドもいくつか提供しています:
TarInfo.isfile()
Tarinfo オブジェクトが一般ファイルの場合に、True を返します。
TarInfo.isreg()
isfile() と同じです。
TarInfo.isdir()
ディレクトリの場合に True を返します。
TarInfo.issym()
シンボリックリンクの場合に True を返します。
TarInfo.islnk()
ハードリンクの場合に True を返します。
TarInfo.ischr()
キャラクターデバイスの場合に True を返します。
TarInfo.isblk()
ブロックデバイスの場合に True を返します。
TarInfo.isfifo()
FIFO の場合に True を返します。
TarInfo.isdev()
キャラクターデバイス、ブロックデバイスあるいは FIFO のいずれかの場合に True を返します。
コマンドラインインターフェイス
バージョン 3.4 で追加.
tarfile モジュールは、 tar アーカイブを操作するための簡単なコマンドラインインターフェースを提供しています。
tar アーカイブを新規に作成したい場合、-c オプションの後にまとめたいファイル名のリストを指定してください:
$ python -m tarfile -c monty.tar  spam.txt eggs.txt
ディレクトリを渡すこともできます:
$ python -m tarfile -c monty.tar life-of-brian_1979/
tar アーカイブをカレントディレクトリに展開したい場合、-e オプションを使用してください:
$ python -m tarfile -e monty.tar
ディレクトリ名を渡すことで tar アーカイブを別のディレクトリに取り出すこともできます:
$ python -m tarfile -e monty.tar  other-dir/
tar アーカイブ内のファイル一覧を表示するには -l を使用してください:
$ python -m tarfile -l monty.tar
コマンドラインオプション
-l <tarfile>
--list <tarfile>
tarfile 内のファイル一覧を表示します。
-c <tarfile> <source1> ... <sourceN>
--create <tarfile> <source1> ... <sourceN>
ソースファイルから tarfile を作成します。
-e <tarfile> [<output_dir>]
--extract <tarfile> [<output_dir>]
output_dir が指定されていない場合、カレントディレクトリに tarfile を展開します。
-t <tarfile>
--test <tarfile>
tarfile が有効かどうか調べます。
-v, --verbose
詳細も出力します。
使用例
tar アーカイブから現在のディレクトリにすべて抽出する方法:
import tarfile
tar = tarfile.open("sample.tar.gz")
tar.extractall()
tar.close()
tar アーカイブの一部を、リストの代わりにジェネレーター関数を利用して TarFile.extractall() で展開する方法:
import os
import tarfile
def py_files(members):
    for tarinfo in members:
        if os.path.splitext(tarinfo.name)[1] == ".py":
            yield tarinfo
tar = tarfile.open("sample.tar.gz")
tar.extractall(members=py_files(tar))
tar.close()
非圧縮 tar アーカイブをファイル名のリストから作成する方法:
import tarfile
tar = tarfile.open("sample.tar", "w")
for name in ["foo", "bar", "quux"]:
    tar.add(name)
tar.close()
with 文を利用した同じ例:
import tarfile
with tarfile.open("sample.tar", "w") as tar:
    for name in ["foo", "bar", "quux"]:
        tar.add(name)
gzip 圧縮 tar アーカイブを作成してメンバー情報のいくつかを表示する方法:
import tarfile
tar = tarfile.open("sample.tar.gz", "r:gz")
for tarinfo in tar:
    print(tarinfo.name, "is", tarinfo.size, "bytes in size and is ", end="")
    if tarinfo.isreg():
        print("a regular file.")
    elif tarinfo.isdir():
        print("a directory.")
    else:
        print("something else.")
tar.close()
TarFile.add() 関数の filter 引数を利用してユーザー情報をリセットしながらアーカイブを作成する方法:
import tarfile
def reset(tarinfo):
    tarinfo.uid = tarinfo.gid = 0
    tarinfo.uname = tarinfo.gname = "root"
    return tarinfo
tar = tarfile.open("sample.tar.gz", "w:gz")
tar.add("foo", filter=reset)
tar.close()
サポートしている tar フォーマット
tarfile モジュールは 3 種類の tar フォーマットを作成することができます:
POSIX.1-1988 ustar format (USTAR_FORMAT). ファイル名の長さは256文字までで、リンク名の長さは100文字までです。最大のファイルサイズは8GiBです。このフォーマットは古くて制限が多いですが、広くサポートされています。
GNU tar format (GNU_FORMAT). 長いファイル名とリンク名、8GiBを超えるファイルやスパース(sparse)ファイルをサポートしています。これは GNU/Linux システムにおいてデファクト・スタンダードになっています。 tarfile モジュールは長いファイル名を完全にサポートしています。 スパースファイルは読み込みのみサポートしています。
他にも、読み込みのみサポートしている tar フォーマットがいくつかあります:
ancient V7 フォーマット。これは Unix 7th Edition から存在する、最初の tar フォーマットです。通常のファイルとディレクトリのみ保存します。名前は 100 文字を超えてはならず、ユーザー/グループ名に関する情報は保存されません。いくつかのアーカイブは、フィールドが ASCII でない文字を含む場合に、ヘッダーのチェックサムの計算を誤ります。
SunOS tar 拡張フォーマット。POSIX.1-2001 pax フォーマットの亜流ですが、互換性がありません。
Unicode に関する問題
tar フォーマットは、もともとテープドライブにファイルシステムのバックアップをとる目的で設計されました。現在、tarアーカイブはファイルを配布する際に一般的に用いられ、ネットワーク上で交換されています。オリジナルフォーマットが抱える一つの問題は (他の多くのフォーマットでも同じですが)、様々な文字エンコーディングのサポートについて考慮していないことです。例えば、UTF-8 システム上で作成された通常の tar アーカイブは、非 ASCII 文字を含んでいた場合、Latin-1 システムでは正しく読み取ることができません。テキストのメタデータ (ファイル名、リンク名、ユーザー/グループ名など) は破壊されます。残念なことに、アーカイブのエンコーディングを自動検出する方法はありません。pax フォーマットはこの問題を解決するために設計されました。これは非 ASCII メタデータをユニバーサル文字エンコーディング UTF-8 を使用して格納します。
tarfile における文字変換処理の詳細は TarFile クラスのキーワード引数 encoding および errors によって制御されます。
encoding はアーカイブのメタデータに使用する文字エンコーディングを指定します。デフォルト値は sys.getfilesystemencoding() で、フォールバックとして 'ascii' が使用されます。アーカイブの読み書き時に、メタデータはそれぞれデコードまたはエンコードしなければなりません。encoding に適切な値が設定されていない場合、その変換は失敗することがあります。
引数 errors は文字を変換できない時の扱いを指定します。指定できる値は エラーハンドラ 節を参照してください。デフォルトのスキームは 'surrogateescape' で、Python はそのファイルシステムの呼び出しも使用します。ファイル名、コマンドライン引数、および環境変数 を参照してください。
datetime --- 基本的な日付型および時間型
ソースコード: Lib/datetime.py
datetime モジュールは、日付や時刻を操作するためのクラスを提供しています。
日付や時刻に対する算術がサポートされている一方、実装では出力のフォーマットや操作のための効率的な属性の抽出に重点を置いています。
参考
calendar モジュール
汎用のカレンダー関連関数。
time モジュール
時刻へのアクセスと変換。
dateutil パッケージ
拡張タイムゾーンと構文解析サポートのあるサードパーティーライブラリ。
Aware オブジェクトと Naive オブジェクト
日時のオブジェクトは、それらがタイムゾーンの情報を含んでいるかどうかによって "aware" あるいは "naive" に分類されます。
タイムゾーンや夏時間の情報のような、アルゴリズム的で政治的な適用可能な時間調節に関する知識を持っているため、 aware オブジェクトは他の aware オブジェクトとの相対関係を特定できます。 aware オブジェクトは解釈の余地のない特定の実時刻を表現します。 1
naive オブジェクトには他の日付時刻オブジェクトとの相対関係を把握するのに足る情報が含まれません。あるプログラム内の数字がメートルを表わしているのか、マイルなのか、それとも質量なのかがプログラムによって異なるように、naive オブジェクトが協定世界時 (UTC) なのか、現地時間なのか、それとも他のタイムゾーンなのかはそのプログラムに依存します。Naive オブジェクトはいくつかの現実的な側面を無視してしまうというコストを無視すれば、簡単に理解でき、うまく利用することができます。
aware オブジェクトを必要とするアプリケーションのために、 datetime と time オブジェクトは追加のタイムゾーン情報の属性 tzinfo を持ちます。 tzinfo には抽象クラス tzinfo のサブクラスのインスタンスを設定できます。 これらの tzinfo オブジェクトは UTC 時間からのオフセットやタイムゾーンの名前、夏時間が実施されるかどうかの情報を保持しています。
ただ一つの具象 tzinfo クラスである timezone クラスが datetime モジュールで提供されています。 timezone クラスは単純な UTC からの固定オフセットだけを表わすUTC 自身や北アメリカの EST や EDT タイムゾーンのようなものも表現できます。より深く詳細までタイムゾーンをサポートするかはアプリケーションに依存します。世界中の時刻の調整を決めるルールは合理的というよりかは政治的なもので、頻繁に変わり、UTC を除くと都合のよい基準というものはありません。
定数
datetime モジュールでは以下の定数を公開しています:
datetime.MINYEAR
date や datetime オブジェクトで許されている、年を表現する最小の数字です。 MINYEAR は 1 です。
datetime.MAXYEAR
date や datetime オブジェクトで許されている、年を表現する最大の数字です。 MAXYEAR は 9999 です。
利用可能なデータ型
class datetime.date
理想的な naive な日付で、これまでもこれからも現在のグレゴリオ暦 (Gregorian calender) が有効であることを仮定しています。 属性は year, month,および day です。
class datetime.time
理想的な時刻で、特定の日から独立しており、毎日が厳密に 24*60*60 秒であると仮定しています。("うるう秒: leap seconds" の概念はありません。) 属性は hour, minute, second, microsecond, および tzinfo です。
class datetime.datetime
日付と時刻を組み合わせたものです。 属性は year, month, day, hour, minute, second, microsecond, および tzinfo です。
class datetime.timedelta
date, time, あるいは datetime クラスの二つのインスタンス間の時間差をマイクロ秒精度で表す経過時間値です。
class datetime.tzinfo
タイムゾーン情報オブジェクトの抽象基底クラスです。 datetime および time クラスで用いられ、カスタマイズ可能な時刻修正の概念 (たとえばタイムゾーンや夏時間の計算) を提供します。
class datetime.timezone
tzinfo 抽象基底クラスを UTC からの固定オフセットとして実装するクラスです。
バージョン 3.2 で追加.
これらの型のオブジェクトは変更不可能 (immutable) です。
サブクラスの関係は以下のようになります:
object
    timedelta
    tzinfo
        timezone
    time
    date
        datetime
共通の特徴
date 型、datetime 型、time 型、timezone 型には共通する特徴があります:
これらの型のオブジェクトは変更不可能 (immutable) です。
これらの型のオブジェクトはハッシュ可能であり、辞書のキーとして使えることになります。
これらの型のオブジェクトは pickle モジュールを利用して効率的な pickle 化をサポートしています。
オブジェクトが Aware なのか Naive なのかの判断
date 型のオブジェクトは常に naive です。
time 型あるいは datetime 型のオブジェクトは aware か naive のどちらかです。
次の条件を両方とも満たす場合、 datetime オブジェクト d は aware です:
d.tzinfo が None でない
d.tzinfo.utcoffset(d) が None を返さない
どちらかを満たさない場合は、 d は naive です。
次の条件を両方とも満たす場合、 time オブジェクト t は aware です:
t.tzinfo が None でない
t.tzinfo.utcoffset(None) が None を返さない
どちらかを満たさない場合は、 t は naive です。
aware なオブジェクトと naive なオブジェクトの区別は timedelta オブジェクトにはあてはまりません。
timedelta オブジェクト
timedelta オブジェクトは経過時間、すなわち二つの日付や時刻間の差を表します。
class datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)
全ての引数がオプションで、デフォルト値は 0 です。 引数は整数、浮動小数点数でもよく、正でも負でもかまいません。
days, seconds, microseconds だけが内部的に保持されます。 引数は以下のようにして変換されます:
1 ミリ秒は 1000 マイクロ秒に変換されます。
1 分は 60 秒に変換されます。
1 時間は 3600 秒に変換されます。
1 週間は 7 日に変換されます。
さらに、値が一意に表されるように days, seconds, microseconds が以下のように正規化されます
0 <= microseconds < 1000000
0 <= seconds < 3600*24 (一日中の秒数)
-999999999 <= days <= 999999999
次の例は、 days, seconds, microseconds に加えて任意の引数がどう "集約" され、最終的に3つの属性に正規化されるかの説明をしています:
>>>
>>> from datetime import timedelta
>>> delta = timedelta(
...     days=50,
...     seconds=27,
...     microseconds=10,
...     milliseconds=29000,
...     minutes=5,
...     hours=8,
...     weeks=2
... )
>>> # Only days, seconds, and microseconds remain
>>> delta
datetime.timedelta(days=64, seconds=29156, microseconds=10)
引数のいずれかが浮動小数点であり、小数のマイクロ秒が存在する場合、小数のマイクロ秒は全ての引数から一度取り置かれ、それらの和は最近接偶数のマイクロ秒に丸められます。浮動小数点の引数がない場合、値の変換と正規化の過程は厳密な (失われる情報がない) ものとなります。
日の値を正規化した結果、指定された範囲の外側になった場合には、 OverflowError が送出されます。
負の値を正規化すると、最初は混乱するような値になります。例えば:
>>>
>>> from datetime import timedelta
>>> d = timedelta(microseconds=-1)
>>> (d.days, d.seconds, d.microseconds)
(-1, 86399, 999999)
以下にクラス属性を示します:
timedelta.min
最小の値を表す timedelta オブジェクトで、 timedelta(-999999999) です。
timedelta.max
最大の値を表す timedelta オブジェクトで、 timedelta(days=999999999, hours=23, minutes=59, seconds=59, microseconds=999999) です。
timedelta.resolution
timedelta オブジェクトが等しくならない最小の時間差で、 timedelta(microseconds=1) です。
正規化のために、 timedelta.max > -timedelta.min となるので注意してください。 -timedelta.max は timedelta オブジェクトとして表現することができません。
インスタンスの属性 (読み出しのみ):
属性
値
days
両端値を含む -999999999 から 999999999 の間
seconds
両端値を含む 0 から 86399 の間
microseconds
両端値を含む 0 から 999999 の間
サポートされている演算を以下に示します:
演算
結果
t1 = t2 + t3
t2 と t3 の和。演算後、t1-t2 == t3 および t1-t3 == t2 は真になります。(1)
t1 = t2 - t3
t2 と t3 の差分です。演算後、 t1 == t2 - t3 および t2 == t1 + t3 は真になります。 (1)(6)
t1 = t2 * i または t1 = i * t2
時間差と整数の積。演算後、t1 // i == t2 は i != 0 であれば真となります。
一般的に、t1 * i == t1 * (i-1) + t1 は真となります。(1)
t1 = t2 * f または t1 = f * t2
時間差と浮動小数点の積。結果は最近接偶数への丸めを利用して最も近い timedelta.resolution の倍数に丸められます。
f = t2 / t3
t2 を t3 で除算 (3) したもの。float オブジェクトを返します。
t1 = t2 / f または t1 = t2 / i
時間差を浮動小数点や整数で除したもの。結果は最近接偶数への丸めを利用して最も近い timedelta.resolution の倍数に丸められます。
t1 = t2 // i または t1 = t2 // t3
floor が計算され、余りは (もしあれば) 捨てられます。後者の場合、整数が返されます。(3)
t1 = t2 % t3
剰余が timedelta オブジェクトとして計算されます。(3)
q, r = divmod(t1, t2)
商と剰余が計算されます: q = t1 // t2 (3) と r = t1 % t2 。q は整数で r は timedelta オブジェクトです。
+t1
同じ値を持つ timedelta オブジェクトを返します。(2)
-t1
timedelta(-t1.days, -t1.seconds, -t1.microseconds)、および t1* -1 と同じです。 (1)(4)
abs(t)
t.days >= 0 のときには +t, t.days < 0 のときには -t となります。(2)
str(t)
[D day[s], ][H]H:MM:SS[.UUUUUU] という形式の文字列を返します。t が負の値の場合は D は負の値となります。(5)
repr(t)
timedelta オブジェクトの文字列表現を返します。その文字列は、正規の属性値を持つコンストラクタ呼び出しのコードになっています。
注釈:
この演算は正確ですが、オーバフローするかもしれません。
この演算は正確であり、オーバフローし得ません。
0 による除算は ZeroDivisionError を送出します。
-timedelta.max は timedelta オブジェクトで表現することができません。
timedelta オブジェクトの文字列表現は内部表現に類似した形に正規化されます。そのため負の timedelta は少し変な結果になります。例えば:
>>>
>>> timedelta(hours=-5)
datetime.timedelta(days=-1, seconds=68400)
>>> print(_)
-1 day, 19:00:00
t3 が timedelta.max のときを除けば、式 t2 - t3 は常に、式 t2 + (-t3) と同等です。t3 が timedelta.max の場合、前者の式は結果の値が出ますが、後者はオーバーフローを起こします。
上に列挙した操作に加え timedelta オブジェクトは date および datetime オブジェクトとの間で加減算をサポートしています (下を参照してください)。
バージョン 3.2 で変更: timedelta オブジェクトの別の timedelta オブジェクトによる、切り捨て除算と真の除算、および剰余演算と divmod() 関数がサポートされるようになりました。 timedelta オブジェクトと float オブジェクトの真の除算と掛け算がサポートされるようになりました。
timedelta オブジェクトどうしの比較が、注意書き付きでサポートされました。
== および != の比較は、比較されているオブジェクトの型が何であれ、 常に bool を返します:
>>>
>>> from datetime import timedelta
>>> delta1 = timedelta(seconds=57)
>>> delta2 = timedelta(hours=25, seconds=2)
>>> delta2 != delta1
True
>>> delta2 == 5
False
(< and > などの) それ以外の全ての比較で、 timedelta オブジェクトを異なる型のオブジェクトと比較したときは TypeError が送出されます:
>>>
>>> delta2 > delta1
True
>>> delta2 > 5
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: '>' not supported between instances of 'datetime.timedelta' and 'int'
ブール演算コンテキストでは、 timedelta オブジェクトは timedelta(0) に等しくない場合かつそのときに限り真となります。
インスタンスメソッド:
timedelta.total_seconds()
この期間に含まれるトータルの秒数を返します。td / timedelta(seconds=1) と等価です。 秒以外の期間の単位では、直接に除算する形式 (例えば td / timedelta(microseconds=1)) が使われます。
非常に長い期間 (多くのプラットフォームでは270年以上) については、このメソッドはマイクロ秒の精度を失うことがあることに注意してください。
バージョン 3.2 で追加.
使用例: timedelta
正規化の追加の例です:
>>>
>>> # Components of another_year add up to exactly 365 days
>>> from datetime import timedelta
>>> year = timedelta(days=365)
>>> another_year = timedelta(weeks=40, days=84, hours=23,
...                          minutes=50, seconds=600)
>>> year == another_year
True
>>> year.total_seconds()
31536000.0
timedelta の計算の例です:
>>>
>>> from datetime import timedelta
>>> year = timedelta(days=365)
>>> ten_years = 10 * year
>>> ten_years
datetime.timedelta(days=3650)
>>> ten_years.days // 365
10
>>> nine_years = ten_years - year
>>> nine_years
datetime.timedelta(days=3285)
>>> three_years = nine_years // 3
>>> three_years, three_years.days // 365
(datetime.timedelta(days=1095), 3)
date オブジェクト
date オブジェクトは、両方向に無期限に拡張された現在のグレゴリオ暦という理想化された暦の日付 (年月日) を表します。
1 年 1 月 1 日は日番号 1、1 年 1 月 2 日は日番号 2 と呼ばれ、他も同様です。 2
class datetime.date(year, month, day)
全ての引数が必須です。 引数は整数で、次の範囲に収まっていなければなりません:
MINYEAR <= year <= MAXYEAR
1 <= month <= 12
1 <= day <= 指定された月と年における日数
範囲を超えた引数を与えた場合、 ValueError が送出されます。
他のコンストラクタ、および全てのクラスメソッドを以下に示します:
classmethod date.today()
現在のローカルな日付を返します。
date.fromtimestamp(time.time()) と等価です。
classmethod date.fromtimestamp(timestamp)
time.time() で返されるような POSIX タイムスタンプに対応するローカルな日付を返します。
timestamp がプラットフォームの C 関数 localtime() がサポートする値の範囲から外れていた場合、 OverflowError を送出するかもしれません。また localtime() 呼び出しが失敗した場合には OSError を送出するかもしれません。この範囲は通常は 1970 年から 2038 年までに制限されています。タイムスタンプの表記にうるう秒を含める非 POSIX なシステムでは、うるう秒は fromtimestamp() では無視されます。
バージョン 3.3 で変更: timestamp がプラットフォームの C 関数 localtime() のサポートする値の範囲から外れていた場合、 ValueError ではなく OverflowError を送出するようになりました。 localtime() の呼び出し失敗で ValueError ではなく OSError を送出するようになりました。
classmethod date.fromordinal(ordinal)
先発グレゴリオ暦による序数に対応する日付を返します。 1 年 1 月 1 日が序数 1 となります。
1 <= ordinal <= date.max.toordinal() でない場合、 ValueError が送出されます。 任意の日付 d に対し、 date.fromordinal(d.toordinal()) == d となります。
classmethod date.fromisoformat(date_string)
YYYY-MM-DD という書式で与えられた date_string に対応する date を返します
>>>
>>> from datetime import date
>>> date.fromisoformat('2019-12-04')
datetime.date(2019, 12, 4)
この関数は date.isoformat() の逆関数です。 YYYY-MM-DD という書式のみをサポートしています。
バージョン 3.7 で追加.
classmethod date.fromisocalendar(year, week, day)
年月日で指定された ISO 暦の日付に対応する date を返します。 この関数は date.isocalendar() 関数の逆関数です。
バージョン 3.8 で追加.
以下にクラス属性を示します:
date.min
表現できる最も古い日付で、date(MINYEAR, 1, 1) です。
date.max
表現できる最も新しい日付で、date(MAXYEAR, 12, 31) です。
date.resolution
等しくない日付オブジェクト間の最小の差で、timedelta(days=1) です。
インスタンスの属性 (読み出しのみ):
date.year
両端値を含む MINYEAR から MAXYEAR までの値です。
date.month
両端値を含む 1 から 12 までの値です。
date.day
1 から与えられた月と年における日数までの値です。
サポートされている演算を以下に示します:
演算
結果
date2 = date1 + timedelta
date2 は date1 から timedelta.days 日だけ移動した日付です。(1)
date2 = date1 - timedelta
date2 + timedelta == date1 であるような日付 date2 を計算します。(2)
timedelta = date1 - date2
(3)
date1 < date2
date1 が時刻として date2 よりも前を表す場合に、date1 は date2 よりも小さいと見なされます。(4)
注釈:
date2 は、 timedelta.days > 0 の場合は進む方向に、 timedelta.days < 0 の場合は戻る方向に移動します。 演算後は date2 - date1 == timedelta.days が成立します。 timedelta.seconds および timedelta.microseconds は無視されます。 date2.year が MINYEAR になってしまったり、 MAXYEAR より大きくなってしまう場合には OverflowError が送出されます。
timedelta.seconds と timedelta.microseconds は無視されます。
この演算は厳密で、オーバフローしません。timedelta.seconds および timedelta.microseconds は 0 で、演算後には date2 + timedelta == date1 となります。
言い換えると、 date1 < date2 は date1.toordinal() < date2.toordinal() と同等です。 日付の比較は、比較相手が date オブジェクトでない場合には、 TypeError を送出します。 ただし、 比較相手に timetuple() 属性がある場合は、 NotImplemented が代わりに送出されます。 このフックによって、他の種類の日付オブジェクトに、違う型どうしの比較処理を実装できる可能性が生まれます。 相手が timetuple() 属性を持っていない場合に date と違う型のオブジェクトと比較すると、 == または != の比較でない限り TypeError が送出されます。 後者の場合では、それぞれ False および True が返されます。
ブール演算コンテキストでは、全ての time オブジェクトは真とみなされます。
インスタンスメソッド:
date.replace(year=self.year, month=self.month, day=self.day)
キーワード引数で指定されたパラメータが置き換えられることを除き、同じ値を持つ date オブジェクトを返します。
以下はプログラム例です:
>>>
>>> from datetime import date
>>> d = date(2002, 12, 31)
>>> d.replace(day=26)
datetime.date(2002, 12, 26)
date.timetuple()
time.localtime() が返すような time.struct_time を返します。
時分秒が 0 で、 DST フラグが -1 です。
d.timetuple() は次の式と等価です:
time.struct_time((d.year, d.month, d.day, 0, 0, 0, d.weekday(), yday, -1))
ここで、 yday = d.toordinal() - date(d.year, 1, 1).toordinal() + 1 は本年の 1 月 1 日を 1 としたときの日付番号です。
date.toordinal()
先発グレゴリオ暦における日付序数を返します。 1 年の 1 月 1 日が序数 1 となります。任意の date オブジェクト d について、 date.fromordinal(d.toordinal()) == d となります。
date.weekday()
月曜日を 0、日曜日を 6 として、曜日を整数で返します。例えば、 date(2002, 12, 4).weekday() == 2 であり、水曜日を示します。 isoweekday() も参照してください。
date.isoweekday()
月曜日を 1,日曜日を 7 として、曜日を整数で返します。例えば、 date(2002, 12, 4).isoweekday() == 3 であり、水曜日を示します。 weekday(), isocalendar() も参照してください。
date.isocalendar()
year、week、weekday の3つで構成された named tuple を返します。
ISO 暦はグレゴリオ暦の変種として広く用いられています。 3
ISO 年は完全な週が 52 週または 53 週あり、週は月曜から始まって日曜に終わります。ISO 年でのある年における最初の週は、その年の木曜日を含む最初の (グレゴリオ暦での) 週となります。この週は週番号 1 と呼ばれ、この木曜日での ISO 年はグレゴリオ暦における年と等しくなります。
例えば、2004 年は木曜日から始まるため、ISO 年の最初の週は 2003 年 12 月 29 日、月曜日から始まり、2004 年 1 月 4 日、日曜日に終わります
>>>
>>> from datetime import date
>>> date(2003, 12, 29).isocalendar()
datetime.IsoCalendarDate(year=2004, week=1, weekday=1)
>>> date(2004, 1, 4).isocalendar()
datetime.IsoCalendarDate(year=2004, week=1, weekday=7)
バージョン 3.9 で変更: 結果が タプル から named tuple へ変更されました。
date.isoformat()
日付を ISO 8601 書式の YYYY-MM-DD で表した文字列を返します:
>>>
>>> from datetime import date
>>> date(2002, 12, 4).isoformat()
'2002-12-04'
この関数は date.fromisoformat() の逆関数です。
date.__str__()
date オブジェクト d において、str(d) は d.isoformat() と等価です。
date.ctime()
日付を表す文字列を返します:
>>>
>>> from datetime import date
>>> date(2002, 12, 4).ctime()
'Wed Dec  4 00:00:00 2002'
d.ctime() は次の式と等価です:
time.ctime(time.mktime(d.timetuple()))
これが等価になるのは、 (time.ctime() に呼び出され、 date.ctime() に呼び出されない) ネイティブの C 関数 ctime() が C 標準に準拠しているプラットフォーム上でです。
date.strftime(format)
明示的な書式文字列で制御された、日付を表現する文字列を返します。 時間、分、秒を表す書式コードは値 0 になります。 完全な書式化指定子のリストについては strftime() と strptime() の振る舞い を参照してください。
date.__format__(format)
date.strftime() と等価です。 これにより、 フォーマット済み文字列リテラル の中や str.format() を使っているときに date オブジェクトの書式文字列を指定できます。 書式化コードの完全なリストについては strftime() と strptime() の振る舞い を参照してください。
使用例: date
イベントまでの日数を数える例を示します:
>>>
>>> import time
>>> from datetime import date
>>> today = date.today()
>>> today
datetime.date(2007, 12, 5)
>>> today == date.fromtimestamp(time.time())
True
>>> my_birthday = date(today.year, 6, 24)
>>> if my_birthday < today:
...     my_birthday = my_birthday.replace(year=today.year + 1)
>>> my_birthday
datetime.date(2008, 6, 24)
>>> time_to_birthday = abs(my_birthday - today)
>>> time_to_birthday.days
202
さらなる date を使う例:
>>> from datetime import date
>>> d = date.fromordinal(730920) # 730920th day after 1. 1. 0001
>>> d
datetime.date(2002, 3, 11)
>>> # Methods related to formatting string output
>>> d.isoformat()
'2002-03-11'
>>> d.strftime("%d/%m/%y")
'11/03/02'
>>> d.strftime("%A %d. %B %Y")
'Monday 11. March 2002'
>>> d.ctime()
'Mon Mar 11 00:00:00 2002'
>>> 'The {1} is {0:%d}, the {2} is {0:%B}.'.format(d, "day", "month")
'The day is 11, the month is March.'
>>> # Methods for to extracting 'components' under different calendars
>>> t = d.timetuple()
>>> for i in t:     
...     print(i)
2002                # year
3                   # month
11                  # day
0
0
0
0                   # weekday (0 = Monday)
70                  # 70th day in the year
-1
>>> ic = d.isocalendar()
>>> for i in ic:    
...     print(i)
2002                # ISO year
11                  # ISO week number
1                   # ISO day number ( 1 = Monday )
>>> # A date object is immutable; all operations produce a new object
>>> d.replace(year=2005)
datetime.date(2005, 3, 11)
datetime オブジェクト
datetime オブジェクトは date オブジェクトおよび time オブジェクトの全ての情報が入っている単一のオブジェクトです。
date オブジェクトと同様に、 datetime は現在のグレゴリオ暦が両方向に延長されているものと仮定します。また、 time オブジェクトと同様に、 datetime は毎日が厳密に 3600*24 秒であると仮定します。
以下にコンストラクタを示します:
class datetime.datetime(year, month, day, hour=0, minute=0, second=0, microsecond=0, tzinfo=None, *, fold=0)
year, month, day 引数は必須です。 tzinfo は None または tzinfo サブクラスのインスタンスです。 残りの引数は次の範囲の整数でなければなりません:
MINYEAR <= year <= MAXYEAR,
1 <= month <= 12,
1 <= day <= 指定された月と年における日数,
0 <= hour < 24,
0 <= minute < 60,
0 <= second < 60,
0 <= microsecond < 1000000,
fold in [0, 1].
範囲を超えた引数を与えた場合、 ValueError が送出されます。
バージョン 3.6 で追加: fold 引数が追加されました。
他のコンストラクタ、および全てのクラスメソッドを以下に示します:
classmethod datetime.today()
tzinfo を None にして、現在のローカルな日時を返します。
次と等価です:
datetime.fromtimestamp(time.time())
now(), fromtimestamp() も参照してください。
このメソッドの機能は now() と等価ですが、 tz 引数はありません。
classmethod datetime.now(tz=None)
現在のローカルな日時を返します。
オプションの引数 tz が None であるか指定されていない場合、このメソッドは today() と同様ですが、可能ならば time.time() タイムスタンプを通じて得ることができる、より高い精度で時刻を提供します (例えば、プラットフォームが C 関数 gettimeofday() をサポートする場合には可能なことがあります)。
tz が None でない場合、 tz は tzinfo のサブクラスのインスタンスでなければならず、現在の日付および時刻は tz のタイムゾーンに変換されます。
today() および utcnow() よりもこの関数を使う方が好ましいです。
classmethod datetime.utcnow()
tzinfo が None である現在の UTC の日付および時刻を返します。
このメソッドは now() と似ていますが、 naive な datetime オブジェクトとして現在の UTC 日付および時刻を返します。 aware な現在の UTC datetime は datetime.now(timezone.utc) を呼び出すことで取得できます。 now() も参照してください。
警告 naive な datetime オブジェクトは多くの datetime メソッドでローカルな時間として扱われるため、 aware な datetime を使って UTC の時刻を表すのが好ましいです。 そのため、 UTC での現在の時刻を表すオブジェクトの作成では datetime.now(timezone.utc) を呼び出す方法が推奨されます。
classmethod datetime.fromtimestamp(timestamp, tz=None)
time.time() が返すような、 POSIX タイムスタンプに対応するローカルな日付と時刻を返します。オプションの引数 tz が None であるか、指定されていない場合、タイムスタンプはプラットフォームのローカルな日付および時刻に変換され、返される datetime オブジェクトは naive なものになります。
tz が None でない場合、 tz は tzinfo のサブクラスのインスタンスでなければならず、タイムスタンプは tz のタイムゾーンに変換されます。
タイムスタンプがプラットフォームの C 関数 localtime() や gmtime() でサポートされている範囲を超えた場合、 fromtimestamp() は OverflowError を送出することがあります。この範囲はよく 1970 年から 2038 年に制限されています。 また localtime() や gmtime() が失敗した際は OSError を送出します。 うるう秒がタイムスタンプの概念に含まれている非 POSIX システムでは、 fromtimestamp() はうるう秒を無視します。 このため、秒の異なる二つのタイムスタンプが同一の datetime オブジェクトとなることが起こり得ます。 utcfromtimestamp() よりも、このメソッドの方が好ましいです。
バージョン 3.3 で変更: timestamp がプラットフォームの C 関数 localtime() もしくは gmtime() のサポートする値の範囲から外れていた場合、 ValueError ではなく OverflowError を送出するようになりました。 localtime() もしくは gmtime() の呼び出し失敗で ValueError ではなく OSError を送出するようになりました。
バージョン 3.6 で変更: fromtimestamp() は fold を1にしてインスタンスを返します。
classmethod datetime.utcfromtimestamp(timestamp)
POSIX タイムスタンプに対応する、tzinfo が None の UTC での datetime を返します。(返されるオブジェクトは naive です。)
タイムスタンプがプラットフォームにおける C 関数 localtime() でサポートされている範囲を超えている場合には OverflowError を、gmtime() が失敗した場合には OSError を送出します。 これはたいてい 1970 年から 2038 年に制限されています。
aware な datetime オブジェクトを得るには fromtimestamp() を呼んでください:
datetime.fromtimestamp(timestamp, timezone.utc)
POSIX 互換プラットフォームでは、これは以下の表現と等価です:
datetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)
後者を除き、式は常に年の全範囲 (MINYEAR から MAXYEAR を含みます) をサポートします。
警告 naive な datetime オブジェクトは多くの datetime メソッドでローカルな時間として扱われるため、 aware な datetime を使って UTC の時刻を表すのが好ましいです。 そのため、 UTC でのある特定のタイムスタンプを表すオブジェクトの作成では datetime.fromtimestamp(timestamp, tz=timezone.utc) を呼び出す方法が推奨されます。
バージョン 3.3 で変更: timestamp がプラットフォームの C 関数 gmtime() のサポートする値の範囲から外れていた場合、 ValueError ではなく OverflowError を送出するようになりました。 gmtime() の呼び出し失敗で ValueError ではなく OSError を送出するようになりました。
classmethod datetime.fromordinal(ordinal)
1 年 1 月 1 日を序数 1 とする早期グレゴリオ暦序数に対応する datetime オブジェクトを返します。 1 <= ordinal <= datetime.max.toordinal() でなければ ValueError が送出されます。 返されるオブジェクトの時間、分、秒、およびマイクロ秒はすべて 0 で、 tzinfo は None となっています。
classmethod datetime.combine(date, time, tzinfo=self.tzinfo)
日付部分と与えられた date オブジェクトとが等しく、時刻部分と与えられた time オブジェクトとが等しい、新しい datetime オブジェクトを返します。 tzinfo 引数が与えられた場合、その値は返り値の tzinfo 属性に設定するのに使われます。そうでない場合、 time 引数の tzinfo 属性が使われます。
任意の datetime オブジェクト d で d == datetime.combine(d.date(), d.time(), d.tzinfo) が成立します。 date が datetime オブジェクトだった場合、その datetime オブジェクトの時刻部分と tzinfo 属性は無視されます。
バージョン 3.6 で変更: tzinfo 引数が追加されました。
classmethod datetime.fromisoformat(date_string)
date.isoformat() および datetime.isoformat() の出力書式で、 date_string に対応する datetime を返します。
具体的には、この関数は次の書式の文字列をサポートしています:
YYYY-MM-DD[*HH[:MM[:SS[.fff[fff]]]][+HH:MM[:SS[.ffffff]]]]
ここで * は任意の一文字にマッチします。
ご用心 このメソッドは任意の ISO 8601 文字列の構文解析をサポートしてはいません - このメソッドは datetime.isoformat() の逆操作をするためだけのものです。 より高機能な ISO 8601 構文解析器である dateutil.parser.isoparse が、サードパーティーパッケージの dateutil から利用可能です。
例:
>>>
>>> from datetime import datetime
>>> datetime.fromisoformat('2011-11-04')
datetime.datetime(2011, 11, 4, 0, 0)
>>> datetime.fromisoformat('2011-11-04T00:05:23')
datetime.datetime(2011, 11, 4, 0, 5, 23)
>>> datetime.fromisoformat('2011-11-04 00:05:23.283')
datetime.datetime(2011, 11, 4, 0, 5, 23, 283000)
>>> datetime.fromisoformat('2011-11-04 00:05:23.283+00:00')
datetime.datetime(2011, 11, 4, 0, 5, 23, 283000, tzinfo=datetime.timezone.utc)
>>> datetime.fromisoformat('2011-11-04T00:05:23+04:00')   
datetime.datetime(2011, 11, 4, 0, 5, 23,
    tzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))
バージョン 3.7 で追加.
classmethod datetime.fromisocalendar(year, week, day)
年月日で指定された ISO 暦の日付に対応する datetime を返します。 datetime の日付でない部分は、標準のデフォルト値で埋められます。 この関数は datetime.isocalendar() の逆関数です。
バージョン 3.8 で追加.
classmethod datetime.strptime(date_string, format)
date_string に対応した datetime を返します。 format にしたがって構文解析されます。
これは次と等価です:
datetime(*(time.strptime(date_string, format)[0:6]))
date_string と format が time.strptime() で構文解析できない場合や、この関数が時刻タプルを返してこない場合には ValueError を送出します。完全な書式化指定子のリストについては strftime() と strptime() の振る舞い を参照してください。
以下にクラス属性を示します:
datetime.min
表現できる最も古い datetime で、 datetime(MINYEAR, 1, 1, tzinfo=None) です。
datetime.max
表現できる最も新しい datetime で、 datetime(MAXYEAR, 12, 31, 23, 59, 59, 999999, tzinfo=None) です。
datetime.resolution
等しくない datetime オブジェクト間の最小の差で、 timedelta(microseconds=1) です。
インスタンスの属性 (読み出しのみ):
datetime.year
両端値を含む MINYEAR から MAXYEAR までの値です。
datetime.month
両端値を含む 1 から 12 までの値です。
datetime.day
1 から与えられた月と年における日数までの値です。
datetime.hour
in range(24) を満たします。
datetime.minute
in range(60) を満たします。
datetime.second
in range(60) を満たします。
datetime.microsecond
in range(1000000) を満たします。
datetime.tzinfo
datetime コンストラクタに tzinfo 引数として与えられたオブジェクトになり、何も渡されなかった場合には None になります。
datetime.fold
[0, 1] のどちらかです。 繰り返し期間中の実時間の曖昧さ除去に使われます。 (繰り返し期間は、夏時間の終わりに時計が巻き戻るときや、現在のゾーンの UTC オフセットが政治的な理由で減少するときに発生します。) 0 (1) という値は、同じ実時間で表現される 2 つの時刻のうちの早い方 (遅い方) を表します。
バージョン 3.6 で追加.
サポートされている演算を以下に示します:
演算
結果
datetime2 = datetime1 + timedelta
(1)
datetime2 = datetime1 - timedelta
(2)
timedelta = datetime1 - datetime2
(3)
datetime1 < datetime2
datetime を datetime と比較します。 (4)
datetime2 は datetime1 から時間 timedelta 移動したもので、 timedelta.days > 0 の場合未来へ、 timedelta.days < 0 の場合過去へ移動します。 結果は入力の datetime と同じ tzinfo 属性を持ち、演算後には datetime2 - datetime1 == timedelta となります。 datetime2.year が MINYEAR よりも小さいか、 MAXYEAR より大きい場合には OverflowError が送出されます。 入力が aware なオブジェクトの場合でもタイムゾーン修正は全く行われません。
datetime2 + timedelta == datetime1 となるような datetime2 を計算します。 ちなみに、結果は入力の datetime と同じ tzinfo 属性を持ち、入力が aware だとしてもタイムゾーン修正は全く行われません。 この操作は date1 + (-timedelta) と等価ではありません。 なぜならば、 date1 - timedelta がオーバフローしない場合でも、-timedelta 単体がオーバフローする可能性があるからです。
datetime から datetime の減算は両方の被演算子が naive であるか、両方とも aware である場合にのみ定義されています。片方が aware でもう一方が naive の場合、 TypeError が送出されます。
両方とも naive か、両方とも aware で同じ tzinfo 属性を持つ場合、 tzinfo 属性は無視され、結果は datetime2 + t == datetime1 であるような timedelta オブジェクト t となります。 この場合タイムゾーン修正は全く行われません。
両方が aware で異なる tzinfo 属性を持つ場合、 a-b は a および b をまず naive な UTC datetime オブジェクトに変換したかのようにして行います。 演算結果は決してオーバフローを起こさないことを除き、 (a.replace(tzinfo=None) - a.utcoffset()) - (b.replace(tzinfo=None) - b.utcoffset()) と同じになります。
datetime1 が時刻として datetime2 よりも前を表す場合に、datetime1 は datetime2 よりも小さいと見なされます。
比較の一方が naive であり、もう一方が aware の場合に、順序比較が行われると TypeError が送出されます。等価比較では、 naive インスタンスと aware インスタンスは等価になることはありません。
比較対象が両方とも aware で、同じ tzinfo 属性を持つ場合、 tzinfo は無視され datetime だけで比較が行われます。 比較対象が両方とも aware であり、異なる tzinfo 属性を持つ場合、まず最初に (self.utcoffset() で取得できる) それぞれの UTC オフセットを引いて調整します。
バージョン 3.3 で変更: aware な datetime インスタンスと naive な datetime インスタンスの等価比較では TypeError は送出されません。
注釈 型混合の比較がデフォルトのオブジェクトアドレス比較となってしまうのを抑止するために、被演算子のもう一方が datetime オブジェクトと異なる型のオブジェクトの場合には TypeError が送出されます。しかしながら、被比較演算子のもう一方が timetuple() 属性を持つ場合には NotImplemented が返されます。このフックにより、他種の日付オブジェクトに型混合比較を実装するチャンスを与えています。そうでない場合, datetime オブジェクトと異なる型のオブジェクトが比較されると、比較演算子が == または != でないかぎり TypeError が送出されます。後者の場合、それぞれ False または True を返します。
インスタンスメソッド:
datetime.date()
同じ年、月、日の date オブジェクトを返します。
datetime.time()
同じhour、minute、second、microsecond 及び foldを持つ time オブジェクトを返します。 tzinfo は None です。 timetz() も参照してください。
バージョン 3.6 で変更: 値 foldは返される time オブジェクトにコピーされます。
datetime.timetz()
同じhour、minute、second、microsecond、fold および tzinfo 属性を持つ time オブジェクトを返します。 time() メソッドも参照してください。
バージョン 3.6 で変更: 値 foldは返される time オブジェクトにコピーされます。
datetime.replace(year=self.year, month=self.month, day=self.day, hour=self.hour, minute=self.minute, second=self.second, microsecond=self.microsecond, tzinfo=self.tzinfo, *, fold=0)
キーワード引数で指定した属性の値を除き、同じ属性をもつ datetime オブジェクトを返します。メンバに対する変換を行わずに aware な datetime オブジェクトから naive な datetime オブジェクトを生成するために、tzinfo=None を指定することもできます。
バージョン 3.6 で追加: fold 引数が追加されました。
datetime.astimezone(tz=None)
tz を新たに tzinfo 属性 として持つ datetime オブジェクトを返します。 日付および時刻データを調整して、返り値が self と同じ UTC 時刻を持ち、 tz におけるローカルな時刻を表すようにします。
もし与えられた場合、 tz は tzinfo のサブクラスのインスタンスでなければならず、 インスタンスの utcoffset() および dst() メソッドは None を返してはなりません。もし self が naive ならば、おそらくシステムのタイムゾーンで時間を表現します。
引数無し (もしくは tz=None の形 ) で呼び出された場合、システムのローカルなタイムゾーンが変更先のタイムゾーンだと仮定されます。 変換後の datetime インスタンスの .tzinfo 属性には、 OS から取得したゾーン名とオフセットを持つ timezone インスタンスが設定されます。
self.tzinfo が tz の場合、 self.astimezone(tz) は self に等しくなります。つまり、date および time に対する調整は行われません。そうでない場合、結果はタイムゾーン tz におけるローカル時刻で、 self と同じ UTC 時刻を表すようになります。これは、astz = dt.astimezone(tz) とした後、 astz - astz.utcoffset() は通常 dt - dt.utcoffset() と同じ date および time を持つことを示します。
単にタイムゾーンオブジェクト tz を datetime オブジェクト dt に追加したいだけで、日付や時刻データへの調整を行わないのなら、dt.replace(tzinfo=tz) を使ってください。単に aware な datetime オブジェクト dt からタイムゾーンオブジェクトを除去したいだけで、日付や時刻データの変換を行わないのなら、dt.replace(tzinfo=None) を使ってください。
デフォルトの tzinfo.fromutc() メソッドを tzinfo のサブクラスで上書きして, astimezone() が返す結果に影響を及ぼすことができます。エラーの場合を無視すると、 astimezone() は以下のように動作します:
def astimezone(self, tz):
    if self.tzinfo is tz:
        return self
    # Convert self to UTC, and attach the new time zone object.
    utc = (self - self.utcoffset()).replace(tzinfo=tz)
    # Convert from UTC to tz's local time.
    return tz.fromutc(utc)
バージョン 3.3 で変更: tz が省略可能になりました。
バージョン 3.6 で変更: datetime.datetime.astimezone() メソッドを naive なインスタンスに対して呼び出せるようになりました。これは、システムのローカルな時間を表現していると想定されます。
datetime.utcoffset()
tzinfo が None の場合、 None を返し、そうでない場合には self.tzinfo.utcoffset(self) を返します。 後者の式が None あるいは 1 日以下の大きさを持つ timedelta オブジェクトのいずれかを返さない場合には例外を送出します。
バージョン 3.7 で変更: UTC オフセットが分単位でなければならない制限が無くなりました。
datetime.dst()
tzinfo が None の場合 None を返し、そうでない場合には self.tzinfo.dst(self) を返します。 後者の式が None もしくは、1 日未満の大きさを持つ timedelta オブジェクトのいずれかを返さない場合には例外を送出します。
バージョン 3.7 で変更: DST オフセットが分単位でなければならない制限が無くなりました。
datetime.tzname()
tzinfo が None の場合 None を返し、そうでない場合には self.tzinfo.tzname(self) を返します。 後者の式が None か文字列オブジェクトのいずれかを返さない場合には例外を送出します。
datetime.timetuple()
time.localtime() が返すような time.struct_time を返します。
d.timetuple() は次の式と等価です:
time.struct_time((d.year, d.month, d.day,
                  d.hour, d.minute, d.second,
                  d.weekday(), yday, dst))
ここで yday = d.toordinal() - date(d.year, 1, 1).toordinal() + 1 はその年の1月1日を 1 としたときのその日の位置です。 返されるタプルの tm_isdst フラグは dst() メソッドに従って設定されます: tzinfo が None か dst() が None を返す場合、 tm_isdst は -1 に設定されます; そうでない場合、 dst() がゼロでない値を返すと tm_isdst は 1 となります; それ以外の場合には tm_isdst は 0 に設定されます。
datetime.utctimetuple()
datetime インスタンス d が naive の場合、このメソッドは d.timetuple() と同じであり、 d.dst() の返す内容にかかわらず tm_isdst が 0 に強制される点だけが異なります。 DST が UTC 時刻に影響を及ぼすことは決してありません。
d が aware だった場合、 d は d.utcoffset() を引いて UTC 時刻に正規化され、その時刻が time.struct_time として返されます。 tm_isdst は 0 に強制されます。 d.year が MINYEAR もしくは MAXYEAR であり、 UTC 時刻への調整により適切な年の範囲を越えた場合、 OverflowError が送出される可能性があることに注意してください。
警告 naive な datetime オブジェクトは多くの datetime メソッドでローカルな時間として扱われるため、 aware な datetime を使って UTC の時刻を表すのが好ましいです。結果として、 utcfromtimetuple は誤解を招きやすい返り値を返すかもしれません。 UTC を表す naive な datetime があった場合、 datetime.timetuple() が使えるところでは datetime.replace(tzinfo=timezone.utc) で aware にします。
datetime.toordinal()
先発グレゴリオ暦における日付序数を返します。self.date().toordinal() と同じです。
datetime.timestamp()
datetime インスタンスに対応する POSIX タイムスタンプを返します。 返り値は time.time() で返される値に近い float です。
このメソッドでは naive な datetime インスタンスはローカル時刻とし、プラットフォームの C 関数 mktime() に頼って変換を行います。 datetime は多くのプラットフォームの mktime() より広い範囲の値をサポートしているので、遥か過去の時刻や遥か未来の時刻に対し、このメソッドは OverflowError を送出するかもしれません。
aware な datetime インスタンスに対しては以下のように返り値が計算されます:
(dt - datetime(1970, 1, 1, tzinfo=timezone.utc)).total_seconds()
バージョン 3.3 で追加.
バージョン 3.6 で変更: The timestamp() method uses the fold attribute to disambiguate the times during a repeated interval.
注釈 UTC 時刻を表す naive な datetime インスタンスから直接 POSIX タイムスタンプを取得するメソッドはありません。 アプリケーションがその変換を使っており、システムのタイムゾーンが UTC に設定されていなかった場合、 tzinfo=timezone.utc を引数に与えることで POSIX タイムスタンプを取得できます:
timestamp = dt.replace(tzinfo=timezone.utc).timestamp()
もしくは直接タイムスタンプを計算することもできます:
timestamp = (dt - datetime(1970, 1, 1)) / timedelta(seconds=1)
datetime.weekday()
月曜日を 0、日曜日を 6 として、曜日を整数で返します。 self.date().weekday() と同じです。 isoweekday() も参照してください。
datetime.isoweekday()
月曜日を 1、日曜日を 7 として、曜日を整数で返します。 self.date().isoweekday() と等価です。 weekday() 、 isocalendar() も参照してください。
datetime.isocalendar()
datetime.isoformat(sep='T', timespec='auto')
日時を ISO 8601 書式で表した文字列で返します:
microsecond が 0 でない場合は YYYY-MM-DDTHH:MM:SS.ffffff
microsecond が 0 の場合は YYYY-MM-DDTHH:MM:SS
utcoffset() が None を返さない場合は、文字列の後ろに UTC オフセットが追記されます:
microsecond が 0 でない場合は YYYY-MM-DDTHH:MM:SS.ffffff+HH:MM[:SS[.ffffff]]
microsecond が 0 の場合は YYYY-MM-DDTHH:MM:SS+HH:MM[:SS[.ffffff]]
例:
>>>
>>> from datetime import datetime, timezone
>>> datetime(2019, 5, 18, 15, 17, 8, 132263).isoformat()
'2019-05-18T15:17:08.132263'
>>> datetime(2019, 5, 18, 15, 17, tzinfo=timezone.utc).isoformat()
'2019-05-18T15:17:00+00:00'
オプションの引数 sep (デフォルトでは 'T' です) は 1 文字のセパレータで、結果の文字列の日付と時刻の間に置かれます。例えば:
>>>
>>> from datetime import tzinfo, timedelta, datetime
>>> class TZ(tzinfo):
...     """A time zone with an arbitrary, constant -06:39 offset."""
...     def utcoffset(self, dt):
...         return timedelta(hours=-6, minutes=-39)
...
>>> datetime(2002, 12, 25, tzinfo=TZ()).isoformat(' ')
'2002-12-25 00:00:00-06:39'
>>> datetime(2009, 11, 27, microsecond=100, tzinfo=TZ()).isoformat()
'2009-11-27T00:00:00.000100-06:39'
オプション引数 timespec は、含める追加の時間の要素の数を指定します(デフォルトでは 'auto' です)。以下の内一つを指定してください。
'auto': microsecond が0である場合 'seconds' と等しく、そうでない場合は 'microseconds' と等しくなります。
'hours': hour を2桁の HH 書式で含めます。
'minutes': hour および minute を HH:MM の書式で含めます。
'seconds': hour 、 minute 、 second を HH:MM:SS の書式で含めます。
'milliseconds': 全ての時刻を含みますが、小数第二位をミリ秒に切り捨てます。 HH:MM:SS.sss の書式で表現します。
'microseconds': 全ての時刻を HH:MM:SS.mmmmmm の書式で含めます。
注釈 除外された要素は丸め込みではなく、切り捨てされます。
不正な timespec 引数には ValueError があげられます:
>>>
>>> from datetime import datetime
>>> datetime.now().isoformat(timespec='minutes')   
'2002-12-25T00:00'
>>> dt = datetime(2015, 1, 1, 12, 30, 59, 0)
>>> dt.isoformat(timespec='microseconds')
'2015-01-01T12:30:59.000000'
バージョン 3.6 で追加: timespec 引数が追加されました。
datetime.__str__()
datetime オブジェクト d において、 str(d) は d.isoformat(' ') と等価です。
datetime.ctime()
日付および時刻を表す文字列を返します:
>>>
>>> from datetime import datetime
>>> datetime(2002, 12, 4, 20, 30, 40).ctime()
'Wed Dec  4 20:30:40 2002'
出力文字列は入力が aware であれ naive であれ、タイムゾーン情報を含み ません。
d.ctime() は次の式と等価です:
time.ctime(time.mktime(d.timetuple()))
これが等価になるのは、 (time.ctime() に呼び出され、 datetime.ctime() に呼び出されない) ネイティブの C 関数 ctime() が C 標準に準拠しているプラットフォーム上でです。
datetime.strftime(format)
明示的な書式文字列で制御された、日付および時刻を表現する文字列を返します。完全な書式化指定子のリストについては strftime() と strptime() の振る舞い を参照してください。
datetime.__format__(format)
datetime.strftime() と等価です。 これにより、 フォーマット済み文字列リテラル の中や str.format() を使っているときに datetime オブジェクトの書式文字列を指定できます。 書式化指定子の完全なリストについては strftime() と strptime() の振る舞い を参照してください。
使用例: datetime
datetime オブジェクトを使う例:
>>> from datetime import datetime, date, time, timezone
>>> # Using datetime.combine()
>>> d = date(2005, 7, 14)
>>> t = time(12, 30)
>>> datetime.combine(d, t)
datetime.datetime(2005, 7, 14, 12, 30)
>>> # Using datetime.now()
>>> datetime.now()   
datetime.datetime(2007, 12, 6, 16, 29, 43, 79043)   # GMT +1
>>> datetime.now(timezone.utc)   
datetime.datetime(2007, 12, 6, 15, 29, 43, 79060, tzinfo=datetime.timezone.utc)
>>> # Using datetime.strptime()
>>> dt = datetime.strptime("21/11/06 16:30", "%d/%m/%y %H:%M")
>>> dt
datetime.datetime(2006, 11, 21, 16, 30)
>>> # Using datetime.timetuple() to get tuple of all attributes
>>> tt = dt.timetuple()
>>> for it in tt:   
...     print(it)
...
2006    # year
11      # month
21      # day
16      # hour
30      # minute
0       # second
1       # weekday (0 = Monday)
325     # number of days since 1st January
-1      # dst - method tzinfo.dst() returned None
>>> # Date in ISO format
>>> ic = dt.isocalendar()
>>> for it in ic:   
...     print(it)
...
2006    # ISO year
47      # ISO week
2       # ISO weekday
>>> # Formatting a datetime
>>> dt.strftime("%A, %d. %B %Y %I:%M%p")
'Tuesday, 21. November 2006 04:30PM'
>>> 'The {1} is {0:%d}, the {2} is {0:%B}, the {3} is {0:%I:%M%p}.'.format(dt, "day", "month", "time")
'The day is 21, the month is November, the time is 04:30PM.'
下にある例では、1945年までは +4 UTC 、それ以降は +4:30 UTC を使用しているアフガニスタンのカブールのタイムゾーン情報を表現する tzinfo のサブクラスを定義しています:
from datetime import timedelta, datetime, tzinfo, timezone
class KabulTz(tzinfo):
    # Kabul used +4 until 1945, when they moved to +4:30
    UTC_MOVE_DATE = datetime(1944, 12, 31, 20, tzinfo=timezone.utc)
    def utcoffset(self, dt):
        if dt.year < 1945:
            return timedelta(hours=4)
        elif (1945, 1, 1, 0, 0) <= dt.timetuple()[:5] < (1945, 1, 1, 0, 30):
            # An ambiguous ("imaginary") half-hour range representing
            # a 'fold' in time due to the shift from +4 to +4:30.
            # If dt falls in the imaginary range, use fold to decide how
            # to resolve. See PEP495.
            return timedelta(hours=4, minutes=(30 if dt.fold else 0))
        else:
            return timedelta(hours=4, minutes=30)
    def fromutc(self, dt):
        # Follow same validations as in datetime.tzinfo
        if not isinstance(dt, datetime):
            raise TypeError("fromutc() requires a datetime argument")
        if dt.tzinfo is not self:
            raise ValueError("dt.tzinfo is not self")
        # A custom implementation is required for fromutc as
        # the input to this function is a datetime with utc values
        # but with a tzinfo set to self.
        # See datetime.astimezone or fromtimestamp.
        if dt.replace(tzinfo=timezone.utc) >= self.UTC_MOVE_DATE:
            return dt + timedelta(hours=4, minutes=30)
        else:
            return dt + timedelta(hours=4)
    def dst(self, dt):
        # Kabul does not observe daylight saving time.
        return timedelta(0)
    def tzname(self, dt):
        if dt >= self.UTC_MOVE_DATE:
            return "+04:30"
        return "+04"
上に出てきた KabulTz の使い方:
>>>
>>> tz1 = KabulTz()
>>> # Datetime before the change
>>> dt1 = datetime(1900, 11, 21, 16, 30, tzinfo=tz1)
>>> print(dt1.utcoffset())
4:00:00
>>> # Datetime after the change
>>> dt2 = datetime(2006, 6, 14, 13, 0, tzinfo=tz1)
>>> print(dt2.utcoffset())
4:30:00
>>> # Convert datetime to another time zone
>>> dt3 = dt2.astimezone(timezone.utc)
>>> dt3
datetime.datetime(2006, 6, 14, 8, 30, tzinfo=datetime.timezone.utc)
>>> dt2
datetime.datetime(2006, 6, 14, 13, 0, tzinfo=KabulTz())
>>> dt2 == dt3
True
time オブジェクト
time オブジェクトは (ローカルの) 日中時刻を表現します。 この時刻表現は特定の日の影響を受けず、 tzinfo オブジェクトを介した修正の対象となります。
class datetime.time(hour=0, minute=0, second=0, microsecond=0, tzinfo=None, *, fold=0)
全ての引数はオプションです。 tzinfo は None または tzinfo クラスのサブクラスのインスタンスにすることができます。残りの引数は整数で、以下のような範囲に入らなければなりません:
0 <= hour < 24,
0 <= minute < 60,
0 <= second < 60,
0 <= microsecond < 1000000,
fold in [0, 1].
引数がこれらの範囲外にある場合、 ValueError が送出されます。 tzinfo のデフォルト値が None である以外のデフォルト値は 0 です。
以下にクラス属性を示します:
time.min
表現できる最も古い time で、 time(0, 0, 0, 0) です。
time.max
表現できる最も新しい time で、 time(23, 59, 59, 999999) です。
time.resolution
等しくない time オブジェクト間の最小の差で、 timedelta(microseconds=1) ですが, time オブジェクト間の四則演算はサポートされていないので注意してください。
インスタンスの属性 (読み出しのみ):
time.hour
in range(24) を満たします。
time.minute
in range(60) を満たします。
time.second
in range(60) を満たします。
time.microsecond
in range(1000000) を満たします。
time.tzinfo
time コンストラクタに tzinfo 引数として与えられたオブジェクトになり、何も渡されなかった場合には None になります。
time.fold
[0, 1] のどちらかです。 繰り返し期間中の実時間の曖昧さ除去に使われます。 (繰り返し期間は、夏時間の終わりに時計が巻き戻るときや、現在のゾーンの UTC オフセットが政治的な理由で減少するときに発生します。) 0 (1) という値は、同じ実時間で表現される 2 つの時刻のうちの早い方 (遅い方) を表します。
バージョン 3.6 で追加.
time オブジェクトは time どうしの比較をサポートしていて、 a が b より前の時刻だった場合 a が b より小さいとされます。 比較対象の片方が naive であり、もう片方が aware の場合に、順序比較が行われると TypeError が送出されます。 等価比較では、 naive インスタンスと aware インスタンスは等価になることはありません。
比較対象が両方とも aware であり、同じ tzinfo 属性を持つ場合、 tzinfo は無視され datetime だけで比較が行われます。 比較対象が両方とも aware であり、異なる tzinfo 属性を持つ場合、まず最初に (self.utcoffset() で取得できる) それぞれの UTC オフセットを引いて調整します。 異なる型どうしの比較がデフォルトのオブジェクトアドレス比較となってしまうのを防ぐために、 time オブジェクトを異なる型のオブジェクトと比較すると、比較演算子が == または != でないかぎり TypeError が送出されます。 比較演算子が == または != である場合、それぞれ False または True を返します。
バージョン 3.3 で変更: aware な datetime インスタンスと naive な time インスタンスの等価比較では TypeError は送出されません。
ブール値の文脈では、 time オブジェクトは常に真とみなされます。
バージョン 3.5 で変更: Python 3.5 以前は、 time オブジェクトは UTC で深夜を表すときに偽とみなされていました。 この挙動は分かりにくく、エラーの元となると考えられ、Python 3.5 で削除されました。 全詳細については bpo-13936 を参照してください。
その他のコンストラクタ:
classmethod time.fromisoformat(time_string)
time.isoformat() の出力書式のうちの1つの書式で、 time_string に対応する time を返します。 具体的には、この関数は次の書式の文字列をサポートしています:
HH[:MM[:SS[.fff[fff]]]][+HH:MM[:SS[.ffffff]]]
ご用心 この関数は、任意の ISO 8601 文字列の構文解析をサポートしているわけでは ありません これは time.isoformat() の逆演算を意図して実装されています。
例:
>>>
>>> from datetime import time
>>> time.fromisoformat('04:23:01')
datetime.time(4, 23, 1)
>>> time.fromisoformat('04:23:01.000384')
datetime.time(4, 23, 1, 384)
>>> time.fromisoformat('04:23:01+04:00')
datetime.time(4, 23, 1, tzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))
バージョン 3.7 で追加.
インスタンスメソッド:
time.replace(hour=self.hour, minute=self.minute, second=self.second, microsecond=self.microsecond, tzinfo=self.tzinfo, *, fold=0)
キーワード引数で指定したメンバの値を除き、同じ値をもつ time オブジェクトを返します。データに対する変換を行わずに aware な time オブジェクトから naive な time オブジェクトを生成するために、 tzinfo=None を指定することもできます。
バージョン 3.6 で追加: fold 引数が追加されました。
time.isoformat(timespec='auto')
時刻を ISO 8601 書式で表した次の文字列のうち1つを返します:
microsecond が 0 でない場合は HH:MM:SS.ffffff
microsecond が 0 の場合は HH:MM:SS
utcoffset() が None を返さない場合、 HH:MM:SS.ffffff+HH:MM[:SS[.ffffff]]
microsecond が 0 で utcoffset() が None を返さない場合、 HH:MM:SS+HH:MM[:SS[.ffffff]]
オプション引数 timespec は、含める追加の時間の要素の数を指定します(デフォルトでは 'auto' です)。以下の内一つを指定してください。
'auto': microsecond が0である場合 'seconds' と等しく、そうでない場合は 'microseconds' と等しくなります。
'hours': hour を2桁の HH 書式で含めます。
'minutes': hour および minute を HH:MM の書式で含めます。
'seconds': hour 、 minute 、 second を HH:MM:SS の書式で含めます。
'milliseconds': 全ての時刻を含みますが、小数第二位をミリ秒に切り捨てます。 HH:MM:SS.sss の書式で表現します。
'microseconds': 全ての時刻を HH:MM:SS.mmmmmm の書式で含めます。
注釈 除外された要素は丸め込みではなく、切り捨てされます。
不正な timespec 引数には ValueError があげられます。
以下はプログラム例です:
>>>
>>> from datetime import time
>>> time(hour=12, minute=34, second=56, microsecond=123456).isoformat(timespec='minutes')
'12:34'
>>> dt = time(hour=12, minute=34, second=56, microsecond=0)
>>> dt.isoformat(timespec='microseconds')
'12:34:56.000000'
>>> dt.isoformat(timespec='auto')
'12:34:56'
バージョン 3.6 で追加: timespec 引数が追加されました。
time.__str__()
time オブジェクト t において、str(t) は t.isoformat() と等価です。
time.strftime(format)
明示的な書式文字列で制御された、時刻を表現する文字列を返します。完全な書式化指定子のリストについては strftime() と strptime() の振る舞い を参照してください。
time.__format__(format)
time.strftime() と等価です。 これにより、 フォーマット済み文字列リテラル の中や str.format() を使っているときに time オブジェクトの書式文字列を指定できます。 書式化指定子の完全なリストについては strftime() と strptime() の振る舞い を参照してください。
time.utcoffset()
tzinfo が None の場合、 None を返し、そうでない場合には self.tzinfo.utcoffset(None) を返します。 後者の式が None あるいは 1 日以下の大きさを持つ timedelta オブジェクトのいずれかを返さない場合には例外を送出します。
バージョン 3.7 で変更: UTC オフセットが分単位でなければならない制限が無くなりました。
time.dst()
tzinfo が None の場合 None を返し、そうでない場合には self.tzinfo.dst(None) を返します。 後者の式が None もしくは、1 日未満の大きさを持つ timedelta オブジェクトのいずれかを返さない場合には例外を送出します。
バージョン 3.7 で変更: DST オフセットが分単位でなければならない制限が無くなりました。
time.tzname()
tzinfo が None の場合 None を返し、そうでない場合には self.tzinfo.tzname(None) を返します。 後者の式が None か文字列オブジェクトのいずれかを返さない場合には例外を送出します。
使用例: time
time オブジェクトを使う例:
>>>
>>> from datetime import time, tzinfo, timedelta
>>> class TZ1(tzinfo):
...     def utcoffset(self, dt):
...         return timedelta(hours=1)
...     def dst(self, dt):
...         return timedelta(0)
...     def tzname(self,dt):
...         return "+01:00"
...     def  __repr__(self):
...         return f"{self.__class__.__name__}()"
...
>>> t = time(12, 10, 30, tzinfo=TZ1())
>>> t
datetime.time(12, 10, 30, tzinfo=TZ1())
>>> t.isoformat()
'12:10:30+01:00'
>>> t.dst()
datetime.timedelta(0)
>>> t.tzname()
'+01:00'
>>> t.strftime("%H:%M:%S %Z")
'12:10:30 +01:00'
>>> 'The {} is {:%H:%M}.'.format("time", t)
'The time is 12:10.'
tzinfo オブジェクト
class datetime.tzinfo
このクラスは抽象基底クラスで、直接インスタンス化すべきでないことを意味します。 tzinfo のサブクラスを定義し、ある特定のタイムゾーンに関する情報を保持するようにしてください。
tzinfo (の具体的なサブクラス) のインスタンスは datetime および time オブジェクトのコンストラクタに渡すことができます。後者のオブジェクトでは、データ属性をローカル時刻におけるものとして見ており、 tzinfo オブジェクトはローカル時刻の UTC からのオフセット、タイムゾーンの名前、 DST オフセットを、渡された日付および時刻オブジェクトからの相対で示すためのメソッドを提供します。
具象サブクラスを作成し、(少なくとも) 使いたい datetime のメソッドが必要とする tzinfo のメソッドを実装する必要があります。 datetime モジュールは tzinfo のシンプルな具象サブクラス timezone を提供します。 これは UTC そのものか北アメリカの EST と EDT のような UTC からの固定されたオフセットを持つタイムゾーンを表せます。
pickle 化についての特殊な要求事項: tzinfo のサブクラスは引数なしで呼び出すことのできる __init__() メソッドを持たなければなりません。そうでなければ、 pickle 化することはできますがおそらく unpickle 化することはできないでしょう。これは技術的な側面からの要求であり、将来緩和されるかもしれません。
tzinfo の具体的なサブクラスでは、以下のメソッドを実装する必要があります。厳密にどのメソッドが必要なのかは、 aware な datetime オブジェクトがこのサブクラスのインスタンスをどのように使うかに依存します。不確かならば、単に全てを実装してください。
tzinfo.utcoffset(dt)
ローカル時間の UTC からのオフセットを、 UTC から東向きを正とした分で返します。ローカル時間が UTC の西側にある場合、この値は負になります。
このメソッドは UTC からのオフセットの 総計 を表しています。例えば、 tzinfo オブジェクトがタイムゾーンと DST 修正の両方を表現する場合、 utcoffset() はそれらの合計を返さなければなりません。 UTC オフセットが未知である場合、 None を返します。 そうでない場合には、返される値は -timedelta(hours=24) から timedelta(hours=24) までの timedelta 境界を含まないオブジェクトでなければなりません (オフセットの大きさは 1 日より短くなければなりません)。 ほとんどの utcoffset() 実装は、おそらく以下の二つのうちの一つに似たものになるでしょう:
return CONSTANT                 # fixed-offset class
return CONSTANT + self.dst(dt)  # daylight-aware class
utcoffset() が None を返さない場合、 dst() も None を返してはなりません。
utcoffset() のデフォルトの実装は NotImplementedError を送出します。
バージョン 3.7 で変更: UTC オフセットが分単位でなければならない制限が無くなりました。
tzinfo.dst(dt)
夏時間 (DST) 修正を、 UTC から東向きを正とした分で返します。 DST 情報が未知の場合、 None が返されます。
DST が有効でない場合には timedelta(0) を返します。 DST が有効の場合、オフセットは timedelta オブジェクトで返します (詳細は utcoffset() を参照してください)。 DST オフセットが利用可能な場合、この値は utcoffset() が返す UTC からのオフセットには既に加算されているため、 DST を個別に取得する必要がない限り dst() を使って問い合わせる必要はないので注意してください。 例えば、 datetime.timetuple() は tzinfo 属性の dst() メソッドを呼んで tm_isdst フラグがセットされているかどうか判断し、 tzinfo.fromutc() は dst() タイムゾーンを移動する際に DST による変更があるかどうかを調べます。
標準および夏時間の両方をモデル化している tzinfo サブクラスのインスタンス tz は以下の式:
tz.utcoffset(dt) - tz.dst(dt)
が、 dt.tzinfo == tz 全ての datetime オブジェクト dt について常に同じ結果を返さなければならないという点で、一貫性を持っていなければなりません。正常に実装された tzinfo のサブクラスでは、この式はタイムゾーンにおける "標準オフセット (standard offset)" を表し、特定の日や時刻の事情ではなく地理的な位置にのみ依存していなくてはなりません。 datetime.astimezone() の実装はこの事実に依存していますが、違反を検出することができません; 正しく実装するのはプログラマの責任です。 tzinfo のサブクラスでこれを保証することができない場合、 tzinfo.fromutc() の実装をオーバライドして、 astimezone() に関わらず正しく動作するようにしてもかまいません。
ほとんどの dst() 実装は、おそらく以下の二つのうちの一つに似たものになるでしょう:
def dst(self, dt):
    # a fixed-offset class:  doesn't account for DST
    return timedelta(0)
もしくは:
def dst(self, dt):
    # Code to set dston and dstoff to the time zone's DST
    # transition times based on the input dt.year, and expressed
    # in standard local time.
    if dston <= dt.replace(tzinfo=None) < dstoff:
        return timedelta(hours=1)
    else:
        return timedelta(0)
デフォルトの dst() 実装は NotImplementedError を送出します。
バージョン 3.7 で変更: DST オフセットが分単位でなければならない制限が無くなりました。
tzinfo.tzname(dt)
datetime オブジェクト dt に対応するタイムゾーン名を文字列で返します。 datetime モジュールでは文字列名について何も定義しておらず、特に何かを意味するといった要求仕様もまったくありません。例えば、 "GMT", "UTC", "-500", "-5:00", "EDT", "US/Eastern", "America/New York" は全て有効な応答となります。文字列名が未知の場合には None を返してください。 tzinfo のサブクラスでは、特に, tzinfo クラスが夏時間について記述している場合のように、渡された dt の特定の値によって異なった名前を返したい場合があるため、文字列値ではなくメソッドとなっていることに注意してください。
デフォルトの tzname() 実装は NotImplementedError を送出します。
以下のメソッドは datetime や time オブジェクトにおいて、同名のメソッドが呼び出された際に応じて呼び出されます。 datetime オブジェクトは自身を引数としてメソッドに渡し、 time オブジェクトは引数として None をメソッドに渡します。従って、 tzinfo のサブクラスにおけるメソッドは引数 dt が None の場合と、 datetime の場合を受理するように用意しなければなりません。
None が渡された場合、最良の応答方法を決めるのはクラス設計者次第です。例えば、このクラスが tzinfo プロトコルと関係をもたないということを表明させたければ、 None が適切です。標準時のオフセットを見つける他の手段がない場合には、標準 UTC オフセットを返すために utcoffset(None) を使うともっと便利かもしれません。
datetime オブジェクトが datetime() メソッドの応答として返された場合、 dt.tzinfo は self と同じオブジェクトになります。ユーザが直接 tzinfo メソッドを呼び出さないかぎり、 tzinfo メソッドは dt.tzinfo と self が同じであることに依存します。その結果 tzinfo メソッドは dt がローカル時間であると解釈するので、他のタイムゾーンでのオブジェクトの振る舞いについて心配する必要がありません。
サブクラスでオーバーライドすると良い、もう 1 つの tzinfo のメソッドがあります:
tzinfo.fromutc(dt)
デフォルトの datetime.astimezone() 実装で呼び出されます。 datetime.astimezone() から呼ばれた場合、 dt.tzinfo は self であり、 dt の日付および時刻データは UTC 時刻を表しているものとして見えます。 fromutc() の目的は、 self のローカル時刻に等しい datetime オブジェクトを返すことにより日付と時刻データメンバを修正することにあります。
ほとんどの tzinfo サブクラスではデフォルトの fromutc() 実装を問題なく継承できます。デフォルトの実装は、固定オフセットのタイムゾーンや、標準時と夏時間の両方について記述しているタイムゾーン、そして DST 移行時刻が年によって異なる場合でさえ、扱えるくらい強力なものです。デフォルトの fromutc() 実装が全ての場合に対して正しく扱うことができないような例は、標準時の (UTCからの) オフセットが引数として渡された特定の日や時刻に依存するもので、これは政治的な理由によって起きることがあります。デフォルトの astimezone() や fromutc() の実装は、結果が標準時オフセットの変化にまたがる何時間かの中にある場合、期待通りの結果を生成しないかもしれません。
エラーの場合のためのコードを除き、デフォルトの fromutc() の実装は以下のように動作します:
def fromutc(self, dt):
    # raise ValueError error if dt.tzinfo is not self
    dtoff = dt.utcoffset()
    dtdst = dt.dst()
    # raise ValueError if dtoff is None or dtdst is None
    delta = dtoff - dtdst  # this is self's standard offset
    if delta:
        dt += delta   # convert to standard local time
        dtdst = dt.dst()
        # raise ValueError if dtdst is None
    if dtdst:
        return dt + dtdst
    else:
        return dt
次の tzinfo_examples.py ファイルには、 tzinfo クラスの例がいくつか載っています:
from datetime import tzinfo, timedelta, datetime
ZERO = timedelta(0)
HOUR = timedelta(hours=1)
SECOND = timedelta(seconds=1)
# A class capturing the platform's idea of local time.
# (May result in wrong values on historical times in
#  timezones where UTC offset and/or the DST rules had
#  changed in the past.)
import time as _time
STDOFFSET = timedelta(seconds = -_time.timezone)
if _time.daylight:
    DSTOFFSET = timedelta(seconds = -_time.altzone)
else:
    DSTOFFSET = STDOFFSET
DSTDIFF = DSTOFFSET - STDOFFSET
class LocalTimezone(tzinfo):
    def fromutc(self, dt):
        assert dt.tzinfo is self
        stamp = (dt - datetime(1970, 1, 1, tzinfo=self)) // SECOND
        args = _time.localtime(stamp)[:6]
        dst_diff = DSTDIFF // SECOND
        # Detect fold
        fold = (args == _time.localtime(stamp - dst_diff))
        return datetime(*args, microsecond=dt.microsecond,
                        tzinfo=self, fold=fold)
    def utcoffset(self, dt):
        if self._isdst(dt):
            return DSTOFFSET
        else:
            return STDOFFSET
    def dst(self, dt):
        if self._isdst(dt):
            return DSTDIFF
        else:
            return ZERO
    def tzname(self, dt):
        return _time.tzname[self._isdst(dt)]
    def _isdst(self, dt):
        tt = (dt.year, dt.month, dt.day,
              dt.hour, dt.minute, dt.second,
              dt.weekday(), 0, 0)
        stamp = _time.mktime(tt)
        tt = _time.localtime(stamp)
        return tt.tm_isdst > 0
Local = LocalTimezone()
# A complete implementation of current DST rules for major US time zones.
def first_sunday_on_or_after(dt):
    days_to_go = 6 - dt.weekday()
    if days_to_go:
        dt += timedelta(days_to_go)
    return dt
# US DST Rules
#
# This is a simplified (i.e., wrong for a few cases) set of rules for US
# DST start and end times. For a complete and up-to-date set of DST rules
# and timezone definitions, visit the Olson Database (or try pytz):
# http://www.twinsun.com/tz/tz-link.htm
# http://sourceforge.net/projects/pytz/ (might not be up-to-date)
#
# In the US, since 2007, DST starts at 2am (standard time) on the second
# Sunday in March, which is the first Sunday on or after Mar 8.
DSTSTART_2007 = datetime(1, 3, 8, 2)
# and ends at 2am (DST time) on the first Sunday of Nov.
DSTEND_2007 = datetime(1, 11, 1, 2)
# From 1987 to 2006, DST used to start at 2am (standard time) on the first
# Sunday in April and to end at 2am (DST time) on the last
# Sunday of October, which is the first Sunday on or after Oct 25.
DSTSTART_1987_2006 = datetime(1, 4, 1, 2)
DSTEND_1987_2006 = datetime(1, 10, 25, 2)
# From 1967 to 1986, DST used to start at 2am (standard time) on the last
# Sunday in April (the one on or after April 24) and to end at 2am (DST time)
# on the last Sunday of October, which is the first Sunday
# on or after Oct 25.
DSTSTART_1967_1986 = datetime(1, 4, 24, 2)
DSTEND_1967_1986 = DSTEND_1987_2006
def us_dst_range(year):
    # Find start and end times for US DST. For years before 1967, return
    # start = end for no DST.
    if 2006 < year:
        dststart, dstend = DSTSTART_2007, DSTEND_2007
    elif 1986 < year < 2007:
        dststart, dstend = DSTSTART_1987_2006, DSTEND_1987_2006
    elif 1966 < year < 1987:
        dststart, dstend = DSTSTART_1967_1986, DSTEND_1967_1986
    else:
        return (datetime(year, 1, 1), ) * 2
    start = first_sunday_on_or_after(dststart.replace(year=year))
    end = first_sunday_on_or_after(dstend.replace(year=year))
    return start, end
class USTimeZone(tzinfo):
    def __init__(self, hours, reprname, stdname, dstname):
        self.stdoffset = timedelta(hours=hours)
        self.reprname = reprname
        self.stdname = stdname
        self.dstname = dstname
    def __repr__(self):
        return self.reprname
    def tzname(self, dt):
        if self.dst(dt):
            return self.dstname
        else:
            return self.stdname
    def utcoffset(self, dt):
        return self.stdoffset + self.dst(dt)
    def dst(self, dt):
        if dt is None or dt.tzinfo is None:
            # An exception may be sensible here, in one or both cases.
            # It depends on how you want to treat them.  The default
            # fromutc() implementation (called by the default astimezone()
            # implementation) passes a datetime with dt.tzinfo is self.
            return ZERO
        assert dt.tzinfo is self
        start, end = us_dst_range(dt.year)
        # Can't compare naive to aware objects, so strip the timezone from
        # dt first.
        dt = dt.replace(tzinfo=None)
        if start + HOUR <= dt < end - HOUR:
            # DST is in effect.
            return HOUR
        if end - HOUR <= dt < end:
            # Fold (an ambiguous hour): use dt.fold to disambiguate.
            return ZERO if dt.fold else HOUR
        if start <= dt < start + HOUR:
            # Gap (a non-existent hour): reverse the fold rule.
            return HOUR if dt.fold else ZERO
        # DST is off.
        return ZERO
    def fromutc(self, dt):
        assert dt.tzinfo is self
        start, end = us_dst_range(dt.year)
        start = start.replace(tzinfo=self)
        end = end.replace(tzinfo=self)
        std_time = dt + self.stdoffset
        dst_time = std_time + HOUR
        if end <= dst_time < end + HOUR:
            # Repeated hour
            return std_time.replace(fold=1)
        if std_time < start or dst_time >= end:
            # Standard time
            return std_time
        if start <= std_time < end - HOUR:
            # Daylight saving time
            return dst_time
Eastern  = USTimeZone(-5, "Eastern",  "EST", "EDT")
Central  = USTimeZone(-6, "Central",  "CST", "CDT")
Mountain = USTimeZone(-7, "Mountain", "MST", "MDT")
Pacific  = USTimeZone(-8, "Pacific",  "PST", "PDT")
標準時および夏時間の両方を記述している tzinfo のサブクラスでは、夏時間の移行のときに、回避不能の難解な問題が年に 2 度あるので注意してください。 具体的な例として、東部アメリカ時刻 (US Eastern, UTC -0500) を考えます。 EDT は 3 月の第二日曜日の 1:59 (EST) の 1 分後に開始し、11 月の最初の日曜日の (EDTの) 1:59 に終了します:
  UTC   3:MM  4:MM  5:MM  6:MM  7:MM  8:MM
  EST  22:MM 23:MM  0:MM  1:MM  2:MM  3:MM
  EDT  23:MM  0:MM  1:MM  2:MM  3:MM  4:MM
start  22:MM 23:MM  0:MM  1:MM  3:MM  4:MM
  end  23:MM  0:MM  1:MM  1:MM  2:MM  3:MM
DSTの開始 ("start" ライン) で、ローカルの実時間は 1:59 から 3:00 に飛びます。 この日には、 2:MM という形式の実時間は意味をなさないので、 DST が始まった日に astimezone(Eastern) は ``hour == 2``となる結果を返すことはありません。 例として、 2016 年の春方向の移行では、次のような結果になります:
>>>
>>> from datetime import datetime, timezone
>>> from tzinfo_examples import HOUR, Eastern
>>> u0 = datetime(2016, 3, 13, 5, tzinfo=timezone.utc)
>>> for i in range(4):
...     u = u0 + i*HOUR
...     t = u.astimezone(Eastern)
...     print(u.time(), 'UTC =', t.time(), t.tzname())
...
05:00:00 UTC = 00:00:00 EST
06:00:00 UTC = 01:00:00 EST
07:00:00 UTC = 03:00:00 EDT
08:00:00 UTC = 04:00:00 EDT
DST が終了 ("end" ライン) で、更なる問題が潜んでいます: ローカルの実時間で、曖昧さ無しに時を綴れない 1 時間が存在します: それは夏時間の最後の 1 時間です。 東部では、夏時間が終了する日の UTC での 5:MM 形式の時間がそれです。 ローカルの実時間は (夏時間の) 1:59 から (標準時の) 1:00 に再び巻き戻されます。 ローカルの時刻における 1:MM は曖昧です。 そして astimezone() は 2 つの隣り合う UTC 時間を同じローカルの時間に対応付けて、ローカルの時計の振る舞いを真似ます。 東部の例では、 5:MM および 6:MM という形式の UTC 時刻は両方とも東部時刻に変換された際に 1:MM に対応付けられますが、それ以前の時間は fold 属性を 0 にし、以降の時間では 1 にします。例えば、 2016 年での秋方向の移行では、次のような結果になります:
>>>
>>> u0 = datetime(2016, 11, 6, 4, tzinfo=timezone.utc)
>>> for i in range(4):
...     u = u0 + i*HOUR
...     t = u.astimezone(Eastern)
...     print(u.time(), 'UTC =', t.time(), t.tzname(), t.fold)
...
04:00:00 UTC = 00:00:00 EDT 0
05:00:00 UTC = 01:00:00 EDT 0
06:00:00 UTC = 01:00:00 EST 1
07:00:00 UTC = 02:00:00 EST 0
fold 属性が異なるだけの datetime インスタンスは比較において等しいとみなされることに注意してください。
壁時間に関する曖昧さは、明示的に fold 属性を検証するか、 timezone が使用されたハイブリッドな tzinfo サブクラスか、そのほかの絶対時間差を示す tzinfo サブクラス(EST (-5 時間の絶対時間差) のみを表すクラスや、 EDT (-4 時間の絶対時間差) のみを表すクラス)を使用すると回避できます。 このような曖昧さを許容できないアプリケーションは、このような手法によって回避すべきです。
参考
dateutil.tz
datetime モジュールには (UTC からの任意の固定オフセットを扱う) 基本的な timezone クラスと、(UTC タイムゾーンのインスタンスである) timezone.utc 属性があります。
dateutil.tz ライブラリは Python に IANA タイムゾーンデータベース (オルソンデータベースとしても知られています) を導入するもので、これを使うことが推奨されています。
IANA タイムゾーンデータベース
(しばしば tz、tzdata や zoneinfo と呼ばれる) タイムゾーンデータベースはコードとデータを保持しており、それらは地球全体にわたる多くの代表的な場所のローカル時刻の履歴を表しています。政治団体によるタイムゾーンの境界、UTC オフセット、夏時間のルールの変更を反映するため、定期的にデータベースが更新されます。
timezone オブジェクト
timezone クラスは tzinfo のサブクラスで、各インスタンスは UTC からの固定されたオフセットで定義されたタイムゾーンを表しています。
このクラスのオブジェクトは、一年のうち異なる日に異なるオフセットが使われていたり、常用時 (civil time) に歴史的な変化が起きた場所のタイムゾーン情報を表すのには使えないので注意してください。
class datetime.timezone(offset, name=None)
ローカル時刻と UTC の差分を表す timedelta オブジェクトを offset 引数に指定しなくてはいけません。これは -timedelta(hours=24) から timedelta(hours=24) までの両端を含まない範囲に収まっていなくてはなりません。そうでない場合 ValueError が送出されます。
バージョン 3.2 で追加.
バージョン 3.7 で変更: UTC オフセットが分単位でなければならない制限が無くなりました。
timezone.utcoffset(dt)
timezone インスタンスが構築されたときに指定された固定値を返します。
dt 引数は無視されます。 返り値は、ローカル時刻と UTC の差分に等しい timedelta インスタンスです。
バージョン 3.7 で変更: UTC オフセットが分単位でなければならない制限が無くなりました。
timezone.tzname(dt)
timezone インスタンスが構築されたときに指定された固定値を返します。
name が構築時に与えられなかった場合、 tzname(dt) によって返される name は以下の様に offset の値から生成されます。 offset が timedelta(0) であった場合、 name は "UTC"になります。 それ以外の場合、 'UTC±HH:MM' という書式の文字列になり、± は offset を、HH と MM はそれぞれ二桁の offset.hours と offset.minutes を表現します。
バージョン 3.6 で変更: offset=timedelta(0) によって生成される名前はプレーンな 'UTC' であり 'UTC+00:00' ではありません。
timezone.dst(dt)
常に None を返します。
timezone.fromutc(dt)
dt + offset を返します。 dt 引数は tzinfo が self になっている aware な datetime インスタンスでなければなりません。
以下にクラス属性を示します:
timezone.utc
UTC タイムゾーン timezone(timedelta(0)) です。
strftime() と strptime() の振る舞い
date, datetime, time オブジェクトは全て strftime(format) メソッドをサポートし、時刻を表現する文字列を明示的な書式文字列で統制して作成しています。
逆に datetime.strptime() クラスメソッドは日付や時刻に対応する書式文字列から datetime オブジェクトを生成します。
下の表は strftime() と strptime() との高レベルの対比を表しています。
strftime
strptime
使用法
オブジェクトを与えられた書式に従って文字列に変換する
指定された対応する書式で文字列を構文解析して datetime オブジェクトにする
メソッドの種類
インスタンスメソッド
クラスメソッド
メソッドを持つクラス
date; datetime; time
datetime
シグネチャ
strftime(format)
strptime(date_string, format)
strftime() と strptime() の書式コード
以下のリストは 1989 C 標準が要求する全ての書式コードで、標準 C 実装があれば全ての環境で動作します。
指定子
意味
使用例
注釈
%a
ロケールの曜日名を短縮形で表示します。
Sun, Mon, ..., Sat (en_US);
So, Mo, ..., Sa (de_DE)
(1)
%A
ロケールの曜日名を表示します。
Sunday, Monday, ..., Saturday (en_US);
Sonntag, Montag, ..., Samstag (de_DE)
(1)
%w
曜日を10進表記した文字列を表示します。0 が日曜日で、6 が土曜日を表します。
0, 1, ..., 6
%d
0埋めした10進数で表記した月中の日にち。
01, 02, ..., 31
(9)
%b
ロケールの月名を短縮形で表示します。
Jan, Feb, ..., Dec (en_US);
Jan, Feb, ..., Dez (de_DE)
(1)
%B
ロケールの月名を表示します。
January, February, ..., December (en_US);
Januar, Februar, ..., Dezember (de_DE)
(1)
%m
0埋めした10進数で表記した月。
01, 02, ..., 12
(9)
%y
0埋めした10進数で表記した世紀無しの年。
00, 01, ..., 99
(9)
%Y
西暦 (4桁) の 10 進表記を表します。
0001, 0002, ..., 2013, 2014, ..., 9998, 9999
(2)
%H
0埋めした10進数で表記した時 (24時間表記)。
00, 01, ..., 23
(9)
%I
0埋めした10進数で表記した時 (12時間表記)。
01, 02, ..., 12
(9)
%p
ロケールの AM もしくは PM と等価な文字列になります。
AM, PM (en_US);
am, pm (de_DE)
(1), (3)
%M
0埋めした10進数で表記した分。
00, 01, ..., 59
(9)
%S
0埋めした10進数で表記した秒。
00, 01, ..., 59
(4), (9)
%f
10進数で表記したマイクロ秒 (左側から0埋めされます)。
000000, 000001, ..., 999999
(5)
%z
UTCオフセットを ±HHMM[SS[.ffffff]] の形式で表示します (オブジェクトがnaiveであれば空文字列)。
(空文字列), +0000, -0400, +1030, +063415, -030712.345216
(6)
%Z
タイムゾーンの名前を表示します (オブジェクトがnaiveであれば空文字列)。
(空文字列), UTC, GMT
(6)
%j
0埋めした10進数で表記した年中の日にち。
001, 002, ..., 366
(9)
%U
0埋めした10進数で表記した年中の週番号 (週の始まりは日曜日とする)。新年の最初の日曜日に先立つ日は 0週に属するとします。
00, 01, ..., 53
(7), (9)
%W
0埋めした10進数で表記した年中の週番号 (週の始まりは月曜日とする)。新年の最初の月曜日に先立つ日は 0週に属するとします。
00, 01, ..., 53
(7), (9)
%c
ロケールの日時を適切な形式で表します。
Tue Aug 16 21:30:00 1988 (en_US);
Di 16 Aug 21:30:00 1988 (de_DE)
(1)
%x
ロケールの日付を適切な形式で表します。
08/16/88 (None);
08/16/1988 (en_US);
16.08.1988 (de_DE)
(1)
%X
ロケールの時間を適切な形式で表します。
21:30:00 (en_US);
21:30:00 (de_DE)
(1)
%%
文字 '%' を表します。
%
C89規格により要求されない幾つかの追加のコードが便宜上含まれています。これらのパラメータはすべてISO 8601の日付値に対応しています。
指定子
意味
使用例
注釈
%G
ISO week(%V)の内過半数を含む西暦表記の ISO 8601 year です。
0001, 0002, ..., 2013, 2014, ..., 9998, 9999
(8)
%u
1 を月曜日を表す 10進数表記の ISO 8601 weekday です。
1, 2, ..., 7
%V
週で最初の月曜日を始めとする ISO 8601 week です。Week 01 は 1月4日を含みます。
01, 02, ..., 53
(8), (9)
これらが strftime() メソッドと一緒に使用された場合、すべてのプラットフォームで利用できるわけではありません。 ISO 8601 year 指定子およびISO 8601 week 指定子は、上記のyear および week number 指定子と互換性がありません。不完全またはあいまいなISO 8601 指定子で strptime() を呼び出すと、 ValueError が送出されます。
Python はプラットフォームの C ライブラリの strftime() 関数を呼び出していて、プラットフォームごとにその実装が異なるのはよくあることなので、サポートされる書式コード全体はプラットフォームごとに様々です。 手元のプラットフォームでサポートされているフォーマット記号全体を見るには、 strftime(3) のドキュメントを参照してください。
バージョン 3.6 で追加: %G, %u および %V が追加されました。
技術詳細
大雑把にいうと、 d.strftime(fmt) は time モジュールの time.strftime(fmt, d.timetuple()) のように動作します。ただし全てのオブジェクトが timetuple() メソッドをサポートしているわけではありません。
datetime.strptime() クラスメソッドでは、デフォルト値は 1900-01-01T00:00:00.000 です。書式文字列で指定されなかった部分はデフォルト値から引っ張ってきます。 4
datetime.strptime(date_string, format) は次の式と等価です:
datetime(*(time.strptime(date_string, format)[0:6]))
ただし、 datetime.strptime はサポートしているが time.strptime には無い、秒未満の単位やタイムゾーンオフセットの情報が format に 含まれているときは除きます。
time オブジェクトには、年、月、日の値がないため、それらを書式コードを使うことができません。 無理矢理使った場合、年は 1900 に置き換えられ、月と日は 1 に置き換えられます。
date オブジェクトには、時、分、秒、マイクロ秒の値がないため、それらの書式コードを使うことができません。 無理矢理使った場合、これらの値は 0 に置き換えられます。
同じ理由で、現在のロケールの文字集合で表現できない Unicode コードポイントを含む書式文字列の対処もプラットフォーム依存です。 あるプラットフォームではそういったコードポイントはそのまま出力に出される一方、他のプラットフォームでは strftime が UnicodeError を送出したり、その代わりに空文字列を返したりするかもしれません。
注釈:
書式は現在のロケールに依存するので、出力値について何か仮定するときは注意すべきです。フィールドの順序は様々で (例えば、"月/日/年" と "日/月/年") 、出力はロケールのデフォルトエンコーディングでエンコードされた Unicode 文字列を含むかもしれません (例えば、現在のロケールが ja_JP だった場合、デフォルトエンコーディングは eucJP 、 SJIS 、 utf-8 のいずれかになりえます。 locale.getlocale() を使って現在のロケールのエンコーディングを確認します) 。
strptime() メソッドは [1, 9999] の範囲の年数全てを構文解析できますが、 year < 1000 の範囲の年数は 0 埋めされた 4 桁の数字でなければなりません。
バージョン 3.2 で変更: 以前のバージョンでは、 strftime() メソッドは years >= 1900 の範囲の年数しか扱えませんでした。
バージョン 3.3 で変更: バージョン 3.2 では、 strftime() メソッドは years >= 1000 の範囲の年数しか扱えませんでした。
strptime() メソッドと共に使われた場合、 %p 指定子は出力の時間フィールドのみに影響し、 %I 指定子が使われたかのように振る舞います。
time モジュールと違い、 datetime モジュールはうるう秒をサポートしていません。
strptime() メソッドと共に使われた場合、 %f 指定子は 1 桁から 6 桁の数字を受け付け、右側から0埋めされます。 %f は C 標準規格の書式文字セットの拡張です (とは言え、 datetime モジュールのオブジェクトそれぞれに実装されているので、どれででも使えます)。
naive オブジェクトでは、書式コード %z および %Z は空文字列に置き換えられます。
aware オブジェクトでは次のようになります:
%z
utcoffset() は ±HHMM[SS[.ffffff]] 形式の文字列に変換されます。ここで、 HH は UTC オフセットの時間を表す 2 桁の文字列、 MM は UTC オフセットの分数を表す 2 桁の文字列、 SS は UTC オフセットの秒数を表す 2 桁の文字列、 ffffff は UTC オフセットのマイクロ秒数を表す 6 桁の文字列です。 オフセットに秒未満の端数が無いときは ffffff 部分は省略され、オフセットに分未満の端数が無いときは ffffff 部分も SS 部分も省略されます。 例えば、 utcoffset() が timedelta(hours=-3, minutes=-30) を返す場合、 %z は文字列 '-0330' に置き換えられます。
バージョン 3.7 で変更: UTC オフセットが分単位でなければならない制限が無くなりました。
バージョン 3.7 で変更: %z 指定子が strptime() メソッドに渡されたときは、時分秒のセパレータとしてコロンが UTC オフセットで使えます。 例えば、 '+01:00:00' は 1 時間のオフセットだと構文解析されます。 加えて、 'Z' を渡すことは '+00:00' を渡すことと同等です。
%Z
strptime() only accepts certain values for %Z:
any value in time.tzname for your machine's locale
the hard-coded values UTC and GMT
バージョン 3.2 で変更: %z 指定子が strptime() メソッドに与えられた場合、 aware な datetime オブジェクトが作成されます。返り値の tzinfo は timezone インスタンスになっています。
strptime() メソッドと共に使われた場合、 %U と %W 指定子は、曜日と年(%Y)が指定された場合の計算でのみ使われます。
%U および %W と同様に、 %V は曜日と ISO 年 (%G) が strptime() の書式文字列の中で指定された場合に計算でのみ使われます。 %G と %Y は互いに完全な互換性を持たないことにも注意してください。
strptime() メソッドと共に使われたときは、書式 %d, %m, %H, %I, %M, %S, %J, %U, %W, %V の後ろに続ける 0 は任意です。 書式 %y では後ろに続ける 0 は必須です。
calendar --- 一般的なカレンダーに関する関数群
ソースコード: Lib/calendar.py
このモジュールは Unix の cal プログラムのようなカレンダー出力を行い、それに加えてカレンダーに関する有益な関数群を提供します。標準ではこれらのカレンダーは（ヨーロッパの慣例に従って）月曜日を週の始まりとし、日曜日を最後の日としています。 setfirstweekday() を用いることで、日曜日(6)や他の曜日を週の始まりに設定することができます。日付を表す引数は整数値で与えます。関連する機能として、 datetime と time モジュールも参照してください。
class calendar.Calendar(firstweekday=0)
Calendar オブジェクトを作ります。 firstweekday は整数で週の始まりの曜日を指定するものです。 0 が月曜(デフォルト)、 6 なら日曜です。
Calendar オブジェクトは整形されるカレンダーのデータを準備するために使えるいくつかのメソッドを提供しています。しかし整形機能そのものは提供していません。それはサブクラスの仕事なのです。
Calendar インスタンスには以下のメソッドがあります:
iterweekdays()
曜日の数字を一週間分生成するイテレータを返します。イテレータから得られる最初の数字は firstweekday が返す数字と同じになります。
itermonthdates(year, month)
year 年 month (1--12) 月に対するイテレータを返します。 このイテレータはその月の全ての日、およびその月が始まる前の日とその月が終わった後の日のうち、週の欠けを埋めるために必要な日を (datetime.date オブジェクトとして) 返します。
itermonthdays(year, month)
itermonthdays2(year, month)
itermonthdays3(year, month)
バージョン 3.7 で追加.
itermonthdays4(year, month)
バージョン 3.7 で追加.
monthdatescalendar(year, month)
year 年 month 月の週のリストを返します。週は全て七つの datetime.date オブジェクトからなるリストです。
monthdays2calendar(year, month)
year 年 month 月の週のリストを返します。週は全て七つの日付の数字と曜日を表す数字のタプルからなるリストです。
monthdayscalendar(year, month)
year 年 month 月の週のリストを返します。週は全て七つの日付の数字からなるリストです。
yeardatescalendar(year, width=3)
指定された年のデータを整形に向く形で返します。返される値は月の並びのリストです。月の並びは最大で width ヶ月(デフォルトは3ヶ月)分です。各月は4ないし6週からなり、各週は1ないし7日からなります。各日は datetime.date オブジェクトです。
yeardays2calendar(year, width=3)
指定された年のデータを整形に向く形で返します (yeardatescalendar() と同様です)。週のリストの中が日付の数字と曜日の数字のタプルになります。月の範囲外の部分の日付はゼロです。
yeardayscalendar(year, width=3)
指定された年のデータを整形に向く形で返します (yeardatescalendar() と同様です)。週のリストの中が日付の数字になります。月の範囲外の日付はゼロです。
class calendar.TextCalendar(firstweekday=0)
このクラスはプレインテキストのカレンダーを生成するのに使えます。
TextCalendar インスタンスには以下のメソッドがあります:
formatmonth(theyear, themonth, w=0, l=0)
ひと月分のカレンダーを複数行の文字列で返します。 w により日の列幅を変えることができ、それらは中央揃えされます。 l により各週の表示される行数を変えることができます。 setfirstweekday() メソッドでセットされた週の最初の曜日に依存します。
prmonth(theyear, themonth, w=0, l=0)
formatmonth() で返されるひと月分のカレンダーを出力します。
formatyear(theyear, w=2, l=1, c=6, m=3)
m 列からなる一年間のカレンダーを複数行の文字列で返します。任意の引数 w, l, c はそれぞれ、日付列の表示幅、各週の行数及び月と月の間のスペースの数を変更するためのものです。 setfirstweekday() メソッドでセットされた週の最初の曜日に依存します。カレンダーを出力できる最初の年はプラットフォームに依存します。
pryear(theyear, w=2, l=1, c=6, m=3)
formatyear() で返される一年間のカレンダーを出力します。
class calendar.HTMLCalendar(firstweekday=0)
このクラスは HTML のカレンダーを生成するのに使えます。
HTMLCalendar instances have the following methods:
formatmonth(theyear, themonth, withyear=True)
ひと月分のカレンダーを HTML のテーブルとして返します。withyear が真であればヘッダには年も含まれます。そうでなければ月の名前だけが使われます。
formatyear(theyear, width=3)
一年分のカレンダーを HTML のテーブルとして返します。width の値 (デフォルトでは 3 です) は何ヶ月分を一行に収めるかを指定します。
formatyearpage(theyear, width=3, css='calendar.css', encoding=None)
一年分のカレンダーを一つの完全な HTML ページとして返します。 width の値(デフォルトでは 3 です) は何ヶ月分を一行に収めるかを指定します。 css は使われるカスケーディングスタイルシートの名前です。スタイルシートを使わないようにするために None を渡すこともできます。 encoding には出力に使うエンコーディングを指定します (デフォルトではシステムデフォルトのエンコーディングです)。
HTMLCalendar has the following attributes you can override to customize the CSS classes used by the calendar:
cssclasses
A list of CSS classes used for each weekday. The default class list is:
cssclasses = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]
more styles can be added for each day:
cssclasses = ["mon text-bold", "tue", "wed", "thu", "fri", "sat", "sun red"]
cssclass_noday
バージョン 3.7 で追加.
cssclasses_weekday_head
バージョン 3.7 で追加.
cssclass_month_head
バージョン 3.7 で追加.
cssclass_month
バージョン 3.7 で追加.
cssclass_year
バージョン 3.7 で追加.
cssclass_year_head
バージョン 3.7 で追加.
Note that although the naming for the above described class attributes is singular (e.g. cssclass_month cssclass_noday), one can replace the single CSS class with a space separated list of CSS classes, for example:
"text-bold text-red"
Here is an example how HTMLCalendar can be customized:
class CustomHTMLCal(calendar.HTMLCalendar):
    cssclasses = [style + " text-nowrap" for style in
                  calendar.HTMLCalendar.cssclasses]
    cssclass_month_head = "text-center month-head"
    cssclass_month = "text-center month"
    cssclass_year = "text-italic lead"
class calendar.LocaleTextCalendar(firstweekday=0, locale=None)
この TextCalendar のサブクラスではコンストラクタにロケール名を渡すことができ、メソッドの返り値で月や曜日が指定されたロケールのものになります。このロケールがエンコーディングを含む場合には、月や曜日の入った文字列はユニコードとして返されます。
class calendar.LocaleHTMLCalendar(firstweekday=0, locale=None)
この HTMLCalendar のサブクラスではコンストラクタにロケール名を渡すことができ、メソッドの返り値で月や曜日が指定されたロケールのものになります。このロケールがエンコーディングを含む場合には、月や曜日の入った文字列はユニコードとして返されます。
注釈 これら2つのクラスの formatweekday() と formatmonthname() メソッドは、一時的に現在の locale を指定された locale に変更します。現在の locale はプロセス全体に影響するので、これらはスレッドセーフではありません。
単純なテキストのカレンダーに関して、このモジュールには以下のような関数が提供されています。
calendar.setfirstweekday(weekday)
週の最初の曜日(0 は月曜日, 6 は日曜日)を設定します。定数 MONDAY, TUESDAY, WEDNESDAY, THURSDAY, FRIDAY, SATURDAY 及び SUNDAY は便宜上提供されています。例えば、日曜日を週の開始日に設定するときは:
import calendar
calendar.setfirstweekday(calendar.SUNDAY)
calendar.firstweekday()
現在設定されている週の最初の曜日を返します。
calendar.isleap(year)
year が閏年なら True を、そうでなければ False を返します。
calendar.leapdays(y1, y2)
範囲(y1 ... y2)指定された期間の閏年の回数を返します。ここで y1 や y2 は年を表します。
この関数は、世紀の境目をまたぐ範囲でも正しく動作します。
calendar.weekday(year, month, day)
year (1970--...), month (1--12), day (1--31) で与えられた日の曜日(0 は月曜日)を返します。
calendar.weekheader(n)
短縮された曜日名を含むヘッダを返します。n は各曜日を何文字で表すかを指定します。
calendar.monthrange(year, month)
year と month で指定された月の一日の曜日と日数を返します。
calendar.monthcalendar(year, month)
calendar.prmonth(theyear, themonth, w=0, l=0)
month() 関数によって返される月のカレンダーを出力します。
calendar.month(theyear, themonth, w=0, l=0)
TextCalendar の formatmonth() メソッドを利用して、ひと月分のカレンダーを複数行の文字列で返します。
calendar.prcal(year, w=0, l=0, c=6, m=3)
calendar() 関数で返される一年間のカレンダーを出力します。
calendar.calendar(year, w=2, l=1, c=6, m=3)
TextCalendar の formatyear() メソッドを利用して、 3列からなる一年間のカレンダーを複数行の文字列で返します。
calendar.timegm(tuple)
カレンダーと直接は関係無いが、 time モジュールの gmtime() 関数が返す形式の時刻を表すタプルを引数に取り、1970 を基点とするエポック時刻で POSIX エンコーディングであると仮定して、対応する Unix タイムスタンプの値を返します。実際には、 time.gmtime() と timegm() はお互いの逆関数です。
calendar モジュールの以下のデータ属性を利用することができます:
calendar.day_name
現在のロケールでの曜日を表す配列です。
calendar.day_abbr
現在のロケールでの短縮された曜日を表す配列です。
calendar.month_name
現在のロケールでの月の名を表す配列です。この配列は通常の約束事に従って、1月を数字の 1 で表しますので、長さが 13 ある代わりに month_name[0] が空文字列になります。
calendar.month_abbr
現在のロケールでの短縮された月の名を表す配列です。この配列は通常の約束事に従って、1月を数字の 1 で表しますので、長さが 13 ある代わりに month_abbr[0] が空文字列になります。
参考
datetime モジュール
time モジュールと似た機能を持った日付と時間用のオブジェクト指向インターフェース。
time モジュール
時間に関連した低水準の関数群。
collections --- コンテナデータ型
ソースコード: Lib/collections/__init__.py
このモジュールは、汎用の Python 組み込みコンテナ dict, list, set, および tuple に代わる、特殊なコンテナデータ型を実装しています。
namedtuple()
名前付きフィールドを持つタプルのサブクラスを作成するファクトリ関数
deque
両端における append や pop を高速に行えるリスト風のコンテナ
ChainMap
複数のマッピングの一つのビューを作成する辞書風のクラス
Counter
ハッシュ可能なオブジェクトを数え上げる辞書のサブクラス
OrderedDict
項目が追加された順序を記憶する辞書のサブクラス
defaultdict
ファクトリ関数を呼び出して存在しない値を供給する辞書のサブクラス
UserDict
辞書のサブクラス化を簡単にする辞書オブジェクトのラッパ
UserList
リストのサブクラス化を簡単にするリストオブジェクトのラッパ
UserString
文字列のサブクラス化を簡単にする文字列オブジェクトのラッパ
Deprecated since version 3.3, will be removed in version 3.10: コレクション抽象基底クラス が collections.abc モジュールに移動されました。後方互換性のため、それらは引き続きPython 3.9モジュールでも利用できます。
ChainMap オブジェクト
バージョン 3.3 で追加.
ChainMap クラスは、複数のマッピングを素早く連結し、一つの単位として扱うために提供されています。これはたいてい、新しい辞書を作成して update() を繰り返すよりも早いです。
このクラスはネストされたスコープをシミュレートするのに使え、テンプレート化に便利です。
class collections.ChainMap(*maps)
ChainMap は、複数の辞書やその他のマッピングをまとめて、一つの、更新可能なビューを作成します。 maps が指定されないなら、一つの空辞書が与えられますから、新しいチェーンは必ず一つ以上のマッピングをもちます。
根底のマッピングはリストに保存されます。このリストはパブリックで、 maps 属性を使ってアクセスや更新できます。それ以外に状態はありません。
探索は、根底のマッピングをキーが見つかるまで引き続き探します。対して、書き込み、更新、削除は、最初のマッピングのみ操作します。
ChainMap は、根底のマッピングを参照によって組み込みます。ですから、根底のマッピングの一つが更新されると、その変更は ChainMap に反映されます。
通常の辞書のメソッドすべてがサポートされています。さらに、maps 属性、新しいサブコンテキストを作成するメソッド、最初のマッピング以外のすべてにアクセスするためのプロパティがあります:
maps
マッピングのユーザがアップデートできるリストです。このリストは最初に探されるものから最後に探されるものの順に並んでいます。これが唯一のソートされた状態であり、変更してマッピングが探される順番を変更できます。このリストは常に一つ以上のマッピングを含んでいなければなりません。
new_child(m=None)
新しい辞書の後ろに現在のインスタンスにある全ての辞書が続いたものを持つ、新しい ChainMap を返します。 m が指定された場合、それがマッピングのリストの先頭の新しい辞書になります; 指定されていない場合、 d.new_child() が ChainMap({}, *d.maps) と同等となるように空の辞書が使われます。このメソッドは、親マッピングを変更することなく値を更新できるサブコンテキストを作成するのに使われます。
バージョン 3.4 で変更: オプションの m 引数が追加されました。
parents
現在のインスタンスの最初のマッピング以外のすべてのマッピングを含む新しい ChainMap を返すプロパティです。これは最初のマッピングを検索から飛ばすのに便利です。使用例は nonlocal キーワードを ネストされたスコープ に使う例と似ています。この使用例はまた、組み込み super() 関数にも似ています。 d.parents への参照は ChainMap(*d.maps[1:]) と等価です。
ChainMap() の反復順序は、マッピングオブジェクトを末尾から先頭に向かう走査で決まることに注意してください。
>>>
>>> baseline = {'music': 'bach', 'art': 'rembrandt'}
>>> adjustments = {'art': 'van gogh', 'opera': 'carmen'}
>>> list(ChainMap(adjustments, baseline))
['music', 'art', 'opera']
これは、末尾のマッピングオブジェクトから始めた一連の dict.update() の呼び出しと同じ順序になります。
>>>
>>> combined = baseline.copy()
>>> combined.update(adjustments)
>>> list(combined)
['music', 'art', 'opera']
バージョン 3.9 で変更: Added support for | and |= operators, specified in PEP 584.
参考
Enthought 社の CodeTools パッケージ に含まれる MultiContext クラス は、チェーン内のすべてのマッピングへの書き込みをサポートするオプションを持ちます。
Nested Contexts recipe は、書き込みその他の変更が最初のマッピングにのみ適用されるか、チェーンのすべてのマッピングに適用されるか、制御するオプションを持ちます。
非常に単純化した読み出し専用バージョンの Chainmap。
ChainMap の例とレシピ
この節では、チェーンされたマッピングを扱う様々な手法を示します。
Python の内部探索チェーンをシミュレートする例:
import builtins
pylookup = ChainMap(locals(), globals(), vars(builtins))
ユーザ指定のコマンドライン引数、環境変数、デフォルト値、の順に優先させる例:
import os, argparse
defaults = {'color': 'red', 'user': 'guest'}
parser = argparse.ArgumentParser()
parser.add_argument('-u', '--user')
parser.add_argument('-c', '--color')
namespace = parser.parse_args()
command_line_args = {k: v for k, v in vars(namespace).items() if v is not None}
combined = ChainMap(command_line_args, os.environ, defaults)
print(combined['color'])
print(combined['user'])
ChainMap を使ってネストされたコンテキストをシミュレートするパターンの例:
c = ChainMap()        # Create root context
d = c.new_child()     # Create nested child context
e = c.new_child()     # Child of c, independent from d
e.maps[0]             # Current context dictionary -- like Python's locals()
e.maps[-1]            # Root context -- like Python's globals()
e.parents             # Enclosing context chain -- like Python's nonlocals
d['x'] = 1            # Set value in current context
d['x']                # Get first key in the chain of contexts
del d['x']            # Delete from current context
list(d)               # All nested values
k in d                # Check all nested values
len(d)                # Number of nested values
d.items()             # All nested items
dict(d)               # Flatten into a regular dictionary
ChainMap クラスは、探索はチェーン全体に対して行いますが、更新 (書き込みと削除) は最初のマッピングに対してのみ行います。しかし、深い書き込みと削除を望むなら、チェーンの深いところで見つかったキーを更新するサブクラスを簡単に作れます:
class DeepChainMap(ChainMap):
    'Variant of ChainMap that allows direct updates to inner scopes'
    def __setitem__(self, key, value):
        for mapping in self.maps:
            if key in mapping:
                mapping[key] = value
                return
        self.maps[0][key] = value
    def __delitem__(self, key):
        for mapping in self.maps:
            if key in mapping:
                del mapping[key]
                return
        raise KeyError(key)
>>> d = DeepChainMap({'zebra': 'black'}, {'elephant': 'blue'}, {'lion': 'yellow'})
>>> d['lion'] = 'orange'         # update an existing key two levels down
>>> d['snake'] = 'red'           # new keys get added to the topmost dict
>>> del d['elephant']            # remove an existing key one level down
>>> d                            # display result
DeepChainMap({'zebra': 'black', 'snake': 'red'}, {}, {'lion': 'orange'})
Counter オブジェクト
便利で迅速な検数をサポートするカウンタツールが提供されています。例えば:
>>>
>>> # Tally occurrences of words in a list
>>> cnt = Counter()
>>> for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:
...     cnt[word] += 1
>>> cnt
Counter({'blue': 3, 'red': 2, 'green': 1})
>>> # Find the ten most common words in Hamlet
>>> import re
>>> words = re.findall(r'\w+', open('hamlet.txt').read().lower())
>>> Counter(words).most_common(10)
[('the', 1143), ('and', 966), ('to', 762), ('of', 669), ('i', 631),
 ('you', 554),  ('a', 546), ('my', 514), ('hamlet', 471), ('in', 451)]
class collections.Counter([iterable-or-mapping])
Counter はハッシュ可能なオブジェクトをカウントする dict のサブクラスです。これは、要素を辞書のキーとして保存し、そのカウントを辞書の値として保存するコレクションです。カウントは、0 や負のカウントを含む整数値をとれます。 Counter クラスは、他の言語のバッグや多重集合のようなものです。
要素は、 iterable から数え上げられたり、他の mapping (やカウンタ) から初期化されます:
>>>
c = Counter()                           # a new, empty counter
c = Counter('gallahad')                 # a new counter from an iterable
c = Counter({'red': 4, 'blue': 2})      # a new counter from a mapping
c = Counter(cats=4, dogs=8)             # a new counter from keyword args
カウンタオブジェクトは辞書のインターフェースを持ちますが、存在しない要素に対して KeyError を送出する代わりに 0 を返すという違いがあります:
>>>
c = Counter(['eggs', 'ham'])
c['bacon']                              # count of a missing element is zero
0
カウントを 0 に設定しても、要素はカウンタから取り除かれません。完全に取り除くには、 del を使ってください:
>>>
c['sausage'] = 0                        # counter entry with a zero count
del c['sausage']                        # del actually removes the entry
バージョン 3.1 で追加.
バージョン 3.7 で変更: As a dict subclass, Counter Inherited the capability to remember insertion order. Math operations on Counter objects also preserve order. Results are ordered according to when an element is first encountered in the left operand and then by the order encountered in the right operand.
カウンタオブジェクトは、すべての辞書で利用できるメソッドに加えて、次の 3 つのメソッドをサポートしています。
elements()
>>>
c = Counter(a=4, b=2, c=0, d=-2)
sorted(c.elements())
['a', 'a', 'a', 'a', 'b', 'b']
most_common([n])
Return a list of the n most common elements and their counts from the most common to the least. If n is omitted or None, most_common() returns all elements in the counter. Elements with equal counts are ordered in the order first encountered:
>>>
Counter('abracadabra').most_common(3)
[('a', 5), ('b', 2), ('r', 2)]
subtract([iterable-or-mapping])
要素から iterable の要素または mapping の要素が引かれます。 dict.update() に似ていますが、カウントを置き換えるのではなく引きます。入力も出力も、 0 や負になりえます。
>>>
c = Counter(a=4, b=2, c=0, d=-2)
d = Counter(a=1, b=2, c=3, d=4)
c.subtract(d)
c
Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})
バージョン 3.2 で追加.
普通の辞書のメソッドは、以下の 2 つのメソッドがカウンタに対して異なる振る舞いをするのを除き、 Counter オブジェクトにも利用できます。
fromkeys(iterable)
このクラスメソッドは Counter オブジェクトには実装されていません。
update([iterable-or-mapping])
要素が iterable からカウントされるか、別の mapping (やカウンタ) が追加されます。 dict.update() に似ていますが、カウントを置き換えるのではなく追加します。また、 iterable には (key, value) 対のシーケンスではなく、要素のシーケンスが求められます。
Counter オブジェクトを使ったよくあるパターン:
sum(c.values())                 # total of all counts
c.clear()                       # reset all counts
list(c)                         # list unique elements
set(c)                          # convert to a set
dict(c)                         # convert to a regular dictionary
c.items()                       # convert to a list of (elem, cnt) pairs
Counter(dict(list_of_pairs))    # convert from a list of (elem, cnt) pairs
c.most_common()[:-n-1:-1]       # n least common elements
+c                              # remove zero and negative counts
Counter オブジェクトを組み合わせて多重集合 (1 以上のカウントをもつカウンタ) を作るために、いくつかの数学演算が提供されています。足し算と引き算は、対応する要素を足したり引いたりすることによってカウンタを組み合わせます。積集合と和集合は、対応するカウントの最大値と最小値を返します。それぞれの演算はカウントに符号がついた入力を受け付けますが、カウントが 0 以下である結果は出力から除かれます。
>>>
c = Counter(a=3, b=1)
d = Counter(a=1, b=2)
c + d                       # add two counters together:  c[x] + d[x]
Counter({'a': 4, 'b': 3})
c - d                       # subtract (keeping only positive counts)
Counter({'a': 2})
c & d                       # intersection:  min(c[x], d[x]) 
Counter({'a': 1, 'b': 1})
c | d                       # union:  max(c[x], d[x])
Counter({'a': 3, 'b': 2})
単項加算および減算は、空カウンタの加算や空カウンタからの減算へのショートカットです。
>>>
c = Counter(a=2, b=-4)
+c
Counter({'a': 2})
-c
Counter({'b': 4})
バージョン 3.3 で追加: 単項加算、単項減算、in-place の多重集合操作のサポートが追加されました。
注釈 カウンタはもともと、推移するカウントを正の整数で表すために設計されました。しかし、他の型や負の値を必要とするユースケースを不必要に排除することがないように配慮されています。このようなユースケースの助けになるように、この節で最低限の範囲と型の制限について記述します。
Counter クラス自体は辞書のサブクラスで、キーと値に制限はありません。値はカウントを表す数であることを意図していますが、値フィールドに任意のものを保存 できます 。
most_common() メソッドが要求するのは、値が順序付け可能なことだけです。
c[key] += 1 のようなインプレース演算では、値の型に必要なのは 足し算と引き算ができることだけです。よって分数、浮動小数点数、 小数も使え、負の値がサポートされています。これと同じことが、 負や 0 の値を入力と出力に許す update() と subtract() メソッド にも言えます。
多重集合メソッドは正の値を扱うユースケースに対してのみ設計されています。入力は負や 0 に出来ますが、正の値の出力のみが生成されます。型の制限はありませんが、値の型は足し算、引き算、比較をサポートしている必要があります。
elements() メソッドは整数のカウントを要求します。これは 0 と負のカウントを無視します。
参考
Smalltalk の Bag class 。
Wikipedia の Multisets の項目。
C++ multisets の例を交えたチュートリアル。
数学的な多重集合の演算とそのユースケースは、 Knuth, Donald. The Art of Computer Programming Volume II, Section 4.6.3, Exercise 19 を参照してください。
与えられた要素の集まりからなる与えられた大きさの相違なる多重集合をすべて数え上げるには、 itertools.combinations_with_replacement() を参照してください:
map(Counter, combinations_with_replacement('ABC', 2)) # --> AA AB AC BB BC CC
deque オブジェクト
class collections.deque([iterable[, maxlen]])
iterable で与えられるデータから、新しい deque オブジェクトを (append() をつかって) 左から右に初期化して返します。 iterable が指定されない場合、新しい deque オブジェクトは空になります。
Deque とは、スタックとキューを一般化したものです (この名前は「デック」と発音され、これは「double-ended queue」の省略形です)。Deque はどちらの側からも append と pop が可能で、スレッドセーフでメモリ効率がよく、どちらの方向からもおよそ O(1) のパフォーマンスで実行できます。
list オブジェクトでも同様の操作を実現できますが、これは高速な固定長の操作に特化されており、内部のデータ表現形式のサイズと位置を両方変えるような pop(0) や insert(0, v) などの操作ではメモリ移動のために O(n) のコストを必要とします。
maxlen が指定されなかったり None だった場合、 deque は任意のサイズまで大きくなります。 そうでない場合、 deque のサイズは指定された最大長に制限されます。 長さが制限された deque がいっぱいになると、新しい要素を追加するときに追加した要素数分だけ追加したのと反対側から要素が捨てられます。 長さが制限された deque は Unix における tail フィルタと似た機能を提供します。 トランザクションの tracking や最近使った要素だけを残したいデータプール (pool of data) などにも便利です。
Deque オブジェクトは以下のようなメソッドをサポートしています:
append(x)
x を deque の右側につけ加えます。
appendleft(x)
x を deque の左側につけ加えます。
clear()
deque からすべての要素を削除し、長さを 0 にします。
copy()
deque の浅いコピーを作成します。
バージョン 3.5 で追加.
count(x)
deque の x に等しい要素を数え上げます。
バージョン 3.2 で追加.
extend(iterable)
イテラブルな引数 iterable から得られる要素を deque の右側に追加し拡張します。
extendleft(iterable)
イテラブルな引数 iterable から得られる要素を deque の左側に追加し拡張します。注意: 左から追加した結果は、イテラブルな引数の順序とは逆になります。
index(x[, start[, stop]])
deque 内の x の位置を返します (インデックス start からインデックス stop の両端を含む範囲で)。最初のマッチを返すか、見つからない場合には ValueError を発生させます。
バージョン 3.5 で追加.
insert(i, x)
x を deque の位置 i に挿入します。
挿入によって、長さに制限のある deque の長さが maxlen を超える場合、IndexError が発生します。
バージョン 3.5 で追加.
pop()
deque の右側から要素をひとつ削除し、その要素を返します。要素がひとつも存在しない場合は IndexError を発生させます。
popleft()
deque の左側から要素をひとつ削除し、その要素を返します。要素がひとつも存在しない場合は IndexError を発生させます。
remove(value)
value の最初に現れるものを削除します。要素が見付からないない場合は ValueError を送出します。
reverse()
deque の要素をインプレースに反転し、None を返します。
バージョン 3.2 で追加.
rotate(n=1)
deque の要素を全体で n ステップだけ右にローテートします。n が負の値の場合は、左にローテートします。
deque が空でないときは、 deque をひとつ右にローテートすることは d.appendleft(d.pop()) と同じで、 deque をひとつ左にローテートすることは d.append(d.popleft()) と同じです。
deque オブジェクトは読み出し専用属性も 1 つ提供しています:
maxlen
deque の最大長で、制限されていなければ None です。
バージョン 3.1 で追加.
バージョン 3.5 から deque は __add__(), __mul__(), __imul__() をサポートしました。
例:
>>> from collections import deque
>>> d = deque('ghi')                 # make a new deque with three items
>>> for elem in d:                   # iterate over the deque's elements
...     print(elem.upper())
G
H
I
>>> d.append('j')                    # add a new entry to the right side
>>> d.appendleft('f')                # add a new entry to the left side
>>> d                                # show the representation of the deque
deque(['f', 'g', 'h', 'i', 'j'])
>>> d.pop()                          # return and remove the rightmost item
'j'
>>> d.popleft()                      # return and remove the leftmost item
'f'
>>> list(d)                          # list the contents of the deque
['g', 'h', 'i']
>>> d[0]                             # peek at leftmost item
'g'
>>> d[-1]                            # peek at rightmost item
'i'
>>> list(reversed(d))                # list the contents of a deque in reverse
['i', 'h', 'g']
>>> 'h' in d                         # search the deque
True
>>> d.extend('jkl')                  # add multiple elements at once
>>> d
deque(['g', 'h', 'i', 'j', 'k', 'l'])
>>> d.rotate(1)                      # right rotation
>>> d
deque(['l', 'g', 'h', 'i', 'j', 'k'])
>>> d.rotate(-1)                     # left rotation
>>> d
deque(['g', 'h', 'i', 'j', 'k', 'l'])
>>> deque(reversed(d))               # make a new deque in reverse order
deque(['l', 'k', 'j', 'i', 'h', 'g'])
>>> d.clear()                        # empty the deque
>>> d.pop()                          # cannot pop from an empty deque
Traceback (most recent call last):
    File "<pyshell#6>", line 1, in -toplevel-
        d.pop()
IndexError: pop from an empty deque
>>> d.extendleft('abc')              # extendleft() reverses the input order
>>> d
deque(['c', 'b', 'a'])
deque のレシピ
この節では deque を使った様々なアプローチを紹介します。
長さが制限された deque は Unix における tail フィルタに相当する機能を提供します:
def tail(filename, n=10):
    'Return the last n lines of a file'
    with open(filename) as f:
        return deque(f, n)
deque を使用する別のアプローチは、右に要素を追加し左から要素を取り出すことで最近追加した要素のシーケンスを保持することです:
def moving_average(iterable, n=3):
    # moving_average([40, 30, 50, 46, 39, 44]) --> 40.0 42.0 45.0 43.0
    # http://en.wikipedia.org/wiki/Moving_average
    it = iter(iterable)
    d = deque(itertools.islice(it, n-1))
    d.appendleft(0)
    s = sum(d)
    for elem in it:
        s += elem - d.popleft()
        d.append(elem)
        yield s / n
ラウンドロビンスケジューラ は、入力されたイテレータを deque に格納することで実装できます。 値は、位置0にある選択中のイテレータから取り出されます。 そのイテレータが値を出し切った場合は、 popleft() で除去できます; そうでない場合は、 rotate() メソッドで末尾に回せます:
def roundrobin(*iterables):
    "roundrobin('ABC', 'D', 'EF') --> A D E B F C"
    iterators = deque(map(iter, iterables))
    while iterators:
        try:
            while True:
                yield next(iterators[0])
                iterators.rotate(-1)
        except StopIteration:
            # Remove an exhausted iterator.
            iterators.popleft()
rotate() メソッドは、 deque のスライスや削除の機能を提供します。 例えば、 純粋な Python 実装の del d[n] は rotate() メソッドを頼りに、pop される要素の位置を割り出します:
def delete_nth(d, n):
    d.rotate(-n)
    d.popleft()
    d.rotate(n)
deque のスライスの実装でも、同様のアプローチを使います。まず対象となる要素を rotate() によって deque の左端まで移動させてから、 popleft() で古い要素を削除します。そして、 extend() で新しい要素を追加したのち、循環を逆にします。このアプローチをやや変えたものとして、Forth スタイルのスタック操作、つまり dup, drop, swap, over, pick, rot, および roll を実装するのも簡単です。
defaultdict オブジェクト
class collections.defaultdict([default_factory[, ...]])
新しいディクショナリ様のオブジェクトを返します。 defaultdict は組み込みの dict のサブクラスです。メソッドをオーバーライドし、書き込み可能なインスタンス変数を1つ追加している以外は dict クラスと同じです。同じ部分については以下では省略されています。
1つ目の引数は default_factory 属性の初期値です。デフォルトは None です。残りの引数はキーワード引数も含め、 dict のコンストラクタに与えられた場合と同様に扱われます。
defaultdict オブジェクトは標準の dict に加えて、以下のメソッドを実装しています:
__missing__(key)
もし default_factory 属性が None であれば、このメソッドは KeyError 例外を、 key を引数として発生させます。
もし default_factory 属性が None でない場合、このメソッドは引数なしで呼び出され、与えらえた key に対応するデフォルト値を提供します。この値は、辞書内に key に対応して登録され、最後に返されます。
もし default_factory の呼出が例外を発生させた場合には、変更せずそのまま例外を投げます。
このメソッドは dict クラスの __getitem__() メソッドで、キーが存在しなかった場合によびだされます。値を返すか例外を発生させるのどちらにしても、 __getitem__() からもそのまま値が返るか例外が発生します。
なお、 __missing__() は __getitem__() 以外のいかなる演算に対しても呼び出され ません 。よって get() は、普通の辞書と同様に、 default_factory を使うのではなくデフォルトとして None を返します。
defaultdict オブジェクトは以下のインスタンス変数をサポートしています:
default_factory
この属性は __missing__() メソッドによって使われます。これは存在すればコンストラクタの第1引数によって初期化され、そうでなければ None になります。
バージョン 3.9 で変更: Added merge (|) and update (|=) operators, specified in PEP 584.
defaultdict の使用例
list を default_factory とすることで、キー=値ペアのシーケンスをリストの辞書へ簡単にグループ化できます。:
>>>
s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]
d = defaultdict(list)
for k, v in s:
    d[k].append(v)
sorted(d.items())
[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]
それぞれのキーが最初に登場したとき、マッピングにはまだ存在しません。そのためエントリは default_factory 関数が返す空の list を使って自動的に作成されます。 list.append() 操作は新しいリストに紐付けられます。キーが再度出現した場合には、通常の参照動作が行われます(そのキーに対応するリストが返ります)。そして list.append() 操作で別の値をリストに追加します。このテクニックは dict.setdefault() を使った等価なものよりシンプルで速いです:
>>>
d = {}
for k, v in s:
    d.setdefault(k, []).append(v)
sorted(d.items())
[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]
default_factory を int にすると、 defaultdict を(他の言語の bag や multisetのように)要素の数え上げに便利に使うことができます:
>>>
s = 'mississippi'
d = defaultdict(int)
for k in s:
    d[k] += 1
sorted(d.items())
[('i', 4), ('m', 1), ('p', 2), ('s', 4)]
最初に文字が出現したときは、マッピングが存在しないので default_factory 関数が int() を呼んでデフォルトのカウント0を生成します。インクリメント操作が各文字を数え上げます。
常に0を返す int() は特殊な関数でした。定数を生成するより速くて柔軟な方法は、 0に限らず何でも定数を生成するラムダ関数を使うことです:
>>>
def constant_factory(value):
    return lambda: value
d = defaultdict(constant_factory('<missing>'))
d.update(name='John', action='ran')
'%(name)s %(action)s to %(object)s' % d
'John ran to <missing>'
default_factory を set に設定することで、 defaultdict をセットの辞書を作るために利用することができます:
>>>
s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)]
d = defaultdict(set)
for k, v in s:
    d[k].add(v)
sorted(d.items())
[('blue', {2, 4}), ('red', {1, 3})]
namedtuple() 名前付きフィールドを持つタプルのファクトリ関数
名前付きタプルは、タプルの中のすべての場所に意味を割り当てて、より読みやすく自己解説的なコードを書けるようにします。通常のタプルが利用される場所ならどこでも利用でき、場所に対するインデックスの代わりに名前を使ってフィールドにアクセスできるようになります。
collections.namedtuple(typename, field_names, *, rename=False, defaults=None, module=None)
typename という名前の tuple の新しいサブクラスを返します。新しいサブクラスは、 tuple に似ているけれどもインデックスやイテレータだけでなく属性名によるアクセスもできるオブジェクトを作るのに使います。このサブクラスのインスタンスは、わかりやすい docstring (型名と属性名が入っています) や、 tuple の内容を name=value という形のリストで返す使いやすい __repr__() も持っています。
field_names は ['x', 'y'] のような文字列のシーケンスです。 field_names には、代わりに各属性名を空白文字 (whitespace) および/またはカンマ (,) で区切った文字列を渡すこともできます。例えば、 'x y' や 'x, y' です。
アンダースコア (_) で始まる名前を除いて、 Python の正しい識別子 (identifier) ならなんでも属性名として使うことができます。正しい識別子とはアルファベット(letters), 数字(digits), アンダースコア(_) を含みますが、数字やアンダースコアで始まる名前や、 class, for, return, global, pass, raise などといった keyword は使えません。
rename が真の場合、不適切なフィールド名は自動的に位置を示す名前に置き換えられます。例えば ['abc', 'def', 'ghi', 'abc'] は、予約語の def と、重複しているフィールド名の abc が除去され、['abc', '_1', 'ghi', '_3'] に変換されます。
defaults には None あるいはデフォルト値の iterable が指定できます。 デフォルト値を持つフィールドはデフォルト値を持たないフィールドより後ろに来なければならないので、 defaults は最も右にある変数に適用されます。 例えば、 field_names が ['x', 'y', 'z'] で defaults が (1, 2) の場合、 x は必須の引数、 y は 1 がデフォルト、 z は 2 がデフォルトとなります。
もし module が指定されていれば、名前付きタプルの __module__ 属性は、指定された値に設定されます
名前付きタプルのインスタンスはインスタンスごとの辞書を持たないので、軽量で、普通のタプル以上のメモリを使用しません。
バージョン 3.1 で変更: rename のサポートが追加されました。
バージョン 3.6 で変更: verbose と rename 引数が キーワード専用引数 になりました.
バージョン 3.6 で変更: module 引数が追加されました。
バージョン 3.7 で変更: Removed the verbose parameter and the _source attribute.
バージョン 3.7 で変更: defaults 引数と _field_defaults 属性が追加されました。
>>> # Basic example
>>> Point = namedtuple('Point', ['x', 'y'])
>>> p = Point(11, y=22)     # instantiate with positional or keyword arguments
>>> p[0] + p[1]             # indexable like the plain tuple (11, 22)
33
>>> x, y = p                # unpack like a regular tuple
>>> x, y
(11, 22)
>>> p.x + p.y               # fields also accessible by name
33
>>> p                       # readable __repr__ with a name=value style
Point(x=11, y=22)
名前付きタプルは csv や sqlite3 モジュールが返すタプルのフィールドに名前を付けるときにとても便利です:
EmployeeRecord = namedtuple('EmployeeRecord', 'name, age, title, department, paygrade')
import csv
for emp in map(EmployeeRecord._make, csv.reader(open("employees.csv", "rb"))):
    print(emp.name, emp.title)
import sqlite3
conn = sqlite3.connect('/companydata')
cursor = conn.cursor()
cursor.execute('SELECT name, age, title, department, paygrade FROM employees')
for emp in map(EmployeeRecord._make, cursor.fetchall()):
    print(emp.name, emp.title)
タプルから継承したメソッドに加えて、名前付きタプルは3つの追加メソッドと2つの属性をサポートしています。フィールド名との衝突を避けるために、メソッド名と属性名はアンダースコアで始まります。
classmethod somenamedtuple._make(iterable)
既存の sequence や Iterable から新しいインスタンスを作るクラスメソッド.
>>> t = [11, 22]
>>> Point._make(t)
Point(x=11, y=22)
somenamedtuple._asdict()
フィールド名を対応する値にマッピングする新しい dict を返します:
>>> p = Point(x=11, y=22)
>>> p._asdict()
{'x': 11, 'y': 22}
バージョン 3.1 で変更: 通常の dict の代わりに OrderedDict を返すようになりました。
バージョン 3.8 で変更: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts are guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation is to cast the result to the desired type: OrderedDict(nt._asdict()).
somenamedtuple._replace(**kwargs)
指定されたフィールドを新しい値で置き換えた、新しい名前付きタプルを作って返します:
>>>
>>> p = Point(x=11, y=22)
>>> p._replace(x=33)
Point(x=33, y=22)
>>> for partnum, record in inventory.items():
...     inventory[partnum] = record._replace(price=newprices[partnum], timestamp=time.now())
somenamedtuple._fields
フィールド名をリストにしたタプルです。内省 (introspection) したり、既存の名前付きタプルをもとに新しい名前つきタプルを作成する時に便利です。
>>> p._fields            # view the field names
('x', 'y')
>>> Color = namedtuple('Color', 'red green blue')
>>> Pixel = namedtuple('Pixel', Point._fields + Color._fields)
>>> Pixel(11, 22, 128, 255, 0)
Pixel(x=11, y=22, red=128, green=255, blue=0)
somenamedtuple._field_defaults
フィールド名からデフォルト値への対応を持つ辞書です。
>>> Account = namedtuple('Account', ['type', 'balance'], defaults=[0])
>>> Account._field_defaults
{'balance': 0}
>>> Account('premium')
Account(type='premium', balance=0)
文字列に格納された名前を使って名前つきタプルから値を取得するには getattr() 関数を使います:
>>>
getattr(p, 'x')
11
辞書を名前付きタプルに変換するには、 ** 演算子 (double-star-operator, 引数リストのアンパック で説明しています) を使います。:
>>>
d = {'x': 11, 'y': 22}
Point(**d)
Point(x=11, y=22)
名前付きタプルは通常の Python クラスなので、継承して機能を追加したり変更するのは容易です。次の例では計算済みフィールドと固定幅の print format を追加しています:
>>> class Point(namedtuple('Point', ['x', 'y'])):
...     __slots__ = ()
...     @property
...     def hypot(self):
...         return (self.x ** 2 + self.y ** 2) ** 0.5
...     def __str__(self):
...         return 'Point: x=%6.3f  y=%6.3f  hypot=%6.3f' % (self.x, self.y, self.hypot)
>>> for p in Point(3, 4), Point(14, 5/7):
...     print(p)
Point: x= 3.000  y= 4.000  hypot= 5.000
Point: x=14.000  y= 0.714  hypot=14.018
このサブクラスは __slots__ に空のタプルをセットしています。これにより、インスタンス辞書の作成を抑制してメモリ使用量を低く保つのに役立ちます。
サブクラス化は新しいフィールドを追加するのには適していません。代わりに、新しい名前付きタプルを _fields 属性を元に作成してください:
>>>
Point3D = namedtuple('Point3D', Point._fields + ('z',))
__doc__ フィールドに直接代入することでドックストリングをカスタマイズすることが出来ます:
>>>
Book = namedtuple('Book', ['id', 'title', 'authors'])
Book.__doc__ += ': Hardcover book in active collection'
Book.id.__doc__ = '13-digit ISBN'
Book.title.__doc__ = 'Title of first printing'
Book.authors.__doc__ = 'List of authors sorted by last name'
バージョン 3.5 で変更: 属性ドックストリングが書き込み可能になりました。
参考
名前付きタプルに型ヒントを追加する方法については、 typing.NamedTuple を参照してください。 class キーワードを使った洗練された記法も紹介されています:
class Component(NamedTuple):
    part_number: int
    weight: float
    description: Optional[str] = None
タプルではなく、辞書をもとにした変更可能な名前空間を作成するには types.SimpleNamespace() を参照してください。
dataclasses モジュールは、生成される特殊メソッドをユーザー定義クラスに自動的に追加するためのデコレータや関数を提供しています。
OrderedDict オブジェクト
順序付き辞書は普通の辞書のようですが、順序操作に関係する追加の機能があります。 組み込みの dict クラスが挿入順序を記憶しておく機能 (この新しい振る舞いは Python 3.7 で保証されるようになりました) を獲得した今となっては、順序付き辞書の重要性は薄れました。
いまだ残っている dict との差分:
通常の dict は対応付けに向いているように設計されました。 挿入順序の追跡は二の次です。
OrderedDict は並べ替え操作に向いているように設計されました。 空間効率、反復処理の速度、更新操作のパフォーマンスは二の次です。
アルゴリズム的に、 OrderedDict は高頻度の並べ替え操作を dict よりも上手く扱えます。 この性質により、 OrderedDict は直近のアクセスの追跡 (例えば、 LRU キャッシュ) に向いています。
OrderedDict に対する等価演算は突き合わせ順序もチェックします。
OrderedDict の popitem() メソッドはシグネチャが異なります。 どの要素を取り出すかを指定するオプション引数を受け付けます。
OrderedDict には、 効率的に要素を末尾に置き直す move_to_end() メソッドがあります。
Python 3.8 以前は、 dict には __reversed__() メソッドが欠けています。
class collections.OrderedDict([items])
辞書の順序を並べ直すためのメソッドを持つ dict のサブクラスのインスタンスを返します。
バージョン 3.1 で追加.
popitem(last=True)
順序付き辞書の popitem() メソッドは、(key, value) 対を返して消去します。この対は last が真なら LIFO で、偽なら FIFO で返されます。
move_to_end(key, last=True)
既存の key を順序付き辞書の両端に移動します。項目は、 last が真 (デフォルト) なら右端に、 last が偽なら最初に移動されます。 key が存在しなければ KeyError を送出します:
>>>
>>> d = OrderedDict.fromkeys('abcde')
>>> d.move_to_end('b')
>>> ''.join(d.keys())
'acdeb'
>>> d.move_to_end('b', last=False)
>>> ''.join(d.keys())
'bacde'
バージョン 3.2 で追加.
通常のマッピングのメソッドに加え、順序付き辞書は reversed() による逆順の反復もサポートしています。
OrderedDict 間の等価判定は順序が影響し、 list(od1.items())==list(od2.items()) のように実装されます。 OrderedDict オブジェクトと他のマッピング (Mapping) オブジェクトの等価判定は、順序に影響されず、通常の辞書と同様です。これによって、 OrderedDict オブジェクトは通常の辞書が使われるところならどこでも使用できます。
バージョン 3.5 で変更: OrderedDict の項目、キー、値の ビュー が reversed() による逆順の反復をサポートするようになりました。
バージョン 3.6 で変更: PEP 468 の受理によって、OrderedDict のコンストラクタと、update() メソッドに渡したキーワード引数の順序は保持されます。
バージョン 3.9 で変更: Added merge (|) and update (|=) operators, specified in PEP 584.
OrderedDict の例とレシピ
キーが 最後に 追加されたときの順序を記憶する、順序付き辞書の変種を作るのは簡単です。 新しい値が既存の値を上書きする場合、元々の挿入位置が最後尾へ変更されます:
class LastUpdatedOrderedDict(OrderedDict):
    'Store items in the order the keys were last added'
    def __setitem__(self, key, value):
        super().__setitem__(key, value)
        self.move_to_end(key)
OrderedDict は functools.lru_cache() の変種を実装するのにも役に立ちます:
class LRU(OrderedDict):
    'Limit size, evicting the least recently looked-up key when full'
    def __init__(self, maxsize=128, /, *args, **kwds):
        self.maxsize = maxsize
        super().__init__(*args, **kwds)
    def __getitem__(self, key):
        value = super().__getitem__(key)
        self.move_to_end(key)
        return value
    def __setitem__(self, key, value):
        if key in self:
            self.move_to_end(key)
        super().__setitem__(key, value)
        if len(self) > self.maxsize:
            oldest = next(iter(self))
            del self[oldest]
UserDict オブジェクト
クラス UserDict は、辞書オブジェクトのラッパとしてはたらきます。このクラスの必要性は、 dict から直接的にサブクラス化できる能力に部分的に取って代わられました; しかし、根底の辞書に属性としてアクセスできるので、このクラスを使った方が簡単になることもあります。
class collections.UserDict([initialdata])
辞書をシミュレートするクラスです。インスタンスの内容は通常の辞書に保存され、 UserDict インスタンスの data 属性を通してアクセスできます。 initialdata が与えられれば、 data はその内容で初期化されます。他の目的のために使えるように、 initialdata への参照が保存されないことがあるということに注意してください。
マッピングのメソッドと演算をサポートするのに加え、 UserDict インスタンスは以下の属性を提供します:
data
UserDict クラスの内容を保存するために使われる実際の辞書です。
UserList オブジェクト
このクラスはリストオブジェクトのラッパとしてはたらきます。これは独自のリスト風クラスの基底クラスとして便利で、既存のメソッドをオーバーライドしたり新しいメソッドを加えたりできます。こうして、リストに新しい振る舞いを加えられます。
このクラスの必要性は、 list から直接的にサブクラス化できる能力に部分的に取って代わられました; しかし、根底のリストに属性としてアクセスできるので、このクラスを使った方が簡単になることもあります。
class collections.UserList([list])
リストをシミュレートするクラスです。インスタンスの内容は通常のリストに保存され、 UserList インスタンスの data 属性を通してアクセスできます。インスタンスの内容は最初に list のコピーに設定されますが、デフォルトでは空リスト [] です。 list は何らかのイテラブル、例えば通常の Python リストや UserList オブジェクト、です。
ミュータブルシーケンスのメソッドと演算をサポートするのに加え、 UserList インスタンスは以下の属性を提供します:
data
UserList クラスの内容を保存するために使われる実際の list オブジェクトです。
サブクラス化の要件: UserList のサブクラスは引数なしか、あるいは一つの引数のどちらかとともに呼び出せるコンストラクタを提供することが期待されています。新しいシーケンスを返すリスト演算は現在の実装クラスのインスタンスを作成しようとします。そのために、データ元として使われるシーケンスオブジェクトである一つのパラメータとともにコンストラクタを呼び出せると想定しています。
派生クラスがこの要求に従いたくないならば、このクラスがサポートしているすべての特殊メソッドはオーバーライドされる必要があります。その場合に提供される必要のあるメソッドについての情報は、ソースを参考にしてください。
UserString オブジェクト
クラス UserString は、文字列オブジェクトのラッパとしてはたらきます。このクラスの必要性は、 str から直接的にサブクラス化できる能力に部分的に取って代わられました; しかし、根底の文字列に属性としてアクセスできるので、このクラスを使った方が簡単になることもあります。
class collections.UserString(seq)
文字列オブジェクトをシミュレートするクラスです。 インスタンスの内容は通常の文字列に保存され、 UserString インスタンスの data 属性を通してアクセスできます。 インスタンスの内容には最初に seq のコピーが設定されます。 seq 引数は、組み込みの str() 関数で文字列に変換できる任意のオブジェクトです。
文字列のメソッドと演算をサポートするのに加え、 UserString インスタンスは次の属性を提供します:
data
UserString クラスの内容を保存するために使われる実際の str オブジェクトです。
バージョン 3.5 で変更: 新たなメソッド __getnewargs__, __rmod__, casefold, format_map, isprintable, maketrans。
collections.abc --- コレクションの抽象基底クラス
バージョン 3.3 で追加: 以前はこのモジュールは collections モジュールの一部でした。
ソースコード: Lib/_collections_abc.py
このモジュールは、 抽象基底クラス を提供します。抽象基底クラスは、クラスが特定のインターフェースを提供しているか、例えばハッシュ可能であるかやマッピングであるかを判定します。
コレクション抽象基底クラス
collections モジュールは以下の ABC (抽象基底クラス) を提供します:
ABC
継承しているクラス
抽象メソッド
mixin メソッド
Container
__contains__
Hashable
__hash__
Iterable
__iter__
Iterator
Iterable
__next__
__iter__
Reversible
Iterable
__reversed__
Generator
Iterator
send, throw
close, __iter__, __next__
Sized
__len__
Callable
__call__
Collection
Sized, Iterable, Container
__contains__, __iter__, __len__
Sequence
Reversible, Collection
__getitem__, __len__
__contains__, __iter__, __reversed__, index, count
MutableSequence
Sequence
__getitem__, __setitem__, __delitem__, __len__, insert
Sequence から継承したメソッドと、 append, reverse, extend, pop, remove, __iadd__
ByteString
Sequence
__getitem__, __len__
Sequence から継承したメソッド
Set
Collection
__contains__, __iter__, __len__
__le__, __lt__, __eq__, __ne__, __gt__, __ge__, __and__, __or__, __sub__, __xor__, isdisjoint
MutableSet
Set
__contains__, __iter__, __len__, add, discard
Set から継承したメソッドと、 clear, pop, remove, __ior__, __iand__, __ixor__, __isub__
Mapping
Collection
__getitem__, __iter__, __len__
__contains__, keys, items, values, get, __eq__, __ne__
MutableMapping
Mapping
__getitem__, __setitem__, __delitem__, __iter__, __len__
Mapping から継承したメソッドと、 pop, popitem, clear, update, setdefault
MappingView
Sized
__len__
ItemsView
MappingView, Set
__contains__, __iter__
KeysView
MappingView, Set
__contains__, __iter__
ValuesView
MappingView, Collection
__contains__, __iter__
Awaitable
__await__
Coroutine
Awaitable
send, throw
close
AsyncIterable
__aiter__
AsyncIterator
AsyncIterable
__anext__
__aiter__
AsyncGenerator
AsyncIterator
asend, athrow
aclose, __aiter__, __anext__
class collections.abc.Container
class collections.abc.Hashable
class collections.abc.Sized
class collections.abc.Callable
class collections.abc.Iterable
__iter__() メソッドを提供するクラスの ABC です。
メソッド isinstance(obj, Iterable) で使用すると、 Iterable や __iter__() メソッドを持っているクラスを検出できます。しかし、__getitem__() メソッドで反復するクラスは検出しません。 オブジェクトが iterable であるかどうかを判別するにあたって、信頼できる唯一の方法は iter(obj) を呼び出す方法です。
class collections.abc.Collection
サイズ付きのイテラブルなコンテナクラスの ABC です。
バージョン 3.6 で追加.
class collections.abc.Iterator
__iter__() メソッドと __next__() メソッドを提供するクラスの ABC です。 iterator の定義も参照してください。
class collections.abc.Reversible
__reversed__() メソッドを提供するイテラブルクラスの ABC です。
バージョン 3.6 で追加.
class collections.abc.Generator
PEP 342 で定義された、イテレータを send(), throw(), close() の各メソッドに拡張するプロトコルを実装する、ジェネレータクラスの ABC です。generator の定義も参照してください。
バージョン 3.5 で追加.
class collections.abc.Sequence
class collections.abc.MutableSequence
class collections.abc.ByteString
読み出し専用の シーケンス およびミュータブルな シーケンス の ABC です。
実装における注意: __iter__(), __reversed__(), index() など、一部の mixin メソッドは、下層の __getitem__() メソッドを繰り返し呼び出します。その結果、__getitem__() が定数のアクセス速度で実装されている場合、mixin メソッドは線形のパフォーマンスとなります。下層のメソッドが線形 (リンクされたリストの場合など) の場合、mixin は 2 乗のパフォーマンスとなるため、多くの場合上書きする必要があるでしょう。
バージョン 3.5 で変更: index() メソッドは stop と start 引数をサポートしました。
class collections.abc.Set
class collections.abc.MutableSet
読み出し専用の集合およびミュータブルな集合の ABC です。
class collections.abc.Mapping
class collections.abc.MutableMapping
読み出し専用の マッピング およびミュータブルな マッピング の ABC です。
class collections.abc.MappingView
class collections.abc.ItemsView
class collections.abc.KeysView
class collections.abc.ValuesView
マッピング、要素、キー、値の ビュー の ABC です。
class collections.abc.Awaitable
await で使用できる awaitable オブジェクトの ABC です。カスタムの実装は、__await__() メソッドを提供しなければなりません。
注釈 CPython では、ジェネレータベースのコルーチン (types.coroutine() または asyncio.coroutine() でデコレートされたジェネレータ) は、 __await__() メソッドを持ちませんが、待機可能 (awaitables) です。これらに対して isinstance(gencoro, Awaitable) を使用すると、 False が返されます。これらを検出するには、 inspect.isawaitable() を使用します。
バージョン 3.5 で追加.
class collections.abc.Coroutine
コルーチンと互換性のあるクラスの ABC です。これらは、コルーチンオブジェクト で定義された send(), throw(), close() のメソッドを実装します。カスタムの実装は、__await__() も実装しなければなりません。Coroutine のすべてのインスタンスは、 Awaitable のインスタンスでもあります。coroutine の定義も参照してください。
注釈 CPython では、ジェネレータベースのコルーチン (types.coroutine() または asyncio.coroutine() でデコレートされたジェネレータ) は、 __await__() メソッドを持ちませんが、待機可能 (awaitables) です。これらに対して isinstance(gencoro, Coroutine) を使用すると、 False が返されます。これらを検出するには、 inspect.isawaitable() を使用します。
バージョン 3.5 で追加.
class collections.abc.AsyncIterable
__aiter__ メソッドを提供するクラスの ABC です。asynchronous iterable の定義も参照してください。
バージョン 3.5 で追加.
class collections.abc.AsyncIterator
__aiter__ および __anext__ メソッドを提供するクラスの ABC です。asynchronous iterator の定義も参照してください。
バージョン 3.5 で追加.
class collections.abc.AsyncGenerator
PEP 525 と PEP 492 に定義されているプロトコルを実装した非同期ジェネレータクラスの ABC です。
バージョン 3.6 で追加.
これらの ABC はクラスやインスタンスが特定の機能を提供しているかどうかを調べるのに使えます。例えば:
size = None
if isinstance(myvar, collections.abc.Sized):
    size = len(myvar)
幾つかの ABC はコンテナ型 API を提供するクラスを開発するのを助ける mixin 型としても使えます。例えば、 Set API を提供するクラスを作る場合、3つの基本になる抽象メソッド __contains__(), __iter__(), __len__() だけが必要です。ABC が残りの __and__() や isdisjoint() といったメソッドを提供します:
class ListBasedSet(collections.abc.Set):
    ''' Alternate set implementation favoring space over speed
        and not requiring the set elements to be hashable. '''
    def __init__(self, iterable):
        self.elements = lst = []
        for value in iterable:
            if value not in lst:
                lst.append(value)
    def __iter__(self):
        return iter(self.elements)
    def __contains__(self, value):
        return value in self.elements
    def __len__(self):
        return len(self.elements)
s1 = ListBasedSet('abcdef')
s2 = ListBasedSet('defghi')
overlap = s1 & s2            # The __and__() method is supported automatically
Set と MutableSet を mixin 型として利用するときの注意点:
(たぶん意味はそのままに速度を向上する目的で)比較をオーバーライドする場合、 __le__() と __ge__() だけを再定義すれば、その他の演算は自動的に追随します。
Set mixin型は set のハッシュ値を計算する _hash() メソッドを提供しますが、すべての set が hashable や immutable とは限らないので、 __hash__() は提供しません。 mixin を使ってハッシュ可能な set を作る場合は、 Set と Hashable の両方を継承して、 __hash__ = Set._hash と定義してください。
heapq --- ヒープキューアルゴリズム
ソースコード: Lib/heapq.py
このモジュールではヒープキューアルゴリズムの一実装を提供しています。優先度キューアルゴリズムとしても知られています。
ヒープとは、全ての親ノードの値が、その全ての子の値以下であるようなバイナリツリーです。この実装は、全ての k に対して、ゼロから要素を数えていった際に、heap[k] <= heap[2*k+1] かつ heap[k] <= heap[2*k+2] となる配列を使っています。比較のために、存在しない要素は無限大として扱われます。ヒープの興味深い性質は、最小の要素が常にルート、つまり heap[0] になることです。
以下の API は教科書におけるヒープアルゴリズムとは 2 つの側面で異なっています: (a) ゼロベースのインデクス化を行っています。これにより、ノードに対するインデクスとその子ノードのインデクスの関係がやや明瞭でなくなりますが、Python はゼロベースのインデクス化を使っているのでよりしっくりきます。(b) われわれの pop メソッドは最大の要素ではなく最小の要素 (教科書では "min heap:最小ヒープ" と呼ばれています; 教科書では並べ替えをインプレースで行うのに適した "max heap:最大ヒープ" が一般的です)。
これらの 2 点によって、ユーザに戸惑いを与えることなく、ヒープを通常の Python リストとして見ることができます: heap[0] が最小の要素となり、heap.sort() はヒープ不変式を保ちます!
ヒープを作成するには、 [] に初期化されたリストを使うか、 heapify() を用いて要素の入ったリストを変換します。
次の関数が用意されています:
heapq.heappush(heap, item)
item を heap に push します。ヒープ不変式を保ちます。
heapq.heappop(heap)
pop を行い、 heap から最小の要素を返します。ヒープ不変式は保たれます。ヒープが空の場合、 IndexError が送出されます。pop せずに最小の要素にアクセスするには、 heap[0] を使ってください。
heapq.heappushpop(heap, item)
item を heap に push した後、pop を行って heap から最初の要素を返します。この一続きの動作を heappush() に引き続いて heappop() を別々に呼び出すよりも効率的に実行します。
heapq.heapify(x)
リスト x をインプレース処理し、線形時間でヒープに変換します。
heapq.heapreplace(heap, item)
heap から最小の要素を pop して返し、新たに item を push します。ヒープのサイズは変更されません。ヒープが空の場合、 IndexError が送出されます。
この一息の演算は heappop() に次いで heappush() を送出するよりも効率的で、固定サイズのヒープを用いている場合にはより適しています。 pop/push の組み合わせは必ずヒープから要素を一つ返し、それを item と置き換えます。
返される値は加えられた item よりも大きくなるかもしれません。それを望まないなら、代わりに heappushpop() を使うことを考えてください。この push/pop の組み合わせは二つの値の小さい方を返し、大きい方の値をヒープに残します。
このモジュールではさらに3つのヒープに基く汎用関数を提供します。
heapq.merge(*iterables, key=None, reverse=False)
複数のソートされた入力をマージ(merge)して一つのソートされた出力にします (たとえば、複数のログファイルの時刻の入ったエントリーをマージします)。ソートされた値にわたる iterator を返します。
sorted(itertools.chain(*iterables)) と似ていますが、イテレータを返し、一度にはデータをメモリに読み込まず、それぞれの入力ストリームが予め(最小から最大へ)ソートされていることを仮定します。
2 つのオプション引数があり、これらはキーワード引数として指定されなければなりません。
key は 1 つの引数からなる key function を指定します。この関数は、入力の各要素から比較のキーを取り出すのに使われます。デフォルト値は None です (要素を直接比較します)。
reverse is a boolean value. If set to True, then the input elements are merged as if each comparison were reversed. To achieve behavior similar to sorted(itertools.chain(*iterables), reverse=True), all iterables must be sorted from largest to smallest.
バージョン 3.5 で変更: オプションの key 引数および reverse 引数を追加.
heapq.nlargest(n, iterable, key=None)
heapq.nsmallest(n, iterable, key=None)
後ろ二つの関数は n の値が小さな場合に最適な動作をします。大きな値の時には sorted() 関数の方が効率的です。さらに、 n==1 の時には min() および max() 関数の方が効率的です。この関数を繰り返し使うことが必要なら、iterable を実際のヒープに変えることを考えてください。
基本的な例
すべての値をヒープに push してから最小値を 1 つずつ pop することで、ヒープソート を実装できます:
>>>
>>> def heapsort(iterable):
...     h = []
...     for value in iterable:
...         heappush(h, value)
...     return [heappop(h) for i in range(len(h))]
...
>>> heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
これは sorted(iterable) に似ていますが、 sorted() とは異なり、この実装はステーブルソートではありません。
ヒープの要素はタプルに出来ます。これは、追跡される主レコードとは別に (タスクの優先度のような) 比較値を指定するときに便利です:
>>>
>>> h = []
>>> heappush(h, (5, 'write code'))
>>> heappush(h, (7, 'release product'))
>>> heappush(h, (1, 'write spec'))
>>> heappush(h, (3, 'create tests'))
>>> heappop(h)
(1, 'write spec')
優先度キュー実装の注釈
優先度つきキュー は、ヒープの一般的な使い方で、実装にはいくつか困難な点があります:
ソート安定性: 優先度が等しい二つのタスクが、もともと追加された順序で返されるためにはどうしたらいいでしょうか？
(priority, task) ペアに対するタプルの比較は、priority が同じで task がデフォルトの比較順を持たないときに破綻します。
あるタスクの優先度が変化したら、どうやってそれをヒープの新しい位置に移動させるのでしょうか？
未解決のタスクが削除される必要があるとき、どのようにそれをキューから探して削除するのでしょうか？
最初の二つの困難の解決策は、項目を優先度、項目番号、そしてタスクを含む 3 要素のリストとして保存することです。この項目番号は、同じ優先度の二つのタスクが、追加された順序で返されるようにするための同点決勝戦として働きます。そして二つの項目番号が等しくなることはありませんので、タプルの比較が二つのタスクを直接比べようとすることはありえません。
Another solution to the problem of non-comparable tasks is to create a wrapper class that ignores the task item and only compares the priority field:
from dataclasses import dataclass, field
from typing import Any
@dataclass(order=True)
class PrioritizedItem:
    priority: int
    item: Any=field(compare=False)
残りの困難は主に、未解決のタスクを探して、その優先度を変更したり、完全に削除することです。タスクを探すことは、キュー内の項目を指し示す辞書によってなされます。
項目を削除したり、優先度を変更することは、ヒープ構造の不変関係を壊すことになるので、もっと難しいです。ですから、可能な解決策は、その項目が無効であるものとしてマークし、必要なら変更された優先度の項目を加えることです:
pq = []                         # list of entries arranged in a heap
entry_finder = {}               # mapping of tasks to entries
REMOVED = '<removed-task>'      # placeholder for a removed task
counter = itertools.count()     # unique sequence count
def add_task(task, priority=0):
    'Add a new task or update the priority of an existing task'
    if task in entry_finder:
        remove_task(task)
    count = next(counter)
    entry = [priority, count, task]
    entry_finder[task] = entry
    heappush(pq, entry)
def remove_task(task):
    'Mark an existing task as REMOVED.  Raise KeyError if not found.'
    entry = entry_finder.pop(task)
    entry[-1] = REMOVED
def pop_task():
    'Remove and return the lowest priority task. Raise KeyError if empty.'
    while pq:
        priority, count, task = heappop(pq)
        if task is not REMOVED:
            del entry_finder[task]
            return task
    raise KeyError('pop from an empty priority queue')
理論
ヒープとは、全ての k について、要素を 0 から数えたときに、a[k] <= a[2*k+1] かつ a[k] <= a[2*k+2] となる配列です。比較のために、存在しない要素を無限大と考えます。ヒープの興味深い属性は a[0] が常に最小の要素になることです。
上記の奇妙な不変式は、勝ち抜き戦判定の際に効率的なメモリ表現を行うためのものです。以下の番号は a[k] ではなく k とします:
                               0
              1                                 2
      3               4                5               6
  7       8       9       10      11      12      13      14
15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30
上の木構造では、各セル k は 2*k+1 および 2*k+2 を最大値としています。スポーツに見られるような通常の 2 つ組勝ち抜き戦では、各セルはその下にある二つのセルに対する勝者となっていて、個々のセルの勝者を追跡していくことにより、そのセルに対する全ての相手を見ることができます。しかしながら、このような勝ち抜き戦を使う計算機アプリケーションの多くでは、勝歴を追跡する必要はりません。メモリ効率をより高めるために、勝者が上位に進級した際、下のレベルから持ってきて置き換えることにすると、あるセルとその下位にある二つのセルは異なる三つの要素を含み、かつ上位のセルは二つの下位のセルに対して "勝者と" なります。
このヒープ不変式が常に守られれば、インデクス 0 は明らかに最勝者となります。最勝者の要素を除去し、"次の" 勝者を見つけるための最も単純なアルゴリズム的手法は、ある敗者要素 (ここでは上図のセル 30 とします) を 0 の場所に持っていき、この新しい 0 を濾過するようにしてツリーを下らせて値を交換してゆきます。不変関係が再構築されるまでこれを続けます。この操作は明らかに、ツリー内の全ての要素数に対して対数的な計算量となります。全ての要素について繰り返すと、O(n log n) のソート(並べ替え)になります。
このソートの良い点は、新たに挿入する要素が、最後に取り出された 0 番目の要素よりも "良い値" でない限り、ソートを行っている最中に新たな要素を効率的に追加できるというところです。この性質は、シミュレーション的な状況で、ツリーで全ての入力イベントを保持し、"勝者" の状況を最小のスケジュール時刻にするような場合に特に便利です。あるイベントが他のイベント群の実行をスケジュールする際、それらは未来にスケジュールされることになるので、それらのイベント群を容易にヒープに積むことができます。すなわち、ヒープはスケジューラを実装する上で良いデータ構造であるといえます (私はこれを MIDI シーケンサで使っています :-)。
これまで、スケジューラを実装するための様々なデータ構造が広範に研究されてきました。ヒープは、十分高速で、速度はおおむね一定であり、最悪の場合でも平均的な速度とさほど変わらないため、良いデータ構造といえます。しかし、最悪の場合にひどい速度になるとしても、全体的にはより効率の高い他のデータ構造表現も存在します。
ヒープはまた、巨大なディスクのソートでも非常に有用です。おそらくご存知のように、巨大なソートを行うと、複数の "ラン (run)" (予めソートされた配列で、そのサイズは通常 CPU メモリの量に関係しています) が生成され、続いて統合処理 (merging) がこれらのランを判定します。この統合処理はしばしば非常に巧妙に組織されています 1。重要なのは、最初のソートが可能な限り長いランを生成することです。勝ち抜き戦はこれを達成するための良い方法です。もし利用可能な全てのメモリを使って勝ち抜き戦を行い、要素を置換および濾過処理して現在のランに収めれば、ランダムな入力に対してメモリの二倍のサイズのランを生成することになり、大体順序づけがなされている入力に対してはもっと高い効率になります。
さらに、ディスク上の 0 番目の要素を出力して、現在の勝ち抜き戦に (最後に出力した値に "勝って" しまうために) 収められない入力を得たなら、ヒープには収まらないため、ヒープのサイズは減少します。解放されたメモリは二つ目のヒープを段階的に構築するために巧妙に再利用することができ、この二つ目のヒープは最初のヒープが崩壊していくのと同じ速度で成長します。最初のヒープが完全に消滅したら、ヒープを切り替えて新たなランを開始します。なんと巧妙で効率的なのでしょう！
一言で言うと、ヒープは知って得するメモリ構造です。私はいくつかのアプリケーションでヒープを使っていて、'ヒープ' モジュールを常備するのはいい事だと考えています。:-)
bisect --- 配列二分法アルゴリズム
ソースコード: Lib/bisect.py
このモジュールは、挿入の度にリストをソートすることなく、リストをソートされた順序に保つことをサポートします。大量の比較操作を伴うような、アイテムがたくさんあるリストでは、より一般的なアプローチに比べて、パフォーマンスが向上します。動作に基本的な二分法アルゴリズムを使っているので、 bisect と呼ばれています。ソースコードはこのアルゴリズムの実例として一番役に立つかもしれません (境界条件はすでに正しいです!)。
次の関数が用意されています:
bisect.bisect_left(a, x, lo=0, hi=len(a))
ソートされた順序を保ったまま x を a に挿入できる点を探し当てます。リストの中から検索する部分集合を指定するには、パラメータの lo と hi を使います。デフォルトでは、リスト全体が使われます。x がすでに a に含まれている場合、挿入点は既存のどのエントリーよりも前(左)になります。戻り値は、list.insert() の第一引数として使うのに適しています。a はすでにソートされているものとします。
返された挿入点 i は、配列 a を二つに分け、all(val < x for val in a[lo:i]) が左側に、all(val >= x for val in a[i:hi]) が右側になるようにします。
bisect.bisect_right(a, x, lo=0, hi=len(a))
bisect.bisect(a, x, lo=0, hi=len(a))
bisect_left() と似ていますが、 a に含まれる x のうち、どのエントリーよりも後ろ(右)にくるような挿入点を返します。
返された挿入点 i は、配列 a を二つに分け、all(val <= x for val in a[lo:i]) が左側に、all(val > x for val in a[i:hi]) が右側になるようにします。
bisect.insort_left(a, x, lo=0, hi=len(a))
x を a にソート順で挿入します。これは、a がすでにソートされている場合、a.insert(bisect.bisect_left(a, x, lo, hi), x) と等価です。なお、O(log n) の探索に対して、遅い O(n) の挿入の段階が律速となります。
bisect.insort_right(a, x, lo=0, hi=len(a))
bisect.insort(a, x, lo=0, hi=len(a))
insort_left() と似ていますが、 a に含まれる x のうち、どのエントリーよりも後ろに x を挿入します。
参考 bisect を利用して、直接の探索ができ、キー関数をサポートする、完全な機能を持つコレクションクラスを組み立てる SortedCollection recipe。キーは、探索中に不必要な呼び出しをさせないために、予め計算しておきます。
ソート済みリストの探索
上記の bisect() 関数群は挿入点を探索するのには便利ですが、普通の探索タスクに使うのはトリッキーだったり不器用だったりします。以下の 5 関数は、これらをどのように標準の探索やソート済みリストに変換するかを説明します:
def index(a, x):
    'Locate the leftmost value exactly equal to x'
    i = bisect_left(a, x)
    if i != len(a) and a[i] == x:
        return i
    raise ValueError
def find_lt(a, x):
    'Find rightmost value less than x'
    i = bisect_left(a, x)
    if i:
        return a[i-1]
    raise ValueError
def find_le(a, x):
    'Find rightmost value less than or equal to x'
    i = bisect_right(a, x)
    if i:
        return a[i-1]
    raise ValueError
def find_gt(a, x):
    'Find leftmost value greater than x'
    i = bisect_right(a, x)
    if i != len(a):
        return a[i]
    raise ValueError
def find_ge(a, x):
    'Find leftmost item greater than or equal to x'
    i = bisect_left(a, x)
    if i != len(a):
        return a[i]
    raise ValueError
その他の使用例
bisect() 関数は数値テーブルの探索に役に立ちます。この例では、 bisect() を使って、(たとえば)順序のついた数値の区切り点の集合に基づいて、試験の成績の等級を表す文字を調べます。区切り点は 90 以上は 'A'、 80 から 89 は 'B'、などです:
>>>
>>> def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):
...     i = bisect(breakpoints, score)
...     return grades[i]
...
>>> [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]
['F', 'A', 'C', 'C', 'B', 'A', 'A']
sorted() 関数と違い、 bisect() 関数に key や reversed 引数を用意するのは、設計が非効率になるので、非合理的です (連続する bisect 関数の呼び出しは前回の key 参照の結果を "記憶" しません)。
代わりに、事前に計算しておいたキーのリストから検索して、レコードのインデックスを見つけます:
>>>
>>> data = [('red', 5), ('blue', 1), ('yellow', 8), ('black', 0)]
>>> data.sort(key=lambda r: r[1])
>>> keys = [r[1] for r in data]         # precomputed list of keys
>>> data[bisect_left(keys, 0)]
('black', 0)
>>> data[bisect_left(keys, 1)]
('blue', 1)
>>> data[bisect_left(keys, 5)]
('red', 5)
>>> data[bisect_left(keys, 8)]
('yellow', 8)
array --- 効率のよい数値アレイ
このモジュールでは、基本的な値 (文字、整数、浮動小数点数) のアレイ (array、配列) をコンパクトに表現できるオブジェクト型を定義しています。アレイはシーケンス (sequence) 型であり、中に入れるオブジェクトの型に制限があることを除けば、リストとまったく同じように振る舞います。オブジェクト生成時に一文字の 型コード を用いて型を指定します。次の型コードが定義されています:
型コード
C の型
Python の型
最小サイズ (バイト単位)
注釈
'b'
signed char
int
1
'B'
unsigned char
int
1
'u'
wchar_t
Unicode文字(unicode型)
2
(1)
'h'
signed short
int
2
'H'
unsigned short
int
2
'i'
signed int
int
2
'I'
unsigned int
int
2
'l'
signed long
int
4
'L'
unsigned long
int
4
'q'
signed long long
int
8
'Q'
unsigned long long
int
8
'f'
浮動小数点数
浮動小数点数
4
'd'
double
浮動小数点数
8
注釈:
バージョン 3.9 で変更: array('u') now uses wchar_t as C type instead of deprecated Py_UNICODE. This change doesn't affect to its behavior because Py_UNICODE is alias of wchar_t since Python 3.3.
値の実際の表現はマシンアーキテクチャ (厳密に言うとCの実装) によって決まります。値の実際のサイズは itemsize 属性から得られます。
このモジュールでは次の型を定義しています:
class array.array(typecode[, initializer])
要素のデータ型が typecode に限定される新しいアレイで、 オプションの値 initializer を渡すと初期値になりますが、 リスト、 bytes-like object または適当な型のイテレーション可能オブジェクトでなければなりません。
リストか文字列を渡した場合、initializer は新たに作成されたアレイの fromlist() 、 frombytes() あるいは fromunicode() メソッド (以下を参照) に渡され、アレイに初期項目を追加します。それ以外の場合には、イテラブルの initializer は extend() メソッドに渡されます。
引数 typecode, initializer 付きで 監査イベント array.__new__ を送出します。
array.typecodes
すべての利用可能なタイプコードを含む文字列
アレイオブジェクトでは、インデクス指定、スライス、連結および反復といった、 通常のシーケンスの演算をサポートしています。スライス代入を使うときは、 代入値は同じ型コードのアレイオブジェクトでなければなりません。 それ以外のオブジェクトを指定すると TypeError を送出します。 アレイオブジェクトはバッファインターフェースを実装しており、 bytes-like objects をサポートしている場所ならどこでも利用できます。
次のデータ要素やメソッドもサポートされています:
array.typecode
アレイを作るときに使う型コード文字です。
array.itemsize
アレイの要素 1 つの内部表現に使われるバイト長です。
array.append(x)
値 x の新たな要素をアレイの末尾に追加します。
array.buffer_info()
アレイの内容を記憶するために使っているバッファの、現在のメモリアドレスと要素数の入ったタプル (address, length) を返します。バイト単位で表したメモリバッファの大きさは array.buffer_info()[1] * array.itemsize で計算できます。例えば ioctl() 操作のような、メモリアドレスを必要とする低レベルな (そして、本質的に危険な) I/Oインターフェースを使って作業する場合に、ときどき便利です。アレイ自体が存在し、長さを変えるような演算を適用しない限り、有効な値を返します。
注釈 C やC++ で書いたコードからアレイオブジェクトを使う場合 (buffer_info() の情報を使う意味のある唯一の方法です) は、アレイオブジェクトでサポートしているバッファインターフェースを使う方がより理にかなっています。このメソッドは後方互換性のために保守されており、新しいコードでの使用は避けるべきです。バッファインターフェースの説明は バッファプロトコル (buffer Protocol) にあります。
array.byteswap()
アレイのすべての要素に対して「バイトスワップ」 (リトルエンディアンとビッグエンディアンの変換) を行います。このメソッドは大きさが 1、2、4 および 8 バイトの値のみをサポートしています。他の種類の値に使うと RuntimeError を送出します。異なるバイトオーダを使うマシンで書かれたファイルからデータを読み込むときに役に立ちます。
array.count(x)
シーケンス中の x の出現回数を返します。
array.extend(iterable)
iterable から要素を取り出し、アレイの末尾に要素を追加します。 iterable が別のアレイ型である場合、二つのアレイは 全く 同じ型コードでなければなりません。それ以外の場合には TypeError を送出します。 iterable がアレイでない場合、アレイに値を追加できるような正しい型の要素からなるイテレーション可能オブジェクトでなければなりません。
array.frombytes(s)
文字列から要素を追加します。文字列は、 (ファイルから fromfile() メソッドを使って値を読み込んだときのように) マシンのデータ形式で表された値の配列として解釈されます。
バージョン 3.2 で追加: 明確化のため fromstring() の名前が frombytes() に変更されました。
array.fromfile(f, n)
ファイルオブジェクト f から (マシンのデータ形式そのままで) n 個の要素を読み出し、アレイの末尾に要素を追加します。 n 個未満の要素しか読めなかった場合は EOFError を送出しますが、それまでに読み出せた値はアレイに追加されます。 f は本当の組み込みファイルオブジェクトでなければなりません。 read() メソッドをもつ他の型では動作しません。
array.fromlist(list)
リストから要素を追加します。型に関するエラーが発生した場合にアレイが変更されないことを除き、 for x in list: a.append(x) と同じです。
array.fromunicode(s)
指定した Unicode 文字列のデータを使ってアレイを拡張します。アレイの型コードは 'u' でなければなりません。それ以外の場合には、 ValueError を送出します。他の型のアレイに Unicode 型のデータを追加するには、 array.frombytes(unicodestring.encode(enc)) を使ってください。
array.index(x)
アレイ中で x が出現するインデクスのうち最小の値 i を返します。
array.insert(i, x)
アレイ中の位置 i の前に値 x をもつ新しい要素を挿入します。 i の値が負の場合、アレイの末尾からの相対位置として扱います。
array.pop([i])
アレイからインデクスが i の要素を取り除いて返します。オプションの引数はデフォルトで -1 になっていて、最後の要素を取り除いて返すようになっています。
array.remove(x)
アレイ中の x のうち、最初に現れたものを取り除きます。
array.reverse()
アレイの要素の順番を逆にします。
array.tobytes()
array をマシンの値の array に変換して、 bytes の形で返します (tofile() メソッドを使ってファイルに書かれるバイト列と同じです)。
バージョン 3.2 で追加: 明確化のため tostring() の名前が tobytes() に変更されました。
array.tofile(f)
すべての要素を (マシンの値の形式で) file object f に書き込みます。
array.tolist()
アレイを同じ要素を持つ普通のリストに変換します。
array.tounicode()
アレイを Unicode 文字列に変換します。アレイの型コードは 'u' でなければなりません。それ以外の場合には ValueError を送出します。他の型のアレイから Unicode 文字列を得るには、 array.tobytes().decode(enc) を使ってください。
アレイオブジェクトを表示したり文字列に変換したりすると、 array(typecode, initializer) という形式で表現されます。 アレイが空の場合、 initializer の表示を省略します。 アレイが空でなければ、 typecode が 'u' の場合には文字列に、それ以外の場合には数値のリストになります。 array クラスが from array import array というふうにインポートされている限り、変換後の文字列に eval() を用いると元のアレイオブジェクトと同じデータ型と値を持つアレイに逆変換できることが保証されています。文字列表現の例を以下に示します:
array('l')
array('u', 'hello \u2641')
array('l', [1, 2, 3, 4, 5])
array('d', [1.0, 2.0, 3.14])
参考
struct モジュール
異なる種類のバイナリデータのパックおよびアンパック。
xdrlib モジュール
遠隔手続き呼び出しシステムで使われる外部データ表現仕様 (External Data Representation, XDR) のデータのパックおよびアンパック。
Numerical Python ドキュメント
Numeric Python 拡張モジュール (NumPy) では、別の方法でシーケンス型を定義しています。 Numerical Python に関する詳しい情報は http://www.numpy.org/ を参照してください。
weakref --- 弱参照
ソースコード: Lib/weakref.py
weakref モジュールは、Pythonプログラマがオブジェクトへの弱参照 (weak refarence)を作成できるようにします。
以下では、用語リファレント(referent) は弱参照が参照するオブジェクトを意味します。
オブジェクトへの弱参照があることは、そのオブジェクトを生かしておくのには不十分です。リファレントへの参照が弱参照しか残っていない場合、 garbage collection はリファレントを自由に破棄し、メモリを別のものに再利用することができます。しかし、オブジェクトへの強参照がなくても、オブジェクトが実際に破棄されるまでは、弱参照はオブジェクトを返す場合があります。
弱参照の主な用途は、巨大なオブジェクトを保持するキャッシュやマッピングを実装することです。ここで、キャッシュやマッピングに保持されているからという理由だけで、巨大なオブジェクトが生き続けることは望ましくありません。
例えば、巨大なバイナリ画像のオブジェクトがたくさんあり、それぞれに名前を関連付けたいとします。 Python の辞書型を使って名前を画像に対応付けたり画像を名前に対応付けたりすると、画像オブジェクトは辞書内のキーや値に使われているため存続しつづけることになります。 weakref モジュールが提供している WeakKeyDictionary や WeakValueDictionary クラスはその代用で、対応付けを構築するのに弱参照を使い、キャッシュやマッピングに存在するという理由だけでオブジェクトを存続させないようにします。例えば、もしある画像オブジェクトが WeakValueDictionary の値になっていた場合、最後に残った画像オブジェクトへの参照を弱参照マッピングが保持していれば、ガーベジコレクションはこのオブジェクトを再利用でき、画像オブジェクトに対する弱参照内の対応付けは削除されます。
WeakKeyDictionary と WeakValueDictionary はその実装に弱参照を使用しており、キーや値がガーベジコレクションによって回収されたことを弱参照辞書に通知するコールバック関数を設定しています。 WeakSet は set インターフェースを実装していますが、 WeakKeyDictionary のように要素への弱参照を持ちます。
finalize は、オブジェクトのガベージコレクションの実行時にクリーンアップ関数が呼び出されるように登録する、単純な方法を提供します。これは、未加工の弱参照上にコールバック関数を設定するよりも簡単です。なぜなら、オブジェクトのコレクションが完了するまでファイナライザが生き続けることを、モジュールが自動的に保証するからです。
ほとんどのプログラムでは弱参照コンテナまたは finalize のどれかを使えば必要なものは揃うはずです。通常は直接自前の弱参照を作成する必要はありません。低レベルな機構は、より進んだ使い方をするために weakref モジュールとして公開されています。
バージョン 3.2 で変更: thread.lock, threading.Lock, code オブジェクトのサポートが追加されました。
list や dict など、いくつかの組み込み型は弱参照を直接サポートしませんが、以下のようにサブクラス化を行えばサポートを追加できます:
class Dict(dict):
    pass
obj = Dict(red=1, green=2, blue=3)   # this object is weak referenceable
拡張型は、簡単に弱参照をサポートできます。詳細については、 弱参照(Weak Reference)のサポート を参照してください。
class weakref.ref(object[, callback])
object への弱参照を返します。リファレントがまだ生きているならば、元のオブジェクトは参照オブジェクトの呼び出しで取り出せす。リファレントがもはや生きていないならば、参照オブジェクトを呼び出したときに None を返します。 callback に None 以外の値を与えた場合、オブジェクトをまさに後始末処理しようとするときに呼び出します。このとき弱参照オブジェクトは callback の唯一のパラメタとして渡されます。リファレントはもはや利用できません。
同じオブジェクトに対してたくさんの弱参照を作れます。それぞれの弱参照に対して登録されたコールバックは、もっとも新しく登録されたコールバックからもっとも古いものへと呼び出されます。
コールバックが発生させた例外は標準エラー出力に書き込まれますが、伝播されません。それらはオブジェクトの __del__() メソッドが発生させる例外と完全に同じ方法で処理されます。
object が ハッシュ可能 ならば、弱参照はハッシュ可能です。それらは object が削除された後でもそれらのハッシュ値を保持します。 object が削除されてから初めて hash() が呼び出された場合に、その呼び出しは TypeError を発生させます。
弱参照は等価性のテストをサポートしていますが、順序をサポートしていません。参照がまだ生きているならば、 callback に関係なく二つの参照はそれらのリファレントと同じ等価関係を持ちます。リファレントのどちらか一方が削除された場合、参照オブジェクトが同一である場合に限り、その参照は等価です。
これはサブクラス化可能な型というよりファクトリ関数です。
__callback__
この読み出し専用の属性は、現在弱参照に関連付けられているコールバックを返します。コールバックが存在しないか、弱参照のリファレントが生きていない場合、この属性の値は None になります。
バージョン 3.4 で変更: __callback__ 属性が追加されました。
weakref.proxy(object[, callback])
弱参照を使う object へのプロキシを返します。弱参照オブジェクトを明示的な参照外しをしながら利用する代わりに、多くのケースでプロキシを利用することができます。返されるオブジェクトは、 object が呼び出し可能かどうかによって、 ProxyType または CallableProxyType のどちらかの型を持ちます。プロキシオブジェクトはリファレントに関係なく ハッシュ可能 ではありません。これによって、それらの基本的な変更可能という性質による多くの問題を避けています。そして、辞書のキーとしての利用を妨げます。 callback は ref() 関数の同じ名前のパラメータと同じものです。(--- 訳注: リファレントが変更不能型であっても、プロキシはリファレントが消えるという状態の変更があるために、変更可能型です。---)
バージョン 3.8 で変更: Extended the operator support on proxy objects to include the matrix multiplication operators @ and @=.
weakref.getweakrefcount(object)
object を参照する弱参照とプロキシの数を返します。
weakref.getweakrefs(object)
object を参照するすべての弱参照とプロキシオブジェクトのリストを返します。
class weakref.WeakKeyDictionary([dict])
キーを弱参照するマッピングクラス。キーへの強参照がなくなったときに、辞書のエントリは捨てられます。アプリケーションの他の部分が所有するオブジェクトへ属性を追加することもなく、それらのオブジェクトに追加データを関連づけるために使うことができます。これは属性へのアクセスをオーバーライドするオブジェクトに特に便利です。
バージョン 3.9 で変更: Added support for | and |= operators, specified in PEP 584.
WeakKeyDictionary.keyrefs()
キーへの弱参照を持つ iterable オブジェクトを返します。
class weakref.WeakValueDictionary([dict])
値を弱参照するマッピングクラス。値への強参照が存在しなくなったときに、辞書のエントリは捨てられます。
バージョン 3.9 で変更: Added support for | and |= operators, as specified in PEP 584.
WeakValueDictionary オブジェクトは WeakKeyDictionary オブジェクトの keyrefs() メソッドと同じ目的を持つ追加のメソッドを持っています。
WeakValueDictionary.valuerefs()
値への弱参照を持つ iterable オブジェクトを返します。
class weakref.WeakSet([elements])
要素への弱参照を持つ集合型。要素への強参照が無くなったときに、その要素は削除されます。
class weakref.WeakMethod(method)
拡張された ref のサブクラスで、束縛されたメソッドへの弱参照をシミュレートします (つまり、クラスで定義され、インスタンスにあるメソッド)。 束縛されたメソッドは短命なので、標準の弱参照では保持し続けられません。 WeakMethod には、オブジェクトと元々の関数が死ぬまで束縛されたメソッドを再作成する特別なコードがあります:
>>>
>>> class C:
...     def method(self):
...         print("method called!")
...
>>> c = C()
>>> r = weakref.ref(c.method)
>>> r()
>>> r = weakref.WeakMethod(c.method)
>>> r()
<bound method C.method of <__main__.C object at 0x7fc859830220>>
>>> r()()
method called!
>>> del c
>>> gc.collect()
0
>>> r()
>>>
バージョン 3.4 で追加.
class weakref.finalize(obj, func, /, *args, **kwargs)
obj がガベージコレクションで回収されるときに呼び出される、呼び出し可能なファイナライザオブジェクトを返します。 通常の弱参照とは異なり、ファイナライザは参照しているオブジェクトが回収されるまで必ず生き残り、そのおかげでライフサイクル管理が大いに簡単になります。
ファイナライザは (直接もしくはガベージコレクションのときに) 呼び出されるまで 生きている と見なされ、呼び出された後には 死んでいます 。 生きているファイナライザを呼び出すと、 func(*arg, **kwargs) を評価した結果を返します。一方、死んでいるファイナライザを呼び出すと None を返します。
ガベージコレクション中にファイナライザコールバックが発生させた例外は、標準エラー出力に表示されますが、伝播することはできません。これらの例外は、オブジェクトの __del__() メソッドや弱参照のコールバックが発生させる例外と同じ方法で処理されます。
プログラムが終了するとき、生き残ったそれぞれのファイナライザは、自身の atexit 属性が偽に設定されるまで呼び出され続けます。 ファイナライザは生成された順序の逆順で呼び出されます。
__call__()
detach()
peek()
alive
ファイナライザが生きている場合には真、そうでない場合には偽のプロパティです。
atexit
注釈 It is important to ensure that func, args and kwargs do not own any references to obj, either directly or indirectly, since otherwise obj will never be garbage collected. In particular, func should not be a bound method of obj.
バージョン 3.4 で追加.
weakref.ReferenceType
弱参照オブジェクトのための型オブジェクト。
weakref.ProxyType
呼び出し可能でないオブジェクトのプロキシのための型オブジェクト。
weakref.CallableProxyType
呼び出し可能なオブジェクトのプロキシのための型オブジェクト。
weakref.ProxyTypes
プロキシのためのすべての型オブジェクトを含むシーケンス。これは両方のプロキシ型の名前付けに依存しないで、オブジェクトがプロキシかどうかのテストをより簡単にできます。
参考
PEP 205 - 弱参照
この機能の提案と理論的根拠。初期の実装と他の言語における類似の機能についての情報へのリンクを含んでいます。
弱参照オブジェクト
Weak reference objects have no methods and no attributes besides ref.__callback__. A weak reference object allows the referent to be obtained, if it still exists, by calling it:
>>>
import weakref
class Object:
    pass
o = Object()
r = weakref.ref(o)
o2 = r()
o is o2
True
リファレントがもはや存在しないならば、参照オブジェクトの呼び出しは None を返します:
>>>
del o, o2
print(r())
None
弱参照オブジェクトがまだ生きているかどうかのテストは、式 ref() is not None を用いて行われます。通常、参照オブジェクトを使う必要があるアプリケーションコードはこのパターンに従います:
# r is a weak reference object
o = r()
if o is None:
    # referent has been garbage collected
    print("Object has been deallocated; can't frobnicate.")
else:
    print("Object is still live!")
    o.do_something_useful()
"生存性(liveness)"のテストを分割すると、スレッド化されたアプリケーションにおいて競合状態を作り出します。 (訳注:if r() is not None: r().do_something() では、2度目のr()がNoneを返す可能性があります) 弱参照が呼び出される前に、他のスレッドは弱参照が無効になる原因となり得ます。上で示したイディオムは、シングルスレッドのアプリケーションと同じくマルチスレッド化されたアプリケーションにおいても安全です。
サブクラス化を行えば、 ref オブジェクトの特殊なバージョンを作成できます。これは WeakValueDictionary の実装で使われており、マップ内の各エントリによるメモリのオーバヘッドを減らしています。こうした実装は、ある参照に追加情報を関連付けたい場合に便利ですし、リファレントを取り出すための呼び出し時に何らかの追加処理を行いたい場合にも使えます。
以下の例では、 ref のサブクラスを使って、あるオブジェクトに追加情報を保存し、リファレントがアクセスされたときにその値に作用をできるようにするための方法を示しています:
import weakref
class ExtendedRef(weakref.ref):
    def __init__(self, ob, callback=None, /, **annotations):
        super(ExtendedRef, self).__init__(ob, callback)
        self.__counter = 0
        for k, v in annotations.items():
            setattr(self, k, v)
    def __call__(self):
        """Return a pair containing the referent and the number of
        times the reference has been called.
        """
        ob = super(ExtendedRef, self).__call__()
        if ob is not None:
            self.__counter += 1
            ob = (ob, self.__counter)
        return ob
使用例
この簡単な例では、アプリケーションが以前に参照したオブジェクトを取り出すためにオブジェクトIDを利用する方法を示します。オブジェクトに生きたままであることを強制することなく、オブジェクトの IDを他のデータ構造の中で使うことができ、必要に応じてIDからオブジェクトを取り出せます。
import weakref
_id2obj_dict = weakref.WeakValueDictionary()
def remember(obj):
    oid = id(obj)
    _id2obj_dict[oid] = obj
    return oid
def id2obj(oid):
    return _id2obj_dict[oid]
ファイナライザオブジェクト
The main benefit of using finalize is that it makes it simple to register a callback without needing to preserve the returned finalizer object. For instance
>>>
import weakref
class Object:
    pass
kenny = Object()
weakref.finalize(kenny, print, "You killed Kenny!")  
<finalize object at ...; for 'Object' at ...>
del kenny
You killed Kenny!
ファイナライザは直接呼び出すこともできます。ただし、ファイナライザはコールバックを最大でも一度しか呼び出しません。
>>>
def callback(x, y, z):
    print("CALLBACK")
    return x + y + z
obj = Object()
f = weakref.finalize(obj, callback, 1, 2, z=3)
assert f.alive
assert f() == 6
CALLBACK
assert not f.alive
f()                     # callback not called because finalizer dead
del obj                 # callback not called because finalizer dead
>>>
obj = Object()
f = weakref.finalize(obj, callback, 1, 2, z=3)
f.detach()                                           
(<...Object object ...>, <function callback ...>, (1, 2), {'z': 3})
newobj, func, args, kwargs = _
assert not f.alive
assert newobj is obj
assert func(*args, **kwargs) == 6
CALLBACK
Unless you set the atexit attribute to False, a finalizer will be called when the program exits if it is still alive. For instance
>>> obj = Object()
>>> weakref.finalize(obj, print, "obj dead or exiting")
<finalize object at ...; for 'Object' at ...>
>>> exit()
obj dead or exiting
ファイナライザと __del__() メソッドとの比較
インスタンスが一時ディレクトリを表す、クラスを作成するとします。そのディレクトリは、次のイベントのいずれかが起きた時に、そのディレクトリの内容とともに削除されるべきです。
オブジェクトのガベージコレクションが行われた場合
オブジェクトの remove() メソッドが呼び出された場合
プログラムが終了した場合
ここでは、 __del__() メソッドを使用して次のようにクラスを実装します:
class TempDir:
    def __init__(self):
        self.name = tempfile.mkdtemp()
    def remove(self):
        if self.name is not None:
            shutil.rmtree(self.name)
            self.name = None
    @property
    def removed(self):
        return self.name is None
    def __del__(self):
        self.remove()
A more robust alternative can be to define a finalizer which only references the specific functions and objects that it needs, rather than having access to the full state of the object:
class TempDir:
    def __init__(self):
        self.name = tempfile.mkdtemp()
        self._finalizer = weakref.finalize(self, shutil.rmtree, self.name)
    def remove(self):
        self._finalizer()
    @property
    def removed(self):
        return not self._finalizer.alive
The other advantage of weakref based finalizers is that they can be used to register finalizers for classes where the definition is controlled by a third party, such as running code when a module is unloaded:
import weakref, sys
def unloading_module():
    # implicit reference to the module globals from the function body
weakref.finalize(sys.modules[__name__], unloading_module)
types --- 動的な型生成と組み込み型に対する名前
ソースコード: Lib/types.py
このモジュールは新しい型の動的な生成を支援するユーティリティ関数を定義します。
さらに、標準の Python インタプリタによって使用されているものの、 int や str のように組み込みとして公開されていないようないくつかのオブジェクト型の名前を定義しています。
最後に、組み込みになるほど基本的でないような追加の型関連のユーティリティと関数をいくつか提供しています。
動的な型生成
types.new_class(name, bases=(), kwds=None, exec_body=None)
適切なメタクラスを使用して動的にクラスオブジェクトを生成します。
最初の3つの引数はクラス定義ヘッダーを構成する—クラス名、基底クラス (順番に)、キーワード引数 (例えば metaclass)—です。
exec_body 引数は、新規に生成されたクラスの名前空間を構築するために使用されるコールバックです。それは唯一の引数としてクラスの名前空間を受け取り、クラスの内容で名前空間を直接更新します。コールバックが渡されない場合、それは lambda ns: ns を渡すことと同じ効果があります。
バージョン 3.3 で追加.
types.prepare_class(name, bases=(), kwds=None)
適切なメタクラスを計算してクラスの名前空間を生成します。
引数はクラス定義ヘッダーを構成する要素—クラス名、基底クラス (順番に)、キーワード引数 (例えば metaclass)—です。
返り値は metaclass, namespace, kwds の3要素のタプルです
metaclass は適切なメタクラスです。namespace は用意されたクラスの名前空間です。また kwds は、'metaclass' エントリが削除された、渡された kwds 引数の更新されたコピーです。kwds 引数が渡されなければ、これは空の dict になります。
バージョン 3.3 で追加.
バージョン 3.6 で変更: 返されるタプルの namespace 要素のデフォルト値が変更されました。 現在では、メタクラスが __prepare__ メソッドを持っていないときは、挿入順序を保存するマッピングが使われます。
参考
メタクラス
これらの関数によってサポートされるクラス生成プロセスの完全な詳細
PEP 3115 - Metaclasses in Python 3000
__prepare__ 名前空間フックの導入
types.resolve_bases(bases)
バージョン 3.7 で追加.
参考 PEP 560 - typing モジュールとジェネリック型に対する言語コアによるサポート
標準的なインタプリタ型
このモジュールは、Python インタプリタを実装するために必要な多くの型に対して名前を提供します。それは、listiterator 型のような、単に処理中に付随的に発生するいくつかの型が含まれることを意図的に避けています。
これらの名前は典型的に isinstance() や issubclass() によるチェックに使われます。
以下の型に対して標準的な名前が定義されています:
types.FunctionType
types.LambdaType
ユーザ定義の関数と lambda 式によって生成された関数の型です。
types.GeneratorType
ジェネレータ関数によって生成された ジェネレータ イテレータオブジェクトの型です。
types.CoroutineType
async def 関数に生成される コルーチン オブジェクトです。
バージョン 3.5 で追加.
types.AsyncGeneratorType
非同期ジェネレータ関数によって作成された 非同期ジェネレータ イテレータオブジェクトの型です。
バージョン 3.6 で追加.
class types.CodeType(**kwargs)
compile() 関数が返すようなコードオブジェクトの型です。
replace(**kwargs)
バージョン 3.8 で追加.
types.CellType
バージョン 3.8 で追加.
types.MethodType
ユーザー定義のクラスのインスタンスのメソッドの型です。
types.BuiltinFunctionType
types.BuiltinMethodType
len() や sys.exit() のような組み込み関数や、組み込み型のメソッドの型です。 (ここでは "組み込み" という単語を "Cで書かれた" という意味で使っています)
types.WrapperDescriptorType
バージョン 3.7 で追加.
types.MethodWrapperType
バージョン 3.7 で追加.
types.MethodDescriptorType
バージョン 3.7 で追加.
types.ClassMethodDescriptorType
バージョン 3.7 で追加.
class types.ModuleType(name, doc=None)
注釈 インポートによりコントロールされる様々な属性を設定する場合、importlib.util.module_from_spec() を使用して新しいモジュールを作成してください。
__doc__
モジュールの docstring です。デフォルトは None です。
__loader__
モジュールをロードする loader です。デフォルトは None です。
注釈 A future version of Python may stop setting this attribute by default. To guard against this potential change, preferrably read from the __spec__ attribute instead or use getattr(module, "__loader__", None) if you explicitly need to use this attribute.
バージョン 3.4 で変更: デフォルトが None になりました。以前はオプションでした。
__name__
__package__
モジュールがどの package に属しているかです。モジュールがトップレベルである (すなわち、いかなる特定のパッケージの一部でもない) 場合、この属性は '' に設定されます。そうでない場合、パッケージ名 (モジュールがパッケージ自身なら __name__) に設定されます。デフォルトは None です。
注釈 A future version of Python may stop setting this attribute by default. To guard against this potential change, preferrably read from the __spec__ attribute instead or use getattr(module, "__package__", None) if you explicitly need to use this attribute.
バージョン 3.4 で変更: デフォルトが None になりました。以前はオプションでした。
__spec__
バージョン 3.4 で追加.
class types.GenericAlias(t_origin, t_args)
t_origin should be a non-parameterized generic class, such as list, tuple or dict. t_args should be a tuple (possibly of length 1) of types which parameterize t_origin:
>>>
>>> from types import GenericAlias
>>> list[int] == GenericAlias(list, (int,))
True
>>> dict[str, int] == GenericAlias(dict, (str, int))
True
バージョン 3.9 で追加.
バージョン 3.9.2 で変更: This type can now be subclassed.
class types.TracebackType(tb_next, tb_frame, tb_lasti, tb_lineno)
sys.exc_info()[2] で得られるようなトレースバックオブジェクトの型です。
types.FrameType
フレームオブジェクトの型です。トレースバックオブジェクト tb の tb.tb_frame などです。
types.GetSetDescriptorType
FrameType.f_locals や array.array.typecode のような、拡張モジュールにおいて PyGetSetDef によって定義されたオブジェクトの型です。この型はオブジェクト属性のディスクリプタとして利用されます。 property 型と同じ目的を持った型ですが、こちらは拡張モジュールで定義された型のためのものです。
types.MemberDescriptorType
datetime.timedelta.days のような、拡張モジュールにおいて PyMemberDef によって定義されたオブジェクトの型です。この型は、標準の変換関数を利用するような、Cのシンプルなデータメンバで利用されます。 property 型と同じ目的を持った型ですが、こちらは拡張モジュールで定義された型のためのものです。
CPython implementation detail: Pythonの他の実装では、この型は GetSetDescriptorType と同じかもしれません。
class types.MappingProxyType(mapping)
読み出し専用のマッピングのプロキシです。マッピングのエントリーに関する動的なビューを提供します。つまり、マッピングが変わった場合にビューがこれらの変更を反映するということです。
バージョン 3.3 で追加.
バージョン 3.9 で変更: Updated to support the new union (|) operator from PEP 584, which simply delegates to the underlying mapping.
key in proxy
元になったマッピングが key というキーを持っている場合 True を返します。そうでなければ False を返します。
proxy[key]
元になったマッピングの key というキーに対応するアイテムを返します。 key が存在しなければ、 KeyError が発生します。
iter(proxy)
元になったマッピングのキーを列挙するイテレータを返します。これは iter(proxy.keys()) のショートカットです。
len(proxy)
元になったマッピングに含まれるアイテムの数を返します。
copy()
元になったマッピングの浅いコピーを返します。
get(key[, default])
key が元になったマッピングに含まれている場合 key に対する値を返し、そうでなければ default を返します。もし default が与えられない場合は、デフォルト値の None になります。そのため、このメソッドが KeyError を発生させることはありません。
items()
元になったマッピングの items ((key, value) ペアの列) に対する新しいビューを返します。
keys()
元になったマッピングの keys に対する新しいビューを返します。
values()
元になったマッピングの values に対する新しいビューを返します。
reversed(proxy)
バージョン 3.9 で追加.
追加のユーティリティクラスと関数
class types.SimpleNamespace
名前空間への属性アクセスに加えて意味のある repr を提供するための、単純な object サブクラスです。
object とは異なり、 SimpleNamespace は、属性を追加したり削除したりすることができます。 SimpleNamespace オブジェクトがキーワード引数で初期化される場合、それらは元になる名前空間に直接追加されます。
この型は以下のコードとほぼ等価です:
class SimpleNamespace:
    def __init__(self, /, **kwargs):
        self.__dict__.update(kwargs)
    def __repr__(self):
        items = (f"{k}={v!r}" for k, v in self.__dict__.items())
        return "{}({})".format(type(self).__name__, ", ".join(items))
    def __eq__(self, other):
        if isinstance(self, SimpleNamespace) and isinstance(other, SimpleNamespace):
           return self.__dict__ == other.__dict__
        return NotImplemented
SimpleNamespace は class NS: pass を置き換えるものとして有用かもしれません。ですが、構造化されたレコード型に対しては、これよりはむしろ namedtuple() を使用してください。
バージョン 3.3 で追加.
バージョン 3.9 で変更: Attribute order in the repr changed from alphabetical to insertion (like dict).
types.DynamicClassAttribute(fget=None, fset=None, fdel=None, doc=None)
クラスの属性アクセスを __getattr__ に振り替えます。
これは記述子で、インスタンス経由のアクセスとクラス経由のアクセスで振る舞いが異なる属性を定義するのに使います。インスタンスアクセスは通常通りですが、クラス経由の属性アクセスはクラスの __getattr__ メソッドに振り替えられます。これは AttributeError の送出により行われます。
バージョン 3.4 で追加.
コルーチンユーティリティ関数
types.coroutine(gen_func)
この関数は、 generator 関数を、ジェネレータベースのコルーチンを返す coroutine function に変換します。返されるジェネレータベースのコルーチンは依然として generator iterator ですが、同時に coroutine オブジェクトかつ awaitable であるとみなされます。ただし、必ずしも __await__() メソッドを実装する必要はありません。
gen_func はジェネレータ関数で、インプレースに変更されます。
gen_func がジェネレータ関数でない場合、この関数はラップされます。この関数が collections.abc.Generator のインスタンスを返す場合、このインスタンスは awaitable なプロキシオブジェクトにラップされます。それ以外のすべての型のオブジェクトは、そのまま返されます。
バージョン 3.5 で追加.
copy --- 浅いコピーおよび深いコピー操作
ソースコード: Lib/copy.py
Python において代入文はオブジェクトをコピーしません。代入はターゲットとオブジェクトの間に束縛を作ります。ミュータブルなコレクションまたはミュータブルなアイテムを含むコレクションについては、元のオブジェクトを変更せずにコピーを変更できるように、コピーが必要になることが時々あります。このモジュールは、汎用的な浅い (shallow) コピーと深い (deep) コピーの操作 (以下で説明されます) を提供します。
以下にインターフェースをまとめます:
copy.copy(x)
x の浅い (shallow) コピーを返します。
copy.deepcopy(x[, memo])
x の深い (deep) コピーを返します。
exception copy.error
モジュール特有のエラーを送出します。
浅い (shallow) コピーと深い (deep) コピーの違いが関係するのは、複合オブジェクト (リストやクラスインスタンスのような他のオブジェクトを含むオブジェクト) だけです:
浅いコピー (shallow copy) は新たな複合オブジェクトを作成し、その後 (可能な限り) 元のオブジェクト中に見つかったオブジェクトに対する 参照 を挿入します。
深いコピー (deep copy) は新たな複合オブジェクトを作成し、その後元のオブジェクト中に見つかったオブジェクトの コピー を挿入します。
深いコピー操作には、しばしば浅いコピー操作の時には存在しない 2 つの問題がついてまわります:
再帰的なオブジェクト (直接、間接に関わらず、自分自身に対する参照を持つ複合オブジェクト) は再帰ループを引き起こします。
深いコピーは何もかもコピーしてしまうため、例えば複数のコピー間で共有するつもりだったデータも余分にコピーしてしまいます。
deepcopy() 関数では、これらの問題を以下のようにして回避しています:
現時点でのコピー過程ですでにコピーされたオブジェクトの memo 辞書を保持する。
ユーザ定義のクラスでコピー操作やコピーされる内容の集合を上書きできるようにする。
このモジュールでは、モジュール、メソッド、スタックトレース、スタックフレーム、ファイル、ソケット、ウィンドウ、アレイ、その他これらに類似の型をコピーしません。このモジュールでは元のオブジェクトを変更せずに返すことで関数とクラスを (浅くまたは深く)「コピー」します。これは pickle モジュールでの扱われかたと同じです。
辞書型の浅いコピーは dict.copy() で、リストの浅いコピーはリスト全体を指すスライス (例えば copied_list = original_list[:]) でできます。
クラスは、コピーを制御するために pickle の制御に使用するのと同じインターフェースを使用することができます。これらのメソッドについての情報はモジュール pickle の説明を参照してください。実際、 copy モジュールは、 copyreg モジュールによって登録された pickle 関数を使用します。
クラス独自のコピー実装を定義するために、特殊メソッド __copy__() および __deepcopy__() を定義することができます。前者は浅いコピー操作を実装するために使われます; 追加の引数はありません。後者は深いコピー操作を実現するために呼び出されます; この関数には単一の引数として memo 辞書が渡されます。 __deepcopy__() の実装で、内容のオブジェクトに対して深いコピーを生成する必要がある場合、 deepcopy() を呼び出し、最初の引数にそのオブジェクトを、メモ辞書を二つ目の引数に与えなければなりません。
参考
pickle モジュール
オブジェクト状態の取得と復元をサポートするために使われる特殊メソッドについて議論されています。
pprint --- データ出力の整然化
ソースコード: Lib/pprint.py
pprint モジュールを使うと、Pythonの任意のデータ構造をインタープリタへの入力で使われる形式にして "pretty-print" できます。書式化された構造の中にPythonの基本的なタイプではないオブジェクトがあるなら、表示できないかもしれません。表示できないのは、ファイル、ソケット、あるいはクラスのようなオブジェクトや、 その他Pythonのリテラルとして表現できない様々なオブジェクトが含まれていた場合です。
可能であればオブジェクトを1行で整形しますが、与えられた幅に合わないなら複数行に分けて整形します。 出力幅を指定したい場合は、 PrettyPrinter オブジェクトを作成して明示してください。
辞書は表示される前にキーの順でソートされます。
バージョン 3.9 で変更: Added support for pretty-printing types.SimpleNamespace.
pprint モジュールには1つのクラスが定義されています:
class pprint.PrettyPrinter(indent=1, width=80, depth=None, stream=None, *, compact=False, sort_dicts=True)
バージョン 3.4 で変更: compact 引数が追加されました。
バージョン 3.8 で変更: Added the sort_dicts parameter.
>>>
import pprint
stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
stuff.insert(0, stuff[:])
pp = pprint.PrettyPrinter(indent=4)
pp.pprint(stuff)
[   ['spam', 'eggs', 'lumberjack', 'knights', 'ni'],
    'spam',
    'eggs',
    'lumberjack',
    'knights',
    'ni']
pp = pprint.PrettyPrinter(width=41, compact=True)
pp.pprint(stuff)
[['spam', 'eggs', 'lumberjack',
  'knights', 'ni'],
 'spam', 'eggs', 'lumberjack', 'knights',
 'ni']
tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',
('parrot', ('fresh fruit',))))))))
pp = pprint.PrettyPrinter(depth=6)
pp.pprint(tup)
('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead', (...)))))))
pprint モジュールは幾つかのショートカット関数も提供しています:
pprint.pformat(object, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True)
バージョン 3.4 で変更: compact 引数が追加されました。
バージョン 3.8 で変更: Added the sort_dicts parameter.
pprint.pp(object, *args, sort_dicts=False, **kwargs)
バージョン 3.8 で追加.
pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *, compact=False, sort_dicts=True)
バージョン 3.4 で変更: compact 引数が追加されました。
バージョン 3.8 で変更: Added the sort_dicts parameter.
>>>
import pprint
stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
stuff.insert(0, stuff)
pprint.pprint(stuff)
[<Recursion on list with id=...>,
 'spam',
 'eggs',
 'lumberjack',
 'knights',
 'ni']
pprint.isreadable(object)
>>>
pprint.isreadable(stuff)
False
pprint.isrecursive(object)
object が再帰的な表現かどうかを返します。
さらにもう1つ、関数が定義されています:
pprint.saferepr(object)
object の文字列表現を、再帰的なデータ構造から保護した形式で返します。もし object の文字列表現が再帰的な要素を持っているなら、再帰的な参照は <Recursion on typename with id=number> で表示されます。出力は他と違って書式化されません。
>>>
pprint.saferepr(stuff)
"[<Recursion on list with id=...>, 'spam', 'eggs', 'lumberjack', 'knights', 'ni']"
PrettyPrinter オブジェクト
PrettyPrinter インスタンスには以下のメソッドがあります:
PrettyPrinter.pformat(object)
object の書式化した表現を返します。これは PrettyPrinter のコンストラクタに渡されたオプションを考慮して書式化されます。
PrettyPrinter.pprint(object)
object の書式化した表現を指定したストリームに出力し、最後に改行します。
以下のメソッドは、対応する同じ名前の関数と同じ機能を持っています。以下のメソッドをインスタンスに対して使うと、新たに PrettyPrinter オブジェクトを作る必要がないのでちょっぴり効果的です。
PrettyPrinter.isreadable(object)
object を書式化して出力できる（"readable"）か、あるいは eval() を使って値を再構成できるかを返します。これは再帰的なオブジェクトに対して False を返すことに注意して下さい。もし PrettyPrinter の depth 引数が設定されていて、オブジェクトのレベルが設定よりも深かったら、 False を返します。
PrettyPrinter.isrecursive(object)
オブジェクトが再帰的な表現かどうかを返します。
このメソッドをフックとして、サブクラスがオブジェクトを文字列に変換する方法を修正するのが可能になっています。デフォルトの実装では、内部で saferepr() を呼び出しています。
PrettyPrinter.format(object, context, maxlevels, level)
次の3つの値を返します。object をフォーマット化して文字列にしたもの、その結果が読み込み可能かどうかを示すフラグ、再帰が含まれているかどうかを示すフラグ。最初の引数は表示するオブジェクトです。 2つめの引数はオブジェクトの id() をキーとして含むディクショナリで、オブジェクトを含んでいる現在の（直接、間接に object のコンテナとして表示に影響を与える）環境です。ディクショナリ context の中でどのオブジェクトが表示されたか表示する必要があるなら、3つめの返り値は True になります。 format() メソッドの再帰呼び出しではこのディクショナリのコンテナに対してさらにエントリを加えます。 3つめの引数 maxlevels で再帰呼び出しのレベルを制限します。制限しない場合、 0 になります。この引数は再帰呼び出しでそのまま渡されます。 4つめの引数 level で現在のレベルを設定します。再帰呼び出しでは、現在の呼び出しより小さい値が渡されます。
使用例
pprint() 関数のいくつかの用途とそのパラメータを実証するために、PyPI からプロジェクトに関する情報を取って来ましょう:
>>>
>>> import json
>>> import pprint
>>> from urllib.request import urlopen
>>> with urlopen('https://pypi.org/pypi/sampleproject/json') as resp:
...     project_info = json.load(resp)['info']
その基本形式では、 pprint() はオブジェクト全体を表示します:
>>>
>>> pprint.pprint(project_info)
{'author': 'The Python Packaging Authority',
 'author_email': 'pypa-dev@googlegroups.com',
 'bugtrack_url': None,
 'classifiers': ['Development Status :: 3 - Alpha',
                 'Intended Audience :: Developers',
                 'License :: OSI Approved :: MIT License',
                 'Programming Language :: Python :: 2',
                 'Programming Language :: Python :: 2.6',
                 'Programming Language :: Python :: 2.7',
                 'Programming Language :: Python :: 3',
                 'Programming Language :: Python :: 3.2',
                 'Programming Language :: Python :: 3.3',
                 'Programming Language :: Python :: 3.4',
                 'Topic :: Software Development :: Build Tools'],
 'description': 'A sample Python project\n'
                '=======================\n'
                '\n'
                'This is the description file for the project.\n'
                '\n'
                'The file should use UTF-8 encoding and be written using '
                'ReStructured Text. It\n'
                'will be used to generate the project webpage on PyPI, and '
                'should be written for\n'
                'that purpose.\n'
                '\n'
                'Typical contents for this file would include an overview of '
                'the project, basic\n'
                'usage examples, etc. Generally, including the project '
                'changelog in here is not\n'
                'a good idea, although a simple "What\'s New" section for the '
                'most recent version\n'
                'may be appropriate.',
 'description_content_type': None,
 'docs_url': None,
 'download_url': 'UNKNOWN',
 'downloads': {'last_day': -1, 'last_month': -1, 'last_week': -1},
 'home_page': 'https://github.com/pypa/sampleproject',
 'keywords': 'sample setuptools development',
 'license': 'MIT',
 'maintainer': None,
 'maintainer_email': None,
 'name': 'sampleproject',
 'package_url': 'https://pypi.org/project/sampleproject/',
 'platform': 'UNKNOWN',
 'project_url': 'https://pypi.org/project/sampleproject/',
 'project_urls': {'Download': 'UNKNOWN',
                  'Homepage': 'https://github.com/pypa/sampleproject'},
 'release_url': 'https://pypi.org/project/sampleproject/1.2.0/',
 'requires_dist': None,
 'requires_python': None,
 'summary': 'A sample Python project',
 'version': '1.2.0'}
結果をある深さ depth に制限することができます (より深い内容には省略記号が使用されます):
>>>
>>> pprint.pprint(project_info, depth=1)
{'author': 'The Python Packaging Authority',
 'author_email': 'pypa-dev@googlegroups.com',
 'bugtrack_url': None,
 'classifiers': [...],
 'description': 'A sample Python project\n'
                '=======================\n'
                '\n'
                'This is the description file for the project.\n'
                '\n'
                'The file should use UTF-8 encoding and be written using '
                'ReStructured Text. It\n'
                'will be used to generate the project webpage on PyPI, and '
                'should be written for\n'
                'that purpose.\n'
                '\n'
                'Typical contents for this file would include an overview of '
                'the project, basic\n'
                'usage examples, etc. Generally, including the project '
                'changelog in here is not\n'
                'a good idea, although a simple "What\'s New" section for the '
                'most recent version\n'
                'may be appropriate.',
 'description_content_type': None,
 'docs_url': None,
 'download_url': 'UNKNOWN',
 'downloads': {...},
 'home_page': 'https://github.com/pypa/sampleproject',
 'keywords': 'sample setuptools development',
 'license': 'MIT',
 'maintainer': None,
 'maintainer_email': None,
 'name': 'sampleproject',
 'package_url': 'https://pypi.org/project/sampleproject/',
 'platform': 'UNKNOWN',
 'project_url': 'https://pypi.org/project/sampleproject/',
 'project_urls': {...},
 'release_url': 'https://pypi.org/project/sampleproject/1.2.0/',
 'requires_dist': None,
 'requires_python': None,
 'summary': 'A sample Python project',
 'version': '1.2.0'}
それに加えて、最大の文字幅 width を指示することもできます。長いオブジェクトを分離することができなければ、指定された幅を超過します:
>>>
>>> pprint.pprint(project_info, depth=1, width=60)
{'author': 'The Python Packaging Authority',
 'author_email': 'pypa-dev@googlegroups.com',
 'bugtrack_url': None,
 'classifiers': [...],
 'description': 'A sample Python project\n'
                '=======================\n'
                '\n'
                'This is the description file for the '
                'project.\n'
                '\n'
                'The file should use UTF-8 encoding and be '
                'written using ReStructured Text. It\n'
                'will be used to generate the project '
                'webpage on PyPI, and should be written '
                'for\n'
                'that purpose.\n'
                '\n'
                'Typical contents for this file would '
                'include an overview of the project, '
                'basic\n'
                'usage examples, etc. Generally, including '
                'the project changelog in here is not\n'
                'a good idea, although a simple "What\'s '
                'New" section for the most recent version\n'
                'may be appropriate.',
 'description_content_type': None,
 'docs_url': None,
 'download_url': 'UNKNOWN',
 'downloads': {...},
 'home_page': 'https://github.com/pypa/sampleproject',
 'keywords': 'sample setuptools development',
 'license': 'MIT',
 'maintainer': None,
 'maintainer_email': None,
 'name': 'sampleproject',
 'package_url': 'https://pypi.org/project/sampleproject/',
 'platform': 'UNKNOWN',
 'project_url': 'https://pypi.org/project/sampleproject/',
 'project_urls': {...},
 'release_url': 'https://pypi.org/project/sampleproject/1.2.0/',
 'requires_dist': None,
 'requires_python': None,
 'summary': 'A sample Python project',
 'version': '1.2.0'}
reprlib --- もう一つの repr() の実装
ソースコード: Lib/reprlib.py
reprlib モジュールは、結果の文字列のサイズに対する制限付きでオブジェクト表現を生成するための手段を提供します。これは Python デバッガの中で使用されており、他の文脈でも同様に役に立つかもしれません。
このモジュールはクラスとインスタンス、それに関数を提供します:
class reprlib.Repr
組み込み関数 repr() に似た関数を実装するために役に立つフォーマット用サービスを提供します。 過度に長い表現を作り出さないようにするための大きさの制限をオブジェクト型ごとに設定できます。
reprlib.aRepr
これは下で説明される repr() 関数を提供するために使われる Repr のインスタンスです。このオブジェクトの属性を変更すると、 repr() と Python デバッガが使うサイズ制限に影響します。
reprlib.repr(obj)
これは aRepr の repr() メソッドです。同じ名前の組み込み関数が返す文字列と似ていますが、最大サイズに制限のある文字列を返します。
サイズを制限するツールに加えて、このモジュールはさらに __repr__() に対する再帰呼び出しの検出とプレースホルダー文字列による置換のためのデコレータを提供します。
@reprlib.recursive_repr(fillvalue="...")
__repr__() メソッドに対する同一スレッド内の再帰呼び出しを検出するデコレータです。再帰呼び出しが行われている場合 fillvalue が返されます。そうでなければ通常の __repr__() 呼び出しが行われます。例えば:
>>>
from reprlib import recursive_repr
class MyList(list):
    @recursive_repr()
    def __repr__(self):
        return '<' + '|'.join(map(repr, self)) + '>'
m = MyList('abc')
m.append(m)
m.append('x')
print(m)
<'a'|'b'|'c'|...|'x'>
バージョン 3.2 で追加.
Reprオブジェクト
Repr インスタンスはオブジェクト型毎に表現する文字列のサイズを制限するために使えるいくつかの属性と、特定のオブジェクト型をフォーマットするメソッドを提供します。
Repr.maxlevel
再帰的な表現を作る場合の深さ制限。デフォルトは 6 です。
Repr.maxdict
Repr.maxlist
Repr.maxtuple
Repr.maxset
Repr.maxfrozenset
Repr.maxdeque
Repr.maxarray
指定されたオブジェクト型に対するエントリ表現の数についての制限。 maxdict に対するデフォルトは 4 で、 maxarray は 5 、その他に対しては 6 です。
Repr.maxlong
整数の表現のおける文字数の最大値。中央の数字が抜け落ちます。デフォルトは 40 です。
Repr.maxstring
文字列の表現における文字数の制限。文字列の"通常の"表現は文字の「元」として使われることに注意してください。表現にエスケープシーケンスが必要とされる場合、表現が短縮されるときにこれらのエスケープシーケンスの形式は崩れます。デフォルトは 30 です。
Repr.maxother
この制限は Repr オブジェクトに利用できる特定のフォーマットメソッドがないオブジェクト型のサイズをコントロールするために使われます。 maxstring と同じようなやり方で適用されます。デフォルトは 20 です。
Repr.repr(obj)
このインスタンスで設定されたフォーマットを使う、組み込み repr() と等価なもの。
Repr.repr1(obj, level)
repr() が使う再帰的な実装。 obj の型を使ってどのフォーマットメソッドを呼び出すかを決定し、それに obj と level を渡します。 再帰呼び出しにおいて level の値に対して level - 1 を与える再帰的なフォーマットを実行するために、型に固有のメソッドは repr1() を呼び出します。
Repr.repr_TYPE(obj, level)
型名に基づく名前をもつメソッドとして、特定の型に対するフォーマットメソッドは実装されます。メソッド名では、 TYPE は '_'.join(type(obj).__name__.split()) に置き換えられます。これらのメソッドへのディスパッチは repr1() によって処理されます。再帰的に値をフォーマットする必要がある型固有のメソッドは、 self.repr1(subobj, level - 1) を呼び出します。
Reprオブジェクトをサブクラス化する
更なる組み込みオブジェクト型へのサポートを追加するため、あるいはすでにサポートされている型の扱いを変更するために、 Repr.repr1() による動的なディスパッチは Repr のサブクラス化に対応しています。 この例はファイルオブジェクトのための特別なサポートを追加する方法を示しています:
import reprlib
import sys
class MyRepr(reprlib.Repr):
    def repr_TextIOWrapper(self, obj, level):
        if obj.name in {'<stdin>', '<stdout>', '<stderr>'}:
            return obj.name
        return repr(obj)
aRepr = MyRepr()
print(aRepr.repr(sys.stdin))         # prints '<stdin>'
enum --- 列挙型のサポート
バージョン 3.4 で追加.
ソースコード: Lib/enum.py
列挙型は、一意の定数値に束縛された識別名 (メンバー) の集合です。列挙型の中でメンバーの同一性を比較でき、列挙型自身でイテレートが可能です。
注釈 Case of Enum Members
モジュールコンテンツ
このモジュールでは一意の名前と値の集合を定義するのに使用できる 4 つの列挙型クラス Enum, IntEnum, Flag, IntFlag を定義しています。 このモジュールはデコレータの unique() とヘルパークラスの auto も定義しています。
class enum.Enum
列挙型定数を作成する基底クラスです。もうひとつの構築構文については 機能 API を参照してください。
class enum.IntEnum
int のサブクラスでもある列挙型定数を作成する基底クラスです。
class enum.IntFlag
列挙型定数を作成する基底クラスで、ビット演算子を使って組み合わせられ、その結果も IntFlag メンバーになります。 IntFlag は int のサブクラスでもあります。
class enum.Flag
列挙型定数を作成する基底クラスで、ビット演算を使って組み合わせられ、その結果も IntFlag メンバーになります。
enum.unique()
一つの名前だけがひとつの値に束縛されていることを保証する Enum クラスのデコレーターです。
class enum.auto
バージョン 3.6 で追加: Flag, IntFlag, auto
Enum の作成
列挙型は読み書きが容易になるよう class 文を使って作成します。もうひとつの作成方法は 機能 API で説明しています。列挙型は以下のように Enum のサブクラスとして定義します:
>>>
>>> from enum import Enum
>>> class Color(Enum):
...     RED = 1
...     GREEN = 2
...     BLUE = 3
...
注釈 列挙型のメンバー値
メンバー値は何であっても構いません: int, str などなど。 正確な値が重要でない場合は、 auto インスタンスを使っておくと、適切な値が選ばれます。 auto とそれ以外の値を混ぜて使う場合は注意する必要があります。
注釈 用語
クラス Color は 列挙型 (または Enum) です
属性 Color.RED, Color.GREEN などは 列挙型のメンバー (または Enum メンバー) で、機能的には定数です。
列挙型のメンバーは 名前 と 値 を持ちます (Color.RED の名前は RED 、 Color.BLUE の値は 3 など。)
注釈 Enum の作成に class 文を使用するものの、Enum は通常の Python クラスではありません。詳細は Enum はどう違うのか? を参照してください。
列挙型のメンバーは人が読める文字列表現を持ちます:
>>>
>>> print(Color.RED)
Color.RED
...その一方でそれらの repr はより多くの情報を持っています:
>>>
>>> print(repr(Color.RED))
<Color.RED: 1>
列挙型メンバーの データ型 はそれが所属する列挙型になります:
>>>
>>> type(Color.RED)
<enum 'Color'>
>>> isinstance(Color.GREEN, Color)
True
>>>
Enum メンバーは自身の名前を持つだけのプロパティも持っています:
>>>
>>> print(Color.RED.name)
RED
列挙型は定義順でのイテレーションをサポートしています:
>>>
>>> class Shake(Enum):
...     VANILLA = 7
...     CHOCOLATE = 4
...     COOKIES = 9
...     MINT = 3
...
>>> for shake in Shake:
...     print(shake)
...
Shake.VANILLA
Shake.CHOCOLATE
Shake.COOKIES
Shake.MINT
列挙型のメンバーはハッシュ化可能なため、辞書や集合で使用できます:
>>>
>>> apples = {}
>>> apples[Color.RED] = 'red delicious'
>>> apples[Color.GREEN] = 'granny smith'
>>> apples == {Color.RED: 'red delicious', Color.GREEN: 'granny smith'}
True
列挙型メンバーおよびそれらの属性へのプログラム的アクセス
プログラム的にメンバーに番号でアクセスしたほうが便利な場合があります (すなわち、プログラムを書いている時点で正確な色がまだわからなく、Color.RED と書くのが無理な場合など)。 Enum ではそのようなアクセスも可能です:
>>>
>>> Color(1)
<Color.RED: 1>
>>> Color(3)
<Color.BLUE: 3>
列挙型メンバーに 名前 でアクセスしたい場合はアイテムとしてアクセスできます:
>>>
>>> Color['RED']
<Color.RED: 1>
>>> Color['GREEN']
<Color.GREEN: 2>
列挙型メンバーの name か value が必要な場合:
>>>
>>> member = Color.RED
>>> member.name
'RED'
>>> member.value
1
列挙型メンバーと値の重複
同じ名前の列挙型メンバーを複数持つことはできません:
>>>
>>> class Shape(Enum):
...     SQUARE = 2
...     SQUARE = 3
...
Traceback (most recent call last):
...
TypeError: Attempted to reuse key: 'SQUARE'
ただし、複数の列挙型メンバーが同じ値を持つことはできます。同じ値を持つ 2 つのメンバー A および B (先に定義したのは A) が与えられたとき、B は A の別名になります。A および B を値で調べたとき、A が返されます。B を名前で調べたとき、A が返されます:
>>>
>>> class Shape(Enum):
...     SQUARE = 2
...     DIAMOND = 1
...     CIRCLE = 3
...     ALIAS_FOR_SQUARE = 2
...
>>> Shape.SQUARE
<Shape.SQUARE: 2>
>>> Shape.ALIAS_FOR_SQUARE
<Shape.SQUARE: 2>
>>> Shape(2)
<Shape.SQUARE: 2>
注釈 すでに定義されている属性と同じ名前のメンバー (一方がメンバーでもう一方がメソッド、など) の作成、あるいはメンバーと同じ名前の属性の作成はできません。
番号付けの値が同一であることの確認
デフォルトでは、前述のように複数の名前への同じ値の定義は別名とすることで許されています。この挙動を望まない場合、以下のデコレーターを使用することで各値が列挙型内で一意かどうか確認できます:
@enum.unique
列挙型専用の class デコレーターです。列挙型の __members__ に別名がないかどうか検索します; 見つかった場合、ValueError が詳細情報とともに送出されます:
>>>
>>> from enum import Enum, unique
>>> @unique
... class Mistake(Enum):
...     ONE = 1
...     TWO = 2
...     THREE = 3
...     FOUR = 3
...
Traceback (most recent call last):
...
ValueError: duplicate values found in <enum 'Mistake'>: FOUR -> THREE
値の自動設定を使う
正確な値が重要でない場合、 auto が使えます:
>>>
>>> from enum import Enum, auto
>>> class Color(Enum):
...     RED = auto()
...     BLUE = auto()
...     GREEN = auto()
...
>>> list(Color)
[<Color.RED: 1>, <Color.BLUE: 2>, <Color.GREEN: 3>]
その値は _generate_next_value_() によって選ばれ、この関数はオーバーライドできます:
>>>
>>> class AutoName(Enum):
...     def _generate_next_value_(name, start, count, last_values):
...         return name
...
>>> class Ordinal(AutoName):
...     NORTH = auto()
...     SOUTH = auto()
...     EAST = auto()
...     WEST = auto()
...
>>> list(Ordinal)
[<Ordinal.NORTH: 'NORTH'>, <Ordinal.SOUTH: 'SOUTH'>, <Ordinal.EAST: 'EAST'>, <Ordinal.WEST: 'WEST'>]
注釈 The goal of the default _generate_next_value_() method is to provide the next int in sequence with the last int provided, but the way it does this is an implementation detail and may change.
注釈 The _generate_next_value_() method must be defined before any members.
イテレーション
列挙型のメンバーのイテレートは別名をサポートしていません:
>>>
>>> list(Shape)
[<Shape.SQUARE: 2>, <Shape.DIAMOND: 1>, <Shape.CIRCLE: 3>]
特殊属性 __members__ は読み出し専用で、順序を保持した、対応する名前と列挙型メンバーのマッピングです。これには別名も含め、列挙されたすべての名前が入っています。
>>>
>>> for name, member in Shape.__members__.items():
...     name, member
...
('SQUARE', <Shape.SQUARE: 2>)
('DIAMOND', <Shape.DIAMOND: 1>)
('CIRCLE', <Shape.CIRCLE: 3>)
('ALIAS_FOR_SQUARE', <Shape.SQUARE: 2>)
属性 __members__ は列挙型メンバーへの詳細なアクセスに使用できます。以下はすべての別名を探す例です:
>>>
>>> [name for name, member in Shape.__members__.items() if member.name != name]
['ALIAS_FOR_SQUARE']
比較
列挙型メンバーは同一性を比較できます:
>>>
>>> Color.RED is Color.RED
True
>>> Color.RED is Color.BLUE
False
>>> Color.RED is not Color.BLUE
True
列挙型の値の順序の比較はサポートされて いません。Enum メンバーは整数ではありません (IntEnum を参照してください):
>>>
>>> Color.RED < Color.BLUE
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: '<' not supported between instances of 'Color' and 'Color'
ただし等価の比較は定義されています:
>>>
>>> Color.BLUE == Color.RED
False
>>> Color.BLUE != Color.RED
True
>>> Color.BLUE == Color.BLUE
True
非列挙型の値との比較は常に不等となります (繰り返しになりますが、IntEnum はこれと異なる挙動になるよう設計されています):
>>>
>>> Color.BLUE == 2
False
列挙型で許されるメンバーと属性
上述の例では列挙型の値に整数を使用しています。整数の使用は短くて使いやすい (そして 機能 API でデフォルトで提供されています) のですが、厳密には強制ではありません。ほとんどの事例では列挙型の実際の値が何かを気にしていません。しかし、値が重要で ある 場合、列挙型は任意の値を持つことができます。
列挙型は Python のクラスであり、通常どおりメソッドや特殊メソッドを持つことができます:
>>>
>>> class Mood(Enum):
...     FUNKY = 1
...     HAPPY = 3
...
...     def describe(self):
...         # self is the member here
...         return self.name, self.value
...
...     def __str__(self):
...         return 'my custom str! {0}'.format(self.value)
...
...     @classmethod
...     def favorite_mood(cls):
...         # cls here is the enumeration
...         return cls.HAPPY
...
上記の結果が以下のようになります:
>>>
>>> Mood.favorite_mood()
<Mood.HAPPY: 3>
>>> Mood.HAPPY.describe()
('HAPPY', 3)
>>> str(Mood.FUNKY)
'my custom str! 1'
Restricted Enum subclassing
A new Enum class must have one base Enum class, up to one concrete data type, and as many object-based mixin classes as needed. The order of these base classes is:
class EnumName([mix-in, ...,] [data-type,] base-enum):
    pass
Also, subclassing an enumeration is allowed only if the enumeration does not define any members. So this is forbidden:
>>>
>>> class MoreColor(Color):
...     PINK = 17
...
Traceback (most recent call last):
...
TypeError: Cannot extend enumerations
以下のような場合は許されます:
>>>
>>> class Foo(Enum):
...     def some_behavior(self):
...         pass
...
>>> class Bar(Foo):
...     HAPPY = 1
...     SAD = 2
...
メンバーが定義された列挙型のサブクラス化を許可すると、いくつかのデータ型およびインスタンスの重要な不変条件の違反を引き起こします。とはいえ、それが許可されると、列挙型のグループ間での共通の挙動を共有するという利点もあります。 (OrderedEnum の例を参照してください。)
Pickle 化
列挙型は pickle 化と unpickle 化が行えます:
>>>
>>> from test.test_enum import Fruit
>>> from pickle import dumps, loads
>>> Fruit.TOMATO is loads(dumps(Fruit.TOMATO))
True
通常の pickle 化の制限事項が適用されます: pickle 可能な列挙型はモジュールのトップレベルで定義されていなくてはならず、unpickle 化はモジュールからインポート可能でなければなりません。
注釈 pickle プロトコルバージョン 4 では他のクラスで入れ子になった列挙型の pickle 化も容易です。
Enum メンバーをどう pickle 化/unpickle 化するかは、列挙型クラス内の __reduce_ex__() で定義することで変更できます。
機能 API
Enum クラスは呼び出し可能で、以下の機能 API を提供しています:
>>>
>>> Animal = Enum('Animal', 'ANT BEE CAT DOG')
>>> Animal
<enum 'Animal'>
>>> Animal.ANT
<Animal.ANT: 1>
>>> Animal.ANT.value
1
>>> list(Animal)
[<Animal.ANT: 1>, <Animal.BEE: 2>, <Animal.CAT: 3>, <Animal.DOG: 4>]
この API の動作は namedtuple と似ています。Enum 呼び出しの第 1 引数は列挙型の名前です。
第 2 引数は列挙型メンバー名の ソース です。空白で区切った名前の文字列、名前のシーケンス、キー/値のペアの 2 要素タプルのシーケンス、あるいは名前と値のマッピング (例: 辞書) を指定できます。最後の 2 個のオプションでは、列挙型へ任意の値を割り当てることができます。前の 2 つのオプションでは、1 から始まり増加していく整数を自動的に割り当てます (別の開始値を指定するには、start 引数を使用します)。Enum から派生した新しいクラスが返されます。言い換えれば、上記の Animal への割り当ては以下と等価です:
>>>
>>> class Animal(Enum):
...     ANT = 1
...     BEE = 2
...     CAT = 3
...     DOG = 4
...
デフォルトの開始番号が 0 ではなく 1 である理由は、0 がブール演算子では False になりますが、すべての列挙型メンバーの評価は True でなければならないためです。
機能 API による Enum の pickle 化は、その列挙型がどのモジュールで作成されたかを見つけ出すためにフレームスタックの実装の詳細が使われるので、トリッキーになることがあります (例えば別のモジュールのユーティリティ関数を使うと失敗しますし、IronPython や Jython ではうまくいきません)。解決策は、以下のようにモジュール名を明示的に指定することです:
>>>
>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__)
警告 module が与えられない場合、Enum はそれがなにか決定できないため、新しい Enum メンバーは unpickle 化できなくなります; エラーをソースの近いところで発生させるため、pickle 化は無効になります。
新しい pickle プロトコルバージョン 4 では、一部の状況において、pickle がクラスを発見するための場所の設定に __qualname__ を参照します。例えば、そのクラスがグローバルスコープ内のクラス SomeData 内で利用可能とするには以下のように指定します:
>>>
>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', qualname='SomeData.Animal')
完全な構文は以下のようになります:
Enum(value='NewEnumName', names=<...>, *, module='...', qualname='...', type=<mixed-in class>, start=1)
value
新しい Enum クラスに記録されるそれ自身の名前です。
名前
Enum のメンバーです。 空白またはカンマで区切った文字列でも構いません (特に指定がない限り、値は 1 から始まります):
'RED GREEN BLUE' | 'RED,GREEN,BLUE' | 'RED, GREEN, BLUE'
または名前のイテレータで指定もできます:
['RED', 'GREEN', 'BLUE']
または (名前, 値) のペアのイテレータでも指定できます:
[('CYAN', 4), ('MAGENTA', 5), ('YELLOW', 6)]
またはマッピングでも指定できます:
{'CHARTREUSE': 7, 'SEA_GREEN': 11, 'ROSEMARY': 42}
module
新しい Enum クラスが属するモジュールの名前です。
qualname
新しい Enum クラスが属するモジュールの場所です。
type
新しい Enum クラスに複合されるデータ型です。
start
names のみが渡されたときにカウントを開始する数です。
バージョン 3.5 で変更: start 引数が追加されました。
派生列挙型
IntEnum
提供されている 1 つ目の Enum の派生型であり、 int のサブクラスでもあります。 IntEnum のメンバーは整数と比較できます; さらに言うと、異なる整数列挙型どうしでも比較できます:
>>>
>>> from enum import IntEnum
>>> class Shape(IntEnum):
...     CIRCLE = 1
...     SQUARE = 2
...
>>> class Request(IntEnum):
...     POST = 1
...     GET = 2
...
>>> Shape == 1
False
>>> Shape.CIRCLE == 1
True
>>> Shape.CIRCLE == Request.POST
True
ただし、これらも標準の Enum 列挙型とは比較できません:
>>>
>>> class Shape(IntEnum):
...     CIRCLE = 1
...     SQUARE = 2
...
>>> class Color(Enum):
...     RED = 1
...     GREEN = 2
...
>>> Shape.CIRCLE == Color.RED
False
IntEnum の値は他の用途では整数のように振る舞います:
>>>
>>> int(Shape.CIRCLE)
1
>>> ['a', 'b', 'c'][Shape.CIRCLE]
'b'
>>> [i for i in range(Shape.SQUARE)]
[0, 1]
IntFlag
提供されている 2 つ目の Enum の派生型 IntFlag も int を基底クラスとしています。 IntFlag メンバーが Enum メンバーと異なるのは、ビット演算子 (&, |, ^, ~) を使って組み合わせられ、その結果も IntFlag メンバーになることです。 しかし、名前が示すように、 IntFlag は int のサブクラスでもあり、 int が使われるところでもどこでも使えます。 IntFlag メンバーに対してビット演算以外のどんな演算をしても、その結果は IntFlag メンバーではなくなります。
バージョン 3.6 で追加.
IntFlag クラスの例:
>>>
>>> from enum import IntFlag
>>> class Perm(IntFlag):
...     R = 4
...     W = 2
...     X = 1
...
>>> Perm.R | Perm.W
<Perm.R|W: 6>
>>> Perm.R + Perm.W
6
>>> RW = Perm.R | Perm.W
>>> Perm.R in RW
True
組み合わせにも名前を付けられます:
>>>
>>> class Perm(IntFlag):
...     R = 4
...     W = 2
...     X = 1
...     RWX = 7
>>> Perm.RWX
<Perm.RWX: 7>
>>> ~Perm.RWX
<Perm.-8: -8>
IntFlag と Enum のもう 1 つの重要な違いは、フラグが設定されていない (値が0である) 場合、その真偽値としての評価は False になることです:
>>>
>>> Perm.R & Perm.X
<Perm.0: 0>
>>> bool(Perm.R & Perm.X)
False
IntFlag は int のサブクラスでもあるので、その両者を組み合わせられます:
>>>
>>> Perm.X | 8
<Perm.8|X: 9>
Flag
最後の派生型は Flag です。 IntFlag と同様に、 Flag メンバーもビット演算子 (&, |, ^, ~) を使って組み合わせられます。 しかし IntFlag とは違い、他のどの Flag 列挙型とも int とも組み合わせたり、比較したりできません。 値を直接指定することも可能ですが、値として auto を使い、 Flag に適切な値を選ばせることが推奨されています。
バージョン 3.6 で追加.
IntFlag と同様に、 Flag メンバーの組み合わせがどのフラグも設定されていない状態になった場合、その真偽値としての評価は False となります:
>>>
>>> from enum import Flag, auto
>>> class Color(Flag):
...     RED = auto()
...     BLUE = auto()
...     GREEN = auto()
...
>>> Color.RED & Color.GREEN
<Color.0: 0>
>>> bool(Color.RED & Color.GREEN)
False
個別のフラグは 2 のべき乗 (1, 2, 4, 8, ...) の値を持つべきですが、フラグの組み合わせはそうはなりません:
>>>
>>> class Color(Flag):
...     RED = auto()
...     BLUE = auto()
...     GREEN = auto()
...     WHITE = RED | BLUE | GREEN
...
>>> Color.WHITE
<Color.WHITE: 7>
"フラグが設定されていない" 状態に名前を付けても、その真偽値は変わりません:
>>>
>>> class Color(Flag):
...     BLACK = 0
...     RED = auto()
...     BLUE = auto()
...     GREEN = auto()
...
>>> Color.BLACK
<Color.BLACK: 0>
>>> bool(Color.BLACK)
False
注釈 ほとんどの新しいコードでは、 Enum と Flag が強く推奨されます。 というのは、 IntEnum と IntFlag は (整数と比較でき、従って推移的に他の無関係な列挙型と比較できてしまうことにより) 列挙型の意味論的な約束に反するからです。 IntEnum と IntFlag は、 Enum や Flag では上手くいかない場合のみに使うべきです; 例えば、整数定数を列挙型で置き換えるときや、他のシステムとの相互運用性を持たせたいときです。
その他
IntEnum は enum モジュールの一部ですが、単独での実装もとても簡単に行なえます:
class IntEnum(int, Enum):
    pass
ここでは似たような列挙型の派生を定義する方法を紹介します; 例えば、StrEnum は int ではなく str で複合させたものです。
いくつかのルール:
Enum のサブクラスを作成するとき、複合させるデータ型は、基底クラスの並びで Enum 自身より先に記述しなければなりません (上記 IntEnum の例を参照)。
他のデータ型と複合された場合、 value 属性は、たとえ等価であり等価であると比較が行えても、列挙型メンバー自身としては 同じではありません 。
%-方式の書式: %s および %r はそれぞれ Enum クラスの __str__() および __repr__() を呼び出します; その他のコード (IntEnum の %i や %h など) は列挙型のメンバーを複合されたデータ型として扱います。
When to use __new__() vs. __init__()
__new__() must be used whenever you want to customize the actual value of the Enum member. Any other modifications may go in either __new__() or __init__(), with __init__() being preferred.
For example, if you want to pass several items to the constructor, but only want one of them to be the value:
>>>
>>> class Coordinate(bytes, Enum):
...     """
...     Coordinate with binary codes that can be indexed by the int code.
...     """
...     def __new__(cls, value, label, unit):
...         obj = bytes.__new__(cls, [value])
...         obj._value_ = value
...         obj.label = label
...         obj.unit = unit
...         return obj
...     PX = (0, 'P.X', 'km')
...     PY = (1, 'P.Y', 'km')
...     VX = (2, 'V.X', 'km/s')
...     VY = (3, 'V.Y', 'km/s')
...
>>> print(Coordinate['PY'])
Coordinate.PY
>>> print(Coordinate(3))
Coordinate.VY
興味深い例
Enum, IntEnum, IntFlag, Flag は用途の大部分をカバーすると予想されますが、そのすべてをカバーできているわけではありません。 ここでは、そのまま、あるいは独自の列挙型を作る例として使える、様々なタイプの列挙型を紹介します。
値の省略
多くの用途では、列挙型の実際の値が何かは気にされません。 このタイプの単純な列挙型を定義する方法はいくつかあります:
値に auto インスタンスを使用する
値として object インスタンスを使用する
値として解説文字列を使用する
値としてタプルを使用し、独自の __new__() を使用してタプルを int 値で置き換える
これらのどの方法を使ってもユーザーに対して、値は重要ではなく、他のメンバーの番号の振り直しをする必要無しに、メンバーの追加、削除、並べ替えが行えるということを示せます。
どの方法を選んでも、(重要でない) 値を隠す repr() を提供すべきです:
>>>
>>> class NoValue(Enum):
...     def __repr__(self):
...         return '<%s.%s>' % (self.__class__.__name__, self.name)
...
auto を使う
auto を使うと次のようになります:
>>>
>>> class Color(NoValue):
...     RED = auto()
...     BLUE = auto()
...     GREEN = auto()
...
>>> Color.GREEN
<Color.GREEN>
object を使う
object を使うと次のようになります:
>>>
>>> class Color(NoValue):
...     RED = object()
...     GREEN = object()
...     BLUE = object()
...
>>> Color.GREEN
<Color.GREEN>
解説文字列を使う
値として文字列を使うと次のようになります:
>>>
>>> class Color(NoValue):
...     RED = 'stop'
...     GREEN = 'go'
...     BLUE = 'too fast!'
...
>>> Color.GREEN
<Color.GREEN>
>>> Color.GREEN.value
'go'
独自の __new__() を使う
自動で番号を振る __new__() を使うと次のようになります:
>>>
>>> class AutoNumber(NoValue):
...     def __new__(cls):
...         value = len(cls.__members__) + 1
...         obj = object.__new__(cls)
...         obj._value_ = value
...         return obj
...
>>> class Color(AutoNumber):
...     RED = ()
...     GREEN = ()
...     BLUE = ()
...
>>> Color.GREEN
<Color.GREEN>
>>> Color.GREEN.value
2
To make a more general purpose AutoNumber, add *args to the signature:
>>>
>>> class AutoNumber(NoValue):
...     def __new__(cls, *args):      # this is the only change from above
...         value = len(cls.__members__) + 1
...         obj = object.__new__(cls)
...         obj._value_ = value
...         return obj
...
Then when you inherit from AutoNumber you can write your own __init__ to handle any extra arguments:
>>>
>>> class Swatch(AutoNumber):
...     def __init__(self, pantone='unknown'):
...         self.pantone = pantone
...     AUBURN = '3497'
...     SEA_GREEN = '1246'
...     BLEACHED_CORAL = () # New color, no Pantone code yet!
...
>>> Swatch.SEA_GREEN
<Swatch.SEA_GREEN: 2>
>>> Swatch.SEA_GREEN.pantone
'1246'
>>> Swatch.BLEACHED_CORAL.pantone
'unknown'
注釈 __new__() メソッドが定義されていれば、Enum 番号の作成時に使用されます; これは Enum の __new__() と置き換えられ、クラスが作成された後の既存の番号を取得に使用されます。
OrderedEnum
IntEnum をベースとしないため、通常の Enum の不変条件 (他の列挙型と比較できないなど) のままで、メンバーを順序付けできる列挙型です:
>>>
>>> class OrderedEnum(Enum):
...     def __ge__(self, other):
...         if self.__class__ is other.__class__:
...             return self.value >= other.value
...         return NotImplemented
...     def __gt__(self, other):
...         if self.__class__ is other.__class__:
...             return self.value > other.value
...         return NotImplemented
...     def __le__(self, other):
...         if self.__class__ is other.__class__:
...             return self.value <= other.value
...         return NotImplemented
...     def __lt__(self, other):
...         if self.__class__ is other.__class__:
...             return self.value < other.value
...         return NotImplemented
...
>>> class Grade(OrderedEnum):
...     A = 5
...     B = 4
...     C = 3
...     D = 2
...     F = 1
...
>>> Grade.C < Grade.A
True
DuplicateFreeEnum
値が同じメンバーが見つかった場合、別名を作るのではなく、エラーを送出します:
>>>
>>> class DuplicateFreeEnum(Enum):
...     def __init__(self, *args):
...         cls = self.__class__
...         if any(self.value == e.value for e in cls):
...             a = self.name
...             e = cls(self.value).name
...             raise ValueError(
...                 "aliases not allowed in DuplicateFreeEnum:  %r --> %r"
...                 % (a, e))
...
>>> class Color(DuplicateFreeEnum):
...     RED = 1
...     GREEN = 2
...     BLUE = 3
...     GRENE = 2
...
Traceback (most recent call last):
...
ValueError: aliases not allowed in DuplicateFreeEnum:  'GRENE' --> 'GREEN'
注釈 これは Enum に別名を無効にするのと同様な振る舞いの追加や変更をおこなうためのサブクラス化に役立つ例です。単に別名を無効にしたいだけなら、 unique() デコレーターを使用して行えます。
Planet
__new__() や __init__() が定義されている場合、列挙型メンバーの値はこれらのメソッドに渡されます:
>>>
>>> class Planet(Enum):
...     MERCURY = (3.303e+23, 2.4397e6)
...     VENUS   = (4.869e+24, 6.0518e6)
...     EARTH   = (5.976e+24, 6.37814e6)
...     MARS    = (6.421e+23, 3.3972e6)
...     JUPITER = (1.9e+27,   7.1492e7)
...     SATURN  = (5.688e+26, 6.0268e7)
...     URANUS  = (8.686e+25, 2.5559e7)
...     NEPTUNE = (1.024e+26, 2.4746e7)
...     def __init__(self, mass, radius):
...         self.mass = mass       # in kilograms
...         self.radius = radius   # in meters
...     @property
...     def surface_gravity(self):
...         # universal gravitational constant  (m3 kg-1 s-2)
...         G = 6.67300E-11
...         return G * self.mass / (self.radius * self.radius)
...
>>> Planet.EARTH.value
(5.976e+24, 6378140.0)
>>> Planet.EARTH.surface_gravity
9.802652743337129
TimePeriod
An example to show the _ignore_ attribute in use:
>>>
>>> from datetime import timedelta
>>> class Period(timedelta, Enum):
...     "different lengths of time"
...     _ignore_ = 'Period i'
...     Period = vars()
...     for i in range(367):
...         Period['day_%d' % i] = i
...
>>> list(Period)[:2]
[<Period.day_0: datetime.timedelta(0)>, <Period.day_1: datetime.timedelta(days=1)>]
>>> list(Period)[-2:]
[<Period.day_365: datetime.timedelta(days=365)>, <Period.day_366: datetime.timedelta(days=366)>]
Enum はどう違うのか?
Enum は Enum 派生クラスやそれらのインスタンス (メンバー) 双方の多くの側面に影響を及ぼすカスタムメタクラスを持っています。
Enum クラス
Enum メンバー (インスタンス)
Enum メンバーについて最も興味深いのは、それらがシングルトンであるということです。EnumMeta は Enum 自身を作成し、メンバーを作成し、新しいインスタンスが作成されていないかどうかを確認するために既存のメンバーインスタンスだけを返すカスタム __new__() を追加します。
細かい点
__dunder__ 名のサポート
__members__ is a read-only ordered mapping of member_name:member items. It is only available on the class.
__new__() が、もし指定されていた場合、列挙型のメンバーを作成し、返します; そのメンバー の _value_ を適切に設定するのも非常によい考えです。 いったん全てのメンバーが作成されると、それ以降 __new__() は使われません。
_sunder_ 名のサポート
_name_ -- メンバー名
_value_ -- メンバーの値; __new__ で設定したり、変更したりできます
_missing_ -- 値が見付からなかったときに使われる検索関数; オーバーライドされていることがあります
_ignore_ -- a list of names, either as a list or a str, that will not be transformed into members, and will be removed from the final class
_order_ -- used in Python 2/3 code to ensure member order is consistent (class attribute, removed during class creation)
_generate_next_value_ -- used by the Functional API and by auto to get an appropriate value for an enum member; may be overridden
バージョン 3.6 で追加: _missing_, _order_, _generate_next_value_
バージョン 3.7 で追加: _ignore_
To help keep Python 2 / Python 3 code in sync an _order_ attribute can be provided. It will be checked against the actual order of the enumeration and raise an error if the two do not match:
>>>
>>> class Color(Enum):
...     _order_ = 'RED GREEN BLUE'
...     RED = 1
...     BLUE = 3
...     GREEN = 2
...
Traceback (most recent call last):
...
TypeError: member order does not match _order_
注釈 In Python 2 code the _order_ attribute is necessary as definition order is lost before it can be recorded.
_Private__names
Enum メンバー型
Enum メンバーは、それらの Enum クラスのインスタンスで、通常は EnumClass.member のようにアクセスします。 ある状況下では、 EnumClass.member.member としてもアクセスできますが、この方法は絶対に使うべきではありません。 というのは、この検索は失敗するか、さらに悪い場合には、探している Enum メンバー以外のものを返す場合もあるからです (これがメンバーの名前に大文字のみを使うのが良い理由の 1 つでもあります):
>>>
>>> class FieldTypes(Enum):
...     name = 0
...     value = 1
...     size = 2
...
>>> FieldTypes.value.size
<FieldTypes.size: 2>
>>> FieldTypes.size.value
2
バージョン 3.5 で変更.
Enum クラスとメンバーの真偽値
(int, str などのような) 非 Enum 型と複合させた Enum のメンバーは、その複合された型の規則に従って評価されます; そうでない場合は、全てのメンバーは True と評価されます。 メンバーの値に依存する独自の Enum の真偽値評価を行うには、クラスに次のコードを追加してください:
def __bool__(self):
    return bool(self.value)
Enum クラスは常に True と評価されます。
メソッド付きの Enum クラス
Enum サブクラスに追加のメソッドを与えた場合、上述の Planet クラスのように、そのメソッドはメンバーの dir() に表示されますが、クラスの dir() には表示されません:
>>>
>>> dir(Planet)
['EARTH', 'JUPITER', 'MARS', 'MERCURY', 'NEPTUNE', 'SATURN', 'URANUS', 'VENUS', '__class__', '__doc__', '__members__', '__module__']
>>> dir(Planet.EARTH)
['__class__', '__doc__', '__module__', 'name', 'surface_gravity', 'value']
Flag のメンバーの組み合わせ
Flag メンバーの組み合わせに名前が無い場合、 repr() の出力には、その値にある全ての名前を持つフラグと全ての名前を持つ組み合わせが含まれます:
>>>
>>> class Color(Flag):
...     RED = auto()
...     GREEN = auto()
...     BLUE = auto()
...     MAGENTA = RED | BLUE
...     YELLOW = RED | GREEN
...     CYAN = GREEN | BLUE
...
>>> Color(3)  # named combination
<Color.YELLOW: 3>
>>> Color(7)      # not named combination
<Color.CYAN|MAGENTA|BLUE|YELLOW|GREEN|RED: 7>
csv --- CSV ファイルの読み書き
ソースコード: Lib/csv.py
CSV (Comma Separated Values、カンマ区切り値列) と呼ばれる形式は、 スプレッドシートやデータベース間でのデータのインポートやエクスポートにおける最も一般的な形式です。 CSVフォーマットは、 RFC 4180 によって標準的な方法でフォーマットを記述する試みが行われる以前から長年使用されました。明確に定義された標準がないということは、異なるアプリケーション によって生成されたり取り込まれたりするデータ間では、しばしば微妙な違いが発生するということを意味します。こうした違いのために、複数のデータ源から得られた CSV ファイルを処理する作業が鬱陶しいものになることがあります。とはいえ、デリミタ (delimiter) やクオート文字の 相違はあっても、全体的な形式は十分似通っているため、こうしたデータを効率的に操作し、データの読み書きにおける細々としたことをプログラマ から隠蔽するような単一のモジュールを書くことは可能です。
csv モジュールでは、CSV 形式で書かれたテーブル状のデータを読み書きするためのクラスを実装しています。このモジュールを使うことで、プログラマは Excel で使われている CSV 形式に関して詳しい知識をもっていなくても、 "このデータを Excel で推奨されている形式で書いてください" とか、 "データを Excel で作成されたこのファイルから読み出してください" と言うことができます。プログラマはまた、他のアプリケーションが解釈できる CSV 形式を記述したり、独自の特殊な目的をもった CSV 形式を定義することができます。
csv モジュールの reader および writer オブジェクトはシーケンス型を読み書きします。プログラマは DictReader や DictWriter クラスを使うことで、データを辞書形式で読み書きすることもできます。
参考
PEP 305 - CSV File API
Python へのこのモジュールの追加を提案している Python 改良案 (PEP: Python Enhancement Proposal)。
モジュールコンテンツ
csv モジュールでは以下の関数を定義しています:
csv.reader(csvfile, dialect='excel', **fmtparams)
与えられた csvfile 内の行を反復処理するような reader オブジェクトを返します。 csvfile は イテレータ プロトコルをサポートし、 __next__() メソッドが呼ばれた際に常に文字列を返すような任意のオブジェクトにすることができます --- ファイルオブジェクト でもリストでも構いません。 csvfile がファイルオブジェクトの場合、 newline='' として開くべきです。 1 オプションとして dialect パラメータを与えることができ、特定の CSV 表現形式 (dialect) 特有のパラメータの集合を定義するために使われます。 dialect 引数は Dialect クラスのサブクラスのインスタンスか、 list_dialects() 関数が返す文字列の一つにすることができます。別のオプションである fmtparams キーワード引数は、現在の表現形式における個々の書式パラメータを上書きするために与えることができます。表現形式および書式化パラメータの詳細については、 Dialect クラスと書式化パラメータ 節を参照してください。
csv ファイルから読み込まれた各行は、文字列のリストとして返されます。QUOTE_NONNUMERIC フォーマットオプションが指定された場合を除き、データ型の変換が自動的に行われることはありません (このオプションが指定された場合、クォートされていないフィールドは浮動小数点数に変換されます)。
短い利用例:
>>>
>>> import csv
>>> with open('eggs.csv', newline='') as csvfile:
...     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')
...     for row in spamreader:
...         print(', '.join(row))
Spam, Spam, Spam, Spam, Spam, Baked Beans
Spam, Lovely Spam, Wonderful Spam
csv.writer(csvfile, dialect='excel', **fmtparams)
ユーザが与えたデータをデリミタで区切られた文字列に変換し、与えられたファイルオブジェクトに書き込むための writer オブジェクトを返します。 csvfile は write() メソッドを持つ任意のオブジェクトです。 csvfile がファイルオブジェクトの場合、 newline='' として開くべきです 1 。オプションとして dialect 引数を与えることができ、利用するCSV表現形式(dialect)を指定することができます。 dialect パラメータは Dialect クラスのサブクラスのインスタンスか、 list_dialects() 関数が返す文字列の1つにすることができます。別のオプション引数である fmtparams キーワード引数は、現在の表現形式における個々の書式パラメータを上書きするために与えることができます。dialect と書式パラメータについての詳細は、 Dialect クラスと書式化パラメータ 節を参照してください。 DB API を実装するモジュールとのインタフェースを可能な限り容易にするために、 None は空文字列として書き込まれます。この処理は可逆な変換ではありませんが、SQL で NULL データ値を CSV にダンプする処理を、 cursor.fetch* 呼び出しによって返されたデータを前処理することなく簡単に行うことができます。他の非文字列データは、書き出される前に str() を使って文字列に変換されます。
短い利用例:
import csv
with open('eggs.csv', 'w', newline='') as csvfile:
    spamwriter = csv.writer(csvfile, delimiter=' ',
                            quotechar='|', quoting=csv.QUOTE_MINIMAL)
    spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])
    spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])
csv.register_dialect(name[, dialect[, **fmtparams]])
dialect を name と関連付けます。 name は文字列でなければなりません。表現形式(dialect)は Dialect のサブクラスを渡すか、またはキーワード引数 fmtparams 、もしくは両方で指定できますが、キーワード引数の方が優先されます。表現形式と書式化パラメータについての詳細は、 Dialect クラスと書式化パラメータ 節を参照してください。
csv.unregister_dialect(name)
name に関連づけられた表現形式を表現形式レジストリから削除します。 name が表現形式名でない場合には Error を送出します。
csv.get_dialect(name)
name に関連づけられた表現形式を返します。 name が表現形式名でない場合には Error を送出します。この関数は不変の Dialect を返します。
csv.list_dialects()
登録されている全ての表現形式を返します。
csv.field_size_limit([new_limit])
パーサが許容する現在の最大フィールドサイズを返します。 new_limit が渡されたときは、その値が新しい上限になります。
csv モジュールでは以下のクラスを定義しています:
class csv.DictReader(f, fieldnames=None, restkey=None, restval=None, dialect='excel', *args, **kwds)
その他の省略可能またはキーワード形式のパラメータは、ベースになっている reader インスタンスに渡されます。
バージョン 3.6 で変更: 返される列の型は OrderedDict になりました。
バージョン 3.8 で変更: 返される列の型は dict になりました。
短い利用例:
>>>
>>> import csv
>>> with open('names.csv', newline='') as csvfile:
...     reader = csv.DictReader(csvfile)
...     for row in reader:
...         print(row['first_name'], row['last_name'])
...
Eric Idle
John Cleese
>>> print(row)
{'first_name': 'John', 'last_name': 'Cleese'}
class csv.DictWriter(f, fieldnames, restval='', extrasaction='raise', dialect='excel', *args, **kwds)
通常の writer のように動作しますが、辞書を出力行にマップするオブジェクトを生成します。 fieldnames パラメータは、writerow() メソッドに渡された辞書の値がどのような順番でファイル f に書かれるかを指定するキーの sequence です。 writerow() メソッドに渡された辞書に fieldnames には存在しないキーが含まれている場合、オプションの extrasaction パラメータによってどんな動作を行うかが指定されます。この値がデフォルト値である 'raise' に設定されている場合、 ValueError が送出されます。 'ignore' に設定されている場合、辞書の余分な値は無視されます。その他のパラメータはベースになっている writer インスタンスに渡されます。
DictReader クラスとは異なり、 DictWriter の fieldnames パラメータは省略可能ではありません。
短い利用例:
import csv
with open('names.csv', 'w', newline='') as csvfile:
    fieldnames = ['first_name', 'last_name']
    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerow({'first_name': 'Baked', 'last_name': 'Beans'})
    writer.writerow({'first_name': 'Lovely', 'last_name': 'Spam'})
    writer.writerow({'first_name': 'Wonderful', 'last_name': 'Spam'})
class csv.Dialect
Dialect クラスはコンテナクラスで、基本的な用途としては、その属性を特定の reader や writer インスタンスのパラメータを定義するために用います。
class csv.excel
excel クラスは Excel で生成される CSV ファイルの通常のプロパティを定義します。これは 'excel' という名前の dialect として登録されています。
class csv.excel_tab
excel_tab クラスは Excel で生成されるタブ分割ファイルの通常のプロパティを定義します。これは 'excel-tab' という名前の dialect として登録されています。
class csv.unix_dialect
unix_dialect クラスは UNIX システムで生成される CSV ファイルの通常のプロパティ (行終端記号として '\n' を用い全てのフィールドをクォートするもの) を定義します。これは 'unix' という名前の dialect として登録されています。
バージョン 3.2 で追加.
class csv.Sniffer
Sniffer クラスは CSV ファイルの書式を推理するために用いられるクラスです。
Sniffer クラスではメソッドを二つ提供しています:
sniff(sample, delimiters=None)
与えられた sample を解析し、発見されたパラメータを反映した Dialect サブクラスを返します。オプションの delimiters パラメータを与えた場合、有効なデリミタ文字を含んでいるはずの文字列として解釈されます。
has_header(sample)
(CSV 形式と仮定される) サンプルテキストを解析して、最初の行がカラムヘッダの羅列のように推察される場合 True を返します。
Sniffer の利用例:
with open('example.csv', newline='') as csvfile:
    dialect = csv.Sniffer().sniff(csvfile.read(1024))
    csvfile.seek(0)
    reader = csv.reader(csvfile, dialect)
    # ... process CSV file contents here ...
csv モジュールでは以下の定数を定義しています:
csv.QUOTE_ALL
writer オブジェクトに対し、全てのフィールドをクオートするように指示します。
csv.QUOTE_MINIMAL
writer オブジェクトに対し、 delimiter 、 quotechar または lineterminator に含まれる任意の文字のような特別な文字を含むフィールドだけをクオートするように指示します。
csv.QUOTE_NONNUMERIC
writer オブジェクトに対し、全ての非数値フィールドをクオートするように指示します。
reader に対しては、クオートされていない全てのフィールドを float 型に変換するよう指示します。
csv.QUOTE_NONE
writer オブジェクトに対し、フィールドを決してクオートしないように指示します。現在の delimiter が出力データ中に現れた場合、現在設定されている escapechar 文字が前に付けられます。 escapechar がセットされていない場合、エスケープが必要な文字に遭遇した writer は Error を送出します。
reader に対しては、クオート文字の特別扱いをしないように指示します。
csv モジュールでは以下の例外を定義しています:
exception csv.Error
全ての関数において、エラーが検出された際に送出される例外です。
Dialect クラスと書式化パラメータ
レコードに対する入出力形式の指定をより簡単にするために、特定の書式化パラメータは表現形式 (dialect) にまとめてグループ化されます。表現形式は Dialect クラスのサブクラスで、様々なクラス特有のメソッドと、 validate() メソッドを一つ持っています。 reader または writer オブジェクトを生成するとき、プログラマは文字列または Dialect クラスのサブクラスを表現形式パラメータとして渡さなければなりません。さらに、 dialect パラメータの代りに、プログラマは上で定義されている属性と同じ名前を持つ個々の書式化パラメータを Dialect クラスに指定することができます。
Dialect は以下の属性をサポートしています:
Dialect.delimiter
フィールド間を分割するのに用いられる 1 文字からなる文字列です。デフォルトでは ',' です。
Dialect.doublequote
フィールド内に現れた quotechar のインスタンスで、クオートではないその文字自身でなければならない文字をどのようにクオートするかを制御します。 True の場合、この文字は二重化されます。 False の場合、 escapechar は quotechar の前に置かれます。デフォルトでは True です。
出力においては、 doublequote が False で escapechar がセットされていない場合、フィールド内に quotechar が現れると Error が送出されます。
Dialect.escapechar
writer が、 quoting が QUOTE_NONE に設定されている場合に delimiter をエスケープするため、および、 doublequote が False の場合に quotechar をエスケープするために用いられる、 1 文字からなる文字列です。読み込み時には escapechar はそれに引き続く文字の特別な意味を取り除きます。デフォルトでは None で、エスケープを行ないません。
Dialect.lineterminator
writer が作り出す各行を終端する際に用いられる文字列です。デフォルトでは '\r\n' です。
注釈 reader は '\r' または '\n' のどちらかを行末と認識するようにハードコードされており、 lineterminator を無視します。この振る舞いは将来変更されるかもしれません。
Dialect.quotechar
delimiter や quotechar といった特殊文字を含むか、改行文字を含むフィールドをクオートする際に用いられる 1 文字からなる文字列です。デフォルトでは '"' です。
Dialect.quoting
クオートがいつ writer によって生成されるか、また reader によって認識されるかを制御します。 QUOTE_* 定数のいずれか (モジュールコンテンツ 節参照) をとることができ、デフォルトでは QUOTE_MINIMAL です。
Dialect.skipinitialspace
True の場合、 delimiter の直後に続く空白は無視されます。デフォルトでは False です。
Dialect.strict
True の場合、 不正な CSV 入力に対して Error を送出します。デフォルトでは False です。
reader オブジェクト
reader オブジェクト(DictReader インスタンス、および reader() 関数によって返されたオブジェクト) は、以下の public なメソッドを持っています:
csvreader.__next__()
reader の反復可能なオブジェクトから、現在の表現形式に基づいて次の行を解析してリスト（オブジェクトが reader() から返された場合）または辞書 （ DictReader のインスタンスの場合）として返します。通常は next(reader) のようにして呼び出すことになります。
reader オブジェクトには以下の公開属性があります:
csvreader.dialect
パーサで使われる表現形式の読み出し専用の記述です。
csvreader.line_num
ソースイテレータから読んだ行数です。この数は返されるレコードの数とは、レコードが複数行に亘ることがあるので、一致しません。
DictReader オブジェクトは、以下の public な属性を持っています:
csvreader.fieldnames
オブジェクトを生成するときに渡されなかった場合、この属性は最初のアクセス時か、ファイルから最初のレコードを読み出したときに初期化されます。
writer オブジェクト
Writer オブジェクト(DictWriter インスタンス、および writer() 関数によって返されたオブジェクト) は、以下の public なメソッドを持っています: row には、 Writer オブジェクトの場合には文字列か数値のイテラブルを指定し、 DictWriter オブジェクトの場合はフィールド名をキーとして対応する文字列か数値を格納した辞書オブジェクトを指定します(数値は str() で変換されます)。複素数を出力する場合、値をかっこで囲んで出力します。このため、CSV ファイルを読み込むアプリケーションで（そのアプリケーションが複素数をサポートしていたとしても）問題が発生する場合があります。
csvwriter.writerow(row)
バージョン 3.5 で変更: 任意のイテラブルのサポートの追加。
csvwriter.writerows(rows)
rows 引数 (上で解説した row オブジェクトのイテラブル) の全ての要素を現在の表現形式に基づいて書式化し、writer のファイルオブジェクトに書き込みます。
writer オブジェクトには以下の公開属性があります:
csvwriter.dialect
writer で使われる表現形式の読み出し専用の記述です。
DictWriter のオブジェクトは以下の public メソッドを持っています:
DictWriter.writeheader()
バージョン 3.2 で追加.
バージョン 3.8 で変更: writeheader() now also returns the value returned by the csvwriter.writerow() method it uses internally.
使用例
最も簡単な CSV ファイル読み込みの例です:
import csv
with open('some.csv', newline='') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
別の書式での読み込み:
import csv
with open('passwd', newline='') as f:
    reader = csv.reader(f, delimiter=':', quoting=csv.QUOTE_NONE)
    for row in reader:
        print(row)
上に対して、単純な書き込みのプログラム例は以下のようになります。
import csv
with open('some.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerows(someiterable)
open() が CSV ファイルの読み込みに使われるため、ファイルはデフォルトではシステムのデフォルトエンコーディングでユニコード文字列にデコードされます (locale.getpreferredencoding() を参照)。他のエンコーディングを用いてデコードするには、open の引数 encoding を設定して、以下のようにします:
import csv
with open('some.csv', newline='', encoding='utf-8') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
システムのデフォルトエンコーディング以外で書き込む場合も同様です。出力ファイルを開く際に引数 encoding を明示してください。
新しい表現形式の登録:
import csv
csv.register_dialect('unixpwd', delimiter=':', quoting=csv.QUOTE_NONE)
with open('passwd', newline='') as f:
    reader = csv.reader(f, 'unixpwd')
もう少し手の込んだ reader の使い方 --- エラーを捉えてレポートします。
import csv, sys
filename = 'some.csv'
with open(filename, newline='') as f:
    reader = csv.reader(f)
    try:
        for row in reader:
            print(row)
    except csv.Error as e:
        sys.exit('file {}, line {}: {}'.format(filename, reader.line_num, e))
このモジュールは文字列の解析は直接サポートしませんが、簡単にできます。
import csv
for row in csv.reader(['one,two,three']):
    print(row)
脚注
1(1,2)
newline='' が指定されない場合、クォートされたフィールド内の改行は適切に解釈されず、書き込み時に \r\n を行末に用いる処理系では余分な \r が追加されてしまいます。csv モジュールは独自 (universal) の改行処理を行うため、newline='' を指定することは常に安全です。
configparser --- 設定ファイルのパーサー
ソースコード: Lib/configparser.py
このモジュールは、 Microsoft Windows の INI ファイルに似た構造を持ったベーシックな設定用言語を実装した ConfigParser クラスを提供します。このクラスを使ってユーザーが簡単にカスタマイズできる Python プログラムを作ることができます。
注釈 このライブラリでは、Windowsのレジストリ用に拡張された INI 文法はサポート していません 。
参考
shlex モジュール
アプリケーション設定ファイルのフォーマットとして使える、Unix シェルに似たミニ言語の作成を支援します。
json モジュール
json モジュールは、同じ目的に利用できる JavaScript の文法のサブセットを実装しています。
クイックスタート
次のような、非常に簡単な設定ファイルを例に考えましょう:
[DEFAULT]
ServerAliveInterval = 45
Compression = yes
CompressionLevel = 9
ForwardX11 = yes
[bitbucket.org]
User = hg
[topsecret.server.com]
Port = 50022
ForwardX11 = no
INI ファイルの構造は 下のセクション で解説します。 基本的に、ファイルは複数のセクションからなり、各セクションは複数のキーと値を持ちます。 configparser のクラス群はそれらのファイルを読み書きできます。 まずは上のような設定ファイルをプログラムから作成してみましょう。
>>> import configparser
>>> config = configparser.ConfigParser()
>>> config['DEFAULT'] = {'ServerAliveInterval': '45',
...                      'Compression': 'yes',
...                      'CompressionLevel': '9'}
>>> config['bitbucket.org'] = {}
>>> config['bitbucket.org']['User'] = 'hg'
>>> config['topsecret.server.com'] = {}
>>> topsecret = config['topsecret.server.com']
>>> topsecret['Port'] = '50022'     # mutates the parser
>>> topsecret['ForwardX11'] = 'no'  # same here
>>> config['DEFAULT']['ForwardX11'] = 'yes'
>>> with open('example.ini', 'w') as configfile:
...   config.write(configfile)
...
この例でわかるように、config parser は辞書のように扱うことができます。辞書との違いは 後に 説明しますが、このインターフェイスは辞書に対して期待するのととても近い動作をします。
これで設定ファイルを作成して保存できました。次はこれを読み込み直して、中のデータを取り出してみましょう。
>>> config = configparser.ConfigParser()
>>> config.sections()
[]
>>> config.read('example.ini')
['example.ini']
>>> config.sections()
['bitbucket.org', 'topsecret.server.com']
>>> 'bitbucket.org' in config
True
>>> 'bytebong.com' in config
False
>>> config['bitbucket.org']['User']
'hg'
>>> config['DEFAULT']['Compression']
'yes'
>>> topsecret = config['topsecret.server.com']
>>> topsecret['ForwardX11']
'no'
>>> topsecret['Port']
'50022'
>>> for key in config['bitbucket.org']:  
...     print(key)
user
compressionlevel
serveraliveinterval
compression
forwardx11
>>> config['bitbucket.org']['ForwardX11']
'yes'
上の例からわかるように、API はとても直感的です。唯一の魔術は、DEFAULT セクションが他の全てのセクションのためのデフォルト値を提供していることです 1。 また、セクション内の各キーは大文字小文字を区別せず、全て小文字で保存されていることにも注意してください 1。
サポートされるデータ型
Config parser は値のデータ型について何も推論せず、常に文字列のまま内部に保存します。他のデータ型が必要な場合は自分で変換する必要があります:
>>> int(topsecret['Port'])
50022
>>> float(topsecret['CompressionLevel'])
9.0
このタスクはとても一般的なため、設定パーサーでは整数、浮動小数点数、真偽値を扱うための手頃なゲッターメソッドが提供されています。真偽値の扱いは一筋縄ではいきません。文字列を bool() に渡しても、 bool('False') が True になってしまいます。そこで config parser は getboolean() を提供しています。このメソッドは大文字小文字を区別せず、 'yes'/'no'、'on'/'off'、'true'/'false'、'1'/'0' を真偽値として認識します 1。例えば:
>>> topsecret.getboolean('ForwardX11')
False
>>> config['bitbucket.org'].getboolean('ForwardX11')
True
>>> config.getboolean('bitbucket.org', 'Compression')
True
config parser では、 getboolean() 以外に getint() と getfloat() メソッドも提供されています。独自のコンバーターの登録、提供されたメソッドのカスタマイズもできます。 1
代替値
辞書と同じように、セクションの get() メソッドは代替値を提供しています:
>>> topsecret.get('Port')
'50022'
>>> topsecret.get('CompressionLevel')
'9'
>>> topsecret.get('Cipher')
>>> topsecret.get('Cipher', '3des-cbc')
'3des-cbc'
デフォルト値は代替値よりも優先されることに注意してください。例えば上の例では、'CompressionLevel' キーは 'DEFAULT' セクションにしか存在しません。その値を 'topsecret.server.com' から取得しようとした場合、代替値を指定しても常にデフォルト値を返します:
>>> topsecret.get('CompressionLevel', '3')
'9'
もう一つ注意すべき点は、パーサーレベルの (訳注: ConfigParserクラスの) get() メソッドは、後方互換性のために、カスタムのより複雑なインターフェースを提供します。 このメソッドを使用する際には、フォールバック値はキーワード専用引数 fallback を介して提供されます:
>>> config.get('bitbucket.org', 'monster',
...            fallback='No such things as monsters')
'No such things as monsters'
同様の fallback 引数を、getint() 、 getfloat() と getboolean() メソッドでも使えます。例えば:
>>> 'BatchMode' in topsecret
False
>>> topsecret.getboolean('BatchMode', fallback=True)
True
>>> config['DEFAULT']['BatchMode'] = 'no'
>>> topsecret.getboolean('BatchMode', fallback=True)
False
サポートするINI ファイルの構造
設定ファイルは複数のセクションから構成されます。セクションは、[section] ヘッダに続いた、特定の文字列(デフォルトでは = または : 1 )で区切られたキーと値のエントリです。デフォルトでは、セクション名は大文字と小文字を区別しますが、キーはそうではありません 1。キーと値、それぞれの先頭と末尾の空白は取り除かれます。値は省略することができ、その際でも、キーと値の区切り文字は残しておけます。値はまた、値の先頭の行より深くインデントされていれば、複数の行にまたがっても構いません。パーサーのモードによって、空白行は、複数行からなる値の一部として扱われるか、無視されます。
設定ファイルには先頭に特定の文字 (デフォルトでは # および ; 1) をつけてコメントをつけることができます。コメントは、他の内容がない行に置くことができ、インデントされていても構いません。1
例えば:
[Simple Values]
key=value
spaces in keys=allowed
spaces in values=allowed as well
spaces around the delimiter = obviously
you can also use : to delimit keys from values
[All Values Are Strings]
values like this: 1000000
or this: 3.14159265359
are they treated as numbers? : no
integers, floats and booleans are held as: strings
can use the API to get converted values directly: true
[Multiline Values]
chorus: I'm a lumberjack, and I'm okay
    I sleep all night and I work all day
[No Values]
key_without_value
empty string value here =
[You can use comments]
# like this
; or this
# By default only in an empty line.
# Inline comments can be harmful because they prevent users
# from using the delimiting characters as parts of values.
# That being said, this can be customized.
    [Sections Can Be Indented]
        can_values_be_as_well = True
        does_that_mean_anything_special = False
        purpose = formatting for readability
        multiline_values = are
            handled just fine as
            long as they are indented
            deeper than the first line
            of a value
        # Did I mention we can indent comments, too?
値の補間
コア機能に加えて、 ConfigParser は補間(interpolation, 内挿とも)をサポートします。これは get() コールが値を返す前に、その値に対して前処理を行えることを意味します。
class configparser.BasicInterpolation
ConfigParser が使用するデフォルト実装です。値に、同じセクションか特別なデフォルトセクション中 1 の他の値を参照するフォーマット文字列を含めることができます。追加のデフォルト値を初期化時に提供できます。
例えば:
[Paths]
home_dir: /Users
my_dir: %(home_dir)s/lumberjack
my_pictures: %(my_dir)s/Pictures
[Escape]
gain: 80%%  # use a %% to escape the % sign (% is the only character that needs to be escaped)
上の例では、 interpolation に BasicInterpolation() を設定した ConfigParser が %(home_dir)s を home_dir の値(このケースでは /Users )として解決しています、その結果 %(my_dir)s は /Users/lumberjack になります。全ての補間は必要に応じて実行されるため、設定ファイル中で参照の連鎖をもつキーを特定の順序で記述する必要はありません。
interpolation に None を設定すれば、パーサーは単に my_pictures の値として %(my_dir)s/Pictures を返し、my_dir の値として %(home_dir)s/lumberjack を返します。
class configparser.ExtendedInterpolation
zc.buildout で使用されるような、より高度な文法を実装した補間ハンドラの別の選択肢です。拡張された補間は、他のセクション中の値を示すのに ${section:option} と書けます。補間は複数のレベルに及べます、利便性のために、もし section: の部分が省略されると、現在のセクションがデフォルト値となります(スペシャルセクション中のデフォルト値を使用することもできます)。
たとえば、上記の basic interpolation で指定した設定は、extended interpolation を使うと下記のようになります:
[Paths]
home_dir: /Users
my_dir: ${home_dir}/lumberjack
my_pictures: ${my_dir}/Pictures
[Escape]
cost: $$80  # use a $$ to escape the $ sign ($ is the only character that needs to be escaped)
他のセクションから値を持ってくることもできます:
[Common]
home_dir: /Users
library_dir: /Library
system_dir: /System
macports_dir: /opt/local
[Frameworks]
Python: 3.2
path: ${Common:system_dir}/Library/Frameworks/
[Arthur]
nickname: Two Sheds
last_name: Jackson
my_dir: ${Common:home_dir}/twosheds
my_pictures: ${my_dir}/Pictures
python_dir: ${Frameworks:path}/Python/Versions/${Frameworks:Python}
マップ型プロトコルアクセス
バージョン 3.2 で追加.
マップ型プロトコルアクセスは、カスタムオブジェクトを辞書であるかのように使うための機能の総称です。 configparser の場合、マップ型インタフェースの実装は parser['section']['option'] 表記を使います。
とくに、parser['section'] はパーサー内のそのセクションのデータへのプロキシを返します。つまり、値はコピーされるのではなく必要に応じてオリジナルのパーサーから取られます。さらに重要なことに、セクションのプロキシの値が変更されると、オリジナルのパーサー中の値が実際に変更されます。
configparser は可能な限り実際の辞書と近い振る舞いをします。マップ型インタフェースは MutableMapping を矛盾なく完成します。しかし、考慮するべき違いがいくつかあります:
デフォルトでは、セクション内の全てのキーは大文字小文字の区別なくアクセスできます 1。例えば、for option in parser["section"] は optionxform されたオプションキー名のみを yield します。つまり小文字のキーがデフォルトです。同時に、キー 'a' を含むセクションにおいて、どちらの式も True を返します:
"a" in parser["section"]
"A" in parser["section"]
全てのセクションは DEFAULTSECT 値を持ち、すなわちセクションで .clear() してもセクションは見た目上空になりません。これは、デフォルト値は (技術的にはそこにないので) セクションから削除できないためです。デフォルト値が上書きされた場合、それが削除されるとデフォルト値が再び見えるようになります。デフォルト値を削除しようとすると KeyError が発生します。
DEFAULTSECT はパーサーから取り除けません:
削除しようとすると ValueError が発生します。
parser.clear() はこれをそのまま残し、
parser.popitem() がこれを返すことはありません。
parser.get(section, option, **kwargs) - 第二引数は代替値では ありません。ただし、セクションごとの get() メソッドはマップ型プロトコルと旧式の configparser API の両方に互換です。
parser.items() はマップ型プロトコルと互換です (DEFAULTSECT を含む section_name, section_proxy 対のリストを返します)。ただし、このメソッドは parser.items(section, raw, vars) のようにして引数を与えることでも呼び出せます。後者の呼び出しは指定された section の option, value 対のリストを、(raw=True が与えられない限り) 全ての補間を展開して返します。
マップ型プロトコルは、既存のレガシーな API の上に実装されているので、オリジナルのインタフェースを上書きする派生クラスもまたは期待どおりにはたらきます。
パーサーの振る舞いをカスタマイズする
INI フォーマットの変種は、それを使うアプリケーションの数と同じくらい多く存在します。 configparser は、可能な限り広い範囲の INI スタイルを集めた集合をサポートするために、非常に役立ちます。デフォルトの機能は主に歴史的背景によって決められたので、機能によってはカスタマイズしてお使いください。
特定の設定パーサーのはたらきを変える最も一般的な方法は __init__() オプションを使うことです:
defaults, デフォルト値: None
このオプションは最初に DEFAULT セクションに加えられるキー-値の対の辞書を受け付けます。
ヒント: 特定のセクションにデフォルト値を指定したいなら、実際のファイルを読み込む前に read_dict() を使ってください。
dict_type, default value: dict
Please note: there are ways to add a set of key-value pairs in a single operation. When you use a regular dictionary in those operations, the order of the keys will be ordered. For example:
>>> parser = configparser.ConfigParser()
>>> parser.read_dict({'section1': {'key1': 'value1',
...                                'key2': 'value2',
...                                'key3': 'value3'},
...                   'section2': {'keyA': 'valueA',
...                                'keyB': 'valueB',
...                                'keyC': 'valueC'},
...                   'section3': {'foo': 'x',
...                                'bar': 'y',
...                                'baz': 'z'}
... })
>>> parser.sections()
['section1', 'section2', 'section3']
>>> [option for option in parser['section3']]
['foo', 'bar', 'baz']
allow_no_value, デフォルト値: False
一部の設定ファイルには値のない設定項目がありますが、それ以外は ConfigParser がサポートする文法に従います。コンストラクタの allow_no_value 引数で、そのような値を許可することができます。
>>> import configparser
>>> sample_config = """
... [mysqld]
...   user = mysql
...   pid-file = /var/run/mysqld/mysqld.pid
...   skip-external-locking
...   old_passwords = 1
...   skip-bdb
...   # we don't need ACID today
...   skip-innodb
... """
>>> config = configparser.ConfigParser(allow_no_value=True)
>>> config.read_string(sample_config)
>>> # Settings with values are treated as before:
>>> config["mysqld"]["user"]
'mysql'
>>> # Settings without values provide None:
>>> config["mysqld"]["skip-bdb"]
>>> # Settings which aren't specified still raise an error:
>>> config["mysqld"]["does-not-exist"]
Traceback (most recent call last):
  ...
KeyError: 'does-not-exist'
delimiters, デフォルト値: ('=', ':')
デリミタはセクション内でキーを値から区切る部分文字列です。行中で最初に現れた区切り部分文字列がデリミタと見なされます。つまり値にはデリミタを含めることができます (キーには含めることができません)。
ConfigParser.write() の space_around_delimiters 引数も参照してください。
comment_prefixes, デフォルト値: ('#', ';')
inline_comment_prefixes, デフォルト値: None
コメント接頭辞は設定ファイル中で有効なコメントの開始を示す文字列です。comment_prefixes は他の内容がない行 (インデントは自由) にのみ使用でき、inline_comment_prefixes は任意の有効な値 (例えば、セクション名、オプション、空行も可能) の後に使えます。デフォルトではインラインコメントは無効化されていて、'#' と ';' を行全体のコメントに使用します。
バージョン 3.2 で変更: 以前のバージョンの configparser の振る舞いは comment_prefixes=('#',';') および inline_comment_prefixes=(';',) に該当します。
設定パーサーはコメント接頭辞のエスケープをサポートしないので、inline_comment_prefixes はユーザーがコメント接頭辞として使われる文字を含むオプション値を指定するのを妨げる可能性があります。疑わしい場合には、inline_comment_prefixes を設定しないようにしてください。どのような状況でも、複数行にわたる値で、行の先頭にコメント接頭辞文字を保存する唯一の方法は、次の例のように接頭辞を補間することです:
>>>
>>> from configparser import ConfigParser, ExtendedInterpolation
>>> parser = ConfigParser(interpolation=ExtendedInterpolation())
>>> # the default BasicInterpolation could be used as well
>>> parser.read_string("""
... [DEFAULT]
... hash = #
...
... [hashes]
... shebang =
...   ${hash}!/usr/bin/env python
...   ${hash} -*- coding: utf-8 -*-
...
... extensions =
...   enabled_extension
...   another_extension
...   #disabled_by_comment
...   yet_another_extension
...
... interpolation not necessary = if # is not at line start
... even in multiline values = line #1
...   line #2
...   line #3
... """)
>>> print(parser['hashes']['shebang'])
#!/usr/bin/env python
# -*- coding: utf-8 -*-
>>> print(parser['hashes']['extensions'])
enabled_extension
another_extension
yet_another_extension
>>> print(parser['hashes']['interpolation not necessary'])
if # is not at line start
>>> print(parser['hashes']['even in multiline values'])
line #1
line #2
line #3
strict, デフォルト値: True
True に設定された場合、パーサーは単一のソースから (read_file(), read_string() または read_dict() を使って) 読み込むときにセクションやオプションの重複を許さなくなります。新しいアプリケーションには strict なパーサーを使うことが推奨されます。
バージョン 3.2 で変更: 以前のバージョンの configparser の振る舞いは strict=False に該当します。
empty_lines_in_values, デフォルト値: True
設定パーサーでは、キーよりもその値を深くインデントするかぎり、複数行にまたがる値を使えます。デフォルトのパーサーはさらにその値の間に空行を置けます。同時に、キーは読みやすくするため任意にインデントできます。結果として、設定ファイルが大きく複雑になったとき、ユーザーがファイル構造を見失いやすいです。この例をご覧ください:
[Section]
key = multiline
  value with a gotcha
 this = is still a part of the multiline value of 'key'
これは特にプロポーショナルフォントを使ってファイルを編集しているユーザーにとって問題になることがあります。だから、アプリケーションの値に空行が必要ないなら、空行を認めないべきです。これによって空行で必ずキーが分かれます。上の例では、2 つのキー、key および this が作られます。
default_section, デフォルト値: configparser.DEFAULTSECT (すなわち: "DEFAULT")
他のセクションのデフォルト値や補間目的での特別なセクションを認める慣行はこのライブラリの明確なコンセプトの一つで、ユーザーは複雑で宣言的な設定を作成できます。このセクションは通常 "DEFAULT" と呼ばれますが、任意の有効なセクション名を指すようにカスタマイズできます。典型的な値には "general" や "common" があります。与えられた名前はソースを読み込む際にデフォルトセクションを認識するのに使われ、設定をファイルに書き戻すときにも使われます。現在の値は parser_instance.default_section 属性から取り出すことができ、実行時 (すなわちファイルを別のフォーマットに変換するとき) に変更することもできます。
interpolation, デフォルト値: configparser.BasicInterpolation
補間の振る舞いは、 interpolation 引数を通してカスタムハンドラを与えることでカスタマイズできます。 None 引数を使うと補間を完全に無効にできます。 ExtendedInterpolation() は、 zc.buildout に影響を受けたより高度な補間を提供します。この話題に 特化したドキュメントのセクション をご覧ください。 RawConfigParser のデフォルト値は None です。
converters, デフォルト値: 未設定
設定パーサーは、型変換を実行するオプションの値ゲッターを提供します。デフォルトでは、 getint()、 getfloat()、 getboolean() が実装されています。他のゲッターが必要な場合、ユーザーはそれらをサブクラスで定義するか、辞書を渡します。辞書を渡す場合、各キーはコンバーターの名前で、値は当該変換を実装する呼び出し可能オブジェクトです。例えば、 {'decimal': decimal.Decimal} を渡すと、パーサーオブジェクトとすべてのセクションプロキシの両方に、 getdecimal() が追加されます。つまり、parser_instance.getdecimal('section', 'key', fallback=0) と parser_instance['section'].getdecimal('key', 0) の両方の方法で書くことができます。
コンバーターがパーサーの状態にアクセスする必要がある場合、設定パーサーサブクラスでメソッドとして実装することができます。このメソッドの名前が get から始まる場合、すべてのセクションプロキシで、辞書と互換性のある形式で利用できます (上記の getdecimal() の例を参照)。
これらのパーサー引数のデフォルト値を上書きすれば、さらに進んだカスタマイズができます。デフォルトはクラスで定義されているので、派生クラスや属性の代入で上書きできます。
ConfigParser.BOOLEAN_STATES
デフォルトでは、 getboolean() を使うことで、設定パーサーは以下の値を True と見なします: '1', 'yes', 'true', 'on' 。以下の値を False と見なします: '0', 'no', 'false', 'off' 。文字列と対応するブール値のカスタム辞書を指定することでこれを上書きできます。たとえば:
>>> custom = configparser.ConfigParser()
>>> custom['section1'] = {'funky': 'nope'}
>>> custom['section1'].getboolean('funky')
Traceback (most recent call last):
...
ValueError: Not a boolean: nope
>>> custom.BOOLEAN_STATES = {'sure': True, 'nope': False}
>>> custom['section1'].getboolean('funky')
False
ほかの典型的なブール値ペアには accept/reject や enabled/disabled などがあります。
ConfigParser.optionxform(option)
このメソッドは読み込み、取得、設定操作のたびにオプション名を変換します。デフォルトでは名前を小文字に変換します。従って設定ファイルが書き込まれるとき、すべてのキーは小文字になります。それがふさわしくなければ、このメソッドを上書きしてください。例えば:
>>> config = """
... [Section1]
... Key = Value
...
... [Section2]
... AnotherKey = Value
... """
>>> typical = configparser.ConfigParser()
>>> typical.read_string(config)
>>> list(typical['Section1'].keys())
['key']
>>> list(typical['Section2'].keys())
['anotherkey']
>>> custom = configparser.RawConfigParser()
>>> custom.optionxform = lambda option: option
>>> custom.read_string(config)
>>> list(custom['Section1'].keys())
['Key']
>>> list(custom['Section2'].keys())
['AnotherKey']
注釈 The optionxform function transforms option names to a canonical form. This should be an idempotent function: if the name is already in canonical form, it should be returned unchanged.
ConfigParser.SECTCRE
セクションヘッダを解析するのに使われる、コンパイルされた正規表現です。デフォルトでは [section] が "section" という名前にマッチします。空白はセクション名の一部と見なされるので、[  larch  ] は "  larch  " という名のセクションとして読み込まれます。これがふさわしくない場合、このメソッドを上書きしてください。例えば:
>>> import re
>>> config = """
... [Section 1]
... option = value
...
... [  Section 2  ]
... another = val
... """
>>> typical = configparser.ConfigParser()
>>> typical.read_string(config)
>>> typical.sections()
['Section 1', '  Section 2  ']
>>> custom = configparser.ConfigParser()
>>> custom.SECTCRE = re.compile(r"\[ *(?P<header>[^]]+?) *\]")
>>> custom.read_string(config)
>>> custom.sections()
['Section 1', 'Section 2']
注釈 ConfigParser オブジェクトはオプション行の認識に OPTCRE 属性も使いますが、これを上書きすることは推奨されません。上書きするとコンストラクタオプション allow_no_value および delimiters に干渉します。
レガシーな API の例
主に後方互換性問題の理由から、 configparser は get/set メソッドを明示するレガシーな API も提供します。メソッドを以下に示すように使うこともできますが、新しいプロジェクトではマップ型プロトコルでアクセスするのが望ましいです。レガシーな API は時折高度で、低レベルで、まったく直感的ではありません。
設定ファイルを書き出す例:
import configparser
config = configparser.RawConfigParser()
# Please note that using RawConfigParser's set functions, you can assign
# non-string values to keys internally, but will receive an error when
# attempting to write to a file or when you get it in non-raw mode. Setting
# values using the mapping protocol or ConfigParser's set() does not allow
# such assignments to take place.
config.add_section('Section1')
config.set('Section1', 'an_int', '15')
config.set('Section1', 'a_bool', 'true')
config.set('Section1', 'a_float', '3.1415')
config.set('Section1', 'baz', 'fun')
config.set('Section1', 'bar', 'Python')
config.set('Section1', 'foo', '%(bar)s is %(baz)s!')
# Writing our configuration file to 'example.cfg'
with open('example.cfg', 'w') as configfile:
    config.write(configfile)
設定ファイルを読み込む例:
import configparser
config = configparser.RawConfigParser()
config.read('example.cfg')
# getfloat() raises an exception if the value is not a float
# getint() and getboolean() also do this for their respective types
a_float = config.getfloat('Section1', 'a_float')
an_int = config.getint('Section1', 'an_int')
print(a_float + an_int)
# Notice that the next output does not interpolate '%(bar)s' or '%(baz)s'.
# This is because we are using a RawConfigParser().
if config.getboolean('Section1', 'a_bool'):
    print(config.get('Section1', 'foo'))
補間するには、 ConfigParser を使ってください:
import configparser
cfg = configparser.ConfigParser()
cfg.read('example.cfg')
# Set the optional *raw* argument of get() to True if you wish to disable
# interpolation in a single get operation.
print(cfg.get('Section1', 'foo', raw=False))  # -> "Python is fun!"
print(cfg.get('Section1', 'foo', raw=True))   # -> "%(bar)s is %(baz)s!"
# The optional *vars* argument is a dict with members that will take
# precedence in interpolation.
print(cfg.get('Section1', 'foo', vars={'bar': 'Documentation',
                                       'baz': 'evil'}))
# The optional *fallback* argument can be used to provide a fallback value
print(cfg.get('Section1', 'foo'))
      # -> "Python is fun!"
print(cfg.get('Section1', 'foo', fallback='Monty is not.'))
      # -> "Python is fun!"
print(cfg.get('Section1', 'monster', fallback='No such things as monsters.'))
      # -> "No such things as monsters."
# A bare print(cfg.get('Section1', 'monster')) would raise NoOptionError
# but we can also use:
print(cfg.get('Section1', 'monster', fallback=None))
      # -> None
どちらの型の ConfigParsers でもデフォルト値が利用できます。使われているオプションがどこにも定義されていなければ、そのデフォルト値が補間に使われます。
import configparser
# New instance with 'bar' and 'baz' defaulting to 'Life' and 'hard' each
config = configparser.ConfigParser({'bar': 'Life', 'baz': 'hard'})
config.read('example.cfg')
print(config.get('Section1', 'foo'))     # -> "Python is fun!"
config.remove_option('Section1', 'bar')
config.remove_option('Section1', 'baz')
print(config.get('Section1', 'foo'))     # -> "Life is hard!"
ConfigParser オブジェクト
class configparser.ConfigParser(defaults=None, dict_type=dict, allow_no_value=False, delimiters=('=', ':'), comment_prefixes=('#', ';'), inline_comment_prefixes=None, strict=True, empty_lines_in_values=True, default_section=configparser.DEFAULTSECT, interpolation=BasicInterpolation(), converters={})
主要な設定パーサーです。defaults が与えられれば、その辞書の持つ初期値で初期化されます。dict_type が与えられれば、それがセクションの一覧、セクション中のオプション、およびデフォルト値の辞書オブジェクトを作成するのに使われます。
delimiters が与えられた場合、キーと値を分割する部分文字列の組み合わせとして使われます。comment_prefixes が与えられた場合、他の内容がない行のコメントに接頭する部分文字列の組み合わせとして使われます。コメントはインデントできます。inline_comment_prefixes が与えられた場合、非空行のコメントに接頭する部分文字列としての組み合わせとして使われます。
strict が True (デフォルト) であれば、パーサーは単一のソース (ファイル、文字列、辞書) 中にセクションやオプションの重複を認めず、 DuplicateSectionError や DuplicateOptionError を送出します。 empty_lines_in_values が False (デフォルト: True) なら、空行はそれぞれオプションの終わりを示します。 allow_no_value が True (デフォルト: False) なら、値のないオプションが受け付けられます。そのオプションの値は None となり、後端のデリミタを除いてシリアル化されます。
default_section が与えられた場合、他のセクションへのデフォルト値や補間のためのデフォルト値を保持する特別なセクションの名前を指定します (通常は "DEFAULT" という名前です)。この値は実行時に default_section インスタンス属性を使って取得や変更ができます。
補間の動作は、 interpolation 引数を通してカスタムハンドラを与えることでカスタマイズできます。 None 引数を使うと補間を完全に無効にできます。 ExtendedInterpolation() は、 zc.buildout に影響を受けたより高度な補間を提供します。この件に 特化したドキュメントのセクション を参照してください。
補間に使われるすべてのオプション名は、他のオプション名参照と同様に、 optionxform() メソッドを通して渡されます。例えば、 optionxform() のデフォルトの実装を使うと、値 foo %(bar)s と foo %(BAR)s は等しくなります。
converters が与えられた場合、各キーが型コンバーターの名前を表し、各値が文字列から目的のデータ型への変換を実装する呼び出し可能オブジェクトです。各コンバーターは、自身の対応する get*() メソッドをパーサーオブジェクトとセクションプロキシで取得します。
バージョン 3.1 で変更: デフォルトの dict_type は collections.OrderedDict です。
バージョン 3.2 で変更: allow_no_value, delimiters, comment_prefixes, strict, empty_lines_in_values, default_section および interpolation が追加されました。
バージョン 3.5 で変更: converters 引数が追加されました。
バージョン 3.7 で変更: The defaults argument is read with read_dict(), providing consistent behavior across the parser: non-string keys and values are implicitly converted to strings.
バージョン 3.8 で変更: The default dict_type is dict, since it now preserves insertion order.
defaults()
インスタンス全体で使われるデフォルト値の辞書を返します。
sections()
利用できるセクションのリストを返します。default section はリストに含まれません。
add_section(section)
section という名のセクションをインスタンスに追加します。与えられた名前のセクション名がすでに存在したら、 DuplicateSectionError が送出されます。 default section 名が渡されたら、 ValueError が送出されます。セクションの名前は文字列でなければなりません。そうでなければ、 TypeError が送出されます。
バージョン 3.2 で変更: 文字列でないセクション名は TypeError を送出します。
has_section(section)
指名された section が設定中に存在するかを示します。default section は認識されません。
options(section)
指定された section 中で利用できるオプションのリストを返します。
has_option(section, option)
与えられた section が存在し、与えられた option を含む場合、 True を返します。それ以外の場合には、 False を返します。指定された section が None または空文字列の場合、 DEFAULT が仮定されます。
read(filenames, encoding=None)
ファイル名の iterable を読み込んでパースしようと試みます。正常にパースできたファイル名のリストを返します。
どの設定ファイルも存在しなかった場合、 ConfigParser のインスタンスは 空のデータセットを持ちます。初期値の設定ファイルを先に読み込んでおく必要があるアプリケーションでは、 オプションのファイルを読み込むために read() を呼ぶ前に 、まず read_file() を用いて必要なファイルを読み込んでください:
import configparser, os
config = configparser.ConfigParser()
config.read_file(open('defaults.cfg'))
config.read(['site.cfg', os.path.expanduser('~/.myapp.cfg')],
            encoding='cp1250')
バージョン 3.2 で追加: encoding 引数。以前は、すべてのファイルが open() のデフォルトエンコーディングを使って読まれていました。
バージョン 3.6.1 で追加: filenames 引数が path-like object を受け入れるようになりました。
バージョン 3.7 で追加: The filenames parameter accepts a bytes object.
read_file(f, source=None)
設定データを f から読み込んで解析します。f は Unicode 文字列を yield するイテラブル (例えばテキストモードで開かれたファイル) です。
オプションの引数 source は読み込まれるファイルの名前を指定します。与えられず、 f に name 属性があれば、それが source として使われます。デフォルトは '<???>' です。
バージョン 3.2 で追加: readfp() を置き換えます。
read_string(string, source='<string>')
設定データを文字列から解析します。
オプションの引数 source はコンテキストにおける渡された文字列の名前を指定します。与えられなければ、'<string>' が使われます。これは一般にファイルシステムパスや URL にします。
バージョン 3.2 で追加.
read_dict(dictionary, source='<dict>')
辞書的な items() メソッドを提供する任意のオブジェクトから設定を読み込みます。キーはセクション名で、値はそのセクションに現れるキーと値をもつ辞書です。使われた辞書型が順序を保存するなら、セクションおよびそのキーは順に加えられます。値は自動で文字列に変換されます。
オプションの引数 source はコンテキストにおける渡された辞書の名前を指定します。与えられなければ、<dict> が使われます。
このメソッドを使ってパーサー間で状態をコピーできます。
バージョン 3.2 で追加.
get(section, option, *, raw=False, vars=None[, fallback])
指名された section の option の値を取得します。vars が提供されるなら、それは辞書でなければならず、(与えられたなら) vars, section, DEFAULTSECT 内からこの順で option が探索されます。fallback の値として None を与えられます。
raw が真でない時には、全ての '%' 置換は展開されてから返されます。置換後の値はオプションと同じ順序で探されます。
バージョン 3.2 で変更: 引数 raw, vars および fallback は、(特にマッピングプロトコルを使用するときに) ユーザーが第 3 引数を fallback フォールバックとして使おうとしないように、キーワード専用となりました。
getint(section, option, *, raw=False, vars=None[, fallback])
指定された section 中の option を整数に型強制する補助メソッドです。 raw, vars および fallback の説明は get() を参照してください。
getfloat(section, option, *, raw=False, vars=None[, fallback])
指定された section 中の option を浮動小数点数に型強制する補助メソッドです。 raw, vars および fallback の説明は get() を参照してください。
getboolean(section, option, *, raw=False, vars=None[, fallback])
指定された section 中の option をブール値に型強制する補助メソッドです。なお、このオプションで受け付けられる値はこのメソッドが True を返す '1', 'yes', 'true', および 'on',と、このメソッドが False を返す '0', 'no', 'false', and 'off' です。その他のいかなる値も ValueError を送出します。 raw, vars および fallback の説明は get() を参照してください。
items(raw=False, vars=None)
items(section, raw=False, vars=None)
section が与えられなければ、DEFAULTSECT を含めた section_name, section_proxy の対のリストを返します。
与えられれば、与えられた section 中のオプションの name, value の対のリストを返します。オプションの引数は get() メソッドに与えるものと同じ意味を持ちます。
バージョン 3.8 で変更: vars に現れる項目は結果に表れなくなりました。以前の挙動は、実際のパーサーオプションを補間のために与えられた変数と混合していました。
set(section, option, value)
与えられたセクションが存在すれば、与えられたオプションを指定された値に設定します。そうでなければ NoSectionError を送出します。 option および value は文字列でなければなりません。そうでなければ TypeError が送出されます。
write(fileobject, space_around_delimiters=True)
設定の表現を指定された file object に書き込みます。 fileobject は (文字列を受け付ける) テキストモードで開かれていなければなりません。この表現は後で read() を呼び出すことでパースできます。 space_around_delimiters が真なら、キーと値の間のデリミタはスペースで囲まれます。
remove_option(section, option)
指定された option を指定された section から削除します。セクションが存在しなければ、 NoSectionError を送出します。オプションが存在して削除されれば、 True を返します。そうでなければ False を返します。
remove_section(section)
指定された section を設定から削除します。セクションが実際に存在すれば、True を返します。そうでなければ False を返します。
optionxform(option)
入力ファイルに現れた、またはクライアントコードで渡されたオプション名 option を内部構造で実際に使われる形式に変換します。デフォルトの実装では option の小文字版を返します。派生クラスでこれを上書きするか、クライアントコードでインスタンス上のこの名前の属性を設定して、この動作に影響を与えることができます。
このメソッドを使うためにパーサーを派生クラス化させる必要はなく、インスタンス上で、これを文字列引数をとって文字列を返す関数に設定できます。例えば、これを str に設定すると、オプション名に大文字小文字の区別をつけられます:
cfgparser = ConfigParser()
cfgparser.optionxform = str
なお、設定ファイルを読み込むとき、オプション名の周りの空白は optionxform() が呼び出される前に取り除かれます。
readfp(fp, filename=None)
バージョン 3.2 で非推奨: 代わりに read_file() を使ってください。
バージョン 3.2 で変更: readfp() は fp.readline() を呼び出す代わりに fp をイテレートするようになりました。
readfp() をイテレーションをサポートしない引数で呼び出す既存のコードには、ファイル的なオブジェクトまわりのラッパーとして以下のジェネレーターが使えます:
def readline_generator(fp):
    line = fp.readline()
    while line:
        yield line
        line = fp.readline()
parser.readfp(fp) の代わりに parser.read_file(readline_generator(fp)) を使ってください。
configparser.MAX_INTERPOLATION_DEPTH
get() の raw が偽であるときの再帰的な補間の最大の深さです。これはデフォルトの interpolation を使うときのみ関係します。
RawConfigParser オブジェクト
class configparser.RawConfigParser(defaults=None, dict_type=dict, allow_no_value=False, *, delimiters=('=', ':'), comment_prefixes=('#', ';'), inline_comment_prefixes=None, strict=True, empty_lines_in_values=True, default_section=configparser.DEFAULTSECT[, interpolation])
バージョン 3.8 で変更: The default dict_type is dict, since it now preserves insertion order.
注釈 代わりに内部に保存する値の型を検査する ConfigParser を使うことを検討してください。補間を望まない場合、 ConfigParser(interpolation=None) を使用できます。
add_section(section)
インスタンスに section という名のセクションを追加します。与えられた名前のセクションがすでに存在すれば、 DuplicateSectionError が送出されます。 default section 名が渡されると、 ValueError が送出されます。
section の型は検査されないため、ユーザーは非文字列の名前付きセクションを作ることができます。この振る舞いはサポートされておらず、内部エラーを起こす可能性があります。
set(section, option, value)
与えられたセクションが存在していれば、オプションを指定された値に設定します。セクションが存在しなければ NoSectionError を発生させます。 RawConfigParser (あるいは raw パラメータをセットした ConfigParser) を文字列型でない値の 内部的な 格納場所として使うことは可能ですが、すべての機能 (置換やファイルへの出力を含む) がサポートされるのは文字列を値として使った場合だけです。
ユーザーは、このメソッドを使って非文字列の値をキーに代入できます。この振る舞いはサポートされておらず、非rawモードでの値の取得や、ファイルへの書き出しを試みた際にエラーの原因となりえます。このような代入を許さない マッピングプロトコルAPIを使用してください。
例外
exception configparser.Error
他の全ての configparser 例外の基底クラスです。
exception configparser.NoSectionError
指定したセクションが見つからなかった時に起きる例外です。
exception configparser.DuplicateSectionError
add_section() がすでに存在するセクションの名前で呼び出された場合や、strict なパーサーで単一の入力ファイル、文字列、辞書中に同じセクションが複数回現れたときに送出される例外です。
バージョン 3.2 で追加: オプションの source と lineno が属性および __init__() への引数として加えられました。
exception configparser.DuplicateOptionError
strict なパーサーで、単一の入力ファイル、文字列、辞書中に同じオプションが複数回現れたときに送出される例外です。これはミススペルや大文字小文字の区別に関係するエラー、例えば辞書の二つのキーが同じ大文字小文字の区別のない設定キーを表すこと、を捕捉します。
exception configparser.NoOptionError
指定されたオプションが指定されたセクションに見つからないときに送出される例外です。
exception configparser.InterpolationError
文字列の補間中に問題が起きた時に発生する例外の基底クラスです。
exception configparser.InterpolationDepthError
繰り返しの回数が MAX_INTERPOLATION_DEPTH を超えたために文字列補間が完了しなかったときに送出される例外です。 InterpolationError の派生クラスです。
exception configparser.InterpolationMissingOptionError
InterpolationError の派生クラスで、値が参照しているオプションが見つからない場合に発生する例外です。
exception configparser.InterpolationSyntaxError
置換がなされるソーステキストが要求された文法を満たさないときに送出される例外です。 InterpolationError の派生クラスです。
exception configparser.MissingSectionHeaderError
セクションヘッダを持たないファイルを構文解析しようとした時に起きる例外です。
exception configparser.ParsingError
ファイルの構文解析中にエラーが起きた場合に発生する例外です。
バージョン 3.2 で変更: filename という属性および __init__() の引数は source に名前が変更されました。
netrc --- netrc ファイルの処理
ソースコード: Lib/netrc.py
netrc クラスは、Unix ftp プログラムや他の FTP クライアントで用いられる netrc ファイル形式を解析し、カプセル化 (encapsulate) します。
class netrc.netrc([file])
netrc のインスタンスやサブクラスのインスタンスは netrc ファイルのデータをカプセル化します。 初期化の際の引数が存在する場合、解析対象となるファイルの指定になります。 引数がない場合、 (os.path.expanduser() で特定される) ユーザのホームディレクトリ下にある .netrc が読み出されます。ファイルが見付からなかった場合は FileNotFoundError 例外が送出されます。 解析エラーが発生した場合、ファイル名、行番号、解析を中断したトークンに関する情報の入った NetrcParseError を送出します。 POSIX システムにおいて引数を指定しない場合、ファイルのオーナシップやパーミッションが安全でない (プロセスを実行しているユーザ以外が所有者であるか、誰にでも読み書き出来てしまう) のに .netrc ファイル内にパスワードが含まれていると、 NetrcParseError を送出します。 このセキュリティ的な振る舞いは、 ftp などの .netrc を使うプログラムと同じものです。
バージョン 3.4 で変更: POSIX パーミッションのチェックが追加されました。
バージョン 3.7 で変更: 引数で file が渡されなかったときは、 .netrc ファイルの場所を探すのに os.path.expanduser() が使われるようになりました。
exception netrc.NetrcParseError
ソースファイルのテキスト中で文法エラーに遭遇した場合に netrc クラスによって送出される例外です。 この例外のインスタンスは 3 つのインスタンス変数を持っています: msg はテキストによるエラーの説明、 filename はソースファイルの名前、そして lineno はエラーが発見された行番号です。
netrc オブジェクト
netrc インスタンスは以下のメソッドを持っています:
netrc.authenticators(host)
host の認証情報として、三要素のタプル (login, account, password) を返します。与えられた host に対するエントリが netrc ファイルにない場合、'default' エントリに関連付けられたタプルが返されます。host に対応するエントリがなく、default エントリもない場合、None を返します。
netrc.__repr__()
クラスの持っているデータを netrc ファイルの書式に従った文字列で出力します。(コメントは無視され、エントリが並べ替えられる可能性があります。)
netrc のインスタンスは以下の public なインスタンス変数を持っています:
netrc.hosts
ホスト名を (login, account, password) からなるタプルに対応づけている辞書です。'default' エントリがある場合、その名前の擬似ホスト名として表現されます。
netrc.macros
マクロ名を文字列のリストに対応付けている辞書です。
注釈 利用可能なパスワードの文字セットは、ASCII のサブセットのみです。全ての ASCII の記号を使用することができます。しかし、空白文字と印刷不可文字を使用することはできません。この制限は .netrc ファイルの解析方法によるものであり、将来解除されます。
xdrlib --- XDR データのエンコードおよびデコード
ソースコード: Lib/xdrlib.py
xdrlib モジュールは外部データ表現標準 (External Data Representation Standard) のサポートを実現します。この標準は 1987 年に Sun Microsystems, Inc. によって書かれ、 RFC 1014 で定義されています。このモジュールでは RFC で記述されているほとんどのデータ型をサポートしています。
xdrlib モジュールでは 2 つのクラスが定義されています。一つは変数を XDR 表現にパックするためのクラスで、もう一方は XDR 表現からアンパックするためのものです。2 つの例外クラスが同様にして定義されています。
class xdrlib.Packer
Packer はデータを XDR 表現にパックするためのクラスです。 Packer クラスのインスタンス生成は引数なしで行われます。
class xdrlib.Unpacker(data)
Unpacker は Packer と対をなしていて、文字列バッファから XDR をアンパックするためのクラスです。入力バッファ data を引数に与えてインスタンスを生成します。
参考
RFC 1014 - XDR: External Data Representation Standard
この RFC が、かつてこのモジュールが最初に書かれた当時に XDR 標準であったデータのエンコード方法を定義していました。現在は RFC 1832 に更新されているようです。
RFC 1832 - XDR: External Data Representation Standard
こちらが新しい方のRFCで、XDR の改訂版が定義されています。
Packer オブジェクト
Packer インスタンスには以下のメソッドがあります:
Packer.get_buffer()
現在のパック処理用バッファを文字列で返します。
Packer.reset()
パック処理用バッファをリセットして、空文字にします。
一般的には、適切な pack_type() メソッドを使えば、一般に用いられているほとんどの XDR データをパックすることができます。各々のメソッドは一つの引数をとり、パックしたい値を与えます。単純なデータ型をパックするメソッドとして、以下のメソッド: pack_uint() 、 pack_int() 、 pack_enum() 、 pack_bool() 、 pack_uhyper() そして pack_hyper() がサポートされています。
Packer.pack_float(value)
単精度 (single-precision) の浮動小数点数 value をパックします。
Packer.pack_double(value)
倍精度 (double-precision) の浮動小数点数 value をパックします。
以下のメソッドは文字列、バイト列、不透明データ (opaque data) のパック処理をサポートします:
Packer.pack_fstring(n, s)
固定長の文字列、s をパックします。n は文字列の長さですが、この値自体はデータバッファにはパック されません。4 バイトのアラインメントを保証するために、文字列は必要に応じて null バイト列でパディングされます。
Packer.pack_fopaque(n, data)
pack_fstring() と同じく、固定長の不透明データストリームをパックします。
Packer.pack_string(s)
可変長の文字列 s をパックします。文字列の長さが最初に符号なし整数でパックされ、続いて pack_fstring() を使って文字列データがパックされます。
Packer.pack_opaque(data)
pack_string() と同じく、可変長の不透明データ文字列をパックします。
Packer.pack_bytes(bytes)
pack_string() と同じく、可変長のバイトストリームをパックします。
以下のメソッドはアレイやリストのパック処理をサポートします:
Packer.pack_list(list, pack_item)
一様な項目からなる list をパックします。このメソッドはサイズ不定、すなわち、全てのリスト内容を網羅するまでサイズが分からないリストに対して有用です。リストのすべての項目に対し、最初に符号無し整数 1 がパックされ、続いてリスト中のデータがパックされます。pack_item は個々の項目をパックするために呼び出される関数です。リストの末端に到達すると、符号無し整数 0 がパックされます。
例えば、整数のリストをパックするには、コードは以下のようになるはずです:
import xdrlib
p = xdrlib.Packer()
p.pack_list([1, 2, 3], p.pack_int)
Packer.pack_farray(n, array, pack_item)
一様な項目からなる固定長のリスト (array) をパックします。 n はリストの長さです。この値はデータバッファにパック されません が、 len(array) が n と等しくない場合、例外 ValueError が送出されます。上と同様に、 pack_item は個々の要素をパック処理するための関数です。
Packer.pack_array(list, pack_item)
一様の項目からなる可変長の list をパックします。まず、リストの長さが符号無し整数でパックされ、つづいて各要素が上の pack_farray() と同じやり方でパックされます。
Unpacker オブジェクト
Unpacker クラスは以下のメソッドを提供します:
Unpacker.reset(data)
文字列バッファを data でリセットします。
Unpacker.get_position()
データバッファ中の現在のアンパック処理位置を返します。
Unpacker.set_position(position)
データバッファ中のアンパック処理位置を position に設定します。 get_position() および set_position() は注意して使わなければなりません。
Unpacker.get_buffer()
現在のアンパック処理用データバッファを文字列で返します。
Unpacker.done()
アンパック処理を終了させます。全てのデータがまだアンパックされていなければ、例外 Error が送出されます。
上のメソッドに加えて、 Packer でパック処理できるデータ型はいずれも Unpacker でアンパック処理できます。アンパック処理メソッドは unpack_type() の形式をとり、引数をとりません。これらのメソッドはアンパックされたデータオブジェクトを返します。
Unpacker.unpack_float()
単精度の浮動小数点数をアンパックします。
Unpacker.unpack_double()
unpack_float() と同様に、倍精度の浮動小数点数をアンパックします。
上のメソッドに加えて、文字列、バイト列、不透明データをアンパックする以下のメソッドが提供されています:
Unpacker.unpack_fstring(n)
固定長の文字列をアンパックして返します。n は予想される文字列の長さです。4 バイトのアラインメントを保証するために null バイトによるパディングが行われているものと仮定して処理を行います。
Unpacker.unpack_fopaque(n)
unpack_fstring() と同様に、固定長の不透明データストリームをアンパックして返します。
Unpacker.unpack_string()
可変長の文字列をアンパックして返します。最初に文字列の長さが符号無し整数としてアンパックされ、次に unpack_fstring() を使って文字列データがアンパックされます。
Unpacker.unpack_opaque()
unpack_string() と同様に、可変長の不透明データ文字列をアンパックして返します。
Unpacker.unpack_bytes()
unpack_string() と同様に、可変長のバイトストリームをアンパックして返します。
以下メソッドはアレイおよびリストのアンパック処理をサポートします:
Unpacker.unpack_list(unpack_item)
一様な項目からなるリストをアンパック処理して返します。リストは、まず符号無し整数によるフラグをアンパックすることで、一度に 1 要素づつアンパック処理されます。フラグが 1 の場合、要素はアンパックされ、返り値のリストに追加されます。フラグが 0 の場合、リストの終端を示します。unpack_item は個々の項目をアンパック処理するために呼び出される関数です。
Unpacker.unpack_farray(n, unpack_item)
一様な項目からなる固定長のアレイをアンパックして（リストとして）返します。n はバッファ内に存在すると期待されるリストの要素数です。上と同様に、unpack_item は各要素をアンパックするために使われる関数です。
Unpacker.unpack_array(unpack_item)
一様な項目からなる可変長の list をアンパックして返します。まず、リストの長さが符号無し整数としてアンパックされ、続いて各要素が上の unpack_farray() のようにしてアンパック処理されます。
例外
このモジュールでの例外はクラスインスタンスとしてコードされています:
exception xdrlib.Error
ベースとなる例外クラスです。 Error public な属性として msg を持ち、エラーの詳細が収められています。
exception xdrlib.ConversionError
Error から派生したクラスです。インスタンス変数は追加されていません。
これらの例外を補足する方法を以下の例に示します:
import xdrlib
p = xdrlib.Packer()
try:
    p.pack_double(8.01)
except xdrlib.ConversionError as instance:
    print('packing the double failed:', instance.msg)
plistlib --- Generate and parse Apple .plist files
ソースコード: Lib/plistlib.py
プロパティーリスト (.plist) ファイル形式は基本的型のオブジェクト、たとえば辞書やリスト、数、文字列など、に対する単純な直列化です。たいてい、トップレベルのオブジェクトは辞書です。
plist ファイルを書き出したり解析したりするには dump() や load() 関数を利用します。
バイトオブジェクトの plist データを扱うためには dumps() や loads() を利用します。
バージョン 3.4 で変更: 新しい API。古い API は撤廃されました。バイナリ形式の plist がサポートされました。
バージョン 3.8 で変更: Support added for reading and writing UID tokens in binary plists as used by NSKeyedArchiver and NSKeyedUnarchiver.
バージョン 3.9 で変更: Old API removed.
参考
PList マニュアルページ
このファイル形式の Apple の文書。
このモジュールは以下の関数を定義しています:
plistlib.load(fp, *, fmt=None, dict_type=dict)
plist ファイルを読み込みます。fp は読み込み可能かつバイナリのファイルオブジェクトです。展開されたルートオブジェクト (通常は辞書です) を返します。
fmt はファイルの形式で、次の値が有効です。
None: ファイル形式を自動検出します
FMT_XML: XML ファイル形式です
FMT_BINARY: バイナリの plist 形式です
dict_type は、 plist ファイルから読み出された辞書に使われる型です。
FMT_XML 形式の XML データは xml.parsers.expat にある Expat パーサーを使って解析されます。不正な形式の XML に対して送出される可能性のある例外については、そちらの文書を参照してください。plist 解析器では、未知の要素は単純に無視されます。
バイナリ形式のパーサーは、ファイルを解析できない場合に InvalidFileException を送出します。
バージョン 3.4 で追加.
plistlib.loads(data, *, fmt=None, dict_type=dict)
バイナリオブジェクトから plist をロードします。キーワード引数の説明については、 load() を参照してください。
バージョン 3.4 で追加.
plistlib.dump(value, fp, *, fmt=FMT_XML, sort_keys=True, skipkeys=False)
plist ファイルに value を書き込みます。Fp は、書き込み可能なバイナリファイルオブジェクトにしてください。
fmt 引数は plist ファイルの形式を指定し、次のいずれかの値をとることができます。
FMT_XML: XML 形式の plist ファイルです
FMT_BINARY: バイナリ形式の plist ファイルです
sort_keys が真 (デフォルト) の場合、辞書内のキーは、plist にソートされた順序で書き込まれます。偽の場合、ディクショナリのイテレートの順序で書き込まれます。
skipkeys が偽 (デフォルト) の場合、この関数は辞書のキーが文字列でない場合に TypeError を送出します。真の場合、そのようなキーは読み飛ばされます。
TypeError が、オブジェクトがサポート外の型のものであったりサポート外の型のオブジェクトを含むコンテナだった場合に、送出されます。
(バイナリの) plist ファイル内で表現できない整数値に対しては、 OverflowError が送出されます。
バージョン 3.4 で追加.
plistlib.dumps(value, *, fmt=FMT_XML, sort_keys=True, skipkeys=False)
value を plist 形式のバイトオブジェクトとして返します。この関数のキーワード引数の説明については、 dump() を参照してください。
バージョン 3.4 で追加.
以下のクラスが使用可能です:
class plistlib.UID(data)
バージョン 3.8 で追加.
以下の定数が利用可能です:
plistlib.FMT_XML
plist ファイルの XML 形式です
バージョン 3.4 で追加.
plistlib.FMT_BINARY
plist ファイルのバイナリ形式です
バージョン 3.4 で追加.
使用例
plist を作ります:
pl = dict(
    aString = "Doodah",
    aList = ["A", "B", 12, 32.1, [1, 2, 3]],
    aFloat = 0.1,
    anInt = 728,
    aDict = dict(
        anotherString = "<hello & hi there!>",
        aThirdString = "M\xe4ssig, Ma\xdf",
        aTrueValue = True,
        aFalseValue = False,
    ),
    someData = b"<binary gunk>",
    someMoreData = b"<lots of binary gunk>" * 10,
    aDate = datetime.datetime.fromtimestamp(time.mktime(time.gmtime())),
)
with open(fileName, 'wb') as fp:
    dump(pl, fp)
plist を解析します:
with open(fileName, 'rb') as fp:
    pl = load(fp)
print(pl["aKey"])
itertools --- 効率的なループ実行のためのイテレータ生成関数
このモジュールは イテレータ を構築する部品を実装しています。プログラム言語 APL, Haskell, SML からアイデアを得ていますが、 Python に適した形に修正されています。
このモジュールは、高速でメモリ効率に優れ、単独でも組合せても使用することのできるツールを標準化したものです。同時に、このツール群は "イテレータの代数" を構成していて、pure Python で簡潔かつ効率的なツールを作れるようにしています。
例えば、SML の作表ツール tabulate(f) は f(0), f(1), ... のシーケンスを作成します。同じことを Python では map() と count() を組合せて map(f, count()) という形で実現できます。
これらのツールと組み込み関数は operator モジュール内の高速な関数とともに使うことで見事に動作します。例えば、乗算演算子を2つのベクトルにわたってマップすることで効率的な内積計算を実現できます: sum(map(operator.mul, vector1, vector2)) 。
無限イテレータ:
イテレータ
引数
結果
使用例
count()
start, [step]
start, start+step, start+2*step, ...
count(10) --> 10 11 12 13 14 ...
cycle()
p
p0, p1, ... plast, p0, p1, ...
cycle('ABCD') --> A B C D A B C D ...
repeat()
elem [,n]
elem, elem, elem, ... 無限もしくは n 回
repeat(10, 3) --> 10 10 10
一番短い入力シーケンスで止まるイテレータ:
イテレータ
引数
結果
使用例
accumulate()
p [,func]
p0, p0+p1, p0+p1+p2, ...
accumulate([1,2,3,4,5]) --> 1 3 6 10 15
chain()
p, q, ...
p0, p1, ... plast, q0, q1, ...
chain('ABC', 'DEF') --> A B C D E F
chain.from_iterable()
iterable
p0, p1, ... plast, q0, q1, ...
chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
compress()
data, selectors
(d[0] if s[0]), (d[1] if s[1]), ...
compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
dropwhile()
pred, seq
seq[n], seq[n+1], pred が偽の場所から始まる
dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
filterfalse()
pred, seq
pred(elem) が偽になるseqの要素
filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
groupby()
iterable[, key]
key(v) の値でグループ化したサブイテレータ
islice()
seq, [start,] stop [, step]
seq[start:stop:step]
islice('ABCDEFG', 2, None) --> C D E F G
starmap()
func, seq
func(*seq[0]), func(*seq[1]), ...
starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
takewhile()
pred, seq
seq[0], seq[1], pred が偽になるまで
takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
tee()
it, n
it1, it2 , ... itn 一つのイテレータを n 個に分ける
zip_longest()
p, q, ...
(p[0], q[0]), (p[1], q[1]), ...
zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
組合せイテレータ:
イテレータ
引数
結果
product()
p, q, ... [repeat=1]
デカルト積、ネストしたforループと等価
permutations()
p[, r]
長さrのタプル列、重複なしのあらゆる並び
combinations()
p, r
長さrのタプル列、ソートされた順で重複なし
combinations_with_replacement()
p, r
長さrのタプル列、ソートされた順で重複あり
使用例
結果
product('ABCD', repeat=2)
AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD
permutations('ABCD', 2)
AB AC AD BA BC BD CA CB CD DA DB DC
combinations('ABCD', 2)
AB AC AD BC BD CD
combinations_with_replacement('ABCD', 2)
AA AB AC AD BB BC BD CC CD DD
Itertool関数
以下の関数は全て、イテレータを作成して返します。無限長のストリームのイテレータを返す関数もあり、この場合にはストリームを中断するような関数かループ処理から使用しなければなりません。
itertools.accumulate(iterable[, func, *, initial=None])
If func is supplied, it should be a function of two arguments. Elements of the input iterable may be any type that can be accepted as arguments to func. (For example, with the default operation of addition, elements may be any addable type including Decimal or Fraction.)
およそ次と等価です:
def accumulate(iterable, func=operator.add, *, initial=None):
    'Return running totals'
    # accumulate([1,2,3,4,5]) --> 1 3 6 10 15
    # accumulate([1,2,3,4,5], initial=100) --> 100 101 103 106 110 115
    # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120
    it = iter(iterable)
    total = initial
    if initial is None:
        try:
            total = next(it)
        except StopIteration:
            return
    yield total
    for element in it:
        total = func(total, element)
        yield total
func 引数の利用法はたくさんあります。最小値にするために min() を、最大値にするために max() を、積にするために operator.mul() を使うことができます。金利を累積し支払いを適用して償還表を作成することもできます。初期値をイテラブルに与えて func 引数で累積和を利用するだけで一階の 漸化式 をモデル化できます:
>>>
>>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]
>>> list(accumulate(data, operator.mul))     # running product
[3, 12, 72, 144, 144, 1296, 0, 0, 0, 0]
>>> list(accumulate(data, max))              # running maximum
[3, 4, 6, 6, 6, 9, 9, 9, 9, 9]
# Amortize a 5% loan of 1000 with 4 annual payments of 90
>>> cashflows = [1000, -90, -90, -90, -90]
>>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt))
[1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001]
# Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map
>>> logistic_map = lambda x, _:  r * x * (1 - x)
>>> r = 3.8
>>> x0 = 0.4
>>> inputs = repeat(x0, 36)     # only the initial value is used
>>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)]
['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63',
 '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57',
 '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32',
 '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60']
最終的な累積値だけを返す類似の関数については functools.reduce() を見てください。
バージョン 3.2 で追加.
バージョン 3.3 で変更: オプションの func 引数が追加されました。
バージョン 3.8 で変更: オプションの initial パラメータが追加されました。
itertools.chain(*iterables)
先頭の iterable の全要素を返し、次に2番目の iterable の全要素を返し、と全 iterable の要素を返すイテレータを作成します。連続したシーケンスを一つのシーケンスとして扱う場合に使用します。およそ次と等価です:
def chain(*iterables):
    # chain('ABC', 'DEF') --> A B C D E F
    for it in iterables:
        for element in it:
            yield element
classmethod chain.from_iterable(iterable)
chain() のためのもう一つのコンストラクタです。遅延評価される iterable 引数一つから連鎖した入力を受け取ります。この関数は、以下のコードとほぼ等価です:
def from_iterable(iterables):
    # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
    for it in iterables:
        for element in it:
            yield element
itertools.combinations(iterable, r)
入力 iterable の要素からなる長さ r の部分列を返します。
組合せ(combination)は入力 iterable に応じた辞書式順序で出力されます。したがって、入力 iterable がソートされていれば、出力される組合わせ(combination)タプルもソートされた順番で生成されます。
各要素は場所に基づいて一意に取り扱われ、値にはよりません。入力された要素がバラバラなら各組合せの中に重複した値は現れません。
およそ次と等価です:
def combinations(iterable, r):
    # combinations('ABCD', 2) --> AB AC AD BC BD CD
    # combinations(range(4), 3) --> 012 013 023 123
    pool = tuple(iterable)
    n = len(pool)
    if r > n:
        return
    indices = list(range(r))
    yield tuple(pool[i] for i in indices)
    while True:
        for i in reversed(range(r)):
            if indices[i] != i + n - r:
                break
        else:
            return
        indices[i] += 1
        for j in range(i+1, r):
            indices[j] = indices[j-1] + 1
        yield tuple(pool[i] for i in indices)
combinations() のコードは permutations() のシーケンスから (入力プールでの位置に応じた順序で) 要素がソートされていないものをフィルターしたようにも表現できます:
def combinations(iterable, r):
    pool = tuple(iterable)
    n = len(pool)
    for indices in permutations(range(n), r):
        if sorted(indices) == list(indices):
            yield tuple(pool[i] for i in indices)
返される要素の数は、0 <= r <= n の場合は、n! / r! / (n-r)! で、r > n の場合は 0 です。
itertools.combinations_with_replacement(iterable, r)
入力 iterable から、それぞれの要素が複数回現れることを許して、長さ r の要素の部分列を返します。
組合せ(combination)は入力 iterable に応じた辞書式順序で出力されます。したがって、入力 iterable がソートされていれば、出力される組合わせ(combination)タプルもソートされた順番で生成されます。
要素は、値ではなく位置に基づいて一意に扱われます。ですから、入力の要素が一意であれば、生成された組合せも一意になります。
およそ次と等価です:
def combinations_with_replacement(iterable, r):
    # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
    pool = tuple(iterable)
    n = len(pool)
    if not n and r:
        return
    indices = [0] * r
    yield tuple(pool[i] for i in indices)
    while True:
        for i in reversed(range(r)):
            if indices[i] != n - 1:
                break
        else:
            return
        indices[i:] = [indices[i] + 1] * (r - i)
        yield tuple(pool[i] for i in indices)
combinations_with_replacement() のコードは、 product() の部分列から、要素が (入力プールの位置に従って) ソートされた順になっていない項目をフィルタリングしたものとしても表せます:
def combinations_with_replacement(iterable, r):
    pool = tuple(iterable)
    n = len(pool)
    for indices in product(range(n), repeat=r):
        if sorted(indices) == list(indices):
            yield tuple(pool[i] for i in indices)
返される要素の数は、n > 0 のとき (n+r-1)! / r! / (n-1)! です。
バージョン 3.1 で追加.
itertools.compress(data, selectors)
data の要素から selectors の対応する要素が True と評価されるものだけをフィルタしたイテレータを作ります。data と selectors のいずれかが尽きたときに止まります。およそ次と等価です:
def compress(data, selectors):
    # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
    return (d for d, s in zip(data, selectors) if s)
バージョン 3.1 で追加.
itertools.count(start=0, step=1)
数 start で始まる等間隔の値を返すイテレータを作成します。map() に渡して連続したデータを生成するのによく使われます。 また、 zip() に連続した番号を追加するのにも使われます。 およそ次と等価です:
def count(start=0, step=1):
    # count(10) --> 10 11 12 13 14 ...
    # count(2.5, 0.5) -> 2.5 3.0 3.5 ...
    n = start
    while True:
        yield n
        n += step
浮動小数点数でカウントするときは (start + step * i for i in count()) のように掛け算を使ったコードに置き換えたほうが正確にできることがあります。
バージョン 3.1 で変更: step 引数が追加され、非整数の引数が許されるようになりました。
itertools.cycle(iterable)
iterable から要素を取得し、そのコピーを保存するイテレータを作成します。iterable の全要素を返すと、セーブされたコピーから要素を返します。これを無限に繰り返します。およそ次と等価です:
def cycle(iterable):
    # cycle('ABCD') --> A B C D A B C D A B C D ...
    saved = []
    for element in iterable:
        yield element
        saved.append(element)
    while saved:
        for element in saved:
              yield element
cycle() は大きなメモリ領域を使用します。使用するメモリ量は iterable の大きさに依存します。
itertools.dropwhile(predicate, iterable)
predicate (述語) が真である間は要素を飛ばし、その後は全ての要素を返すイテレータを作成します。このイテレータは、predicate が最初に偽になるまで 全く 要素を返さないため、要素を返し始めるまでに長い時間がかかる場合があります。およそ次と等価です:
def dropwhile(predicate, iterable):
    # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
    iterable = iter(iterable)
    for x in iterable:
        if not predicate(x):
            yield x
            break
    for x in iterable:
        yield x
itertools.filterfalse(predicate, iterable)
iterable から predicate が False となる要素だけを返すイテレータを作成します。predicate が None の場合、偽の要素だけを返します。およそ次と等価です:
def filterfalse(predicate, iterable):
    # filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
    if predicate is None:
        predicate = bool
    for x in iterable:
        if not predicate(x):
            yield x
itertools.groupby(iterable, key=None)
同じキーをもつような要素からなる iterable 中のグループに対して、キーとグループを返すようなイテレータを作成します。key は各要素に対するキー値を計算する関数です。キーを指定しない場合や None にした場合、key 関数のデフォルトは恒等関数になり要素をそのまま返します。通常、iterable は同じキー関数でソート済みである必要があります。
groupby() の操作は Unix の uniq フィルターと似ています。 key 関数の値が変わるたびに休止または新しいグループを生成します (このために通常同じ key 関数でソートしておく必要があるのです)。この動作は SQL の入力順に関係なく共通の要素を集約する GROUP BY とは違います。
返されるグループはそれ自体がイテレータで、 groupby() と iterable を共有しています。もととなる iterable を共有しているため、 groupby() オブジェクトの要素取り出しを先に進めると、それ以前の要素であるグループは見えなくなってしまいます。従って、データが後で必要な場合にはリストの形で保存しておく必要があります:
groups = []
uniquekeys = []
data = sorted(data, key=keyfunc)
for k, g in groupby(data, keyfunc):
    groups.append(list(g))      # Store group iterator as a list
    uniquekeys.append(k)
groupby() はおよそ次と等価です:
class groupby:
    # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
    # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
    def __init__(self, iterable, key=None):
        if key is None:
            key = lambda x: x
        self.keyfunc = key
        self.it = iter(iterable)
        self.tgtkey = self.currkey = self.currvalue = object()
    def __iter__(self):
        return self
    def __next__(self):
        self.id = object()
        while self.currkey == self.tgtkey:
            self.currvalue = next(self.it)    # Exit on StopIteration
            self.currkey = self.keyfunc(self.currvalue)
        self.tgtkey = self.currkey
        return (self.currkey, self._grouper(self.tgtkey, self.id))
    def _grouper(self, tgtkey, id):
        while self.id is id and self.currkey == tgtkey:
            yield self.currvalue
            try:
                self.currvalue = next(self.it)
            except StopIteration:
                return
            self.currkey = self.keyfunc(self.currvalue)
itertools.islice(iterable, stop)
itertools.islice(iterable, start, stop[, step])
iterable から要素を選択して返すイテレータを作成します。 start が0でない場合、iterable の要素は start に達するまでスキップされます。その後、 要素が順に返されます。
def islice(iterable, *args):
    # islice('ABCDEFG', 2) --> A B
    # islice('ABCDEFG', 2, 4) --> C D
    # islice('ABCDEFG', 2, None) --> C D E F G
    # islice('ABCDEFG', 0, None, 2) --> A C E G
    s = slice(*args)
    start, stop, step = s.start or 0, s.stop or sys.maxsize, s.step or 1
    it = iter(range(start, stop, step))
    try:
        nexti = next(it)
    except StopIteration:
        # Consume *iterable* up to the *start* position.
        for i, element in zip(range(start), iterable):
            pass
        return
    try:
        for i, element in enumerate(iterable):
            if i == nexti:
                yield element
                nexti = next(it)
    except StopIteration:
        # Consume to *stop*.
        for i, element in zip(range(i + 1, stop), iterable):
            pass
start が None の場合、イテレーションは0から始まります。step が None の場合、ステップはデフォルトの1になります。
itertools.permutations(iterable, r=None)
iterable の要素からなる長さ r の順列 (permutation) を連続的に返します。
r が指定されない場合や None の場合、r はデフォルトで iterable の長さとなり、可能な最長の順列の全てが生成されます。
順列(permutation)は入力 iterable に応じた辞書式順序で出力されます。したがって、入力 iterable がソートされていれば、出力される組合わせタプルもソートされた順番で生成されます。
要素は値ではなく位置に基づいて一意的に扱われます。したがって入力された要素が全て異なっている場合、それぞれの順列に重複した要素が現れないことになります。
およそ次と等価です:
def permutations(iterable, r=None):
    # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
    # permutations(range(3)) --> 012 021 102 120 201 210
    pool = tuple(iterable)
    n = len(pool)
    r = n if r is None else r
    if r > n:
        return
    indices = list(range(n))
    cycles = list(range(n, n-r, -1))
    yield tuple(pool[i] for i in indices[:r])
    while n:
        for i in reversed(range(r)):
            cycles[i] -= 1
            if cycles[i] == 0:
                indices[i:] = indices[i+1:] + indices[i:i+1]
                cycles[i] = n - i
            else:
                j = cycles[i]
                indices[i], indices[-j] = indices[-j], indices[i]
                yield tuple(pool[i] for i in indices[:r])
                break
        else:
            return
permutations() のコードは product() の列から重複 (それらは入力プールの同じ位置から取られたものです) を除くようフィルタしたものとしても表現できます:
def permutations(iterable, r=None):
    pool = tuple(iterable)
    n = len(pool)
    r = n if r is None else r
    for indices in product(range(n), repeat=r):
        if len(set(indices)) == r:
            yield tuple(pool[i] for i in indices)
返される要素の数は、0 <= r <= n の場合 n! / (n-r)! で、r > n の場合は 0 です。
itertools.product(*iterables, repeat=1)
入力イテラブルのデカルト積です。
ジェネレータ式の入れ子になった for ループとおよそ等価です。たとえば product(A, B) は ((x,y) for x in A for y in B) と同じものを返します。
入れ子ループは走行距離計と同じように右端の要素がイテレーションごとに更新されていきます。このパターンは辞書式順序を作り出し、入力のイテレート可能オブジェクトたちがソートされていれば、直積タプルもソートされた順に出てきます。
イテラブル自身との直積を計算するためには、オプションの repeat キーワード引数に繰り返し回数を指定します。たとえば product(A, repeat=4) は product(A, A, A, A) と同じ意味です。
この関数は以下のコードとおよそ等価ですが、実際の実装ではメモリ中に中間結果を作りません:
def product(*args, repeat=1):
    # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
    pools = [tuple(pool) for pool in args] * repeat
    result = [[]]
    for pool in pools:
        result = [x+[y] for x in result for y in pool]
    for prod in result:
        yield tuple(prod)
itertools.repeat(object[, times])
繰り返し object を返すイテレータを作成します。 times 引数を指定しなければ、無限に値を返し続けます。map() の引数にして、呼び出された関数に同じ引数を渡すのに使います。また zip() と使って、タプルの変わらない部分を作ります。
およそ次と等価です:
def repeat(object, times=None):
    # repeat(10, 3) --> 10 10 10
    if times is None:
        while True:
            yield object
    else:
        for i in range(times):
            yield object
repeat は map や zip に定数のストリームを与えるためによく利用されます:
>>>
>>> list(map(pow, range(10), repeat(2)))
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
itertools.starmap(function, iterable)
iterable の要素を引数として funtion を計算するイテレータを作成します。 function の引数が一つの iterable からタプルに既にグループ化されている (データが "zip済み") 場合、map() の代わりに使用します。map() と starmap() の違いは function(a,b) と function(*c) の差に似ています。およそ次と等価です:
def starmap(function, iterable):
    # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
    for args in iterable:
        yield function(*args)
itertools.takewhile(predicate, iterable)
predicate が真である限り iterable から要素を返すイテレータを作成します。およそ次と等価です:
def takewhile(predicate, iterable):
    # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
    for x in iterable:
        if predicate(x):
            yield x
        else:
            break
itertools.tee(iterable, n=2)
一つの iterable から n 個の独立したイテレータを返します。
以下の Python コードは tee がすることについての理解を助けるでしょう (ただし実際の実装はより複雑で、下層の FIFO キューを一つしか使いませんが)。
およそ次と等価です:
def tee(iterable, n=2):
    it = iter(iterable)
    deques = [collections.deque() for i in range(n)]
    def gen(mydeque):
        while True:
            if not mydeque:             # when the local deque is empty
                try:
                    newval = next(it)   # fetch a new value and
                except StopIteration:
                    return
                for d in deques:        # load it to all the deques
                    d.append(newval)
            yield mydeque.popleft()
    return tuple(gen(d) for d in deques)
一度 tee() でイテレータを分割すると、もとの iterable を他で使ってはいけません。さもなければ、 tee() オブジェクトの知らない間に iterable が先の要素に進んでしまうことになります。
tee iterators are not threadsafe. A RuntimeError may be raised when using simultaneously iterators returned by the same tee() call, even if the original iterable is threadsafe.
tee() はかなり大きなメモリ領域を使用するかもしれません (使用するメモリ量はiterableの大きさに依存します)。一般には、一つのイテレータが他のイテレータよりも先にほとんどまたは全ての要素を消費するような場合には、 tee() よりも list() を使った方が高速です。
itertools.zip_longest(*iterables, fillvalue=None)
各 iterable の要素をまとめるイテレータを作成します。iterable の長さが違う場合、足りない値は fillvalue で埋められます。最も長い itarable が尽きるまでイテレーションします。およそ次と等価です:
def zip_longest(*args, fillvalue=None):
    # zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
    iterators = [iter(it) for it in args]
    num_active = len(iterators)
    if not num_active:
        return
    while True:
        values = []
        for i, it in enumerate(iterators):
            try:
                value = next(it)
            except StopIteration:
                num_active -= 1
                if not num_active:
                    return
                iterators[i] = repeat(fillvalue)
                value = fillvalue
            values.append(value)
        yield tuple(values)
iterables の1つが無限になりうる場合 zip_longest() は呼び出し回数を制限するような何かでラップしなければいけません(例えば islice() or takewhile())。 fillvalue は指定しない場合のデフォルトは None です。
Itertools レシピ
この節では、既存の itertools を素材としてツールセットを拡張するためのレシピを示します。
Substantially all of these recipes and many, many others can be installed from the more-itertools project found on the Python Package Index:
pip install more-itertools
iterable 全体を一度にメモリ上に置くよりも、要素を一つづつ処理する方がメモリ効率上の有利さを保てます。関数形式のままツールをリンクしてゆくと、コードのサイズを減らし、一時変数を減らす助けになります。インタプリタのオーバヘッドをもたらす for ループや ジェネレータ を使わずに、 "ベクトル化された" ビルディングブロックを使うと、高速な処理を実現できます。
def take(n, iterable):
    "Return first n items of the iterable as a list"
    return list(islice(iterable, n))
def prepend(value, iterator):
    "Prepend a single value in front of an iterator"
    # prepend(1, [2, 3, 4]) -> 1 2 3 4
    return chain([value], iterator)
def tabulate(function, start=0):
    "Return function(0), function(1), ..."
    return map(function, count(start))
def tail(n, iterable):
    "Return an iterator over the last n items"
    # tail(3, 'ABCDEFG') --> E F G
    return iter(collections.deque(iterable, maxlen=n))
def consume(iterator, n=None):
    "Advance the iterator n-steps ahead. If n is None, consume entirely."
    # Use functions that consume iterators at C speed.
    if n is None:
        # feed the entire iterator into a zero-length deque
        collections.deque(iterator, maxlen=0)
    else:
        # advance to the empty slice starting at position n
        next(islice(iterator, n, n), None)
def nth(iterable, n, default=None):
    "Returns the nth item or a default value"
    return next(islice(iterable, n, None), default)
def all_equal(iterable):
    "Returns True if all the elements are equal to each other"
    g = groupby(iterable)
    return next(g, True) and not next(g, False)
def quantify(iterable, pred=bool):
    "Count how many times the predicate is true"
    return sum(map(pred, iterable))
def pad_none(iterable):
    """Returns the sequence elements and then returns None indefinitely.
    Useful for emulating the behavior of the built-in map() function.
    """
    return chain(iterable, repeat(None))
def ncycles(iterable, n):
    "Returns the sequence elements n times"
    return chain.from_iterable(repeat(tuple(iterable), n))
def dotproduct(vec1, vec2):
    return sum(map(operator.mul, vec1, vec2))
def convolve(signal, kernel):
    # See:  https://betterexplained.com/articles/intuitive-convolution/
    # convolve(data, [0.25, 0.25, 0.25, 0.25]) --> Moving average (blur)
    # convolve(data, [1, -1]) --> 1st finite difference (1st derivative)
    # convolve(data, [1, -2, 1]) --> 2nd finite difference (2nd derivative)
    kernel = tuple(kernel)[::-1]
    n = len(kernel)
    window = collections.deque([0], maxlen=n) * n
    for x in chain(signal, repeat(0, n-1)):
        window.append(x)
        yield sum(map(operator.mul, kernel, window))
def flatten(list_of_lists):
    "Flatten one level of nesting"
    return chain.from_iterable(list_of_lists)
def repeatfunc(func, times=None, *args):
    """Repeat calls to func with specified arguments.
    Example:  repeatfunc(random.random)
    """
    if times is None:
        return starmap(func, repeat(args))
    return starmap(func, repeat(args, times))
def pairwise(iterable):
    "s -> (s0,s1), (s1,s2), (s2, s3), ..."
    a, b = tee(iterable)
    next(b, None)
    return zip(a, b)
def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)
def roundrobin(*iterables):
    "roundrobin('ABC', 'D', 'EF') --> A D E B F C"
    # Recipe credited to George Sakkis
    num_active = len(iterables)
    nexts = cycle(iter(it).__next__ for it in iterables)
    while num_active:
        try:
            for next in nexts:
                yield next()
        except StopIteration:
            # Remove the iterator we just exhausted from the cycle.
            num_active -= 1
            nexts = cycle(islice(nexts, num_active))
def partition(pred, iterable):
    "Use a predicate to partition entries into false entries and true entries"
    # partition(is_odd, range(10)) --> 0 2 4 6 8   and  1 3 5 7 9
    t1, t2 = tee(iterable)
    return filterfalse(pred, t1), filter(pred, t2)
def powerset(iterable):
    "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
    s = list(iterable)
    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))
def unique_everseen(iterable, key=None):
    "List unique elements, preserving order. Remember all elements ever seen."
    # unique_everseen('AAAABBBCCDAABBB') --> A B C D
    # unique_everseen('ABBCcAD', str.lower) --> A B C D
    seen = set()
    seen_add = seen.add
    if key is None:
        for element in filterfalse(seen.__contains__, iterable):
            seen_add(element)
            yield element
    else:
        for element in iterable:
            k = key(element)
            if k not in seen:
                seen_add(k)
                yield element
def unique_justseen(iterable, key=None):
    "List unique elements, preserving order. Remember only the element just seen."
    # unique_justseen('AAAABBBCCDAABBB') --> A B C D A B
    # unique_justseen('ABBCcAD', str.lower) --> A B C A D
    return map(next, map(operator.itemgetter(1), groupby(iterable, key)))
def iter_except(func, exception, first=None):
    """ Call a function repeatedly until an exception is raised.
    Converts a call-until-exception interface to an iterator interface.
    Like builtins.iter(func, sentinel) but uses an exception instead
    of a sentinel to end the loop.
    Examples:
        iter_except(functools.partial(heappop, h), IndexError)   # priority queue iterator
        iter_except(d.popitem, KeyError)                         # non-blocking dict iterator
        iter_except(d.popleft, IndexError)                       # non-blocking deque iterator
        iter_except(q.get_nowait, Queue.Empty)                   # loop over a producer Queue
        iter_except(s.pop, KeyError)                             # non-blocking set iterator
    """
    try:
        if first is not None:
            yield first()            # For database APIs needing an initial cast to db.first()
        while True:
            yield func()
    except exception:
        pass
def first_true(iterable, default=False, pred=None):
    """Returns the first true value in the iterable.
    If no true value is found, returns *default*
    If *pred* is not None, returns the first item
    for which pred(item) is true.
    """
    # first_true([a,b,c], x) --> a or b or c or x
    # first_true([a,b], x, f) --> a if f(a) else b if f(b) else x
    return next(filter(pred, iterable), default)
def random_product(*args, repeat=1):
    "Random selection from itertools.product(*args, **kwds)"
    pools = [tuple(pool) for pool in args] * repeat
    return tuple(map(random.choice, pools))
def random_permutation(iterable, r=None):
    "Random selection from itertools.permutations(iterable, r)"
    pool = tuple(iterable)
    r = len(pool) if r is None else r
    return tuple(random.sample(pool, r))
def random_combination(iterable, r):
    "Random selection from itertools.combinations(iterable, r)"
    pool = tuple(iterable)
    n = len(pool)
    indices = sorted(random.sample(range(n), r))
    return tuple(pool[i] for i in indices)
def random_combination_with_replacement(iterable, r):
    "Random selection from itertools.combinations_with_replacement(iterable, r)"
    pool = tuple(iterable)
    n = len(pool)
    indices = sorted(random.choices(range(n), k=r))
    return tuple(pool[i] for i in indices)
def nth_combination(iterable, r, index):
    "Equivalent to list(combinations(iterable, r))[index]"
    pool = tuple(iterable)
    n = len(pool)
    if r < 0 or r > n:
        raise ValueError
    c = 1
    k = min(r, n-r)
    for i in range(1, k+1):
        c = c * (n - k + i) // i
    if index < 0:
        index += c
    if index < 0 or index >= c:
        raise IndexError
    result = []
    while r:
        c, n, r = c*r//n, n-1, r-1
        while index >= c:
            index -= c
            c, n = c*(n-r)//n, n-1
        result.append(pool[-1-n])
    return tuple(result)
functools --- 高階関数と呼び出し可能オブジェクトの操作
ソースコード: Lib/functools.py
functools モジュールは高階関数、つまり関数に影響を及ぼしたり他の関数を返したりする関数のためのものです。一般に、どんな呼び出し可能オブジェクトでもこのモジュールの目的には関数として扱えます。
モジュール functools は以下の関数を定義します:
@functools.cache(user_function)
例えば:
@cache
def factorial(n):
    return n * factorial(n-1) if n else 1
>>> factorial(10)      # no previously cached result, makes 11 recursive calls
3628800
>>> factorial(5)       # just looks up cached value result
120
>>> factorial(12)      # makes two new recursive calls, the other 10 are cached
479001600
バージョン 3.9 で追加.
@functools.cached_property(func)
以下はプログラム例です:
class DataSet:
    def __init__(self, sequence_of_numbers):
        self._data = tuple(sequence_of_numbers)
    @cached_property
    def stdev(self):
        return statistics.stdev(self._data)
If a mutable mapping is not available or if space-efficient key sharing is desired, an effect similar to cached_property() can be achieved by a stacking property() on top of cache():
class DataSet:
    def __init__(self, sequence_of_numbers):
        self._data = sequence_of_numbers
    @property
    @cache
    def stdev(self):
        return statistics.stdev(self._data)
バージョン 3.8 で追加.
functools.cmp_to_key(func)
古いスタイルの比較関数を key function に変換します。key 関数を受け取るツール (sorted(), min(), max(), heapq.nlargest(), heapq.nsmallest(), itertools.groupby() など) と共に使用します。この関数は、主に比較関数を使っていた Python 2 からプログラムの移行のための変換ツールとして使われます。
比較関数は2つの引数を受け取り、それらを比較し、 "より小さい" 場合は負の数を、同値の場合には 0 を、 "より大きい" 場合には正の数を返す、あらゆる呼び出し可能オブジェクトです。key 関数は呼び出し可能オブジェクトで、1つの引数を受け取り、ソートキーとして使われる値を返します。
以下はプログラム例です:
sorted(iterable, key=cmp_to_key(locale.strcoll))  # locale-aware sort order
ソートの例と簡単なチュートリアルは ソート HOW TO を参照して下さい。
バージョン 3.2 で追加.
@functools.lru_cache(user_function)
@functools.lru_cache(maxsize=128, typed=False)
関数をメモ化用の呼び出し可能オブジェクトでラップし、最近の呼び出し最大 maxsize 回まで保存するするデコレータです。高価な関数や I/O に束縛されている関数を定期的に同じ引数で呼び出すときに、時間を節約できます。
結果のキャッシュには辞書が使われるので、関数の位置引数およびキーワード引数はハッシュ可能でなくてはなりません。
引数のパターンが異なる場合は、異なる呼び出しと見なされ別々のキャッシュエントリーとなります。 例えば、 f(a=1, b=2) と f(b=2, a=1) はキーワード引数の順序が異なっているので、2つの別個のキャッシュエントリーになります。
If user_function is specified, it must be a callable. This allows the lru_cache decorator to be applied directly to a user function, leaving the maxsize at its default value of 128:
@lru_cache
def count_vowels(sentence):
    sentence = sentence.casefold()
    return sum(sentence.count(vowel) for vowel in 'aeiou')
typed が真に設定された場合は、関数の異なる型の引数が別々にキャッシュされます。例えば、f(3) と f(3.0) は別の結果をもたらす別の呼び出しとして扱われます。
キャッシュ効率の測定や maxsize パラメータの調整をしやすくするため、ラップされた関数には cache_info() 関数が追加されます。この関数は hits, misses, maxsize, currsize を示す named tuple を返します。マルチスレッド環境では、hits と misses は概算です。
このデコレータは、キャッシュの削除と無効化のための cache_clear() 関数も提供します。
元々の基底の関数には、 __wrapped__ 属性を通してアクセスできます。これはキャッシュを回避して、または関数を別のキャッシュでラップして、内観するのに便利です。
一般的には、 LRU キャッシュは前回計算した値を再利用したいときにのみ使うべきです。 そのため、副作用のある関数、呼び出すごとに個別の可変なオブジェクトを作成する必要がある関数、 time() や random() のような純粋でない関数をキャッシュする意味はありません。
静的 web コンテンツ の LRU キャッシュの例:
@lru_cache(maxsize=32)
def get_pep(num):
    'Retrieve text of a Python Enhancement Proposal'
    resource = 'http://www.python.org/dev/peps/pep-%04d/' % num
    try:
        with urllib.request.urlopen(resource) as s:
            return s.read()
    except urllib.error.HTTPError:
        return 'Not Found'
>>> for n in 8, 290, 308, 320, 8, 218, 320, 279, 289, 320, 9991:
...     pep = get_pep(n)
...     print(n, len(pep))
>>> get_pep.cache_info()
CacheInfo(hits=3, misses=8, maxsize=32, currsize=8)
キャッシュを使って 動的計画法 の技法を実装し、フィボナッチ数 を効率よく計算する例:
@lru_cache(maxsize=None)
def fib(n):
    if n < 2:
        return n
    return fib(n-1) + fib(n-2)
>>> [fib(n) for n in range(16)]
[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610]
>>> fib.cache_info()
CacheInfo(hits=28, misses=16, maxsize=None, currsize=16)
バージョン 3.2 で追加.
バージョン 3.3 で変更: typed オプションが追加されました。
バージョン 3.8 で変更: Added the user_function option.
バージョン 3.9 で追加: Added the function cache_parameters()
@functools.total_ordering
ひとつ以上の拡張順序比較メソッド (rich comparison ordering methods) を定義したクラスを受け取り、残りを実装するクラスデコレータです。このデコレータは全ての拡張順序比較演算をサポートするための労力を軽減します:
引数のクラスは、 __lt__(), __le__(), __gt__(), __ge__() の中からどれか1つと、 __eq__() メソッドを定義する必要があります。
例えば:
@total_ordering
class Student:
    def _is_valid_operand(self, other):
        return (hasattr(other, "lastname") and
                hasattr(other, "firstname"))
    def __eq__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.lastname.lower(), self.firstname.lower()) ==
                (other.lastname.lower(), other.firstname.lower()))
    def __lt__(self, other):
        if not self._is_valid_operand(other):
            return NotImplemented
        return ((self.lastname.lower(), self.firstname.lower()) <
                (other.lastname.lower(), other.firstname.lower()))
注釈 このデコレータにより、完全に順序の付いた振る舞いの良い型を簡単に作ることができますが、実行速度は遅くなり、派生した比較メソッドのスタックトレースは複雑になります。性能ベンチマークにより、これがアプリケーションのボトルネックになっていることがわかった場合は、代わりに 6 つの拡張比較メソッドをすべて実装すれば、簡単にスピードアップを図れるでしょう。
バージョン 3.2 で追加.
バージョン 3.4 で変更: 認識できない型に対して下層の比較関数から NotImplemented を返すことがサポートされるようになりました。
functools.partial(func, /, *args, **keywords)
新しい partial オブジェクト を返します。このオブジェクトは呼び出されると位置引数 args とキーワード引数 keywords 付きで呼び出された func のように振る舞います。呼び出しに際してさらなる引数が渡された場合、それらは args に付け加えられます。追加のキーワード引数が渡された場合には、それらで keywords を拡張または上書きします。おおよそ次のコードと等価です:
def partial(func, /, *args, **keywords):
    def newfunc(*fargs, **fkeywords):
        newkeywords = {**keywords, **fkeywords}
        return func(*args, *fargs, **newkeywords)
    newfunc.func = func
    newfunc.args = args
    newfunc.keywords = keywords
    return newfunc
関数 partial() は、関数の位置引数・キーワード引数の一部を「凍結」した部分適用として使われ、簡素化された引数形式をもった新たなオブジェクトを作り出します。例えば、 partial() を使って base 引数のデフォルトが 2 である int() 関数のように振る舞う呼び出し可能オブジェクトを作ることができます:
>>>
from functools import partial
basetwo = partial(int, base=2)
basetwo.__doc__ = 'Convert base 2 string to an int.'
basetwo('10010')
18
class functools.partialmethod(func, /, *args, **keywords)
partial と似た動作をする新しい partialmethod 記述子 (デスクリプタ) を返します。直接呼び出しではなく、メソッド定義としての使用が目的であることのみが、partial とは異なります。
func は、descriptor または呼び出し可能オブジェクトである必要があります (通常の関数など、両方の性質を持つオブジェクトは記述子として扱われます。)
func が記述子 (Python の通常の関数、 classmethod()、staticmethod()、abstractmethod() または別の partialmethod のインスタンスなど) の場合、 __get__ への呼び出しは下層の記述子に委譲され、返り値として適切な partial オブジェクト が返されます。
func が記述子以外の呼び出し可能オブジェクトである場合、適切な束縛メソッドが動的に作成されます。この func は、メソッドとして使用された場合、Python の通常の関数と同様に動作します。 partialmethod コンストラクタに args と keywords が渡されるよりも前に、 self 引数が最初の位置引数として挿入されます。
以下はプログラム例です:
>>>
>>> class Cell:
...     def __init__(self):
...         self._alive = False
...     @property
...     def alive(self):
...         return self._alive
...     def set_state(self, state):
...         self._alive = bool(state)
...     set_alive = partialmethod(set_state, True)
...     set_dead = partialmethod(set_state, False)
...
>>> c = Cell()
>>> c.alive
False
>>> c.set_alive()
>>> c.alive
True
バージョン 3.4 で追加.
functools.reduce(function, iterable[, initializer])
およそ次と等価です:
def reduce(function, iterable, initializer=None):
    it = iter(iterable)
    if initializer is None:
        value = next(it)
    else:
        value = initializer
    for element in it:
        value = function(value, element)
    return value
@functools.singledispatch
関数を シングルディスパッチ ジェネリック関数 に変換します。
ジェネリック関数を定義するには、 @singledispatch デコレータを付けます。ディスパッチは 1 つ目の引数の型で行われることに注意して、関数を次のように作成してください:
>>>
>>> from functools import singledispatch
>>> @singledispatch
... def fun(arg, verbose=False):
...     if verbose:
...         print("Let me just say,", end=" ")
...     print(arg)
関数にオーバーロード実装を追加するには、ジェネリック関数の register() 属性を使用します。 この属性はデコレータです。 型アノテーションが付いている関数については、このデコレータは1つ目の引数の型を自動的に推測します。
>>>
>>> @fun.register
... def _(arg: int, verbose=False):
...     if verbose:
...         print("Strength in numbers, eh?", end=" ")
...     print(arg)
...
>>> @fun.register
... def _(arg: list, verbose=False):
...     if verbose:
...         print("Enumerate this:")
...     for i, elem in enumerate(arg):
...         print(i, elem)
型アノテーションを使っていないコードについては、デコレータに適切な型引数を明示的に渡せます:
>>>
>>> @fun.register(complex)
... def _(arg, verbose=False):
...     if verbose:
...         print("Better than complicated.", end=" ")
...     print(arg.real, arg.imag)
...
register() 属性を関数形式で使用すると、lambda 関数と既存の関数の登録を有効にできます:
>>>
>>> def nothing(arg, verbose=False):
...     print("Nothing.")
...
>>> fun.register(type(None), nothing)
The register() attribute returns the undecorated function which enables decorator stacking, pickling, as well as creating unit tests for each variant independently:
>>>
>>> @fun.register(float)
... @fun.register(Decimal)
... def fun_num(arg, verbose=False):
...     if verbose:
...         print("Half of your number:", end=" ")
...     print(arg / 2)
...
>>> fun_num is fun
False
汎用関数は、呼び出されると 1 つ目の引数の型でディスパッチします:
>>>
>>> fun("Hello, world.")
>>> fun("test.", verbose=True)
>>> fun(42, verbose=True)
Strength in numbers, eh? 42
>>> fun(['spam', 'spam', 'eggs', 'spam'], verbose=True)
Enumerate this:
0 spam
1 spam
2 eggs
3 spam
>>> fun(None)
>>> fun(1.23)
0.615
特定の型について登録された実装が存在しない場合、その型のメソッド解決順序が、汎用の実装をさらに検索するために使用されます。@singledispatch でデコレートされた元の関数は基底の object 型に登録されます。これは、他によりよい実装が見つからないことを意味します。
If an implementation registered to abstract base class, virtual subclasses will be dispatched to that implementation:
>>>
>>> from collections.abc import Mapping
>>> @fun.register
... def _(arg: Mapping, verbose=False):
...     if verbose:
...         print("Keys & Values")
...     for key, value in arg.items():
...         print(key, "=>", value)
...
>>> fun({"a": "b"})
a => b
指定された型に対して、汎用関数がどの実装を選択するかを確認するには、dispatch() 属性を使用します:
>>>
>>> fun.dispatch(float)
<function fun_num at 0x1035a2840>
>>> fun.dispatch(dict)    # note: default implementation
<function fun at 0x103fe0000>
登録されたすべての実装にアクセスするには、読み出し専用の registry 属性を使用します:
>>>
>>> fun.registry.keys()
dict_keys([<class 'NoneType'>, <class 'int'>, <class 'object'>,
          <class 'decimal.Decimal'>, <class 'list'>,
          <class 'float'>])
>>> fun.registry[float]
<function fun_num at 0x1035a2840>
>>> fun.registry[object]
<function fun at 0x103fe0000>
バージョン 3.4 で追加.
バージョン 3.7 で変更: register() 属性が型アノテーションの使用をサポートするようになりました。
class functools.singledispatchmethod(func)
To define a generic method, decorate it with the @singledispatchmethod decorator. Note that the dispatch happens on the type of the first non-self or non-cls argument, create your function accordingly:
class Negator:
    @singledispatchmethod
    def neg(self, arg):
        raise NotImplementedError("Cannot negate a")
    @neg.register
    def _(self, arg: int):
        return -arg
    @neg.register
    def _(self, arg: bool):
        return not arg
@singledispatchmethod supports nesting with other decorators such as @classmethod. Note that to allow for dispatcher.register, singledispatchmethod must be the outer most decorator. Here is the Negator class with the neg methods being class bound:
class Negator:
    @singledispatchmethod
    @classmethod
    def neg(cls, arg):
        raise NotImplementedError("Cannot negate a")
    @neg.register
    @classmethod
    def _(cls, arg: int):
        return -arg
    @neg.register
    @classmethod
    def _(cls, arg: bool):
        return not arg
バージョン 3.8 で追加.
functools.update_wrapper(wrapper, wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES)
wrapper 関数を wrapped 関数に見えるようにアップデートします。オプション引数はタプルで、元の関数のどの属性がラッパー関数の対応する属性に直接代入されるか、またラッパー関数のどの属性が元の関数の対応する属性でアップデートされるか、を指定します。これらの引数のデフォルト値は、モジュールレベル定数 WRAPPER_ASSIGNMENTS (これはラッパー関数の __module__, __name__, __qualname__, __annotations__ そしてドキュメンテーション文字列 __doc__ に代入する) と WRAPPER_UPDATES (これはラッパー関数の __dict__ すなわちインスタンス辞書をアップデートする) です。
内観や別の目的 (例えば、 lru_cache() のようなキャッシュするデコレータの回避) のために元の関数にアクセスできるように、この関数はラップされている関数を参照するラッパーに自動的に __wrapped__ 属性を追加します。
この関数は主に関数を包んでラッパーを返す デコレータ 関数の中で使われるよう意図されています。もしラッパー関数がアップデートされないとすると、返される関数のメタデータは元の関数の定義ではなくラッパー関数の定義を反映してしまい、これは通常あまり有益ではありません。
update_wrapper() は、関数以外の呼び出し可能オブジェクトにも使えます。 assigned または updated で指名され、ラップされるオブジェクトに存在しない属性は、すべて無視されます (すなわち、ラッパー関数にそれらの属性を設定しようとは試みられません)。しかし、 updated で指名された属性がラッパー関数自身に存在しないなら AttributeError が送出されます。
バージョン 3.2 で追加: __wrapped__ 属性の自動的な追加。
バージョン 3.2 で追加: デフォルトで __annotations__ 属性がコピーされます。
バージョン 3.2 で変更: 存在しない属性によって AttributeError を発生しなくなりました。
バージョン 3.4 で変更: ラップされた関数が __wrapped__ を定義していない場合でも、 __wrapped__ が常にラップされた関数を参照するようになりました。(bpo-17482 を参照)
@functools.wraps(wrapped, assigned=WRAPPER_ASSIGNMENTS, updated=WRAPPER_UPDATES)
これはラッパー関数を定義するときに update_wrapper() を関数デコレータとして呼び出す便宜関数です。これは partial(update_wrapper, wrapped=wrapped, assigned=assigned, updated=updated) と等価です。例えば:
>>>
>>> from functools import wraps
>>> def my_decorator(f):
...     @wraps(f)
...     def wrapper(*args, **kwds):
...         print('Calling decorated function')
...         return f(*args, **kwds)
...     return wrapper
...
>>> @my_decorator
... def example():
...     """Docstring"""
...     print('Called example function')
...
>>> example()
Calling decorated function
Called example function
>>> example.__name__
'example'
>>> example.__doc__
'Docstring'
このデコレータ・ファクトリを使用しないと、上の例中の関数の名前は 'wrapper' となり、元の example() のドキュメンテーション文字列は失われてしまいます。
partial オブジェクト
partial オブジェクトは、 partial() 関数によって作られる呼び出し可能オブジェクトです。オブジェクトには読み出し専用の属性が三つあります:
partial.func
呼び出し可能オブジェクトまたは関数です。 partial オブジェクトの呼び出しは新しい引数とキーワードと共に func に転送されます。
partial.args
最左の位置引数で、 partial オブジェクトの呼び出し時にその呼び出しの際の位置引数の前に追加されます。
partial.keywords
partial オブジェクトの呼び出し時に渡されるキーワード引数です。
partial オブジェクトは function オブジェクトのように呼び出し可能で、弱参照可能で、属性を持つことができます。重要な相違点もあります。例えば、 __name__ と __doc__ 両属性は自動では作られません。また、クラス中で定義された partial オブジェクトはスタティックメソッドのように振る舞い、インスタンスの属性問い合わせの中で束縛メソッドに変換されません。
operator --- 関数形式の標準演算子
ソースコード: Lib/operator.py
operator モジュールは、Python の組み込み演算子に対応する効率的な関数群を提供します。 例えば、 operator.add(x, y) は式 x+y と等価です。 多くの関数名は、特殊メソッドに使われている名前から前後の二重アンダースコアを除いたものと同じです。 後方互換性のため、ほとんどの関数に二重アンダースコアを付けたままのバージョンがあります。 簡潔さのために、二重アンダースコアが無いバージョンの方が好まれます。
これらの関数は、オブジェクト比較、論理演算、数学演算、シーケンス演算をするものに分類されます。
オブジェクト比較関数は全てのオブジェクトで有効で、関数の名前はサポートする拡張比較演算子からとられています:
operator.lt(a, b)
operator.le(a, b)
operator.eq(a, b)
operator.ne(a, b)
operator.ge(a, b)
operator.gt(a, b)
operator.__lt__(a, b)
operator.__le__(a, b)
operator.__eq__(a, b)
operator.__ne__(a, b)
operator.__ge__(a, b)
operator.__gt__(a, b)
a と b の "拡張比較 (rich comparisons)" を行います。具体的には、 lt(a, b) は a < b 、 le(a, b) は a <= b 、 eq(a, b) は a == b 、 ne(a, b) は a != b 、 gt(a, b) は a > b 、そして ge(a, b) は a >= b と等価です。これらの関数はどのような値を返してもよく、ブール値として解釈できてもできなくてもかまいません。拡張比較の詳細については 比較 を参照してください。
論理演算もまた全てのオブジェクトに対して適用でき、真理値判定、同一性判定およびブール演算をサポートします:
operator.not_(obj)
operator.__not__(obj)
not obj の結果を返します。(オブジェクトインスタンスには __not__() メソッドは無いので注意してください; インタプリタコアがこの演算を定義しているだけです。結果は __bool__() および __len__() メソッドに影響されます。)
operator.truth(obj)
obj が真の場合 True を返し、そうでない場合 False を返します。この関数は bool のコンストラクタ呼び出しと同等です。
operator.is_(a, b)
a is b を返します。オブジェクトの同一性を判定します。
operator.is_not(a, b)
a is not b を返します。オブジェクトの同一性を判定します。
演算子で最も多いのは数学演算およびビット単位の演算です:
operator.abs(obj)
operator.__abs__(obj)
obj の絶対値を返します。
operator.add(a, b)
operator.__add__(a, b)
数値 a および b について a + b を返します。
operator.and_(a, b)
operator.__and__(a, b)
a と b のビット単位論理積を返します。
operator.floordiv(a, b)
operator.__floordiv__(a, b)
a // b を返します。
operator.index(a)
operator.__index__(a)
整数に変換された a を返します。a.__index__() と同等です。
operator.inv(obj)
operator.invert(obj)
operator.__inv__(obj)
operator.__invert__(obj)
obj のビット単位反転を返します。~obj と同じです。
operator.lshift(a, b)
operator.__lshift__(a, b)
a の b ビット左シフトを返します。
operator.mod(a, b)
operator.__mod__(a, b)
a % b を返します。
operator.mul(a, b)
operator.__mul__(a, b)
数値 a および b について a * b を返します。
operator.matmul(a, b)
operator.__matmul__(a, b)
a @ b を返します。
バージョン 3.5 で追加.
operator.neg(obj)
operator.__neg__(obj)
負の obj (-obj) を返します。
operator.or_(a, b)
operator.__or__(a, b)
a と b のビット単位論理和を返します。
operator.pos(obj)
operator.__pos__(obj)
正の obj (+obj) を返します。
operator.pow(a, b)
operator.__pow__(a, b)
数値 a および b について a ** b を返します。
operator.rshift(a, b)
operator.__rshift__(a, b)
a の b ビット右シフトを返します。
operator.sub(a, b)
operator.__sub__(a, b)
a - b を返します。
operator.truediv(a, b)
operator.__truediv__(a, b)
2/3 が 0 ではなく 0.66 となるような a / b を返します。 "真の" 除算としても知られています。
operator.xor(a, b)
operator.__xor__(a, b)
a および b のビット単位排他的論理和を返します。
シーケンスを扱う演算子（いくつかの演算子はマッピングも扱います）には以下のようなものがあります:
operator.concat(a, b)
operator.__concat__(a, b)
シーケンス a および b について a + b を返します。
operator.contains(a, b)
operator.__contains__(a, b)
b in a の判定結果を返します。被演算子が左右反転しているので注意してください。
operator.countOf(a, b)
a の中に b が出現する回数を返します。
operator.delitem(a, b)
operator.__delitem__(a, b)
a でインデクスが b の値を削除します。
operator.getitem(a, b)
operator.__getitem__(a, b)
a でインデクスが b の値を返します。
operator.indexOf(a, b)
a で最初に b が出現する場所のインデクスを返します。
operator.setitem(a, b, c)
operator.__setitem__(a, b, c)
a でインデクスが b の値を c に設定します。
operator.length_hint(obj, default=0)
オブジェクト o の概算の長さを返します。最初に実際の長さを、次に object.__length_hint__() を使って概算の長さを、そして最後にデフォルトの値を返そうとします。
バージョン 3.4 で追加.
operator モジュールは属性とアイテムの汎用的な検索のための道具も定義しています。 map(), sorted(), itertools.groupby(), や関数を引数に取るその他の関数に対して高速にフィールドを抽出する際に引数として使うと便利です。
operator.attrgetter(attr)
operator.attrgetter(*attrs)
演算対象から attr を取得する呼び出し可能なオブジェクトを返します。二つ以上の属性を要求された場合には、属性のタプルを返します。属性名はドットを含むこともできます。例えば:
f = attrgetter('name') とした後で、f(b) を呼び出すと b.name を返します。
f = attrgetter('name', 'date') とした後で、f(b) を呼び出すと (b.name, b.date) を返します。
f = attrgetter('name.first', 'name.last') とした後で、f(b) を呼び出すと (b.name.first, b.name.last) を返します。
次と等価です:
def attrgetter(*items):
    if any(not isinstance(item, str) for item in items):
        raise TypeError('attribute name must be a string')
    if len(items) == 1:
        attr = items[0]
        def g(obj):
            return resolve_attr(obj, attr)
    else:
        def g(obj):
            return tuple(resolve_attr(obj, attr) for attr in items)
    return g
def resolve_attr(obj, attr):
    for name in attr.split("."):
        obj = getattr(obj, name)
    return obj
operator.itemgetter(item)
operator.itemgetter(*items)
演算対象からその __getitem__() メソッドを使って item を取得する呼び出し可能なオブジェクトを返します。 二つ以上のアイテムを要求された場合には、アイテムのタプルを返します。例えば:
f = itemgetter(2) とした後で、f(r) を呼び出すと r[2] を返します。
g = itemgetter(2, 5, 3) とした後で、g(r) を呼び出すと (r[2], r[5], r[3]) を返します。
次と等価です:
def itemgetter(*items):
    if len(items) == 1:
        item = items[0]
        def g(obj):
            return obj[item]
    else:
        def g(obj):
            return tuple(obj[item] for item in items)
    return g
アイテムは被演算子の __getitem__() メソッドが受け付けるどんな型でも構いません。辞書ならば任意のハッシュ可能な値を受け付けます。リスト、タプル、文字列などはインデクスかスライスを受け付けます:
>>>
itemgetter('name')({'name': 'tu', 'age': 18})
'tu'
itemgetter(1)('ABCDEFG')
'B'
itemgetter(1,3,5)('ABCDEFG')
('B', 'D', 'F')
itemgetter(slice(2,None))('ABCDEFG')
'CDEFG'
>>>
soldier = dict(rank='captain', name='dotterbart')
itemgetter('rank')(soldier)
'captain'
itemgetter() を使って特定のフィールドをタプルレコードから取り出す例:
>>>
inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]
getcount = itemgetter(1)
list(map(getcount, inventory))
[3, 2, 5, 1]
sorted(inventory, key=getcount)
[('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]
operator.methodcaller(name, /, *args, **kwargs)
引数の name メソッドを呼び出す呼び出し可能オブジェクトを返します。追加の引数および/またはキーワード引数が与えられると、これらもそのメソッドに引き渡されます。例えば:
f = methodcaller('name') とした後で、f(b) を呼び出すと b.name() を返します。
f = methodcaller('name', 'foo', bar=1) とした後で、f(b) を呼び出すと b.name('foo', bar=1) を返します。
次と等価です:
def methodcaller(name, /, *args, **kwargs):
    def caller(obj):
        return getattr(obj, name)(*args, **kwargs)
    return caller
演算子から関数への対応表
下のテーブルでは、個々の抽象的な操作が、どのように Python 構文上の各演算子や operator モジュールの関数に対応しているかを示しています。
演算
操作
関数
加算
a + b
add(a, b)
結合
seq1 + seq2
concat(seq1, seq2)
包含判定
obj in seq
contains(seq, obj)
除算
a / b
truediv(a, b)
除算
a // b
floordiv(a, b)
ビット単位論理積
a & b
and_(a, b)
ビット単位排他的論理和
a ^ b
xor(a, b)
ビット単位反転
~ a
invert(a)
ビット単位論理和
a | b
or_(a, b)
冪乗
a ** b
pow(a, b)
同一性
a is b
is_(a, b)
同一性
a is not b
is_not(a, b)
インデクス指定の代入
obj[k] = v
setitem(obj, k, v)
インデクス指定の削除
del obj[k]
delitem(obj, k)
インデクス指定
obj[k]
getitem(obj, k)
左シフト
a << b
lshift(a, b)
剰余
a % b
mod(a, b)
乗算
a * b
mul(a, b)
行列の乗算
a @ b
matmul(a, b)
(算術) 負
- a
neg(a)
(論理) 否
not a
not_(a)
正
+ a
pos(a)
右シフト
a >> b
rshift(a, b)
スライス指定の代入
seq[i:j] = values
setitem(seq, slice(i, j), values)
スライス指定の削除
del seq[i:j]
delitem(seq, slice(i, j))
スライス指定
seq[i:j]
getitem(seq, slice(i, j))
文字列書式化
s % obj
mod(s, obj)
減算
a - b
sub(a, b)
真理値判定
obj
truth(obj)
順序付け
a < b
lt(a, b)
順序付け
a <= b
le(a, b)
等価性
a == b
eq(a, b)
不等性
a != b
ne(a, b)
順序付け
a >= b
ge(a, b)
順序付け
a > b
gt(a, b)
インプレース (in-place) 演算子
多くの演算に「インプレース」版があります。 以下の関数はそうした演算子の通常の文法に比べてより素朴な呼び出し方を提供します。たとえば、 文 x += y は x = operator.iadd(x, y) と等価です。別の言い方をすると、 z = operator.iadd(x, y) は複合文 z = x; z += y と等価です。
なお、これらの例では、インプレースメソッドが呼び出されたとき、計算と代入は二段階に分けて行われます。以下に挙げるインプレース関数は、インプレースメソッドを呼び出してその第一段階だけを行います。第二段階の代入は扱われません。
文字列、数、タプルのようなイミュータブルなターゲットでは、更新された値が計算されますが、入力変数に代入し返されはしません。
>>>
a = 'hello'
iadd(a, ' world')
'hello world'
a
'hello'
リストや辞書のようなミュータブルなターゲットでは、インプレースメソッドは更新を行うので、その後に代入をする必要はありません。
>>>
s = ['h', 'e', 'l', 'l', 'o']
iadd(s, [' ', 'w', 'o', 'r', 'l', 'd'])
['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']
s
['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']
operator.iadd(a, b)
operator.__iadd__(a, b)
a = iadd(a, b) は a += b と等価です。
operator.iand(a, b)
operator.__iand__(a, b)
a = iand(a, b) は a &= b と等価です。
operator.iconcat(a, b)
operator.__iconcat__(a, b)
a = iconcat(a, b) は二つのシーケンス a と b に対し a += b と等価です。
operator.ifloordiv(a, b)
operator.__ifloordiv__(a, b)
a = ifloordiv(a, b) は a //= b と等価です。
operator.ilshift(a, b)
operator.__ilshift__(a, b)
a = ilshift(a, b) は a <<= b と等価です。
operator.imod(a, b)
operator.__imod__(a, b)
a = imod(a, b) は a %= b と等価です。
operator.imul(a, b)
operator.__imul__(a, b)
a = imul(a, b) は a *= b と等価です。
operator.imatmul(a, b)
operator.__imatmul__(a, b)
a = imatmul(a, b) は a @= b と等価です。
バージョン 3.5 で追加.
operator.ior(a, b)
operator.__ior__(a, b)
a = ior(a, b) は a |= b と等価です。
operator.ipow(a, b)
operator.__ipow__(a, b)
a = ipow(a, b) は a **= b と等価です。
operator.irshift(a, b)
operator.__irshift__(a, b)
a = irshift(a, b) は a >>= b と等価です。
operator.isub(a, b)
operator.__isub__(a, b)
a = isub(a, b) は a -= b と等価です。
operator.itruediv(a, b)
operator.__itruediv__(a, b)
a = itruediv(a, b) は a /= b と等価です。
operator.ixor(a, b)
operator.__ixor__(a, b)
a = ixor(a, b) は a ^= b と等価です。
numbers --- 数の抽象基底クラス
ソースコード: Lib/numbers.py
numbers モジュール (PEP 3141) は数の 抽象基底クラス の階層を定義します。この階層では、さらに多くの演算が順番に定義されます。このモジュールで定義される型はどれもインスタンス化できません。
class numbers.Number
数の階層の根。引数 x が、種類は何であれ、数であるということだけチェックしたい場合、isinstance(x, Number) が使えます。
数値塔
class numbers.Complex
この型のサブクラスは複素数を表し、組み込みの complex 型を受け付ける演算を含みます。それらは: complex および bool への変換、 real, imag, +, -, *, /, abs(), conjugate(), ==, != です。 - と != 以外の全てのものは抽象メソッドや抽象プロパティです。
real
抽象プロパティ。この数の実部を取り出します。
imag
抽象プロパティ。この数の虚部を取り出します。
abstractmethod conjugate()
抽象プロパティ。複素共役を返します。たとえば、(1+3j).conjugate() == (1-3j) です。
class numbers.Real
Real は、Complex 上に、 実数に対して行える演算を加えます。
簡潔に言うとそれらは: float への変換, math.trunc(), round(), math.floor(), math.ceil(), divmod(), //, %, <, <=, > および >= です。
Real はまた complex(), real, imag および conjugate() のデフォルトを提供します。
class numbers.Rational
Real をサブタイプ化し numerator と denominator のプロパティを加えたものです。これらは既約分数のものでなければなりません。この他に float() のデフォルトも提供します。
numerator
抽象プロパティ。
denominator
抽象プロパティ。
class numbers.Integral
Rational をサブタイプ化し int への変換が加わります。 float(), numerator, denominator のデフォルトを提供します。 ** に対する抽象メソッドと、ビット列演算 <<, >>, &, ^, |, ~ を追加します。
型実装者のための注意事項
実装する人は等しい数が等しく扱われるように同じハッシュを与えるように気を付けねばなりません。これは二つの異なった実数の拡張があるような場合にはややこしいことになるかもしれません。たとえば、 fractions.Fraction は hash() を以下のように実装しています:
def __hash__(self):
    if self.denominator == 1:
        # Get integers right.
        return hash(self.numerator)
    # Expensive check, but definitely correct.
    if self == float(self):
        return hash(float(self))
    else:
        # Use tuple's hash to avoid a high collision rate on
        # simple fractions.
        return hash((self.numerator, self.denominator))
さらに数のABCを追加する
数に対する ABC が他にも多く存在しうることは、言うまでもありません。それらの ABC を階層に追加する可能性が閉ざされるとしたら、その階層は貧相な階層でしかありません。たとえば、 MyFoo を Complex と Real の間に付け加えるには、次のようにします:
class MyFoo(Complex): ...
MyFoo.register(Real)
算術演算の実装
算術演算を実装する際には、型混合(mixed-mode)演算を行うと、作者が両方の引数の型について知っているような実装を呼び出すか、両方の引数をそれぞれ最も似ている組み込み型に変換してその型で演算を行うか、どちらになるのが望ましい実装です。つまり、 Integral のサブタイプに対しては __add__() と __radd__() を次のように定義するべきです:
class MyIntegral(Integral):
    def __add__(self, other):
        if isinstance(other, MyIntegral):
            return do_my_adding_stuff(self, other)
        elif isinstance(other, OtherTypeIKnowAbout):
            return do_my_other_adding_stuff(self, other)
        else:
            return NotImplemented
    def __radd__(self, other):
        if isinstance(other, MyIntegral):
            return do_my_adding_stuff(other, self)
        elif isinstance(other, OtherTypeIKnowAbout):
            return do_my_other_adding_stuff(other, self)
        elif isinstance(other, Integral):
            return int(other) + int(self)
        elif isinstance(other, Real):
            return float(other) + float(self)
        elif isinstance(other, Complex):
            return complex(other) + complex(self)
        else:
            return NotImplemented
ここには5つの異なる Complex のサブクラス間の混在型の演算があります。上のコードの中で MyIntegral と OtherTypeIKnowAbout に触れない部分を "ボイラープレート" と呼ぶことにしましょう。 a を Complex のサブタイプである A のインスタンス (a : A <: Complex)、同様に b : B <: Complex として、 a + b を考えます:
A が b を受け付ける __add__() を定義している場合、何も問題はありません。
A でボイラープレート部分に落ち込み、その結果 __add__() が値を返すならば、 B に良く考えられた __radd__() が定義されている可能性を見逃してしまいますので、ボイラープレートは __add__() から NotImplemented を返すのが良いでしょう。(若しくは、 A はまったく __add__() を実装すべきではなかったかもしれません。)
そうすると、 B の __radd__() にチャンスが巡ってきます。ここで a が受け付けられるならば、結果は上々です。
ここでボイラープレートに落ち込むならば、もう他に試すべきメソッドはありませんので、デフォルト実装の出番です。
もし B <: A ならば、Python は A.__add__ の前に B.__radd__ を試します。これで良い理由は、 A についての知識を持って実装しており、 Complex に委ねる前にこれらのインスタンスを扱えるはずだからです。
もし A <: Complex かつ B <: Real で他に共有された知識が無いならば、適切な共通の演算は組み込みの complex を使ったものになり、どちらの __radd__() ともそこに着地するでしょうから、 a+b == b+a です。
ほとんどの演算はどのような型についても非常に良く似ていますので、与えられた演算子について順結合(forward)および逆結合(reverse)のメソッドを生成する支援関数を定義することは役に立ちます。たとえば、 fractions.Fraction では次のようなものを利用しています:
def _operator_fallbacks(monomorphic_operator, fallback_operator):
    def forward(a, b):
        if isinstance(b, (int, Fraction)):
            return monomorphic_operator(a, b)
        elif isinstance(b, float):
            return fallback_operator(float(a), b)
        elif isinstance(b, complex):
            return fallback_operator(complex(a), b)
        else:
            return NotImplemented
    forward.__name__ = '__' + fallback_operator.__name__ + '__'
    forward.__doc__ = monomorphic_operator.__doc__
    def reverse(b, a):
        if isinstance(a, Rational):
            # Includes ints.
            return monomorphic_operator(a, b)
        elif isinstance(a, numbers.Real):
            return fallback_operator(float(a), float(b))
        elif isinstance(a, numbers.Complex):
            return fallback_operator(complex(a), complex(b))
        else:
            return NotImplemented
    reverse.__name__ = '__r' + fallback_operator.__name__ + '__'
    reverse.__doc__ = monomorphic_operator.__doc__
    return forward, reverse
def _add(a, b):
    """a + b"""
    return Fraction(a.numerator * b.denominator +
                    b.numerator * a.denominator,
                    a.denominator * b.denominator)
__add__, __radd__ = _operator_fallbacks(_add, operator.add)
# ...
math --- 数学関数
このモジュールは、 C 標準で定義された数学関数へのアクセスを提供します。
これらの関数で複素数を使うことはできません。複素数に対応する必要があるならば、 cmath モジュールにある同じ名前の関数を使ってください。ほとんどのユーザーは複素数を理解するのに必要なだけの数学を勉強したくないので、複素数に対応した関数と対応していない関数の区別がされています。これらの関数では複素数が利用できないため、引数に複素数を渡されると、複素数の結果が返るのではなく例外が発生します。その結果、どういった理由で例外が送出されたかに早い段階で気づく事ができます。
このモジュールでは次の関数を提供しています。明示的な注記のない限り、戻り値は全て浮動小数点数になります。
数論および数表現の関数
math.ceil(x)
x の「天井」 (x 以上の最小の整数) を返します。 x が浮動小数点数でなければ、内部的に x.__ceil__() が実行され、 Integral 値が返されます。
math.comb(n, k)
バージョン 3.8 で追加.
math.copysign(x, y)
x の大きさ (絶対値) で y と同じ符号の浮動小数点数を返します。符号付きのゼロをサポートしているプラットフォームでは、copysign(1.0, -0.0) は -1.0 を返します。
math.fabs(x)
x の絶対値を返します。
math.factorial(x)
x の階乗を整数で返します。 x が整数でないか、負の数の場合は、 ValueError を送出します。
バージョン 3.9 で非推奨: Accepting floats with integral values (like 5.0) is deprecated.
math.floor(x)
x の「床」 (x 以下の最大の整数) を返します。 x が浮動小数点数でなければ、内部的に x.__floor__() が実行され、 Integral 値が返されます。
math.fmod(x, y)
プラットフォームの C ライブラリで定義されている fmod(x, y) を返します。 Python の x % y という式は必ずしも同じ結果を返さないということに注意してください。 C 標準の要求では、 fmod() は除算の結果が x と同じ符号になり、大きさが abs(y) より小さくなるような整数 n については fmod(x, y) が厳密に (数学的に、つまり無限の精度で) x - n*y と等価であるよう求めています。 Python の x % y は、 y と同じ符号の結果を返し、浮動小数点の引数に対して厳密な解を出せないことがあります。例えば、 fmod(-1e-100, 1e100) は -1e-100 ですが、 Python の -1e-100 % 1e100 は 1e100-1e-100 になり、浮動小数点型で厳密に表現できず、ややこしいことに 1e100 に丸められます。このため、一般には浮動小数点の場合には関数 fmod() 、整数の場合には x % y を使う方がよいでしょう。
math.frexp(x)
x の仮数と指数を (m, e) のペアとして返します。m はfloat型で、e は厳密に x == m * 2**e であるような整数型です。x がゼロの場合は、(0.0, 0) を返し、それ以外の場合は、0.5 <= abs(m) < 1 を返します。これは浮動小数点型の内部表現を可搬性を保ったまま "分解 (pick apart)" するためです。
math.fsum(iterable)
iterable 中の値の浮動小数点数の正確な和を返します。複数の部分和を追跡することで精度のロスを防ぎます:
>>>
>>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
0.9999999999999999
>>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
1.0
アルゴリズムの正確性は、 IEEE-754 演算の保証と、丸めモードが偶数丸め (half-even) である典型的な場合に依存します。Windows 以外のいくつかのビルドでは、下層の C ライブラリが拡張精度の加算を行い、時々計算途中の和を double 型へ丸めてしまうため、最下位ビットが消失することがあります。
より詳細な議論と代替となる二つのアプローチについては、ASPN cookbook recipes for accurate floating point summation をご覧下さい。
math.gcd(*integers)
バージョン 3.5 で追加.
バージョン 3.9 で変更: Added support for an arbitrary number of arguments. Formerly, only two arguments were supported.
math.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)
値 a と b が互いに近い場合 True を、そうでない場合は False を返します。
2値が近いと見なされるかどうかは与えられた絶対または相対許容差により決定されます。
rel_tol は相対許容差、すなわち a と b の絶対値の大きい方に対する a と b の許容される最大の差です。 例えば許容差を 5% に設定する場合 rel_tol=0.05 を渡します。 デフォルトの許容差は 1e-09 で、2値が9桁同じことを保証します。 rel_tol は0より大きくなければなりません。
abs_tol は最小の絶対許容差です。0に近い値を比較するのに有用です。abs_tol は0より大きくなければなりません。
エラーが起こらなければ結果は abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol) です。
IEEE 754 特殊値 NaN、inf、-inf は IEEE の規則に従って処理されます。 具体的には、NaN は自身を含めたあらゆる値に近いとは見なされません。 inf と -inf は自身とのみ近いと見なされます。
バージョン 3.5 で追加.
参考 PEP 485 -- A function for testing approximate equality
math.isfinite(x)
x が無限でも NaN でもない場合に True を返します。それ以外の時には False を返します。 (注意: 0.0 は有限数と扱われます。)
バージョン 3.2 で追加.
math.isinf(x)
x が正ないし負の無限数ならば True を返します。それ以外の時には False を返します。
math.isnan(x)
x がNaN (not a number、非数) の時に True を返します。それ以外の場合には False を返します。
math.isqrt(n)
バージョン 3.8 で追加.
math.lcm(*integers)
バージョン 3.9 で追加.
math.ldexp(x, i)
x * (2**i) を返します。これは本質的に frexp() の逆関数です。
math.modf(x)
x の小数部分と整数部分を返します。両方の結果は x の符号を受け継ぎます。整数部はfloat型で返されます。
math.nextafter(x, y)
例:
math.nextafter(x, math.inf) goes up: towards positive infinity.
math.nextafter(x, -math.inf) goes down: towards minus infinity.
math.nextafter(x, 0.0) goes towards zero.
math.nextafter(x, math.copysign(math.inf, x)) goes away from zero.
バージョン 3.9 で追加.
math.perm(n, k=None)
バージョン 3.8 で追加.
math.prod(iterable, *, start=1)
バージョン 3.8 で追加.
math.remainder(x, y)
IEEE 754 標準方式の x を y で割った剰余を返します。 有限な x と有限な y では、分数 x / y の厳密な値に最も近い整数を n として、 x - n*y がこの返り値となります。 x / y が隣り合う 2 つの整数のちょうど真ん中だった場合は、最も近い 偶数 が n として使われます。 従って、剰余 r = remainder(x, y) は常に abs(r) <= 0.5 * abs(y) を満たします。
特殊なケースについては IEEE 754 に従います: 任意の有限な x に対する remainder(x, math.inf) 、および任意の非 NaN の x に対する remainder(x, 0) と remainder(math.inf, x) は ValueError を送出します。 剰余演算の結果がゼロの場合、そのゼロは x と同じ符号を持ちます。
IEEE 754 の二進浮動小数点数を使用しているプラットフォームでは、この演算の結果は常に厳密に表現可能です。丸め誤差は発生しません。
バージョン 3.7 で追加.
math.trunc(x)
x の Integral 値 (たいていは整数) へ切り捨てられた Real 値を返します。 x.__trunc__() に処理を委譲します。
math.ulp(x)
Return the value of the least significant bit of the float x:
バージョン 3.9 で追加.
frexp() と modf() は C のものとは異なった呼び出し/返しパターンを持っていることに注意してください。引数を1つだけ受け取り、1組のペアになった値を返すので、2つ目の戻り値を '出力用の引数' 経由で返したりはしません (Python には出力用の引数はありません)。
ceil() 、 floor() 、および modf() 関数については、非常に大きな浮動小数点数が 全て 整数そのものになるということに注意してください。通常、Python の浮動小数点型は 53 ビット以上の精度をもたない (プラットフォームにおける C double 型と同じ) ので、結果的に abs(x) >= 2**52 であるような浮動小数点型 x は小数部分を持たなくなるのです。
指数関数と対数関数
math.exp(x)
e = 2.718281... を自然対数の底として、 e の x 乗を返します。 この値は、通常は math.e ** x や pow(math.e, x) よりも精度が高いです。
math.expm1(x)
e の x 乗から 1 を引いた値を返します。 ここでの e は自然対数の底です。 小さい浮動小数点数の x において、減算 exp(x) - 1 は 桁落ち が発生します。 expm1() 関数は、この量を最大精度で計算する方法を提供します。
>>>
>>> from math import exp, expm1
>>> exp(1e-5) - 1  # gives result accurate to 11 places
1.0000050000069649e-05
>>> expm1(1e-5)    # result accurate to full precision
1.0000050000166668e-05
バージョン 3.2 で追加.
math.log(x[, base])
引数が1つの場合、x の (e を底とする)自然対数を返します。
引数が2つの場合、log(x)/log(base) として求められる base を底とした x の対数を返します。
math.log1p(x)
1+x の自然対数(つまり底 e の対数)を返します。結果はゼロに近い x に対して正確になるような方法で計算されます。
math.log2(x)
2を底とする x の対数を返します。この関数は、一般に log(x, 2) よりも正確な値を返します。
バージョン 3.3 で追加.
参考 int.bit_length() は、その整数を二進法で表すのに何ビット必要かを返す関数です。符号と先頭のゼロは無視されます。
math.log10(x)
x の10を底とした対数(常用対数)を返します。この関数は通常、log(x, 10) よりも高精度です。
math.pow(x, y)
x の y 乗を返します。例外的な場合については、 C99 標準の付録 'F' に可能な限り従います。特に、 pow(1.0, x) と pow(x, 0.0) は、たとえ x が零や NaN でも、常に 1.0 を返します。もし x と y の両方が有限の値で、 x が負、 y が整数でない場合、 pow(x, y) は未定義で、 ValueError を送出します。
組み込みの ** 演算子と違って、 math.pow() は両方の引数を float 型に変換します。正確な整数の冪乗を計算するには ** もしくは組み込みの pow() 関数を使ってください。
math.sqrt(x)
x の平方根を返します。
三角関数
math.acos(x)
math.asin(x)
math.atan(x)
math.atan2(y, x)
atan(y / x) を、ラジアンで返します。戻り値は -pi から pi の間になります。この角度は、極座標平面において原点から (x, y) へのベクトルが X 軸の正の方向となす角です。 atan2() のポイントは、両方の入力の符号が既知であるために、位相角の正しい象限を計算できることにあります。例えば、 atan(1) と atan2(1, 1) はいずれも pi/4 ですが、 atan2(-1, -1) は -3*pi/4 になります。
math.cos(x)
x ラジアンの余弦を返します。
math.dist(p, q)
およそ次と等価です:
sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q)))
バージョン 3.8 で追加.
math.hypot(*coordinates)
バージョン 3.8 で変更: Added support for n-dimensional points. Formerly, only the two dimensional case was supported.
math.sin(x)
x ラジアンの正弦を返します。
math.tan(x)
x ラジアンの正接を返します。
角度変換
math.degrees(x)
角 x をラジアンから度に変換します。
math.radians(x)
角 x を度からラジアンに変換します。
双曲線関数
双曲線関数 は円ではなく双曲線を元にした三角関数のようなものです。
math.acosh(x)
x の逆双曲線余弦を返します。
math.asinh(x)
x の逆双曲線正弦を返します。
math.atanh(x)
x の逆双曲線正接を返します。
math.cosh(x)
x の双曲線余弦を返します。
math.sinh(x)
x の双曲線正弦を返します。
math.tanh(x)
x の双曲線正接を返します。
特殊関数
math.erf(x)
x の 誤差関数 を返します。
erf() 関数は、伝統的な統計関数を計算するのに使うことができます。例えば、 累積標準正規分布 を計算する関数は次のように定義できます:
def phi(x):
    'Cumulative distribution function for the standard normal distribution'
    return (1.0 + erf(x / sqrt(2.0))) / 2.0
バージョン 3.2 で追加.
math.erfc(x)
x の相補誤差関数を返します。相補誤差関数 は 1.0 - erf(x) と定義されます。この関数は、1との引き算では 桁落ち をするような大きな x に対し使われます。
バージョン 3.2 で追加.
math.gamma(x)
x の ガンマ関数 を返します。
バージョン 3.2 で追加.
math.lgamma(x)
x のガンマ関数の絶対値の自然対数を返します。
バージョン 3.2 で追加.
定数
math.pi
利用可能なだけの精度の数学定数 π = 3.141592... (円周率)。
math.e
利用可能なだけの精度の数学定数 e = 2.718281... (自然対数の底)。
math.tau
利用可能なだけの精度の数学定数 τ = 6.283185... です。 タウは 2π に等しい円定数で、円周と半径の比です。 タウについて学ぶには Vi Hart のビデオ Pi is (still) Wrong をチェックして、パイを二倍食べて Tau day を祝い始めましょう！
バージョン 3.6 で追加.
math.inf
浮動小数の正の無限大です。(負の無限大には -math.inf を使います。) float('inf') の出力と等価です。
バージョン 3.5 で追加.
math.nan
浮動小数の非数 "not a number" (NaN) です。float('nan') の出力と等価です。
バージョン 3.5 で追加.
CPython implementation detail: math モジュールは、ほとんどが実行プラットフォームにおける C 言語の数学ライブラリ関数に対する薄いラッパでできています。 例外時の挙動は、適切である限り C99 標準の Annex F に従います。 現在の実装では、sqrt(-1.0) や log(0.0) といった (C99 Annex F で不正な演算やゼロ除算を通知することが推奨されている) 不正な操作に対して ValueError を送出し、(例えば exp(1000.0) のような) 演算結果がオーバーフローする場合には OverflowError を送出します。 上記の関数群は、1つ以上の引数が NaN であった場合を除いて NaN を返しません。 引数に NaN が与えられた場合は、殆どの関数は NaN を返しますが、 (C99 Annex F に従って) 別の動作をする場合があります。 例えば、 pow(float('nan'), 0.0) や hypot(float('nan'), float('inf')) といった場合です。 訳注: 例外が発生せずに結果が返ると、計算結果がおかしくなった原因が複素数を渡したためだということに気づくのが遅れる可能性があります。
Python は signaling NaN と quiet NaN を区別せず、signaling NaN に対する挙動は未定義とされていることに注意してください。典型的な挙動は、全ての NaN を quiet NaN として扱うことです。
cmath --- 複素数のための数学関数
このモジュールは、複素数を扱う数学関数へのアクセスを提供しています。 このモジュール中の関数は整数、浮動小数点数または複素数を引数にとります。 また、 __complex__() または __float__() どちらかのメソッドを提供している Python オブジェクトも受け付けます。 これらのメソッドはそのオブジェクトを複素数または浮動小数点数に変換するのにそれぞれ使われ、呼び出された関数はそうして変換された結果を利用します。
注釈 ハードウェア及びシステムレベルでの符号付きゼロのサポートがあるプラットフォームでは、分枝切断 (branch cut) の関わる関数において切断された 両側 の分枝で連続になります。ゼロの符号でどちらの分枝であるかを区別するのです。符号付きゼロがサポートされないプラットフォームでは連続性は以下の仕様で述べるようになります。
極座標変換
Python の複素数 z は内部的には 直交座標 もしくは デカルト座標 と呼ばれる座標を使って格納されています。この座標はその複素数の 実部 z.real と 虚部 z.imag で決まります。言い換えると:
z == z.real + z.imag*1j
極座標 は複素数を表現する別の方法です。極座標では、複素数 z は半径 r と位相角 phi で定義されます。半径 r は z から原点までの距離です。位相 phi は x 軸の正の部分から原点と z を結んだ線分までの角度を反時計回りにラジアンで測った値です。
次の関数はネイティブの直交座標を極座標に変換したりその逆を行うのに使えます。
cmath.phase(x)
x の位相 (x の 偏角 とも呼びます) を浮動小数点数で返します。phase(x) は math.atan2(x.imag, x.real) と同等です。返り値は [-π, π] の範囲にあり、この演算の分枝切断は負の実軸に沿って延びていて、上から連続です。(現在のほとんどのシステムはそうですが) 符号付きゼロをサポートしているシステムでは、結果の符号は x.imag がゼロであってさえ x.imag の符号と等しくなります:
>>>
>>> phase(complex(-1.0, 0.0))
3.141592653589793
>>> phase(complex(-1.0, -0.0))
-3.141592653589793
注釈 複素数 x のモジュラス (絶対値) は組み込みの abs() 関数で計算できます。この演算を行う cmath モジュールの関数はありません。
cmath.polar(x)
x の極座標表現を返します。x の半径 r と x の位相 phi の組 (r, phi) を返します。polar(x) は (abs(x), phase(x)) に等しいです。
cmath.rect(r, phi)
極座標 r, phi を持つ複素数 x を返します。値は r * (math.cos(phi) + math.sin(phi)*1j) に等しいです。
指数関数と対数関数
cmath.exp(x)
e を自然対数の底として、 e の x 乗を返します。
cmath.log(x[, base])
base を底とする x の対数を返します。もし base が指定されていない場合には、x の自然対数を返します。分枝切断を一つもち、0 から負の実数軸に沿って -∞ へと延びており、上から連続しています。
cmath.log10(x)
x の底を 10 とする対数を返します。 log() と同じ分枝切断を持ちます。
cmath.sqrt(x)
x の平方根を返します。 log() と同じ分枝切断を持ちます。
三角関数
cmath.acos(x)
x の逆余弦を返します。この関数には二つの分枝切断 (branch cut) があります: 一つは 1 から右側に実数軸に沿って∞へと延びていて、下から連続しています。もう一つは -1 から左側に実数軸に沿って -∞へと延びていて、上から連続しています。
cmath.asin(x)
x の逆正弦を返します。 acos() と同じ分枝切断を持ちます。
cmath.atan(x)
x の逆正接を返します。二つの分枝切断があります: 一つは 1j から虚数軸に沿って ∞j へと延びており、右から連続です。もう一つは -1j から虚数軸に沿って -∞j へと延びており、左から連続です。
cmath.cos(x)
x の余弦を返します。
cmath.sin(x)
x の正弦を返します。
cmath.tan(x)
x の正接を返します。
双曲線関数
cmath.acosh(x)
x の逆双曲線余弦を返します。分枝切断が一つあり、1 の左側に実数軸に沿って -∞へと延びていて、上から連続しています。
cmath.asinh(x)
x の逆双曲線正弦を返します。二つの分枝切断があります: 一つは 1j から虚数軸に沿って ∞j へと延びており、右から連続です。もう一つは -1j から虚数軸に沿って -∞j へと延びており、左から連続です。
cmath.atanh(x)
x の逆双曲線正接を返します。二つの分枝切断があります: 一つは 1 から実数軸に沿って ∞ へと延びており、下から連続です。もう一つは -1 から実数軸に沿って -∞ へと延びており、上から連続です。
cmath.cosh(x)
x の双曲線余弦を返します。
cmath.sinh(x)
x の双曲線正弦を返します。
cmath.tanh(x)
x の双曲線正接を返します。
類別関数
cmath.isfinite(x)
x の実部、虚部ともに有限であれば True を返し、それ以外の場合 False を返します。
バージョン 3.2 で追加.
cmath.isinf(x)
x の実数部または虚数部が正または負の無限大であれば True を、そうでなければ False を返します。
cmath.isnan(x)
x の実部と虚部のどちらかが NaN のとき True を返し、それ以外の場合 False を返します。
cmath.isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)
値 a と b が互いに近い場合 True を、そうでない場合は False を返します。
2値が近いと見なされるかどうかは与えられた絶対または相対許容差により決定されます。
rel_tol は相対許容差、すなわち a と b の絶対値の大きい方に対する a と b の許容される最大の差です。 例えば許容差を 5% に設定する場合 rel_tol=0.05 を渡します。 デフォルトの許容差は 1e-09 で、2値が9桁同じことを保証します。 rel_tol は0より大きくなければなりません。
abs_tol は最小の絶対許容差です。0に近い値を比較するのに有用です。abs_tol は0より大きくなければなりません。
エラーが起こらなければ結果は abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol) です。
IEEE 754 特殊値 NaN、inf、-inf は IEEE の規則に従って処理されます。 具体的には、NaN は自身を含めたあらゆる値に近いとは見なされません。 inf と -inf は自身とのみ近いと見なされます。
バージョン 3.5 で追加.
参考 PEP 485 -- A function for testing approximate equality
定数
cmath.pi
定数 π (円周率)で、浮動小数点数です。
cmath.e
定数 e (自然対数の底)で、浮動小数点数です。
cmath.tau
数学定数 τ で、浮動小数点数です。
バージョン 3.6 で追加.
cmath.inf
浮動小数点数の正の無限大です。float('inf') と等価です。
バージョン 3.6 で追加.
cmath.infj
実部がゼロ、虚部が正の無限大の複素数です。complex(0.0, float('inf')) と等価です。
バージョン 3.6 で追加.
cmath.nan
浮動小数点数の非数 "not a number" (NaN) です。float('nan') と等価です。
バージョン 3.6 で追加.
cmath.nanj
実部がゼロ、虚部が NaN の複素数です。complex(0.0, float('nan')) と等価です。
バージョン 3.6 で追加.
math と同じような関数が選ばれていますが、全く同じではないので注意してください。機能を二つのモジュールに分けているのは、複素数に興味がなかったり、もしかすると複素数とは何かすら知らないようなユーザがいるからです。そういった人たちはむしろ、 math.sqrt(-1) が複素数を返すよりも例外を送出してほしいと考えます。また、 cmath で定義されている関数は、たとえ結果が実数で表現可能な場合 (虚数部がゼロの複素数) でも、常に複素数を返すので注意してください。
分枝切断 (branch cut) に関する注釈: 分枝切断を持つ曲線上では、与えられた関数は連続ではなくなります。これらは多くの複素関数における必然的な特性です。複素関数を計算する必要がある場合、これらの分枝に関して理解しているものと仮定しています。悟りに至るために何らかの (到底基礎的とはいえない) 複素数に関する書をひもといてください。数値計算を目的とした分枝切断の正しい選択方法についての情報としては、以下がよい参考文献となります:
decimal --- 十進固定及び浮動小数点数の算術演算
ソースコード: Lib/decimal.py
decimal モジュールは正確に丸められた十進浮動小数点算術をサポートします。 decimal には、 float データ型に比べて、以下のような利点があります:
「(Decimal は) 人々を念頭にデザインされた浮動小数点モデルを元にしており、必然的に最も重要な指針があります -- コンピュータは人々が学校で習った算術と同じように動作する算術を提供しなければならない」 -- 十進数演算仕様より。
十進数を正確に表現できます。 1.1 や 2.2 のような数は、二進数の浮動小数点型では正しく表現できません。エンドユーザは普通、 二進数における 1.1 + 2.2 の近似値が 3.3000000000000003 だからといって、そのように表示してほしいとは考えないものです。
値の正確さは算術にも及びます。十進の浮動小数点による計算では、 0.1 + 0.1 + 0.1 - 0.3 は厳密にゼロに等しくなります。 二進浮動小数点では 5.5511151231257827e-017 になってしまいます。ゼロに近い値とはいえ、この誤差は数値間の等価性テストの信頼性を阻害します。また、誤差が蓄積されることもあります。こうした理由から、数値間の等価性を厳しく保たなければならないようなアプリケーションを考えるなら、十進数による数値表現が望ましいということになります。
decimal モジュールでは、有効桁数の表記が取り入れられており、例えば 1.30 + 1.20 は 2.50 になります。すなわち、末尾のゼロは有効数字を示すために残されます。こうした仕様は通貨計算を行うアプリケーションでは慣例です。乗算の場合、「教科書的な」アプローチでは、乗算の被演算子すべての桁数を使います。例えば、 1.3 * 1.2 は 1.56 になり、 1.30 * 1.20 は 1.5600 になります。
ハードウェアによる 2 進浮動小数点表現と違い、decimal モジュールでは計算精度をユーザが変更できます(デフォルトでは 28 桁です)。この桁数はほとんどの問題解決に十分な大きさです:
>>>
from decimal import *
getcontext().prec = 6
Decimal(1) / Decimal(7)
Decimal('0.142857')
getcontext().prec = 28
Decimal(1) / Decimal(7)
Decimal('0.1428571428571428571428571429')
二進と十進の浮動小数点は、いずれも広く公開されている標準仕様のもとに実装されています。組み込みの浮動小数点型では、標準仕様で提唱されている機能のほんのささやかな部分を利用できるにすぎませんが、decimal では標準仕様が要求している全ての機能を利用できます。必要に応じて、プログラマは値の丸めやシグナル処理を完全に制御できます。この中には全ての不正確な操作を例外でブロックして正確な算術を遵守させるオプションもあります。
decimal モジュールは「偏見なく、正確な丸めなしの十進算術(固定小数点算術と呼ばれることもある)と丸めありの浮動小数点数算術」(十進数演算仕様より引用)をサポートするようにデザインされました。
このモジュールは、十進数型、算術コンテキスト (context for arithmetic)、そしてシグナル (signal) という三つの概念を中心に設計されています。
十進数型は変更不能です。これは符号、係数部、そして指数を持ちます。有効桁数を残すために、仮数部の末尾にあるゼロは切り詰められません。 decimal では、 Infinity, -Infinity, および NaN といった特殊な値も定義されています。標準仕様では -0 と +0 も区別します。
算術コンテキストとは、精度や値丸めの規則、指数部の制限を決めている環境です。この環境では、演算結果を表すためのフラグや、演算上発生した特定のシグナルを例外として扱うかどうかを決めるトラップイネーブラも定義しています。丸め規則には ROUND_CEILING, ROUND_DOWN, ROUND_FLOOR, ROUND_HALF_DOWN, ROUND_HALF_EVEN, ROUND_HALF_UP, ROUND_UP, および ROUND_05UP があります。
シグナルとは、演算の過程で生じる例外的条件です。個々のシグナルは、アプリケーションそれぞれの要求に従って、無視されたり、単なる情報とみなされたり、例外として扱われたりします。 decimal モジュールには、 Clamped, InvalidOperation, DivisionByZero, Inexact, Rounded, Subnormal, Overflow, Underflow, および FloatOperation といったシグナルがあります。
各シグナルには、フラグとトラップイネーブラがあります。演算上何らかのシグナルに遭遇すると、フラグは 1 にセットされます。このとき、もしトラップイネーブラが 1 にセットされていれば、例外を送出します。フラグの値は膠着型 (sticky) なので、演算によるフラグの変化をモニタしたければ、予めフラグをリセットしておかなければなりません。
参考
IBM による汎用十進演算仕様、The General Decimal Arithmetic Specification。
クイックスタートチュートリアル
普通、 decimal を使うときには、モジュールをインポートし、現在の演算コンテキストを getcontext() で調べ、必要なら、精度、丸め、有効なトラップを設定します:
>>>
>>> from decimal import *
>>> getcontext()
Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999,
        capitals=1, clamp=0, flags=[], traps=[Overflow, DivisionByZero,
        InvalidOperation])
>>> getcontext().prec = 7       # Set a new precision
Decimal インスタンスは、整数、文字列、浮動小数点数、またはタプルから構成できます。整数や浮動小数点数からの構成は、整数や浮動小数点数の値を正確に変換します。 Decimal は "非数 (Not a Number)" を表す NaN や正負の Infinity (無限大)、 -0 といった特殊な値も表現できます:
>>>
>>> getcontext().prec = 28
>>> Decimal(10)
Decimal('10')
>>> Decimal('3.14')
Decimal('3.14')
>>> Decimal(3.14)
Decimal('3.140000000000000124344978758017532527446746826171875')
>>> Decimal((0, (3, 1, 4), -2))
Decimal('3.14')
>>> Decimal(str(2.0 ** 0.5))
Decimal('1.4142135623730951')
>>> Decimal(2) ** Decimal('0.5')
Decimal('1.414213562373095048801688724')
>>> Decimal('NaN')
Decimal('NaN')
>>> Decimal('-Infinity')
Decimal('-Infinity')
FloatOperation シグナルがトラップされる場合、コンストラクタや順序比較において誤って decimal と float が混ざると、例外が送出されます:
>>>
>>> c = getcontext()
>>> c.traps[FloatOperation] = True
>>> Decimal(3.14)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
decimal.FloatOperation: [<class 'decimal.FloatOperation'>]
>>> Decimal('3.5') < 3.7
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
decimal.FloatOperation: [<class 'decimal.FloatOperation'>]
>>> Decimal('3.5') == 3.5
True
バージョン 3.3 で追加.
新たな Decimal の有効桁数は入力の桁数だけで決まります。演算コンテキストにおける精度や値丸めの設定が影響するのは算術演算の間だけです。
>>> getcontext().prec = 6
>>> Decimal('3.0')
Decimal('3.0')
>>> Decimal('3.1415926535')
Decimal('3.1415926535')
>>> Decimal('3.1415926535') + Decimal('2.7182818285')
Decimal('5.85987')
>>> getcontext().rounding = ROUND_UP
>>> Decimal('3.1415926535') + Decimal('2.7182818285')
Decimal('5.85988')
C バージョンの内部制限を超えた場合、decimal の構成は InvalidOperation を送出します:
>>>
>>> Decimal("1e9999999999999999999")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
decimal.InvalidOperation: [<class 'decimal.InvalidOperation'>]
バージョン 3.3 で変更.
decimal はほとんどの場面で Python の他の機能とうまくやりとりできます。decimal 浮動小数点の空飛ぶサーカス (flying circus) をお見せしましょう:
>>> data = list(map(Decimal, '1.34 1.87 3.45 2.35 1.00 0.03 9.25'.split()))
>>> max(data)
Decimal('9.25')
>>> min(data)
Decimal('0.03')
>>> sorted(data)
[Decimal('0.03'), Decimal('1.00'), Decimal('1.34'), Decimal('1.87'),
 Decimal('2.35'), Decimal('3.45'), Decimal('9.25')]
>>> sum(data)
Decimal('19.29')
>>> a,b,c = data[:3]
>>> str(a)
'1.34'
>>> float(a)
1.34
>>> round(a, 1)
Decimal('1.3')
>>> int(a)
1
>>> a * 5
Decimal('6.70')
>>> a * b
Decimal('2.5058')
>>> c % a
Decimal('0.77')
いくつかの数学的関数も Decimal には用意されています:
>>>
getcontext().prec = 28
Decimal(2).sqrt()
Decimal('1.414213562373095048801688724')
Decimal(1).exp()
Decimal('2.718281828459045235360287471')
Decimal('10').ln()
Decimal('2.302585092994045684017991455')
Decimal('10').log10()
Decimal('1')
quantize() メソッドは位を固定して数値を丸めます。このメソッドは、結果を固定の桁数で丸めることがよくある、金融アプリケーションで便利です:
>>>
Decimal('7.325').quantize(Decimal('.01'), rounding=ROUND_DOWN)
Decimal('7.32')
Decimal('7.325').quantize(Decimal('1.'), rounding=ROUND_UP)
Decimal('8')
前述のように、 getcontext() 関数を使うと現在の演算コンテキストにアクセスでき、設定を変更できます。ほとんどのアプリケーションはこのアプローチで十分です。
より高度な作業を行う場合、 Context() コンストラクタを使って別の演算コンテキストを作っておくと便利なことがあります。別の演算コンテキストをアクティブにしたければ、 setcontext() を使います。
decimal モジュールでは、標準仕様に従って、すぐ利用できる二つの標準コンテキスト、 BasicContext および ExtendedContext を提供しています。前者はほとんどのトラップが有効になっており、とりわけデバッグの際に便利です:
>>> myothercontext = Context(prec=60, rounding=ROUND_HALF_DOWN)
>>> setcontext(myothercontext)
>>> Decimal(1) / Decimal(7)
Decimal('0.142857142857142857142857142857142857142857142857142857142857')
>>> ExtendedContext
Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999,
        capitals=1, clamp=0, flags=[], traps=[])
>>> setcontext(ExtendedContext)
>>> Decimal(1) / Decimal(7)
Decimal('0.142857143')
>>> Decimal(42) / Decimal(0)
Decimal('Infinity')
>>> setcontext(BasicContext)
>>> Decimal(42) / Decimal(0)
Traceback (most recent call last):
  File "<pyshell#143>", line 1, in -toplevel-
    Decimal(42) / Decimal(0)
DivisionByZero: x / 0
演算コンテキストには、演算中に遭遇した例外的状況をモニタするためのシグナルフラグがあります。フラグが一度セットされると、明示的にクリアするまで残り続けます。そのため、フラグのモニタを行いたいような演算の前には clear_flags() メソッドでフラグをクリアしておくのがベストです。
>>>
>>> setcontext(ExtendedContext)
>>> getcontext().clear_flags()
>>> Decimal(355) / Decimal(113)
Decimal('3.14159292')
>>> getcontext()
Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999, Emax=999999,
        capitals=1, clamp=0, flags=[Inexact, Rounded], traps=[])
flags エントリから、 Pi の有理数による近似値が丸められた (コンテキスト内で決められた精度を超えた桁数が捨てられた) ことと、計算結果が厳密でない (無視された桁の値に非ゼロのものがあった) ことがわかります。
コンテキストの traps フィールドに入っている辞書を使うと、個々のトラップをセットできます:
>>> setcontext(ExtendedContext)
>>> Decimal(1) / Decimal(0)
Decimal('Infinity')
>>> getcontext().traps[DivisionByZero] = 1
>>> Decimal(1) / Decimal(0)
Traceback (most recent call last):
  File "<pyshell#112>", line 1, in -toplevel-
    Decimal(1) / Decimal(0)
DivisionByZero: x / 0
ほとんどのプログラムでは、開始時に一度だけ現在の演算コンテキストを修正します。また、多くのアプリケーションでは、データから Decimal への変換はループ内で一度だけキャストして行います。コンテキストを設定し、 Decimal オブジェクトを生成できたら、ほとんどのプログラムは他の Python 数値型と全く変わらないかのように Decimal を操作できます。
Decimal オブジェクト
class decimal.Decimal(value="0", context=None)
value に基づいて新たな Decimal オブジェクトを構築します。
value は整数、文字列、タプル、 float および他の Decimal オブジェクトにできます。 value を指定しない場合、 Decimal('0') を返します。 value が文字列の場合、先頭と末尾の空白および全てのアンダースコアを取り除いた後には以下の 10進数文字列の文法に従わなければなりません:
sign           ::=  '+' | '-'
digit          ::=  '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'
indicator      ::=  'e' | 'E'
digits         ::=  digit [digit]...
decimal-part   ::=  digits '.' [digits] | ['.'] digits
exponent-part  ::=  indicator [sign] digits
infinity       ::=  'Infinity' | 'Inf'
nan            ::=  'NaN' [digits] | 'sNaN' [digits]
numeric-value  ::=  decimal-part [exponent-part] | infinity
numeric-string ::=  [sign] numeric-value | [sign] nan
他の Unicode 数字も上の digit の場所に使うことができます。つまり各書記体系における(アラビア-インド系やデーヴァナーガリーなど)の数字や、全角数字０('\uff10')から９('\uff19')までなどです。
value を tuple にする場合、タプルは三つの要素を持ち、それぞれ符号 (正なら 0 、負なら 1)、仮数部を表す数字の tuple 、そして指数を表す整数でなければなりません。例えば、 Decimal((0, (1, 4, 1, 4), -3)) は Decimal('1.414') を返します。
value を float にする場合、二進浮動小数点数値が損失なく正確に等価な Decimal に変換されます。この変換はしばしば 53 桁以上の精度を要求します。例えば、 Decimal(float('1.1')) は Decimal('1.100000000000000088817841970012523233890533447265625') に変換されます。
context の精度 (precision) は、記憶される桁数には影響しません。桁数は value に指定した桁数だけから決定されます。例えば、演算コンテキストに指定された精度が 3 桁しかなくても、Decimal('3.00000') は 5 つのゼロを全て記憶します。
context 引数の目的は、 value が正しくない形式の文字列であった場合に行う処理を決めることにあります; 演算コンテキストが InvalidOperation をトラップするようになっていれば、例外を送出します。それ以外の場合には、コンストラクタは値が NaN の Decimal を返します。
一度生成すると、 Decimal オブジェクトは変更不能 (immutable) になります。
バージョン 3.2 で変更: コンストラクタに対する引数に float インスタンスも許されるようになりました。
バージョン 3.3 で変更: FloatOperation トラップがセットされていた場合 float 引数は例外を送出します。デフォルトでトラップはオフです。
バージョン 3.6 で変更: コード中の整数リテラルや浮動小数点リテラルと同様に、アンダースコアを用いて桁をグルーピングできます。
十進浮動小数点オブジェクトは、 float や int のような他の組み込み型と多くの点で似ています。通常の数学演算や特殊メソッドを適用できます。また、 Decimal オブジェクトはコピーでき、pickle 化でき、print で出力でき、辞書のキーにでき、集合の要素にでき、比較、保存、他の型 (float や int) への型強制を行えます。
十進オブジェクトの算術演算と整数や浮動小数点数の算術演算には少々違いがあります。十進オブジェクトに対して剰余演算を適用すると、計算結果の符号は除数の符号ではなく 被除数 の符号と一致します:
>>>
>>> (-7) % 4
1
>>> Decimal(-7) % Decimal(4)
Decimal('-3')
整数除算演算子 // も同様に、実際の商の切り捨てではなく (0に近付くように丸めた) 整数部分を返します。そのため通常の恒等式 x == (x // y) * y + x % y が維持されます:
>>>
>>> -7 // 4
-2
>>> Decimal(-7) // Decimal(4)
Decimal('-1')
演算子 % と演算子 // は (それぞれ) 仕様にあるような 剰余 操作と 整数除算 操作を実装しています。
Decimal オブジェクトは一般に、算術演算で浮動小数点数や fractions.Fraction オブジェクトと組み合わせることができません。例えば、 Decimal に float を足そうとすると、 TypeError が送出されます。ただし、Python の比較演算子を使って Decimal インスタンス x と別の数 y を比較することができます。これにより、異なる型の数間の等価比較の際に、紛らわしい結果を避けます。
バージョン 3.2 で変更: Decimal インスタンスと他の数値型が混在する比較が完全にサポートされるようになりました。
こうした標準的な数値型の特性の他に、十進浮動小数点オブジェクトには様々な特殊メソッドがあります:
adjusted()
仮数の先頭の一桁だけが残るように右側の数字を追い出す桁シフトを行い、その結果の指数部を返します: Decimal('321e+5').adjusted() は 7 を返します。最上桁の小数点からの相対位置を調べる際に使います。
as_integer_ratio()
与えられた Decimal インスタンスを、既約分数で分母が正数の分数として表現した整数のペア (n, d) を返します。
>>>
>>> Decimal('-3.14').as_integer_ratio()
(-157, 50)
変換は正確に行われます。無限大に対してはOverflowErrorを、NaNに対してはValueError を送出します。
バージョン 3.6 で追加.
as_tuple()
数値を表現するための 名前付きタプル: DecimalTuple(sign, digittuple, exponent) を返します。
canonical()
引数の標準的(canonical)エンコーディングを返します。現在のところ、 Decimal インスタンスのエンコーディングは常に標準的なので、この操作は引数に手を加えずに返します。
compare(other, context=None)
二つの Decimal インスタンスの値を比較します。 compare() は Decimal インスタンスを返し、被演算子のどちらかが NaN ならば結果は NaN です:
a or b is a NaN  ==> Decimal('NaN')
a < b            ==> Decimal('-1')
a == b           ==> Decimal('0')
a > b            ==> Decimal('1')
compare_signal(other, context=None)
この演算は compare() とほとんど同じですが、全ての NaN がシグナルを送るところが異なります。すなわち、どちらの比較対象も発信 (signaling) NaN でないならば無言 (quiet) NaN である比較対象があたかも発信 NaN であるかのように扱われます。
compare_total(other, context=None)
二つの対象を数値によらず抽象表現によって比較します。 compare() に似ていますが、結果は Decimal に全順序を与えます。この順序づけによると、数値的に等しくても異なった表現を持つ二つの Decimal インスタンスの比較は等しくなりません:
>>>
Decimal('12.0').compare_total(Decimal('12'))
Decimal('-1')
無言 NaN と発信 NaN もこの全順序に位置付けられます。この関数の結果は、もし比較対象が同じ表現を持つならば Decimal('0') であり、一つめの比較対象が二つめより下位にあれば Decimal('-1')、上位にあれば Decimal('1') です。全順序の詳細については仕様を参照してください。
この演算はコンテキストに影響されず、静かです。すなわち、フラグは変更されず、丸めは行われません。例外として、2番目の比較対象の厳密な変換ができない場合、C バージョンのライブラリでは InvalidOperation 例外を送出するかもしれません。
compare_total_mag(other, context=None)
二つの対象を compare_total() のように数値によらず抽象表現によって比較しますが、両者の符号を無視します。 x.compare_total_mag(y) は x.copy_abs().compare_total(y.copy_abs()) と等価です。
この演算はコンテキストに影響されず、静かです。すなわち、フラグは変更されず、丸めは行われません。例外として、2番目の比較対象の厳密な変換ができない場合、C バージョンのライブラリでは InvalidOperation 例外を送出するかもしれません。
conjugate()
self を返すだけです。このメソッドは十進演算仕様に適合するためだけのものです。
copy_abs()
引数の絶対値を返します。この演算はコンテキストに影響されず、静かです。すなわち、フラグは変更されず、丸めは行われません。
copy_negate()
引数の符号を変えて返します。この演算はコンテキストに影響されず、静かです。すなわち、フラグは変更されず、丸めは行われません。
copy_sign(other, context=None)
最初の演算対象のコピーに二つめと同じ符号を付けて返します。たとえば:
>>>
Decimal('2.3').copy_sign(Decimal('-1.5'))
Decimal('-2.3')
この演算はコンテキストに影響されず、静かです。すなわち、フラグは変更されず、丸めは行われません。例外として、2番目の比較対象の厳密な変換ができない場合、C バージョンのライブラリでは InvalidOperation 例外を送出するかもしれません。
exp(context=None)
与えられた数での(自然)指数関数 e**x の値を返します。結果は ROUND_HALF_EVEN 丸めモードで正しく丸められます。
>>>
Decimal(1).exp()
Decimal('2.718281828459045235360287471')
Decimal(321).exp()
Decimal('2.561702493119680037517373933E+139')
from_float(f)
浮動小数点数を正確に小数に変換するクラスメソッドです。
なお、Decimal.from_float(0.1) は Decimal('0.1') と同じではありません。0.1 は二進浮動小数点数で正確に表せないので、その値は表現できる最も近い値、0x1.999999999999ap-4 として記憶されます。浮動小数点数での等価な値は 0.1000000000000000055511151231257827021181583404541015625 です。
注釈 Python 3.2 以降では、 Decimal インスタンスは float から直接構成できるようになりました。
>>> Decimal.from_float(0.1)
Decimal('0.1000000000000000055511151231257827021181583404541015625')
>>> Decimal.from_float(float('nan'))
Decimal('NaN')
>>> Decimal.from_float(float('inf'))
Decimal('Infinity')
>>> Decimal.from_float(float('-inf'))
Decimal('-Infinity')
バージョン 3.1 で追加.
fma(other, third, context=None)
融合積和(fused multiply-add)です。self*other+third を途中結果の積 self*other で丸めを行わずに計算して返します。
>>>
Decimal(2).fma(3, 5)
Decimal('11')
is_canonical()
引数が標準的(canonical)ならば True を返し、そうでなければ False を返します。現在のところ、 Decimal のインスタンスは常に標準的なのでこのメソッドの結果はいつでも True です。
is_finite()
引数が有限の数値ならば True を、無限大か NaN ならば False を返します。
is_infinite()
引数が正または負の無限大ならば True を、そうでなければ False を返します。
is_nan()
引数が (無言か発信かは問わず) NaN であれば True を、そうでなければ False を返します。
is_normal(context=None)
引数が 正規(normal) の有限数値ならば True を返します。引数がゼロ、非正規(subnormal)、無限大または NaN であれば False を返します。
is_qnan()
引数が無言 NaN であれば True を、そうでなければ False を返します。
is_signed()
引数に負の符号がついていれば True を、そうでなければ False を返します。注意すべきはゼロや NaN なども符号を持ち得ることです。
is_snan()
引数が発信 NaN であれば True を、そうでなければ False を返します。
is_subnormal(context=None)
引数が非正規数(subnormal)であれば True を、そうでなければ False を返します。
is_zero()
引数が(正または負の)ゼロであれば True を、そうでなければ False を返します。
ln(context=None)
演算対象の自然対数(底 e の対数)を返します。結果は ROUND_HALF_EVEN 丸めモードで正しく丸められます。
log10(context=None)
演算対象の底 10 の対数を返します。結果は ROUND_HALF_EVEN 丸めモードで正しく丸められます。
logb(context=None)
非零の数値については、 Decimal インスタンスとして調整された指数を返します。演算対象がゼロだった場合、 Decimal('-Infinity') が返され DivisionByZero フラグが送出されます。演算対象が無限大だった場合、 Decimal('Infinity') が返されます。
logical_and(other, context=None)
logical_and() は二つの 論理引数 (論理引数 参照)を取る論理演算です。結果は二つの引数の数字ごとの and です。
logical_invert(context=None)
logical_invert() は論理演算です。結果は引数の数字ごとの反転です。
logical_or(other, context=None)
logical_or() は二つの 論理引数 (論理引数 参照)を取る論理演算です。結果は二つの引数の数字ごとの or です。
logical_xor(other, context=None)
logical_xor() は二つの 論理引数 (論理引数 参照)を取る論理演算です。結果は二つの引数の数字ごとの排他的論理和です。
max(other, context=None)
max(self, other) と同じですが、値を返す前に現在のコンテキストに即した丸め規則を適用します。また、 NaN に対して、(コンテキストの設定と、発信か無言どちらのタイプであるかに応じて) シグナルを発行するか無視します。
max_mag(other, context=None)
max() メソッドに似ていますが、比較は絶対値で行われます。
min(other, context=None)
min(self, other) と同じですが、値を返す前に現在のコンテキストに即した丸め規則を適用します。また、 NaN に対して、(コンテキストの設定と、発信か無言どちらのタイプであるかに応じて) シグナルを発行するか無視します。
min_mag(other, context=None)
min() メソッドに似ていますが、比較は絶対値で行われます。
next_minus(context=None)
与えられたコンテキスト(またはコンテキストが渡されなければ現スレッドのコンテキスト)において表現可能な、操作対象より小さい最大の数を返します。
next_plus(context=None)
与えられたコンテキスト(またはコンテキストが渡されなければ現スレッドのコンテキスト)において表現可能な、操作対象より大きい最小の数を返します。
next_toward(other, context=None)
二つの比較対象が等しくなければ、一つめの対象に最も近く二つめの対象へ近付く方向の数を返します。もし両者が数値的に等しければ、二つめの対象の符号を採った一つめの対象のコピーを返します。
normalize(context=None)
数値を正規化 (normalize) して、右端に連続しているゼロを除去し、 Decimal('0') と同じ結果はすべて Decimal('0e0') に変換します。等価クラスの属性から基準表現を生成する際に用います。たとえば、 Decimal('32.100') と Decimal('0.321000e+2') の正規化は、いずれも同じ値 Decimal('32.1') になります。
number_class(context=None)
操作対象の クラス を表す文字列を返します。返されるのは以下の10種類のいずれかです。
"-Infinity", 負の無限大であることを示します。
"-Normal", 負の通常数であることを示します。
"-Subnormal", 負の非正規数であることを示します。
"-Zero", 負のゼロであることを示します。
"+Zero", 正のゼロであることを示します。
"+Subnormal", 正の非正規数であることを示します。
"+Normal", 正の通常数であることを示します。
"+Infinity", 正の無限大であることを示します。
"NaN", 無言 (quiet) NaN (Not a Number) であることを示します。
"sNaN", 発信(signaling) NaN であることを示します。
quantize(exp, rounding=None, context=None)
二つ目の操作対象と同じ指数を持つように丸めを行った、一つめの操作対象と等しい値を返します。
>>>
Decimal('1.41421356').quantize(Decimal('1.000'))
Decimal('1.414')
他の操作と違い、打ち切り(quantize)操作後の係数の長さが精度を越えた場合には、 InvalidOperation がシグナルされます。これによりエラー条件がない限り打ち切られた指数が常に右側の引数と同じになることが保証されます。
同様に、他の操作と違い、quantize は Underflow を、たとえ結果が非正規になったり不正確になったとしても、シグナルしません。
二つ目の演算対象の指数が一つ目のそれよりも大きければ丸めが必要かもしれません。この場合、丸めモードは以下のように決められます。rounding 引数が与えられていればそれが使われます。そうでなければ context 引数で決まります。どちらの引数も渡されなければ現在のスレッドのコンテキストの丸めモードが使われます。
処理結果の指数が Emax よりも大きい場合や Etiny よりも小さい場合にエラーが返されます。
radix()
Decimal(10) つまり Decimal クラスがその全ての算術を実行する基数を返します。仕様との互換性のために取り入れられています。
remainder_near(other, context=None)
self を other で割った剰余を返します。これは self % other とは違って、剰余の絶対値を小さくするように符号が選ばれます。より詳しく言うと、n を self / other の正確な値に最も近い整数としたときの self - n * other が返り値になります。最も近い整数が2つある場合には偶数のものが選ばれます。
結果が0になる場合の符号は self の符号と同じになります。
>>>
Decimal(18).remainder_near(Decimal(10))
Decimal('-2')
Decimal(25).remainder_near(Decimal(10))
Decimal('5')
Decimal(35).remainder_near(Decimal(10))
Decimal('-5')
rotate(other, context=None)
一つ目の演算対象の数字を二つ目で指定された量だけ巡回(rotate)した結果を返します。二つめの演算対象は -precision から precision までの範囲の整数でなければなりません。この二つ目の演算対象の絶対値を何桁ずらすかを決めます。そしてもし正の数ならば巡回の方向は左に、そうでなければ右になります。一つ目の演算対象の仮数部は必要ならば精度いっぱいまでゼロで埋められます。符号と指数は変えられません。
same_quantum(other, context=None)
self と other が同じ指数を持っているか、あるいは双方とも NaN である場合に真を返します。
この演算はコンテキストに影響されず、静かです。すなわち、フラグは変更されず、丸めは行われません。例外として、2番目の比較対象の厳密な変換ができない場合、C バージョンのライブラリでは InvalidOperation 例外を送出するかもしれません。
scaleb(other, context=None)
二つ目の演算対象で調整された指数の一つ目の演算対象を返します。同じことですが、一つめの演算対象を 10**other 倍したものを返します。二つ目の演算対象は整数でなければなりません。
shift(other, context=None)
一つ目の演算対象の数字を二つ目で指定された量だけシフトした結果を返します。二つ目の演算対象は -precision から precision までの範囲の整数でなければなりません。この二つ目の演算対象の絶対値が何桁ずらすかを決めます。そしてもし正の数ならばシフトの方向は左に、そうでなければ右になります。一つ目の演算対象の係数は必要ならば精度いっぱいまでゼロで埋められます。符号と指数は変えられません。
sqrt(context=None)
引数の平方根を最大精度で求めます。
to_eng_string(context=None)
文字列に変換します。指数が必要なら工学表記が使われます。
工学表記法では指数は 3 の倍数になります。これにより、基数の小数部には最大で 3 桁までの数字が残されるとともに、末尾に 1 つまたは 2 つの 0 の付加が必要とされるかもしれません。
たとえば、Decimal('123E+1') は Decimal('1.23E+3') に変換されます。
to_integral(rounding=None, context=None)
to_integral_value() メソッドと同じです。to_integral の名前は古いバージョンとの互換性のために残されています。
to_integral_exact(rounding=None, context=None)
最近傍の整数に値を丸め、丸めが起こった場合には Inexact または Rounded のシグナルを適切に出します。丸めモードは以下のように決められます。 rounding 引数が与えられていればそれが使われます。そうでなければ context 引数で決まります。どちらの引数も渡されなければ現在のスレッドのコンテキストの丸めモードが使われます。
to_integral_value(rounding=None, context=None)
Inexact や Rounded といったシグナルを出さずに最近傍の整数に値を丸めます。 rounding が指定されていれば適用されます; それ以外の場合、値丸めの方法は context の設定か現在のコンテキストの設定になります。
論理引数
logical_and(), logical_invert(), logical_or(), および logical_xor() メソッドはその引数が 論理引数 であると想定しています。 論理引数 とは Decimal インスタンスで指数と符号は共にゼロであり、各桁の数字が 0 か 1 であるものです。
Context オブジェクト
コンテキスト (context) とは、算術演算における環境設定です。コンテキストは計算精度を決定し、値丸めの方法を設定し、シグナルのどれが例外になるかを決め、指数の範囲を制限しています。
多重スレッドで処理を行う場合には各スレッドごとに現在のコンテキストがあり、 getcontext() や setcontext() といった関数でアクセスしたり設定変更できます:
decimal.getcontext()
アクティブなスレッドの現在のコンテキストを返します。
decimal.setcontext(c)
アクティブなスレッドのコンテキストを c に設定します。
with 文と localcontext() 関数を使って実行するコンテキストを一時的に変更することもできます。
decimal.localcontext(ctx=None)
with 文の入口でアクティブなスレッドのコンテキストを ctx のコピーに設定し、with 文を抜ける時に元のコンテキストに復旧する、コンテキストマネージャを返します。コンテキストが指定されなければ、現在のコンテキストのコピーが使われます。
たとえば、以下のコードでは精度を42桁に設定し、計算を実行し、そして元のコンテキストに復帰します:
from decimal import localcontext
with localcontext() as ctx:
    ctx.prec = 42   # Perform a high precision calculation
    s = calculate_something()
s = +s  # Round the final result back to the default precision
新たなコンテキストは、以下で説明する Context コンストラクタを使って生成できます。その他にも、 decimal モジュールでは作成済みのコンテキストを提供しています:
class decimal.BasicContext
汎用十進演算仕様で定義されている標準コンテキストの一つです。精度は 9 桁に設定されています。丸め規則は ROUND_HALF_UP です。すべての演算結果フラグはクリアされています。 Inexact, Rounded, Subnormal を除く全ての演算エラートラップが有効 (例外として扱う) になっています。
多くのトラップが有効になっているので、デバッグの際に便利なコンテキストです。
class decimal.ExtendedContext
汎用十進演算仕様で定義されている標準コンテキストの一つです。精度は 9 桁に設定されています。丸め規則は ROUND_HALF_EVEN です。すべての演算結果フラグはクリアされています。トラップは全て無効(演算中に一切例外を送出しない) になっています。
トラップが無効になっているので、エラーの伴う演算結果を NaN や Infinity にし、例外を送出しないようにしたいアプリケーションに向いたコンテキストです。このコンテキストを使うと、他の場合にはプログラムが停止してしまうような状況があっても実行を完了させられます。
class decimal.DefaultContext
Context コンストラクタが新たなコンテキストを作成するさいに雛形にするコンテキストです。このコンテキストのフィールド (精度の設定など) を変更すると、 Context コンストラクタが生成する新たなコンテキストに影響を及ぼします。
このコンテキストは、主に多重スレッド環境で便利です。スレッドを開始する前に何らかのフィールドを変更しておくと、システム全体のデフォルト設定に効果を及ぼすことができます。スレッドを開始した後にフィールドを変更すると、競合条件を抑制するためにスレッドを同期化しなければならないので、推奨しません。
単一スレッドの環境では、このコンテキストを使わないよう薦めます。下で述べるように明示的にコンテキストを作成してください。
デフォルトの値は、 prec=28, rounding=ROUND_HALF_EVEN で、トラップ Overflow, InvalidOperation, および DivisionByZero が有効になっています。
上に挙げた三つのコンテキストに加え、 Context コンストラクタを使って新たなコンテキストを生成できます。
class decimal.Context(prec=None, rounding=None, Emin=None, Emax=None, capitals=None, clamp=None, flags=None, traps=None)
新たなコンテキストを生成します。あるフィールドが定義されていないか None であれば、 DefaultContext からデフォルト値をコピーします。 flags フィールドが設定されていいか None の場合には、全てのフラグがクリアされます。
prec フィールドは範囲 [1, MAX_PREC] 内の整数で、コンテキストにおける算術演算の計算精度を設定します。
rounding オプションは、節 丸めモード で挙げられる定数の一つです。
traps および flags フィールドには、セットしたいシグナルを列挙します。一般的に、新たなコンテキストを作成するときにはトラップだけを設定し、フラグはクリアしておきます。
Emin および Emax フィールドは、許容する指数の外限を指定する整数です。 Emin は範囲 [MIN_EMIN, 0] 内で、 Emax は範囲 [0, MAX_EMAX] 内でなければなりません。
capitals フィールドは 0 または 1 (デフォルト) にします。 1 に設定すると、指数記号を大文字 E で出力します。それ以外の場合には Decimal('6.02e+23') のように e を使います。
clamp フィールドは、 0 (デフォルト) または 1 です。 1 に設定されると、このコンテキストにおける Decimal インスタンスの指数 e は厳密に範囲 Emin - prec + 1 <= e <= Emax - prec + 1 に制限されます。 clamp が 0 なら、それより弱い条件が支配します: 調整された Decimal インスタンスの指数は最大で Emax です。 clamp が 1 なら、大きな正規数は、可能なら、指数が減らされ、対応する数の 0 が係数に加えられ、指数の制約に合わせられます; これは数の値を保存しますが、有効な末尾の 0 に関する情報を失います。例えば:
>>>
>>> Context(prec=6, Emax=999, clamp=1).create_decimal('1.23e999')
Decimal('1.23000E+999')
clamp の値 1 は、IEEE 754 で規定された固定幅十進交換形式と互換にできます。
Context クラスでは、いくつかの汎用のメソッドの他、現在のコンテキストで算術演算を直接行うためのメソッドを数多く定義しています。加えて、 Decimal の各メソッドについて(adjusted() および as_tuple() メソッドを例外として)対応する Context のメソッドが存在します。たとえば、 Context インスタンス C と Decimal インスタンス x に対して、 C.exp(x) は x.exp(context=C) と等価です。それぞれの Context メソッドは、Decimal インスタンスが受け付けられるところならどこでも、Python の整数 (int のインスタンス) を受け付けます。
clear_flags()
フラグを全て 0 にリセットします。
clear_traps()
トラップを全て 0 にリセットします。
バージョン 3.3 で追加.
copy()
コンテキストの複製を返します。
copy_decimal(num)
Decimal インスタンス num のコピーを返します。
create_decimal(num)
self をコンテキストとする新たな Decimal インスタンスを num から生成します。 Decimal コンストラクタと違い、数値を変換する際にコンテキストの精度、値丸め方法、フラグ、トラップを適用します。
定数値はしばしばアプリケーションの要求よりも高い精度を持っているため、このメソッドが役に立ちます。また、値丸めを即座に行うため、例えば以下のように、入力値に値丸めを行わないために合計値にゼロの加算を追加するだけで結果が変わってしまうといった、現在の精度よりも細かい値の影響が紛れ込む問題を防げるという恩恵もあります。以下の例は、丸められていない入力を使うということは和にゼロを加えると結果が変わり得るという見本です:
>>> getcontext().prec = 3
>>> Decimal('3.4445') + Decimal('1.0023')
Decimal('4.45')
>>> Decimal('3.4445') + Decimal(0) + Decimal('1.0023')
Decimal('4.44')
このメソッドは IBM 仕様の to-number 演算を実装したものです。引数が文字列の場合、前や後ろに余計な空白を付けたり、アンダースコアを含めたりすることは許されません。
create_decimal_from_float(f)
浮動小数点数 f から新しい Decimal インスタンスを生成しますが、 self をコンテキストとして丸めます。 Decimal.from_float() クラスメソッドとは違い、変換にコンテキストの精度、丸めメソッド、フラグ、そしてトラップが適用されます。
>>> context = Context(prec=5, rounding=ROUND_DOWN)
>>> context.create_decimal_from_float(math.pi)
Decimal('3.1415')
>>> context = Context(prec=5, traps=[Inexact])
>>> context.create_decimal_from_float(math.pi)
Traceback (most recent call last):
    ...
decimal.Inexact: None
バージョン 3.1 で追加.
Etiny()
Emin - prec + 1 に等しい値を返します。演算結果の劣化が起こる桁の最小値です。アンダーフローが起きた場合、指数は Etiny に設定されます。
Etop()
Emax - prec + 1 に等しい値を返します。
Decimal を使った処理を行う場合、通常は Decimal インスタンスを生成して、算術演算を適用するというアプローチをとります。演算はアクティブなスレッドにおける現在のコンテキストの下で行われます。もう一つのアプローチは、コンテキストのメソッドを使った特定のコンテキスト下での計算です。コンテキストのメソッドは Decimal クラスのメソッドに似ているので、ここでは簡単な説明にとどめます。
abs(x)
x の絶対値を返します。
add(x, y)
x と y の和を返します。
canonical(x)
同じ Decimal オブジェクト x を返します。
compare(x, y)
x と y を数値として比較します。
compare_signal(x, y)
二つの演算対象の値を数値として比較します。
compare_total(x, y)
二つの演算対象を抽象的な表現を使って比較します。
compare_total_mag(x, y)
二つの演算対象を抽象的な表現を使い符号を無視して比較します。
copy_abs(x)
x のコピーの符号を 0 にセットして返します。
copy_negate(x)
x のコピーの符号を反転して返します。
copy_sign(x, y)
y から x に符号をコピーします。
divide(x, y)
x を y で除算した値を返します。
divide_int(x, y)
x を y で除算した値を整数に切り捨てて返します。
divmod(x, y)
二つの数値間の除算を行い、結果の整数部を返します。
exp(x)
e ** x を返します。
fma(x, y, z)
x を y 倍したものに z を加えて返します。
is_canonical(x)
x が標準的(canonical)ならば True を返します。そうでなければ False です。
is_finite(x)
x が有限ならば True を返します。そうでなければ False です。
is_infinite(x)
x が無限ならば True を返します。そうでなければ False です。
is_nan(x)
x が qNaN か sNaN であれば True を返します。そうでなければ False です。
is_normal(x)
x が通常の数ならば True を返します。そうでなければ False です。
is_qnan(x)
x が無言 NaN であれば True を返します。そうでなければ False です。
is_signed(x)
x が負の数であれば True を返します。そうでなければ False です。
is_snan(x)
x が発信 NaN であれば True を返します。そうでなければ False です。
is_subnormal(x)
x が非正規数であれば True を返します。そうでなければ False です。
is_zero(x)
x がゼロであれば True を返します。そうでなければ False です。
ln(x)
x の自然対数(底 e の対数)を返します。
log10(x)
x の底 10 の対数を返します。
logb(x)
演算対象の MSD の大きさの指数部を返します。
logical_and(x, y)
それぞれの桁に論理演算 and を当てはめます。
logical_invert(x)
x の全ての桁を反転させます。
logical_or(x, y)
それぞれの桁に論理演算 or を当てはめます。
logical_xor(x, y)
それぞれの桁に論理演算 xor を当てはめます。
max(x, y)
二つの値を数値として比較し、大きいほうを返します。
max_mag(x, y)
値を符号を無視して数値として比較します。
min(x, y)
二つの値を数値として比較し、小さいほうを返します。
min_mag(x, y)
値を符号を無視して数値として比較します。
minus(x)
Python における単項マイナス演算子に対応する演算です。
multiply(x, y)
x と y の積を返します。
next_minus(x)
x より小さい最大の表現可能な数を返します。
next_plus(x)
x より大きい最小の表現可能な数を返します。
next_toward(x, y)
x に y の方向に向かって最も近い数を返します。
normalize(x)
x をもっとも単純な形にします。
number_class(x)
x のクラスを指し示すものを返します。
plus(x)
Python における単項のプラス演算子に対応する演算です。コンテキストにおける精度や値丸めを適用するので、等値 (identity) 演算とは 違います。
power(x, y, modulo=None)
x の y 乗を計算します。modulo が指定されていればモジュロを取ります。
引数が 2 つの場合、 x**y を計算します。x が負の場合、 y は整数でなければなりません。y が整数、結果が有限、結果が 'precision' 桁で正確に表現できる、という条件をすべて満たさない場合、結果は不正確になります。結果はコンテキストの丸めモードを使って丸められます。結果は常に、Python バージョンにおいて正しく丸められます。
バージョン 3.3 で変更: C モジュールは power() を適切に丸められた exp() および ln() 関数によって計算します。結果は well-defined ですが、「ほとんどの場合には適切に丸められる」だけです。
引数が 3 つの場合、 (x**y) % modulo を計算します。この 3 引数の形式の場合、引数には以下の制限が課せられます。
全ての引数は整数
y は非負でなければならない
x と y の少なくともどちらかはゼロでない
modulo は非零で大きくても 'precision' 桁
Context.power(x, y, modulo) で得られる値は (x**y) % modulo を精度無制限で計算して得られるものと同じ値ですが、より効率的に計算されます。結果の指数は x, y, modulo の指数に関係なくゼロです。この計算は常に正確です。
quantize(x, y)
x に値丸めを適用し、指数を y にした値を返します。
radix()
単に 10 を返します。何せ十進ですから :)
remainder(x, y)
整数除算の剰余を返します。
剰余がゼロでない場合、符号は割られる数の符号と同じになります。
remainder_near(x, y)
x - y * n を返します。ここで n は x / y の正確な値に一番近い整数です (この結果が 0 ならばその符号は x の符号と同じです)。
rotate(x, y)
x の y 回巡回したコピーを返します。
same_quantum(x, y)
2つの演算対象が同じ指数を持っている場合に True を返します。
scaleb(x, y)
一つめの演算対象の指数部に二つめの値を加えたものを返します。
shift(x, y)
x を y 回シフトしたコピーを返します。
sqrt(x)
x の平方根を精度いっぱいまで求めます。
subtract(x, y)
x と y の間の差を返します。
to_eng_string(x)
文字列に変換します。指数が必要なら工学表記が使われます。
工学表記法では指数は 3 の倍数になります。これにより、基数の小数部には最大で 3 桁までの数字が残されるとともに、末尾に 1 つまたは 2 つの 0 の付加が必要とされるかもしれません。
to_integral_exact(x)
最近傍の整数に値を丸めます。
to_sci_string(x)
数値を科学表記で文字列に変換します。
定数
この節の定数は C モジュールにのみ意味があります。互換性のために、pure Python 版も含まれます。
32-bit
64-bit
decimal.MAX_PREC
425000000
999999999999999999
decimal.MAX_EMAX
425000000
999999999999999999
decimal.MIN_EMIN
-425000000
-999999999999999999
decimal.MIN_ETINY
-849999999
-1999999999999999997
decimal.HAVE_THREADS
バージョン 3.9 で非推奨.
decimal.HAVE_CONTEXTVAR
バージョン 3.9 で追加: backported to 3.7 and 3.8.
丸めモード
decimal.ROUND_CEILING
Infinity 方向に丸めます。
decimal.ROUND_DOWN
ゼロ方向に丸めます。
decimal.ROUND_FLOOR
-Infinity 方向に丸めます。
decimal.ROUND_HALF_DOWN
近い方に、引き分けはゼロ方向に向けて丸めます。
decimal.ROUND_HALF_EVEN
近い方に、引き分けは偶数整数方向に向けて丸めます。
decimal.ROUND_HALF_UP
近い方に、引き分けはゼロから遠い方向に向けて丸めます。
decimal.ROUND_UP
ゼロから遠い方向に丸めます。
decimal.ROUND_05UP
ゼロ方向に丸めた後の最後の桁が 0 または 5 ならばゼロから遠い方向に、そうでなければゼロ方向に丸めます。
シグナル
シグナルは、計算中に生じた様々なエラー条件を表現します。各々のシグナルは一つのコンテキストフラグと一つのトラップイネーブラに対応しています。
コンテキストフラグは、該当するエラー条件に遭遇するたびにセットされます。演算後にフラグを調べれば、演算に関する情報 (例えば計算が厳密だったかどうか) がわかります。フラグを調べたら、次の計算を始める前にフラグを全てクリアするようにしてください。
あるコンテキストのトラップイネーブラがあるシグナルに対してセットされている場合、該当するエラー条件が生じると Python の例外を送出します。例えば、 DivisionByZero が設定されていると、エラー条件が生じた際に DivisionByZero 例外を送出します。
class decimal.Clamped
値の表現上の制限に沿わせるために指数部が変更されたことを通知します。
通常、クランプ (clamp) は、指数部がコンテキストにおける指数桁の制限値 Emin および Emax を越えた場合に発生します。可能な場合には、係数部にゼロを加えた表現に合わせて指数部を減らします。
class decimal.DecimalException
他のシグナルの基底クラスで、 ArithmeticError のサブクラスです。
class decimal.DivisionByZero
有限値をゼロで除算したときのシグナルです。
除算やモジュロ除算、数を負の値で累乗した場合に起きることがあります。このシグナルをトラップしない場合、演算結果は Infinity または -Infinity になり、その符号は演算に使った入力に基づいて決まります。
class decimal.Inexact
値の丸めによって演算結果から厳密さが失われたことを通知します。
このシグナルは値丸め操作中にゼロでない桁を無視した際に生じます。演算結果は値丸め後の値です。シグナルのフラグやトラップは、演算結果の厳密さが失われたことを検出するために使えるだけです。
class decimal.InvalidOperation
無効な演算が実行されたことを通知します。
ユーザが有意な演算結果にならないような操作を要求したことを示します。このシグナルをトラップしない場合、 NaN を返します。このシグナルの発生原因として考えられるのは、以下のような状況です:
Infinity - Infinity
0 * Infinity
Infinity / Infinity
x % 0
Infinity % x
sqrt(-x) and x > 0
0 ** 0
x ** (non-integer)
x ** Infinity
class decimal.Overflow
数値オーバフローを示すシグナルです。
このシグナルは、値丸めを行った後の指数部が Emax より大きいことを示します。シグナルをトラップしない場合、演算結果は値丸めのモードにより、表現可能な最大の数値になるように内側へ引き込んで丸めを行った値か、 Infinity になるように外側に丸めた値のいずれかになります。いずれの場合も、 Inexact および Rounded が同時にシグナルされます。
class decimal.Rounded
情報が全く失われていない場合も含み、値丸めが起きたときのシグナルです。
このシグナルは、値丸めによって桁がなくなると常に発生します。なくなった桁がゼロ (例えば 5.00 を丸めて 5.0 になった場合) であってもです。このシグナルをトラップしなければ、演算結果をそのまま返します。このシグナルは有効桁数の減少を検出する際に使います。
class decimal.Subnormal
値丸めを行う前に指数部が Emin より小さかったことを示すシグナルです。
演算結果が微小である場合 (指数が小さすぎる場合) に発生します。このシグナルをトラップしなければ、演算結果をそのまま返します。
class decimal.Underflow
演算結果が値丸めによってゼロになった場合に生じる数値アンダフローです。
演算結果が微小なため、値丸めによってゼロになった場合に発生します。 Inexact および Subnormal シグナルも同時に発生します。
class decimal.FloatOperation
float と Decimal の混合の厳密なセマンティクスを有効にします。
シグナルがトラップされなかった場合 (デフォルト)、Decimal コンストラクタ、 create_decimal() 、およびすべての比較演算子において float と Decimal の混合が許されます。変換も比較も正確です。コンテキストフラグ内に FloatOperation を設定することで、混合操作は現れるたびに暗黙に記録されます。 from_float() や create_decimal_from_float() による明示的な変換はフラグを設定しません。
そうでなければ (シグナルがトラップされれば)、等価性比較および明示的な変換のみが静かにに行われ、その他の混合演算は FloatOperation を送出します。
これらのシグナルの階層構造をまとめると、以下の表のようになります:
exceptions.ArithmeticError(exceptions.Exception)
    DecimalException
        Clamped
        DivisionByZero(DecimalException, exceptions.ZeroDivisionError)
        Inexact
            Overflow(Inexact, Rounded)
            Underflow(Inexact, Rounded, Subnormal)
        InvalidOperation
        Rounded
        Subnormal
        FloatOperation(DecimalException, exceptions.TypeError)
浮動小数点数に関する注意
精度を上げて丸め誤差を抑制する
十進浮動小数点数を使うと、十進数表現による誤差を抑制できます (0.1 を正確に表現できるようになります); しかし、ゼロでない桁が一定の精度を越えている場合には、演算によっては依然として値丸めによる誤差を引き起こします。
値丸めによる誤差の影響は、桁落ちを生じるような、ほとんど相殺される量での加算や減算によって増幅されます。Knuth は、十分でない計算精度の下で値丸めを伴う浮動小数点演算を行った結果、加算の結合則や分配則における恒等性が崩れてしまう例を二つ示しています:
# Examples from Seminumerical Algorithms, Section 4.2.2.
>>> from decimal import Decimal, getcontext
>>> getcontext().prec = 8
>>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
>>> (u + v) + w
Decimal('9.5111111')
>>> u + (v + w)
Decimal('10')
>>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
>>> (u*v) + (u*w)
Decimal('0.01')
>>> u * (v+w)
Decimal('0.0060000')
decimal モジュールでは、最下桁を失わないように十分に計算精度を広げることで、上で問題にしたような恒等性をとりもどせます:
>>> getcontext().prec = 20
>>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
>>> (u + v) + w
Decimal('9.51111111')
>>> u + (v + w)
Decimal('9.51111111')
>>>
>>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
>>> (u*v) + (u*w)
Decimal('0.0060000')
>>> u * (v+w)
Decimal('0.0060000')
特殊値
decimal モジュールの数体系では、 NaN, sNaN, -Infinity, Infinity, および二つのゼロ、 +0 と -0 といった特殊な値を提供しています。
無限大 (Infinity) は Decimal('Infinity') で直接構築できます。また、 DivisionByZero をトラップせずにゼロで除算を行った場合にも出てきます。同様に、 Overflow シグナルをトラップしなければ、表現可能な最大の数値の制限を越えた値を丸めたときに出てきます。
無限大には符号があり (アフィン: affine であり)、算術演算に使用でき、非常に巨大で不確定の(indeterminate)値として扱われます。例えば、無限大に何らかの定数を加算すると、演算結果は別の無限大になります。
演算によっては結果が不確定になるものがあり、 NaN を返します。ただし、 InvalidOperation シグナルをトラップするようになっていれば例外を送出します。例えば、 0/0 は NaN を返します。 NaN は「非数値 (not a number)」を表します。このような NaN は暗黙のうちに生成され、一度生成されるとそれを他の計算にも流れてゆき、関係する個々の演算全てが個別の NaN を返すようになります。この挙動は、たまに入力値が欠けるような状況で一連の計算を行う際に便利です --- 特定の計算に対しては無効な結果を示すフラグを立てつつ計算を進められるからです。
一方、 NaN の変種である sNaN は関係する全ての演算で演算後にシグナルを送出します。 sNaN は、無効な演算結果に対して特別な処理を行うために計算を停止する必要がある場合に便利です。
Python の比較演算は NaN が関わってくると少し驚くようなことがあります。等価性のテストの一方の対象が無言または発信 NaN である場合いつでも False を返し(たとえ Decimal('NaN')==Decimal('NaN') でも)、一方で不等価をテストするといつでも True を返します。二つの Decimal を <, <=, > または >= を使って比較する試みは一方が NaN である場合には InvalidOperation シグナルを送出し、このシグナルをトラップしなければ結果は False に終わります。汎用十進演算仕様は直接の比較の振る舞いについて定めていないことに注意しておきましょう。ここでの NaN が関係する比較ルールは IEEE 854 標準から持ってきました (section 5.7 の Table 3 を見て下さい)。厳格に標準遵守を貫くなら、 compare() および compare-signal() メソッドを代わりに使いましょう。
アンダフローの起きた計算は、符号付きのゼロ (signed zero) を返すことがあります。符号は、より高い精度で計算を行った結果の符号と同じになります。符号付きゼロの大きさはやはりゼロなので、正のゼロと負のゼロは等しいとみなされ、符号は単なる参考にすぎません。
二つの符号付きゼロが区別されているのに等価であることに加えて、異なる精度におけるゼロの表現はまちまちなのに、値は等価とみなされるということがあります。これに慣れるには多少時間がかかります。正規化浮動小数点表現に目が慣れてしまうと、以下の計算でゼロに等しい値が返っているとは即座に分かりません:
>>>
1 / Decimal('Infinity')
Decimal('0E-1000026')
スレッドを使った処理
関数 getcontext() は、スレッド毎に別々の Context オブジェクトにアクセスします。別のスレッドコンテキストを持つということは、複数のスレッドが互いに影響を及ぼさずに (getcontext().prec=10 のような) 変更を適用できるということです。
同様に、setcontext() 関数は自動的に引数のコンテキストを現在のスレッドのコンテキストに設定します。
getcontext() を呼び出す前に setcontext() が呼び出されていなければ、現在のスレッドで使うための新たなコンテキストを生成するために getcontext() が自動的に呼び出されます。
新たなコンテキストは、DefaultContext と呼ばれる雛形からコピーされます。アプリケーションを通じて全てのスレッドに同じ値を使うようにデフォルトを設定したければ、DefaultContext オブジェクトを直接変更します。 getcontext() を呼び出すスレッド間で競合条件が生じないようにするため、DefaultContext への変更はいかなるスレッドを開始するよりも 前に 行わなければなりません。以下に例を示します:
# Set applicationwide defaults for all threads about to be launched
DefaultContext.prec = 12
DefaultContext.rounding = ROUND_DOWN
DefaultContext.traps = ExtendedContext.traps.copy()
DefaultContext.traps[InvalidOperation] = 1
setcontext(DefaultContext)
# Afterwards, the threads can be started
t1.start()
t2.start()
t3.start()
 . . .
レシピ
Decimal クラスの利用を実演している例をいくつか示します。これらはユーティリティ関数としても利用できます:
def moneyfmt(value, places=2, curr='', sep=',', dp='.',
             pos='', neg='-', trailneg=''):
    """Convert Decimal to a money formatted string.
    places:  required number of places after the decimal point
    curr:    optional currency symbol before the sign (may be blank)
    sep:     optional grouping separator (comma, period, space, or blank)
    dp:      decimal point indicator (comma or period)
             only specify as blank when places is zero
    pos:     optional sign for positive numbers: '+', space or blank
    neg:     optional sign for negative numbers: '-', '(', space or blank
    trailneg:optional trailing minus indicator:  '-', ')', space or blank
    >>> d = Decimal('-1234567.8901')
    >>> moneyfmt(d, curr='$')
    '-$1,234,567.89'
    >>> moneyfmt(d, places=0, sep='.', dp='', neg='', trailneg='-')
    '1.234.568-'
    >>> moneyfmt(d, curr='$', neg='(', trailneg=')')
    '($1,234,567.89)'
    >>> moneyfmt(Decimal(123456789), sep=' ')
    '123 456 789.00'
    >>> moneyfmt(Decimal('-0.02'), neg='<', trailneg='>')
    '<0.02>'
    """
    q = Decimal(10) ** -places      # 2 places --> '0.01'
    sign, digits, exp = value.quantize(q).as_tuple()
    result = []
    digits = list(map(str, digits))
    build, next = result.append, digits.pop
    if sign:
        build(trailneg)
    for i in range(places):
        build(next() if digits else '0')
    if places:
        build(dp)
    if not digits:
        build('0')
    i = 0
    while digits:
        build(next())
        i += 1
        if i == 3 and digits:
            i = 0
            build(sep)
    build(curr)
    build(neg if sign else pos)
    return ''.join(reversed(result))
def pi():
    """Compute Pi to the current precision.
    >>> print(pi())
    3.141592653589793238462643383
    """
    getcontext().prec += 2  # extra digits for intermediate steps
    three = Decimal(3)      # substitute "three=3.0" for regular floats
    lasts, t, s, n, na, d, da = 0, three, 3, 1, 0, 0, 24
    while s != lasts:
        lasts = s
        n, na = n+na, na+8
        d, da = d+da, da+32
        t = (t * n) / d
        s += t
    getcontext().prec -= 2
    return +s               # unary plus applies the new precision
def exp(x):
    """Return e raised to the power of x.  Result type matches input type.
    >>> print(exp(Decimal(1)))
    2.718281828459045235360287471
    >>> print(exp(Decimal(2)))
    7.389056098930650227230427461
    >>> print(exp(2.0))
    7.38905609893
    >>> print(exp(2+0j))
    (7.38905609893+0j)
    """
    getcontext().prec += 2
    i, lasts, s, fact, num = 0, 0, 1, 1, 1
    while s != lasts:
        lasts = s
        i += 1
        fact *= i
        num *= x
        s += num / fact
    getcontext().prec -= 2
    return +s
def cos(x):
    """Return the cosine of x as measured in radians.
    The Taylor series approximation works best for a small value of x.
    For larger values, first compute x = x % (2 * pi).
    >>> print(cos(Decimal('0.5')))
    0.8775825618903727161162815826
    >>> print(cos(0.5))
    0.87758256189
    >>> print(cos(0.5+0j))
    (0.87758256189+0j)
    """
    getcontext().prec += 2
    i, lasts, s, fact, num, sign = 0, 0, 1, 1, 1, 1
    while s != lasts:
        lasts = s
        i += 2
        fact *= i * (i-1)
        num *= x * x
        sign *= -1
        s += num / fact * sign
    getcontext().prec -= 2
    return +s
def sin(x):
    """Return the sine of x as measured in radians.
    The Taylor series approximation works best for a small value of x.
    For larger values, first compute x = x % (2 * pi).
    >>> print(sin(Decimal('0.5')))
    0.4794255386042030002732879352
    >>> print(sin(0.5))
    0.479425538604
    >>> print(sin(0.5+0j))
    (0.479425538604+0j)
    """
    getcontext().prec += 2
    i, lasts, s, fact, num, sign = 1, 0, x, 1, x, 1
    while s != lasts:
        lasts = s
        i += 2
        fact *= i * (i-1)
        num *= x * x
        sign *= -1
        s += num / fact * sign
    getcontext().prec -= 2
    return +s
Decimal FAQ
Q. decimal.Decimal('1234.5') などと打ち込むのは煩わしいのですが、対話式インタプリタを使う際にタイプ量を少なくする方法はありませんか?
A. コンストラクタを1文字に縮める人もいるようです:
>>>
D = decimal.Decimal
D('1.23') + D('3.45')
Decimal('4.68')
Q. 小数点以下2桁の固定小数点数のアプリケーションの中で、いくつかの入力が余計な桁を保持しているのでこれを丸めなければなりません。その他のものに余計な桁はなくそのまま使えます。どのメソッドを使うのがいいでしょうか?
A. quantize() メソッドで固定した桁に丸められます。 Inexact トラップを設定しておけば、確認にも有用です:
>>>
TWOPLACES = Decimal(10) ** -2       # same as Decimal('0.01')
>>>
# Round to two places
Decimal('3.214').quantize(TWOPLACES)
Decimal('3.21')
>>>
# Validate that a number does not exceed two places
Decimal('3.21').quantize(TWOPLACES, context=Context(traps=[Inexact]))
Decimal('3.21')
>>>
Decimal('3.214').quantize(TWOPLACES, context=Context(traps=[Inexact]))
Traceback (most recent call last):
   ...
Inexact: None
Q. 正当な2桁の入力が得られたとして、その正当性をアプリケーション実行中も変わらず保ち続けるにはどうすればいいでしょうか?
A. 加減算あるいは整数との乗算のような演算は自動的に固定小数点を守ります。その他の除算や整数以外の乗算などは小数点以下の桁を変えてしまいますので実行後は quantize() ステップが必要です:
>>>
a = Decimal('102.72')           # Initial fixed-point values
b = Decimal('3.17')
a + b                           # Addition preserves fixed-point
Decimal('105.89')
a - b
Decimal('99.55')
a * 42                          # So does integer multiplication
Decimal('4314.24')
(a * b).quantize(TWOPLACES)     # Must quantize non-integer multiplication
Decimal('325.62')
(b / a).quantize(TWOPLACES)     # And quantize division
Decimal('0.03')
固定小数点のアプリケーションを開発する際は、 quantize() の段階を扱う関数を定義しておくと便利です:
>>>
def mul(x, y, fp=TWOPLACES):
    return (x * y).quantize(fp)
def div(x, y, fp=TWOPLACES):
    return (x / y).quantize(fp)
>>>
mul(a, b)                       # Automatically preserve fixed-point
Decimal('325.62')
div(b, a)
Decimal('0.03')
Q. 一つの値に対して多くの表現方法があります。 200 と 200.000 と 2E2 と 02E+4 は全て同じ値で違った精度の数です。これらをただ一つの正規化された値に変換することはできますか?
A. normalize() メソッドは全ての等しい値をただ一つの表現に直します:
>>>
values = map(Decimal, '200 200.000 2E2 .02E+4'.split())
[v.normalize() for v in values]
[Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2')]
Q. ある種の十進数値はいつも指数表記で表示されます。指数表記以外の表示にする方法はありますか?
A. 値によっては、指数表記だけが有効桁数を表せる表記法なのです。たとえば、 5.0E+3 を 5000 と表してしまうと、値は変わりませんが元々の2桁という有効数字が反映されません。
もしアプリケーションが有効数字の追跡を等閑視するならば、指数部や末尾のゼロを取り除き、有効数字を忘れ、しかし値を変えずにおくことは容易です:
>>>
def remove_exponent(d):
    return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()
>>>
remove_exponent(Decimal('5E+3'))
Decimal('5000')
Q. 普通の float を Decimal に変換できますか?
A. はい。どんな 2 進浮動小数点数も Decimal として正確に表現できます。ただし、正確な変換は直感的に考えたよりも多い桁になることがあります:
>>> Decimal(math.pi)
Decimal('3.141592653589793115997963468544185161590576171875')
Q. 複雑な計算の中で、精度不足や丸めの異常で間違った結果になっていないことをどうやって保証すれば良いでしょうか。
A. decimal モジュールでは検算は容易です。一番良い方法は、大きめの精度や様々な丸めモードで再計算してみることです。大きく異なった結果が出てきたら、精度不足や丸めの問題や悪条件の入力、または数値計算的に不安定なアルゴリズムを示唆しています。
Q. コンテキストの精度は計算結果には適用されていますが入力には適用されていないようです。様々に異なる精度の入力値を混ぜて計算する時に注意すべきことはありますか?
A. はい。原則として入力値は正確であると見做しておりそれらの値を使った計算も同様です。結果だけが丸められます。入力の強みは "what you type is what you get" (打ち込んだ値が得られる値)という点にあります。入力が丸められないということを忘れていると結果が奇妙に見えるというのは弱点です:
>>> getcontext().prec = 3
>>> Decimal('3.104') + Decimal('2.104')
Decimal('5.21')
>>> Decimal('3.104') + Decimal('0.000') + Decimal('2.104')
Decimal('5.20')
解決策は、精度を増やすか、単項プラス演算子を使って入力の丸めを強制することです:
>>> getcontext().prec = 3
>>> +Decimal('1.23456789')      # unary plus triggers rounding
Decimal('1.23')
もしくは、入力を Context.create_decimal() を使って生成時に丸めてしまうこともできます:
>>>
Context(prec=5, rounding=ROUND_DOWN).create_decimal('1.2345678')
Decimal('1.2345')
Q. CPython 実装は大きな数に対しても速いでしょうか?
The easiest approach for trying out bignum arithmetic is to use the maximum value for prec as well 2:
>>>
>>> setcontext(Context(prec=MAX_PREC, Emax=MAX_EMAX, Emin=MIN_EMIN))
>>> x = Decimal(2) ** 256
>>> x / 128
Decimal('904625697166532776746648320380374280103671755200316906558262375061821325312')
For inexact results, MAX_PREC is far too large on 64-bit platforms and the available memory will be insufficient:
>>>
>>> Decimal(1) / 3
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
MemoryError
On systems with overallocation (e.g. Linux), a more sophisticated approach is to adjust prec to the amount of available RAM. Suppose that you have 8GB of RAM and expect 10 simultaneous operands using a maximum of 500MB each:
>>>
>>> import sys
>>>
>>> # Maximum number of digits for a single operand using 500MB in 8-byte words
>>> # with 19 digits per word (4-byte and 9 digits for the 32-bit build):
>>> maxdigits = 19 * ((500 * 1024**2) // 8)
>>>
>>> # Check that this works:
>>> c = Context(prec=maxdigits, Emax=MAX_EMAX, Emin=MIN_EMIN)
>>> c.traps[Inexact] = True
>>> setcontext(c)
>>>
>>> # Fill the available precision with nines:
>>> x = Decimal(0).logical_invert() * 9
>>> sys.getsizeof(x)
524288112
>>> x + 2
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  decimal.Inexact: [<class 'decimal.Inexact'>]
fractions --- 有理数
ソースコード: Lib/fractions.py
fractions モジュールは有理数計算のサポートを提供します。
Fraction インスタンスは一対の整数、他の有理数、または文字列から生成されます。
class fractions.Fraction(numerator=0, denominator=1)
class fractions.Fraction(other_fraction)
class fractions.Fraction(float)
class fractions.Fraction(decimal)
class fractions.Fraction(string)
最初のバージョンは numerator と denominator が numbers.Rational のインスタンスであることを要求し、 numerator/denominator の値を持つ新しい Fraction インスタンスを返します。 denominator が 0 ならば、 ZeroDivisionError を送出します。二番目のバージョンは other_fraction が numbers.Rational のインスタンスであることを要求し、同じ値を持つ新しい Fraction インスタンスを返します。その次の二つのバージョンは、 float と decimal.Decimal インスタンスを受け付け、それとちょうど同じ値を持つ Fraction インスタンスを返します。なお、二進浮動小数点数にお決まりの問題 (浮動小数点演算、その問題と制限 参照) のため、 Fraction(1.1) の引数は 11/10 と正確に等しいとは言えないので、 Fraction(1.1) は予期した通りの Fraction(11, 10) を返し ません 。(ただし、以下の limit_denominator() メソッドのドキュメントを参照してください。) 最後のバージョンは、文字列またはユニコードのインスタンスを渡されることを想定します。このインスタンスは、通常、次のような形式です:
[sign] numerator ['/' denominator]
ここで、オプションの sign は '+' か '-' のどちらかであり、numerator および (存在する場合) denominator は十進数の数字の文字列です。さらに、 float コンストラクタで受け付けられる有限の値を表す文字列は、Fraction コンストラクタでも受け付けられます。どちらの形式でも、入力される文字列は前後に空白があって構いません。以下に、いくつかの例を示します:
>>>
>>> from fractions import Fraction
>>> Fraction(16, -10)
Fraction(-8, 5)
>>> Fraction(123)
Fraction(123, 1)
>>> Fraction()
Fraction(0, 1)
>>> Fraction('3/7')
Fraction(3, 7)
>>> Fraction(' -3/7 ')
Fraction(-3, 7)
>>> Fraction('1.414213 \t\n')
Fraction(1414213, 1000000)
>>> Fraction('-.125')
Fraction(-1, 8)
>>> Fraction('7e-6')
Fraction(7, 1000000)
>>> Fraction(2.25)
Fraction(9, 4)
>>> Fraction(1.1)
Fraction(2476979795053773, 2251799813685248)
>>> from decimal import Decimal
>>> Fraction(Decimal('1.1'))
Fraction(11, 10)
Fraction クラスは抽象基底クラス numbers.Rational を継承し、その全てのメソッドと演算を実装します。 Fraction インスタンスはハッシュ可能で、不変 (immutable) であるものとして扱われます。加えて、 Fraction には以下のプロパティとメソッドがあります:
バージョン 3.2 で変更: Fraction のコンストラクタが float および decimal.Decimal インスタンスを受け付けるようになりました。
バージョン 3.9 で変更: The math.gcd() function is now used to normalize the numerator and denominator. math.gcd() always return a int type. Previously, the GCD type depended on numerator and denominator.
numerator
有理数を既約分数で表したときの分子。
denominator
有理数を既約分数で表したときの分母。
as_integer_ratio()
2 つの整数からなるタプルで、比が Fraction インスタンスと等しく、分母が正になるものを返します。
バージョン 3.8 で追加.
from_float(flt)
このクラスメソッドは float である flt の正確な値を表す Fraction を構築します。 Fraction.from_float(0.3) と Fraction(3, 10) の値は同じでないことに注意してください 。
注釈 Python 3.2 以降では、 float から直接 Fraction インスタンスを構築できるようになりました。
from_decimal(dec)
このクラスメソッドは decimal.Decimal インスタンスである dec の正確な値を表す Fraction を構築します。
注釈 Python 3.2 以降では、 decimal.Decimal インスタンスから直接 Fraction インスタンスを構築できるようになりました。
limit_denominator(max_denominator=1000000)
分母が高々 max_denominator である、 self に最も近い Fraction を見付けて返します。このメソッドは与えられた浮動小数点数の有理数近似を見つけるのに役立ちます:
>>>
from fractions import Fraction
Fraction('3.1415926535897932').limit_denominator(1000)
Fraction(355, 113)
あるいは float で表された有理数を元に戻すのにも使えます:
>>>
from math import pi, cos
Fraction(cos(pi/3))
Fraction(4503599627370497, 9007199254740992)
Fraction(cos(pi/3)).limit_denominator()
Fraction(1, 2)
Fraction(1.1).limit_denominator()
Fraction(11, 10)
__floor__()
最大の int <= self を返します。このメソッドは math.floor() 関数からでもアクセスできます:
>>>
from math import floor
floor(Fraction(355, 113))
3
__ceil__()
最小の int >= self を返します。このメソッドは math.ceil() 関数からでもアクセスできます。
__round__()
__round__(ndigits)
第一のバージョンは、 self に最も近い int を偶数丸めで返します。第二のバージョンは、このメソッドは self に最も近い Fraction(1, 10**ndigits) の倍数 (論理的に、 ndigits が負なら) を、これも偶数丸めで丸めます。 round() 関数からでもアクセスできます。
random --- 擬似乱数を生成する
ソースコード: Lib/random.py
このモジュールでは様々な分布をもつ擬似乱数生成器を実装しています。
整数用に、ある範囲からの一様な選択があります。シーケンス用には、シーケンスからのランダムな要素の一様な選択、リストのランダムな置換をインプレースに生成する関数、順列を置換せずにランダムサンプリングする関数があります。
実数用としては、一様分布、正規分布 (ガウス分布)、対数正規分布、負の指数分布、ガンマおよびベータ分布を計算する関数があります。角度の分布を生成するにはフォン・ミーゼス分布が利用できます。
ほとんど全てのモジュール関数は、基礎となる関数 random() に依存します。この関数はランダムな浮動小数点数を半開区間 [0.0, 1.0) 内に一様に生成します。Python は中心となる乱数生成器としてメルセンヌツイスタを使います。これは 53 ビット精度の浮動小数点を生成し、周期は 2**19937-1 です。本体は C で実装されていて、高速でスレッドセーフです。メルセンヌツイスタは、現存する中で最も広範囲にテストされた乱数生成器のひとつです。しかしながら、メルセンヌツイスタは完全に決定論的であるため、全ての目的に合致しているわけではなく、暗号化の目的には全く向いていません。
このモジュールで提供されている関数は、実際には random.Random クラスの隠蔽されたインスタンスのメソッドに束縛されています。内部状態を共有しない生成器を取得するため、自分で Random のインスタンスを生成することができます。
自分で考案した基本乱数生成器を使いたい場合、クラス Random をサブクラス化することもできます。この場合、メソッド random()、seed()、getstate()、setstate() をオーバライドしてください。オプションとして、新しいジェネレータは getrandbits() メソッドを提供することができます。これにより randrange() メソッドが任意に大きな範囲から選択を行えるようになります。
random モジュールは SystemRandom クラスも提供していて、このクラスは OS が提供している乱数発生源を利用して乱数を生成するシステム関数 os.urandom() を使うものです。
警告 このモジュールの擬似乱数生成器をセキュリティ目的に使用してはいけません。セキュリティや暗号学的な用途については secrets モジュールを参照してください。
参考 M. Matsumoto and T. Nishimura, "Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator", ACM Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January pp.3--30 1998.
Complementary-Multiply-with-Carry recipe 長い周期と比較的シンプルな更新操作を備えた互換性のある別の乱数生成器。
保守 (bookkeeping) 関数
random.seed(a=None, version=2)
乱数生成器を初期化します。
a が省略されるか None の場合、現在のシステム時刻が使用されます。乱数のソースがオペレーティングシステムによって提供される場合、システム時刻の代わりにそれが使用されます (利用可能性についての詳細は os.urandom() 関数を参照)。
a が int の場合、それが直接使われます。
バージョン2 (デフォルト) では、 str, bytes, bytearray オブジェクトは int に変換され、そのビットがすべて使用されます。
バージョン1 (Python の古いバージョンでのランダムなシーケンスを再現するために提供される) では、 str と bytes に対して適用されるアルゴリズムは、より狭い範囲のシードを生成します。
バージョン 3.2 で変更: 文字列シードのすべてのビットを使うバージョン2スキームに移行。
バージョン 3.9 で非推奨: In the future, the seed must be one of the following types: NoneType, int, float, str, bytes, or bytearray.
random.getstate()
乱数生成器の現在の内部状態を記憶したオブジェクトを返します。このオブジェクトを setstate() に渡して内部状態を復元することができます。
random.setstate(state)
state は予め getstate() を呼び出して得ておかなくてはなりません。 setstate() は getstate() が呼び出された時の乱数生成器の内部状態を復元します。
Functions for bytes
random.randbytes(n)
バージョン 3.9 で追加.
整数用の関数
random.randrange(stop)
random.randrange(start, stop[, step])
range(start, stop, step) の要素からランダムに選ばれた要素を返します。この関数は choice(range(start, stop, step)) と等価ですが、実際には range オブジェクトを生成しません。
位置引数のパターンは range() のそれと一致します。キーワード引数は、この関数に望まれない方法で使われるかもしれないので、使うべきではありません。
バージョン 3.2 で変更: 一様に分布した値の生成に関して randrange() がより洗練されました。以前は int(random()*n) のようなやや一様でない分布を生成するスタイルを使用していました。
random.randint(a, b)
a <= N <= b であるようなランダムな整数 N を返します。randrange(a, b+1) のエイリアスです。
random.getrandbits(k)
バージョン 3.9 で変更: This method now accepts zero for k.
シーケンス用の関数
random.choice(seq)
空でないシーケンス seq からランダムに要素を返します。 seq が空のときは、 IndexError が送出されます。
random.choices(population, weights=None, *, cum_weights=None, k=1)
population から重複ありで選んだ要素からなる大きさ k のリストを返します。population が空の場合 IndexError を送出します。
weights シーケンスが与えられた場合、相対的な重みに基づいて要素が選ばれます。あるいは、cum_weights シーケンスが与えられた場合、累積的な重み (itertools.accumulate() を用いて計算されるかもしれません) で要素が選ばれます。例えば、相対的な重み [10, 5, 30, 5] は累積的な重み [10, 15, 45, 50] と等価です。内部的には、相対的な重みは要素選択の前に累積的な重みに変換されるため、累積的な重みを渡すと手間を省けます。
weights および cum_weights が与えられなかった場合、要素は同じ確率で選択されます。重みのシーケンスが与えられた場合、その長さは population シーケンスと同じでなければなりません。weights と cum_weights を同時に与えると TypeError が送出されます。
与えられた種に対して、同じ重みを持つ choices() 関数は、一般に choice() を繰り返し呼び出す場合とは異なるシーケンスを生成します。 choices() で使用されるアルゴリズムは、内部の一貫性とスピードのために浮動小数点演算を使用します。 choice() で使われるアルゴリズムは、丸め誤差による小さな偏りを避けるために、デフォルトでは選択を繰り返す整数演算になっています。
バージョン 3.6 で追加.
バージョン 3.9 で変更: Raises a ValueError if all weights are zero.
random.shuffle(x[, random])
シーケンス x をインプレースにシャッフルします。
オプション引数 random は [0.0, 1.0) の範囲のランダムな浮動小数を返す引数なしの関数です。デフォルトでは random() 関数です。
イミュータブルなシーケンスをシャッフルしてシャッフルされたリストを新たに返すには、代わりに sample(x, k=len(x)) を使用してください。
たとえ len(x) が小さくても、x の並べ替えの総数 (訳注: 要素数の階乗) は大半の乱数生成器の周期よりもすぐに大きくなることに注意してください。つまり、長いシーケンスの大半の並べ替えは決して生成されないだろう、ということです。例えば、長さ 2080 のシーケンスがメルセンヌツイスタ生成器の周期に収まる中で最大のものになります。
random.sample(population, k, *, counts=None)
母集団のシーケンスまたは集合から選ばれた長さ k の一意な要素からなるリストを返します。重複無しのランダムサンプリングに用いられます。
母集団自体を変更せずに、母集団内の要素を含む新たなリストを返します。返されたリストは選択された順に並んでいるので、このリストの部分スライスもランダムなサンプルになります。これにより、くじの当選者 (サンプル) を1等賞と2等賞（の部分スライス）に分けることも可能です。
母集団の要素は ハッシュ可能 でなくても、ユニークでなくてもかまいません。母集団が繰り返しを含む場合、出現するそれぞれがサンプルに選択されえます。
ある範囲の整数からサンプルを取る場合、引数に range() オブジェクトを使用してください。大きな母集団の場合、これは特に速く、メモリ効率が良いです: sample(range(10000000), k=60)。
サンプルの大きさが母集団の大きさより大きい場合 ValueError が送出されます。
バージョン 3.9 で変更: Added the counts parameter.
バージョン 3.9 で非推奨: In the future, the population must be a sequence. Instances of set are no longer supported. The set must first be converted to a list or tuple, preferably in a deterministic order so that the sample is reproducible.
実数分布
以下の関数は特定の実数値分布を生成します。関数の引数の名前は、一般的な数学の慣例で使われている分布の公式の対応する変数から取られています; これらの公式のほとんどはどんな統計学のテキストにも載っています。
random.random()
次のランダムな浮動小数点数（範囲は [0.0, 1.0) ）を返します。
random.uniform(a, b)
a <= b であれば a <= N <= b 、b < a であれば b <= N <= a であるようなランダムな浮動小数点数 N を返します。
端点の値 b が範囲に含まれるかどうかは、等式 a + (b-a) * random() における浮動小数点の丸めに依存します。
random.triangular(low, high, mode)
low <= N <= high でありこれら境界値の間に指定された最頻値 mode を持つようなランダムな浮動小数点数 N を返します。境界 low と high のデフォルトは 0 と 1 です。最頻値 mode 引数のデフォルトは両境界値の中点になり、対称な分布を与えます。
random.betavariate(alpha, beta)
ベータ分布です。引数の満たすべき条件は alpha > 0 および beta > 0 です。 0 から 1 の範囲の値を返します。
random.expovariate(lambd)
指数分布です。lambd は平均にしたい値の逆数です。(この引数は "lambda" と呼ぶべきなのですが、Python の予約語なので使えません。) 返す値の範囲は lambd が正なら 0 から正の無限大、lambd が負なら負の無限大から 0 です。
random.gammavariate(alpha, beta)
ガンマ分布です (ガンマ関数 ではありません ！)。引数の満たすべき条件は alpha > 0 および beta > 0 です。
確率分布関数は:
          x ** (alpha - 1) * math.exp(-x / beta)
pdf(x) =  --------------------------------------
            math.gamma(alpha) * beta ** alpha
random.gauss(mu, sigma)
ガウス分布です。 mu は平均であり、 sigma は標準偏差です。この関数は後で定義する関数 normalvariate() より少しだけ高速です。
random.lognormvariate(mu, sigma)
対数正規分布です。この分布を自然対数を用いた分布にした場合、平均 mu で標準偏差 sigma の正規分布になります。 mu は任意の値を取ることができ、sigma はゼロより大きくなければなりません。
random.normalvariate(mu, sigma)
正規分布です。 mu は平均で、 sigma は標準偏差です。
random.vonmisesvariate(mu, kappa)
mu は平均の角度で、0 から 2*pi までのラジアンで表されます。 kappa は濃度パラメータで、ゼロ以上でなければなりません。kappa がゼロに等しい場合、この分布は範囲 0 から 2*pi の一様でランダムな角度の分布に退化します。
random.paretovariate(alpha)
パレート分布です。 alpha は形状パラメータです。
random.weibullvariate(alpha, beta)
ワイブル分布です。 alpha は尺度パラメタで、 beta は形状パラメータです。
他の生成器
class random.Random([seed])
デフォルトの疑似乱数生成器を random を使って実装したクラスです。
バージョン 3.9 で非推奨: In the future, the seed must be one of the following types: NoneType, int, float, str, bytes, or bytearray.
class random.SystemRandom([seed])
オペレーティングシステムの提供する発生源によって乱数を生成する os.urandom() 関数を使うクラスです。すべてのシステムで使えるメソッドではありません。ソフトウェアの状態に依存してはいけませんし、一連の操作は再現不能です。従って、 seed() メソッドは何の影響も及ぼさず、無視されます。 getstate() と setstate() メソッドが呼び出されると、例外 NotImplementedError が送出されます。
再現性について
random モジュールのアルゴリズムやシード処理関数のほとんどは、Python バージョン間で変更される対象となりますが、次の二点は変更されないことが保証されています:
新しいシード処理メソッドが追加されたら、後方互換なシード処理器が提供されます。
生成器の random() メソッドは、互換なシード処理器に同じシードが与えられた場合、引き続き同じシーケンスを生成します。
使用例
基礎的な例:
>>>
>>> random()                             # Random float:  0.0 <= x < 1.0
0.37444887175646646
>>> uniform(2.5, 10.0)                   # Random float:  2.5 <= x < 10.0
3.1800146073117523
>>> expovariate(1 / 5)                   # Interval between arrivals averaging 5 seconds
5.148957571865031
>>> randrange(10)                        # Integer from 0 to 9 inclusive
7
>>> randrange(0, 101, 2)                 # Even integer from 0 to 100 inclusive
26
>>> choice(['win', 'lose', 'draw'])      # Single random element from a sequence
'draw'
>>> deck = 'ace two three four'.split()
>>> shuffle(deck)                        # Shuffle a list
>>> deck
['four', 'two', 'ace', 'three']
>>> sample([10, 20, 30, 40, 50], k=4)    # Four samples without replacement
[40, 10, 50, 30]
シミュレーション:
>>>
>>> # Six roulette wheel spins (weighted sampling with replacement)
>>> choices(['red', 'black', 'green'], [18, 18, 2], k=6)
['red', 'green', 'black', 'black', 'red', 'black']
>>> # Deal 20 cards without replacement from a deck
>>> # of 52 playing cards, and determine the proportion of cards
>>> # with a ten-value:  ten, jack, queen, or king.
>>> dealt = sample(['tens', 'low cards'], counts=[16, 36], k=20)
>>> dealt.count('tens') / 20
0.15
>>> # Estimate the probability of getting 5 or more heads from 7 spins
>>> # of a biased coin that settles on heads 60% of the time.
>>> def trial():
...     return choices('HT', cum_weights=(0.60, 1.00), k=7).count('H') >= 5
...
>>> sum(trial() for i in range(10_000)) / 10_000
0.4169
>>> # Probability of the median of 5 samples being in middle two quartiles
>>> def trial():
...     return 2_500 <= sorted(choices(range(10_000), k=5))[2] < 7_500
...
>>> sum(trial() for i in range(10_000)) / 10_000
0.7958
Example of statistical bootstrapping using resampling with replacement to estimate a confidence interval for the mean of a sample:
# http://statistics.about.com/od/Applications/a/Example-Of-Bootstrapping.htm
from statistics import fmean as mean
from random import choices
data = [41, 50, 29, 37, 81, 30, 73, 63, 20, 35, 68, 22, 60, 31, 95]
means = sorted(mean(choices(data, k=len(data))) for i in range(100))
print(f'The sample mean of {mean(data):.1f} has a 90% confidence '
      f'interval from {means[5]:.1f} to {means[94]:.1f}')
薬と偽薬の間に観察された効果の違いについて、統計的有意性、すなわち p 値 を決定するために、リサンプリング順列試験 を行う例:
# Example from "Statistics is Easy" by Dennis Shasha and Manda Wilson
from statistics import fmean as mean
from random import shuffle
drug = [54, 73, 53, 70, 73, 68, 52, 65, 65]
placebo = [54, 51, 58, 44, 55, 52, 42, 47, 58, 46]
observed_diff = mean(drug) - mean(placebo)
n = 10_000
count = 0
combined = drug + placebo
for i in range(n):
    shuffle(combined)
    new_diff = mean(combined[:len(drug)]) - mean(combined[len(drug):])
    count += (new_diff >= observed_diff)
print(f'{n} label reshufflings produced only {count} instances with a difference')
print(f'at least as extreme as the observed difference of {observed_diff:.1f}.')
print(f'The one-sided p-value of {count / n:.4f} leads us to reject the null')
print(f'hypothesis that there is no difference between the drug and the placebo.')
Simulation of arrival times and service deliveries for a multiserver queue:
from heapq import heappush, heappop
from random import expovariate, gauss
from statistics import mean, median, stdev
average_arrival_interval = 5.6
average_service_time = 15.0
stdev_service_time = 3.5
num_servers = 3
waits = []
arrival_time = 0.0
servers = [0.0] * num_servers  # time when each server becomes available
for i in range(100_000):
    arrival_time += expovariate(1.0 / average_arrival_interval)
    next_server_available = heappop(servers)
    wait = max(0.0, next_server_available - arrival_time)
    waits.append(wait)
    service_duration = gauss(average_service_time, stdev_service_time)
    service_completed = arrival_time + wait + service_duration
    heappush(servers, service_completed)
print(f'Mean wait: {mean(waits):.1f}.  Stdev wait: {stdev(waits):.1f}.')
print(f'Median wait: {median(waits):.1f}.  Max wait: {max(waits):.1f}.')
参考 Statistics for Hackers Jake Vanderplas による統計解析のビデオ。シミュレーション、サンプリング、シャッフル、交差検定といった基本的な概念のみを用いています。
Economics Simulation Peter Norvig による市場価格のシミュレーション。このモジュールが提供する多くのツールや分布 (gauss, uniform, sample, betavariate, choice, triangular, randrange) の活用法を示しています。
A Concrete Introduction to Probability (using Python) Peter Norvig によるチュートリアル。確率論の基礎、シミュレーションの書き方、Python を使用したデータ解析法をカバーしています。
レシピ
from random import Random
from math import ldexp
class FullRandom(Random):
    def random(self):
        mantissa = 0x10_0000_0000_0000 | self.getrandbits(52)
        exponent = -53
        x = 0
        while not x:
            x = self.getrandbits(32)
            exponent += x.bit_length() - 32
        return ldexp(mantissa, exponent)
All real valued distributions in the class will use the new method:
>>>
>>> fr = FullRandom()
>>> fr.random()
0.05954861408025609
>>> fr.expovariate(0.25)
8.87925541791544
The recipe is conceptually equivalent to an algorithm that chooses from all the multiples of 2⁻¹⁰⁷⁴ in the range 0.0 ≤ x < 1.0. All such numbers are evenly spaced, but most have to be rounded down to the nearest representable Python float. (The value 2⁻¹⁰⁷⁴ is the smallest positive unnormalized float and is equal to math.ulp(0.0).)
statistics --- 数理統計関数
バージョン 3.4 で追加.
ソースコード: Lib/statistics.py
平均及び中心位置の測度
これらの関数は母集団または標本の平均値や標準値を計算します。
mean()
データの算術平均。
fmean()
geometric_mean()
harmonic_mean()
データの調和平均。
median()
データの中央値。
median_low()
データの low median。
median_high()
データの high median。
median_grouped()
grouped data の中央値、すなわち50パーセンタイル。
mode()
multimode()
quantiles()
分散の測度
これらの関数は母集団または標本が標準値や平均値からどれくらい離れているかについて計算します。
pstdev()
データの母標準偏差。
pvariance()
データの母分散。
stdev()
データの標本標準偏差。
variance()
データの標本標準分散。
関数の詳細
註釈: 関数の引数となるデータをソートしておく必要はありません。例の多くがソートされているのは見やすさのためです。
statistics.mean(data)
算術平均はデータの総和をデータ数で除したものです。単に「平均」と呼ばれることも多いですが、数学における平均の一種に過ぎません。データの中心位置の測度の一つです。
data が空の場合 StatisticsError を送出します。
使用例:
>>> mean([1, 2, 3, 4, 4])
2.8
>>> mean([-1.0, 2.5, 3.25, 5.75])
2.625
>>> from fractions import Fraction as F
>>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])
Fraction(13, 21)
>>> from decimal import Decimal as D
>>> mean([D("0.5"), D("0.75"), D("0.625"), D("0.375")])
Decimal('0.5625')
注釈 The mean is strongly affected by outliers and is not a robust estimator for central location: the mean is not necessarily a typical example of the data points. For more robust measures of central location, see median() and mode().
statistics.fmean(data)
>>> fmean([3.5, 4.0, 5.25])
4.25
バージョン 3.8 で追加.
statistics.geometric_mean(data)
No special efforts are made to achieve exact results. (However, this may change in the future.)
>>> round(geometric_mean([54, 24, 36]), 1)
36.0
バージョン 3.8 で追加.
statistics.harmonic_mean(data)
Suppose a car travels 10 km at 40 km/hr, then another 10 km at 60 km/hr. What is the average speed?
>>> harmonic_mean([40, 60])
48.0
投資家がP / E（価格/収益）の比率が2.5,3,10という3つの会社のそれぞれに等しい価値の株式を購入したとします。投資家のポートフォリオの平均P / Eの比率はいくつでしょうか？
>>> harmonic_mean([2.5, 3, 10])  # For an equal investment portfolio.
3.6
もし data が空の場合、またはいずれの要素が0より小さい場合、例外 StatisticsError が送出されます。
The current algorithm has an early-out when it encounters a zero in the input. This means that the subsequent inputs are not tested for validity. (This behavior may change in the future.)
バージョン 3.6 で追加.
statistics.median(data)
The median is a robust measure of central location and is less affected by the presence of outliers. When the number of data points is odd, the middle data point is returned:
>>> median([1, 3, 5])
3
データ数が偶数の場合は、中央値は中央に最も近い2値の算術平均で補間されます:
>>> median([1, 3, 5, 7])
4.0
データが離散的で、中央値がデータ点にない値でも構わない場合に適しています。
statistics.median_low(data)
low median は必ずデータに含まれています。データ数が奇数の場合は中央の値を返し、偶数の場合は中央の2値の小さい方を返します。
>>> median_low([1, 3, 5])
3
>>> median_low([1, 3, 5, 7])
3
データが離散的で、中央値が補間値よりもデータ点にある値の方が良い場合に用いてください。
statistics.median_high(data)
high median は必ずデータに含まれています。データ数が奇数の場合は中央の値を返し、偶数の場合は中央の2値の大きい方を返します。
>>> median_high([1, 3, 5])
3
>>> median_high([1, 3, 5, 7])
5
データが離散的で、中央値が補間値よりもデータ点にある値の方が良い場合に用いてください。
statistics.median_grouped(data, interval=1)
>>> median_grouped([52, 52, 53, 54])
52.5
次の例ではデータは丸められているため、各値はデータの中間です。例えば 1 は 0.5 と 1.5 の中間、2 は 1.5 と 2.5 の中間、3 は 2.5 と 3.5 の中間です。例では中央の値は 3.5 から 4.5 で、補間により推定されます:
>>> median_grouped([1, 2, 2, 3, 4, 4, 4, 4, 4, 5])
3.7
interval は間隔を表します。デフォルトは1です。間隔を変えると当然補間値は変わります:
>>> median_grouped([1, 3, 3, 5, 7], interval=1)
3.25
>>> median_grouped([1, 3, 3, 5, 7], interval=2)
3.5
この関数はデータ点が少なくとも interval だけ差があるかどうかチェックしません。
CPython implementation detail: 環境によっては median_grouped() はデータ点を強制的に浮動小数点に変換します。この挙動はいずれ変更されるでしょう。
参考
"Statistics for the Behavioral Sciences", Frederick J Gravetter and Larry B Wallnau (8th Edition).
statistics.mode(data)
mode assumes discrete data and returns a single value. This is the standard treatment of the mode as commonly taught in schools:
>>> mode([1, 1, 2, 3, 3, 3, 3, 4])
3
The mode is unique in that it is the only statistic in this package that also applies to nominal (non-numeric) data:
>>> mode(["red", "blue", "blue", "red", "green", "red", "red"])
'red'
バージョン 3.8 で変更: Now handles multimodal datasets by returning the first mode encountered. Formerly, it raised StatisticsError when more than one mode was found.
statistics.multimode(data)
Return a list of the most frequently occurring values in the order they were first encountered in the data. Will return more than one result if there are multiple modes or an empty list if the data is empty:
>>> multimode('aabbbbccddddeeffffgg')
['b', 'd', 'f']
>>> multimode('')
[]
バージョン 3.8 で追加.
statistics.pstdev(data, mu=None)
母標準偏差 (母分散の平方根) を返します。引数や詳細は pvariance() を参照してください。
>>> pstdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])
0.986893273527251
statistics.pvariance(data, mu=None)
母集団全体から分散を計算する場合に用いてください。標本から分散を推定する場合は variance() を使いましょう。
data が空の場合 StatisticsError を送出します。
例:
>>> data = [0.0, 0.25, 0.25, 1.25, 1.5, 1.75, 2.75, 3.25]
>>> pvariance(data)
1.25
既にデータの平均値を計算している場合、それを第2引数 mu に渡して再計算を避けることが出来ます:
>>> mu = mean(data)
>>> pvariance(data, mu)
1.25
Decimal と Fraction がサポートされています:
>>> from decimal import Decimal as D
>>> pvariance([D("27.5"), D("30.25"), D("30.25"), D("34.5"), D("41.75")])
Decimal('24.815')
>>> from fractions import Fraction as F
>>> pvariance([F(1, 4), F(5, 4), F(1, 2)])
Fraction(13, 72)
注釈 母集団全体で呼んだ場合は母分散 σ² を返します。代わりに標本で呼んだ場合は biased variance s²、すなわち自由度 N の分散を返します。
statistics.stdev(data, xbar=None)
標本標準偏差 (標本分散の平方根) を返します。引数や詳細は variance() を参照してください。
>>> stdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])
1.0810874155219827
statistics.variance(data, xbar=None)
data の標本分散を返します。data は少なくとも2つの実数の iterable です。分散、すなわち2次の中心化モーメントはデータの散らばり具合の測度です。分散が大きいデータはばらつきが大きく、分散が小さいデータは平均値のまわりに固まっています。
第2引数 xbar に値を渡す場合は data の平均値でなくてはなりません。xbar が与えられない場合や None の場合 (デフォルト)、平均値は自動的に計算されます。
データが母集団の標本であるときに用いてください。母集団全体から分散を計算するには pvariance() を参照してください。
data の値が2より少ない場合 StatisticsError を送出します。
例:
>>> data = [2.75, 1.75, 1.25, 0.25, 0.5, 1.25, 3.5]
>>> variance(data)
1.3720238095238095
既にデータの平均値を計算している場合、それを第2引数 xbar に渡して再計算を避けることが出来ます:
>>> m = mean(data)
>>> variance(data, m)
1.3720238095238095
この関数は引数として渡した xbar が実際の平均値かどうかチェックしません。任意の値を xbar に渡すと無効な結果やありえない結果が返ることがあります。
Decimal と Fraction がサポートされています:
>>> from decimal import Decimal as D
>>> variance([D("27.5"), D("30.25"), D("30.25"), D("34.5"), D("41.75")])
Decimal('31.01875')
>>> from fractions import Fraction as F
>>> variance([F(1, 6), F(1, 2), F(5, 3)])
Fraction(67, 108)
注釈 Bessel 補正済みの標本分散 s²、すなわち自由度 N-1 の分散です。与えられたデータ点が代表的 (たとえば独立で均等に分布) な場合、戻り値は母分散の不偏推定量になります。
何らかの方法で真の母平均 μ を知っている場合、それを pvariance() の引数 mu に渡して標本の分散を計算することが出来ます。
statistics.quantiles(data, *, n=4, method='exclusive')
# Decile cut points for empirically sampled data
>>> data = [105, 129, 87, 86, 111, 111, 89, 81, 108, 92, 110,
...         100, 75, 105, 103, 109, 76, 119, 99, 91, 103, 129,
...         106, 101, 84, 111, 74, 87, 86, 103, 103, 106, 86,
...         111, 75, 87, 102, 121, 111, 88, 89, 101, 106, 95,
...         103, 107, 101, 81, 109, 104]
>>> [round(q, 1) for q in quantiles(data, n=10)]
[81.0, 86.2, 89.0, 99.4, 102.5, 103.6, 106.0, 109.8, 111.0]
バージョン 3.8 で追加.
例外
例外が1つ定義されています:
exception statistics.StatisticsError
統計関係の例外。ValueError の派生クラス。
NormalDist objects
class statistics.NormalDist(mu=0.0, sigma=1.0)
mean
median
mode
stdev
variance
classmethod from_samples(data)
samples(n, *, seed=None)
pdf(x)
cdf(x)
inv_cdf(p)
overlap(other)
quantiles(n=4)
zscore(x)
バージョン 3.9 で追加.
Instances of NormalDist support addition, subtraction, multiplication and division by a constant. These operations are used for translation and scaling. For example:
>>> temperature_february = NormalDist(5, 2.5)             # Celsius
>>> temperature_february * (9/5) + 32                     # Fahrenheit
NormalDist(mu=41.0, sigma=4.5)
Since normal distributions arise from additive effects of independent variables, it is possible to add and subtract two independent normally distributed random variables represented as instances of NormalDist. For example:
>>> birth_weights = NormalDist.from_samples([2.5, 3.1, 2.1, 2.4, 2.7, 3.5])
>>> drug_effects = NormalDist(0.4, 0.15)
>>> combined = birth_weights + drug_effects
>>> round(combined.mean, 1)
3.1
>>> round(combined.stdev, 1)
0.5
バージョン 3.8 で追加.
NormalDist Examples and Recipes
For example, given historical data for SAT exams showing that scores are normally distributed with a mean of 1060 and a standard deviation of 195, determine the percentage of students with test scores between 1100 and 1200, after rounding to the nearest whole number:
>>> sat = NormalDist(1060, 195)
>>> fraction = sat.cdf(1200 + 0.5) - sat.cdf(1100 - 0.5)
>>> round(fraction * 100.0, 1)
18.4
Find the quartiles and deciles for the SAT scores:
>>> list(map(round, sat.quantiles()))
[928, 1060, 1192]
>>> list(map(round, sat.quantiles(n=10)))
[810, 896, 958, 1011, 1060, 1109, 1162, 1224, 1310]
To estimate the distribution for a model than isn't easy to solve analytically, NormalDist can generate input samples for a Monte Carlo simulation:
>>> def model(x, y, z):
...     return (3*x + 7*x*y - 5*y) / (11 * z)
...
>>> n = 100_000
>>> X = NormalDist(10, 2.5).samples(n, seed=3652260728)
>>> Y = NormalDist(15, 1.75).samples(n, seed=4582495471)
>>> Z = NormalDist(50, 1.25).samples(n, seed=6582483453)
>>> quantiles(map(model, X, Y, Z))       
[1.4591308524824727, 1.8035946855390597, 2.175091447274739]
For example, an open source conference has 750 attendees and two rooms with a 500 person capacity. There is a talk about Python and another about Ruby. In previous conferences, 65% of the attendees preferred to listen to Python talks. Assuming the population preferences haven't changed, what is the probability that the Python room will stay within its capacity limits?
>>> n = 750             # Sample size
>>> p = 0.65            # Preference for Python
>>> q = 1.0 - p         # Preference for Ruby
>>> k = 500             # Room capacity
>>> # Approximation using the cumulative normal distribution
>>> from math import sqrt
>>> round(NormalDist(mu=n*p, sigma=sqrt(n*p*q)).cdf(k + 0.5), 4)
0.8402
>>> # Solution using the cumulative binomial distribution
>>> from math import comb, fsum
>>> round(fsum(comb(n, r) * p**r * q**(n-r) for r in range(k+1)), 4)
0.8402
>>> # Approximation using a simulation
>>> from random import seed, choices
>>> seed(8675309)
>>> def trial():
...     return choices(('Python', 'Ruby'), (p, q), k=n).count('Python')
>>> mean(trial() <= k for i in range(10_000))
0.8398
We're given a training dataset with measurements for eight people. The measurements are assumed to be normally distributed, so we summarize the data with NormalDist:
>>> height_male = NormalDist.from_samples([6, 5.92, 5.58, 5.92])
>>> height_female = NormalDist.from_samples([5, 5.5, 5.42, 5.75])
>>> weight_male = NormalDist.from_samples([180, 190, 170, 165])
>>> weight_female = NormalDist.from_samples([100, 150, 130, 150])
>>> foot_size_male = NormalDist.from_samples([12, 11, 12, 10])
>>> foot_size_female = NormalDist.from_samples([6, 8, 7, 9])
Next, we encounter a new person whose feature measurements are known but whose gender is unknown:
>>> ht = 6.0        # height
>>> wt = 130        # weight
>>> fs = 8          # foot size
Starting with a 50% prior probability of being male or female, we compute the posterior as the prior times the product of likelihoods for the feature measurements given the gender:
>>> prior_male = 0.5
>>> prior_female = 0.5
>>> posterior_male = (prior_male * height_male.pdf(ht) *
...                   weight_male.pdf(wt) * foot_size_male.pdf(fs))
>>> posterior_female = (prior_female * height_female.pdf(ht) *
...                     weight_female.pdf(wt) * foot_size_female.pdf(fs))
The final prediction goes to the largest posterior. This is known as the maximum a posteriori or MAP:
>>> 'male' if posterior_male > posterior_female else 'female'
'female'
asyncio --- 非同期 I/O
Hello World!
import asyncio
async def main():
    print('Hello ...')
    await asyncio.sleep(1)
    print('... World!')
# Python 3.7+
asyncio.run(main())
asyncio は async/await 構文を使い 並行処理の コードを書くためのライブラリです。
asyncio は、高性能なネットワークとウェブサーバ、データベース接続ライブラリ、分散タスクキューなどの複数の非同期 Python フレームワークの基盤として使われています。
asyncio は多くの場合、 IOバウンドだったり高レベルの 構造化された ネットワークコードに完璧に適しています。
asyncio は次の目的で 高レベル API を提供しています:
並行に Python コルーチンを起動 し、実行全体を管理する
ネットワーク IO と IPC を執り行う
subprocesses を管理する
キュー を使ってタスクを分散する
並列処理のコードを 同期 させる
これに加えて、 ライブラリやフレームワークの開発者 が次のことをするための 低レベル API があります:
ネットワーク通信 、 サブプロセス の実行、 OS シグナル の取り扱いなどのための非同期 API を提供する イベントループ の作成と管理を行う
Transport を使った効率的な protocol を実装します
コールバックを用いたライブラリと async/await 構文を使ったコードの 橋渡し
リファレンス
高レベル API
コルーチンと Task
Streams
Synchronization Primitives
Subprocesses
キュー
例外
低レベル API
イベントループ
Future
Transports and Protocols
Policies
Platform Support
ガイドとチュートリアル
高水準の API インデックス
Low-level API Index
Developing with asyncio
注釈 asyncio のソースコードは Lib/asyncio/ にあります。
socket --- 低水準ネットワークインターフェース
ソースコード: Lib/socket.py
このモジュールはBSDの ソケット(socket) インターフェイスへのアクセスを提供します。これは、近代的なUnixシステム、Windows、MacOS、その他多くのプラットフォームで動作します。
注釈 いくつかの挙動はプラットフォームに依存します。オペレーティングシステムのソケットAPIを呼び出しているためです。
Pythonインターフェースは、Unixのソケット用システムコールとライブラリインターフェースを、そのままPythonのオブジェクト指向スタイルに変換したものです。各種ソケット関連のシステムコールは、 socket() 関数で生成される socket オブジェクト のメソッドとして実装されています。 メソッドの引数は C のインターフェイスよりも多少高水準で、例えばファイルに対する read() や write() メソッドと同様に、 受信時のバッファ確保は自動的に処理され、送信時のバッファ長は暗黙的に決まります。
参考
Module socketserver
ネットワークサーバの開発を省力化するためのクラス群。
Module ssl
ソケットオブジェクトに対する TLS/SSL ラッパー.
ソケットファミリー
どのシステムで実行するかとビルドオプションに依存しますが、このモジュールによって多様なソケットファミリーをサポートします。
特定のソケットオブジェクトによって必要とされるアドレスフォーマットは、ソケットオブジェクトが生成されたときに指定されたアドレスファミリーを元に自動的に選択されます。ソケットアドレスは次の通りです。
ファイルシステム上のノードに束縛された AF_UNIX ソケットのアドレスは、ファイルシステムエンコーディングと 'surrogateescape' エラーハンドラ (PEP 383 を参照) を使って文字列として表現されます。 Linux の抽象名前空間のアドレスは、先頭が null バイトとなる bytes-like object として返されます。この名前空間のソケットは通常のファイルシステム上のソケットと通信できるので、 Linux 上で動作することを意図したプログラムは両方のアドレスを扱う必要がある可能性があります。文字列と bytes-like オブジェクトはどちらのタイプのアドレスにも引数として渡すことができます。
バージョン 3.3 で変更: これまでは AF_UNIX ソケットパスは UTF-8 エンコーディングを使用するものとされていました。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
AF_INET アドレスファミリーには、 (host, port) ペアがアドレスとして利用されます。 host はホスト名か 'daring.cwi.nl' のようなインターネットドメインか、 '100.50.200.5' のような IPv4 アドレスで、 port は整数です。
バージョン 3.7 で変更: For multicast addresses (with scope_id meaningful) address may not contain %scope_id (or zone id) part. This information is superfluous and may be safely omitted (recommended).
AF_NETLINK ソケットのアドレスは (pid, groups) のペアで表されます。
Linux 限定で、 AF_TIPC アドレスファミリーを用いて TIPC がサポートされます。 TIPC は、クラスタコンピューティング環境のために設計された、IP ベースではないオープンなネットワークプロトコルです。アドレスはタプルで表現され、フィールドはアドレスタイプに依存します。一般的なタプルの形式は (addr_type, v1, v2, v3 [, scope]) で、それぞれは次の通りです:
addr_type は TIPC_ADDR_NAMESEQ, TIPC_ADDR_NAME, TIPC_ADDR_ID の1つ。
scope は TIPC_ZONE_SCOPE, TIPC_CLUSTER_SCOPE, TIPC_NODE_SCOPE の1つ。
addr_type が TIPC_ADDR_NAME の場合、 v1 はサーバータイプ、 v2 はポートID (the port identifier)、そして v3 は 0 であるべきです。
addr_type が TIPC_ADDR_NAMESEQ の場合、 v1 はサーバータイプ、 v2 はポート番号下位(lower port number)、 v3 はポート番号上位(upper port number) です。
addr_type が TIPC_ADDR_ID の場合、 v1 はノード、 v2 は参照、 v3 は0であるべきです。
AF_CAN アドレスファミリーには (interface,) というタプルを利用します。 interface は 'can0' のようなネットワークインタフェース名を表す文字列です。このファミリーの全てのネットワークインタフェースからパケットを受信するために、ネットワークインタフェース名 '' を利用できます。
文字列またはタプル (id, unit) は PF_SYSTEM ファミリーの SYSPROTO_CONTROL プロトコルのために使用されます。この文字列は、動的に割り当てられたIDによるカーネルコントロールの名前です。このタプルは、カーネルコントロールのIDとユニット番号が既知の場合、または登録済みIDが使用中の場合に使用することができます。
バージョン 3.3 で追加.
AF_BLUETOOTH は以下のプロトコルとアドレスフォーマットをサポートしています。
BTPROTO_L2CAP は (bdaddr, psm) を受け取ります。 bdaddr は Bluetooth アドレスを表す文字列で、 psm は整数です。
BTPROTO_RFCOMM は (bdaddr, channel) を受け取ります。 bdaddr は Bluetooth アドレスを表す文字列で、 channel は整数です。
BTPROTO_HCI は (device_id,) を受け取ります。 device_id は、数値またはインターフェイスの Bluetooth アドレスを表す文字列です。(OS に依存します。NetBSD と DragonFlyBSD は Bluetooth アドレスを期待しますが、その他すべての OS は、数値を期待します。)
バージョン 3.2 で変更: NetBSD と DragonFlyBSD のサポートが追加されました。
BTPROTO_SCO は bdaddr を受け取ります。ここで、 bdaddr は Bluetooth アドレスを文字列形式で持つ bytes オブジェクトです (例: b'12:23:34:45:56:67')。このプロトコルは、 FreeBSD ではサポートされていません。
AF_ALG はカーネル暗号へのソケットベースのインターフェイスで、Linux でのみ使用できます。アルゴリズムソケットは、2 つから 4 つの要素を持つタプル (type, name [, feat [, mask]]) で構成されます。各要素の意味は、以下の通りです。
type はアルゴリズムタイプを示す文字列です。例: aead, hash, skcipher または rng。
name はアルゴリズム名及び操作モードを示す文字列です。例: sha256, hmac(sha256), cbc(aes) または drbg_nopr_ctr_aes256。
feat と mask は、符号を持たない 32 ビットの整数です。
バージョン 3.6 で追加.
バージョン 3.7 で追加.
AF_PACKET is a low-level interface directly to network devices. The packets are represented by the tuple (ifname, proto[, pkttype[, hatype[, addr]]]) where:
ifname - デバイス名を指定する文字列。
proto - An in network-byte-order integer specifying the Ethernet protocol number.
pkttype - パケットタイプを指定するオプションの整数:
hatype - Optional integer specifying the ARP hardware address type.
addr - Optional bytes-like object specifying the hardware physical address, whose interpretation depends on the device.
バージョン 3.8 で追加.
Availability: Linux >= 2.6.20, FreeBSD >= 10.1-RELEASE
バージョン 3.9 で追加.
IPv4/v6ソケットの host 部にホスト名を指定すると、処理結果が一定ではない場合があります。これはPythonはDNSから取得したアドレスのうち最初のアドレスを使用するので、 DNSの処理やホストの設定によって異なるIPv4/6アドレスを取得する場合があるためです。常に同じ結果が必要であれば、 host に数値のアドレスを指定してください。
全てのエラーは例外を発生させます。引数型のエラーやメモリ不足の場合には通常の例外が発生し、ソケットやアドレス関連のエラーは Python 3.3 からは OSError かそのサブクラスを発生させます (Python 3.3 以前は socket.error を発生させていました)。
setblocking() メソッドで、非ブロッキングモードを使用することができます。また、より汎用的に settimeout() メソッドでタイムアウトを指定する事ができます。
モジュールの内容
socket モジュールは以下の要素を公開しています。
例外
exception socket.error
OSError の非推奨のエイリアスです。
バージョン 3.3 で変更: PEP 3151 に基づき、このクラスは OSError のエイリアスになりました。
exception socket.herror
OSError のサブクラス。この例外はアドレス関連のエラー、つまり gethostbyname_ex() と gethostbyaddr() などの、 POSIX C API の h_errno を利用する関数のために利用されます。例外に付随する (h_errno, string) ペアはライブラリの呼び出しによって返されたエラーを表します。 h_errno は数値で、 string は、 hstrerror() C関数によって返される h_errno を説明する文字列です。
バージョン 3.3 で変更: このクラスは OSError のサブクラスになりました。
exception socket.gaierror
OSError のサブクラスです。この例外は getaddrinfo() と getnameinfo() でアドレス関連のエラーが発生した場合に送出されます。例外の値は (error, string) のペアで、ライブラリの呼び出し結果を返します。 string はC関数 gai_strerror() で取得した、 error の意味を示す文字列です。 error の値は、このモジュールで定義される EAI_* 定数のどれかとなります。
バージョン 3.3 で変更: このクラスは OSError のサブクラスになりました。
exception socket.timeout
OSError のサブクラスです。この例外は、あらかじめ settimeout() を呼び出して (あるいは setdefaulttimeout() を利用して暗黙に) タイムアウトを有効にしてあるソケットでタイムアウトが生じた際に送出されます。 例外に付属する値は文字列で、その内容は現状では常に "timed out" となります。
バージョン 3.3 で変更: このクラスは OSError のサブクラスになりました。
定数
AF_* 定数と SOCK_* 定数は、 AddressFamily と SocketKind IntEnum collection になりました。
バージョン 3.4 で追加.
socket.AF_UNIX
socket.AF_INET
socket.AF_INET6
アドレス (およびプロトコル) ファミリーを示す定数で、 socket() の 最初の引数に指定することができます。 AF_UNIX ファミリーをサポート しないプラットフォームでは、 AF_UNIX は未定義となります。システムによってはこれら以外の定数が定義されているかもしれません。
socket.SOCK_STREAM
socket.SOCK_DGRAM
socket.SOCK_RAW
socket.SOCK_RDM
socket.SOCK_SEQPACKET
ソケットタイプを示す定数で、 socket() の2番目の引数に指定することができます。システムによってはこれら以外の定数が定義されているかもしれません。 (ほとんどの場合、 SOCK_STREAM と SOCK_DGRAM 以外は必要ありません。)
socket.SOCK_CLOEXEC
socket.SOCK_NONBLOCK
この2つの定数が定義されていた場合、ソケットタイプと組み合わせていくつかの flags をアトミックに設定することができます (別の呼び出しを不要にして競合状態を避ける事ができます)。
参考 より完全な説明は Secure File Descriptor Handling を参照してください。
バージョン 3.2 で追加.
SO_*
socket.SOMAXCONN
MSG_*
SOL_*
SCM_*
IPPROTO_*
IPPORT_*
INADDR_*
IP_*
IPV6_*
EAI_*
AI_*
NI_*
TCP_*
Unixのソケット・IPプロトコルのドキュメントで定義されている各種定数。ソケットオブジェクトの setsockopt() や getsockopt() で使用します。ほとんどのシンボルはUnixのヘッダファイルに従っています。一部のシンボルには、デフォルト値を定義してあります。
バージョン 3.6 で変更: SO_DOMAIN, SO_PROTOCOL, SO_PEERSEC, SO_PASSSEC, TCP_USER_TIMEOUT, TCP_CONGESTION が追加されました。
バージョン 3.6.5 で変更: Windowsでは、実行時のWindowsがサポートしているならば TCP_FASTOPEN、 ``TCP_KEEPCNT``が表示されます。
バージョン 3.7 で変更: TCP_NOTSENT_LOWAT was added.
socket.AF_CAN
socket.PF_CAN
SOL_CAN_*
CAN_*
Linux ドキュメントにあるこの形式の定数は socket モジュールでも定義されています。
バージョン 3.3 で追加.
socket.CAN_BCM
CAN_BCM_*
CANプロトコルファミリーのCAN_BCMは、ブロードキャストマネージャー(BCM)プロトコルです。Linuxドキュメントにあるこの形式の定数は、socketモジュールでも定義されています。
注釈 The CAN_BCM_CAN_FD_FRAME flag is only available on Linux >= 4.8.
バージョン 3.4 で追加.
socket.CAN_RAW_FD_FRAMES
この定数は、 Linux のドキュメンテーションで説明されています。
バージョン 3.5 で追加.
socket.CAN_RAW_JOIN_FILTERS
この定数は、 Linux のドキュメンテーションで説明されています。
バージョン 3.9 で追加.
socket.CAN_ISOTP
バージョン 3.7 で追加.
socket.CAN_J1939
バージョン 3.9 で追加.
socket.AF_PACKET
socket.PF_PACKET
PACKET_*
Linux ドキュメントにあるこの形式の定数は socket モジュールでも定義されています。
socket.AF_RDS
socket.PF_RDS
socket.SOL_RDS
RDS_*
Linux ドキュメントにあるこの形式の定数は socket モジュールでも定義されています。
バージョン 3.3 で追加.
socket.SIO_RCVALL
socket.SIO_KEEPALIVE_VALS
socket.SIO_LOOPBACK_FAST_PATH
RCVALL_*
Windows の WSAIoctl() のための定数です。この定数はソケットオブジェクトの ioctl() メソッドに引数として渡されます。
バージョン 3.6 で変更: SIO_LOOPBACK_FAST_PATH が追加されました。
TIPC_*
TIPC 関連の定数で、C のソケットAPIが公開しているものにマッチします。詳しい情報は TIPC のドキュメントを参照してください。
socket.AF_ALG
socket.SOL_ALG
ALG_*
Linux カーネル暗号用の定数です。
バージョン 3.6 で追加.
socket.AF_VSOCK
socket.IOCTL_VM_SOCKETS_GET_LOCAL_CID
VMADDR*
SO_VM*
バージョン 3.7 で追加.
socket.AF_LINK
バージョン 3.4 で追加.
socket.has_ipv6
現在のプラットフォームでIPv6がサポートされているか否かを示す真偽値。
socket.BDADDR_ANY
socket.BDADDR_LOCAL
これらは、特別な意味を持つ Bluetooth アドレスを含む文字列定数です。例えば、BDADDR_ANY を使用すると、 BTPROTO_RFCOMM で束縛ソケットを指定する際に、任意のアドレスを指し示すことができます。
socket.HCI_FILTER
socket.HCI_TIME_STAMP
socket.HCI_DATA_DIR
BTPROTO_HCI で使用します。 HCI_FILTER は NetBSD または DragonFlyBSD では使用できません。 HCI_TIME_STAMP と HCI_DATA_DIR は FreeBSD, NetBSD, DragonFlyBSD では使用できません。
socket.AF_QIPCRTR
関数
ソケットの作成
以下の関数は全て socket object を生成します。
socket.socket(family=AF_INET, type=SOCK_STREAM, proto=0, fileno=None)
新たに作成されたソケットは 継承不可 です。
バージョン 3.3 で変更: AF_CAN, AF_RDS ファミリーが追加されました。
バージョン 3.4 で変更: CAN_BCMプロトコルが追加されました。
バージョン 3.4 で変更: 返されるソケットは継承不可になりました。
バージョン 3.7 で変更: The CAN_ISOTP protocol was added.
バージョン 3.7 で変更: When SOCK_NONBLOCK or SOCK_CLOEXEC bit flags are applied to type they are cleared, and socket.type will not reflect them. They are still passed to the underlying system socket() call. Therefore,
sock = socket.socket(
    socket.AF_INET,
    socket.SOCK_STREAM | socket.SOCK_NONBLOCK)
will still create a non-blocking socket on OSes that support SOCK_NONBLOCK, but sock.type will be set to socket.SOCK_STREAM.
バージョン 3.9 で変更: The CAN_J1939 protocol was added.
socket.socketpair([family[, type[, proto]]])
指定されたアドレスファミリー、ソケットタイプ、プロトコル番号から、接続されたソケットオブジェクトのペアを作成します。アドレスファミリー、ソケットタイプ、プロトコル番号は socket() 関数と同様に指定します。デフォルトのアドレスファミリは、プラットフォームで定義されている場合 AF_UNIX 、そうでなければ AF_INET が使われます。
新たに作成されたソケットは 継承不可 です。
バージョン 3.2 で変更: 返されるソケットオブジェクトが、サブセットではなく完全なソケットAPIを提供するようになりました。
バージョン 3.4 で変更: 返されるソケットの組は、どちらも継承不可になりました。
バージョン 3.5 で変更: Windows のサポートが追加されました。
socket.create_connection(address[, timeout[, source_address]])
address ((host, port) ペア) で listen しているTCPサービスに接続し、ソケットオブジェクトを返します。これは socket.connect() を高級にした関数です。 host が数値でないホスト名の場合、 AF_INET と AF_INET6 の両方で名前解決を試み、得られた全てのアドレスに対して成功するまで接続を試みます。この関数を使って IPv4 と IPv6 に両対応したクライアントを簡単に書くことができます。
オプションの timeout 引数を指定すると、接続を試みる前にソケットオブジェクトのタイムアウトを設定します。 timeout が指定されない場合、 getdefaulttimeout() が返すデフォルトのタイムアウト設定値を利用します。
source_address は接続する前にバインドするソースアドレスを指定するオプション引数で、指定する場合は (host, port) の2要素タプルでなければなりません。 host や port が '' か 0 だった場合は、OSのデフォルトの動作になります。
バージョン 3.2 で変更: source_address が追加されました。
socket.create_server(address, *, family=AF_INET, backlog=None, reuse_port=False, dualstack_ipv6=False)
family should be either AF_INET or AF_INET6. backlog is the queue size passed to socket.listen(); when 0 a default reasonable value is chosen. reuse_port dictates whether to set the SO_REUSEPORT socket option.
If dualstack_ipv6 is true and the platform supports it the socket will be able to accept both IPv4 and IPv6 connections, else it will raise ValueError. Most POSIX platforms and Windows are supposed to support this functionality. When this functionality is enabled the address returned by socket.getpeername() when an IPv4 connection occurs will be an IPv6 address represented as an IPv4-mapped IPv6 address. If dualstack_ipv6 is false it will explicitly disable this functionality on platforms that enable it by default (e.g. Linux). This parameter can be used in conjunction with has_dualstack_ipv6():
import socket
addr = ("", 8080)  # all interfaces, port 8080
if socket.has_dualstack_ipv6():
    s = socket.create_server(addr, family=socket.AF_INET6, dualstack_ipv6=True)
else:
    s = socket.create_server(addr)
注釈 On POSIX platforms the SO_REUSEADDR socket option is set in order to immediately reuse previous sockets which were bound on the same address and remained in TIME_WAIT state.
バージョン 3.8 で追加.
socket.has_dualstack_ipv6()
バージョン 3.8 で追加.
socket.fromfd(fd, family, type, proto=0)
ファイル記述子 (ファイルオブジェクトの fileno() メソッドが返す整数) fd を複製して、ソケットオブジェクトを構築します。アドレスファミリとプロトコル番号は socket() と同様に指定します。ファイル記述子 はソケットを指していなければなりませんが、実際にソケットであるかどうかのチェックは行っていません。このため、ソケット以外のファイル記述子 を指定するとその後の処理が失敗する場合があります。この関数が必要な事はあまりありませんが、 (Unixのinetデーモンに起動されるプログラムのように) ソケットを標準入力や標準出力として使用するプログラムでソケットオプションの取得や設定を行うために使われます。この関数で使用するソケットは、ブロッキングモードと想定しています。
新たに作成されたソケットは 継承不可 です。
バージョン 3.4 で変更: 返されるソケットは継承不可になりました。
socket.fromshare(data)
socket.share() メソッドから取得した data からソケットオブジェクトを生成します。ソケットはブロッキングモードだと仮定されます。
利用可能な環境: Windows 。
バージョン 3.3 で追加.
socket.SocketType
ソケットオブジェクトの型を示す型オブジェクト。 type(socket(...)) と同じです。
その他の関数
socket モジュールはネットワーク関連のサービスを提供しています:
socket.close(fd)
バージョン 3.7 で追加.
socket.getaddrinfo(host, port, family=0, type=0, proto=0, flags=0)
host / port 引数の指すアドレス情報を、そのサービスに接続されたソケットを作成するために必要な全ての引数が入った 5 要素のタプルに変換します。 host はドメイン名、IPv4/v6アドレスの文字列、または None です。 port は 'http' のようなサービス名文字列、ポート番号を表す数値、または None です。 host と port に None を指定すると C APIに NULL を渡せます。
オプションの family, type, proto 引数を指定すると、返されるアドレスのリストを絞り込むことができます。これらの引数の値として 0 を渡すと絞り込まない結果を返します。 flags 引数には AI_* 定数のうち 1 つ以上が指定でき、結果の取り方を変えることができます。例えば、 AI_NUMERICHOST を指定するとドメイン名解決を行わないようにし、 host がドメイン名だった場合には例外を送出します。
この関数は以下の構造をとる 5 要素のタプルのリストを返します:
(family, type, proto, canonname, sockaddr)
次の例では example.org の 80 番ポートポートへの TCP 接続を得るためのアドレス情報を取得しようとしています。 (結果は IPv6 をサポートしているかどうかで変わります):
>>>
>>> socket.getaddrinfo("example.org", 80, proto=socket.IPPROTO_TCP)
[(<AddressFamily.AF_INET6: 10>, <SocketType.SOCK_STREAM: 1>,
 6, '', ('2606:2800:220:1:248:1893:25c8:1946', 80, 0, 0)),
 (<AddressFamily.AF_INET: 2>, <SocketType.SOCK_STREAM: 1>,
 6, '', ('93.184.216.34', 80))]
バージョン 3.2 で変更: パラメータをキーワード引数で渡すことができるようになりました。
バージョン 3.7 で変更: for IPv6 multicast addresses, string representing an address will not contain %scope_id part.
socket.getfqdn([name])
name の完全修飾ドメイン名を返します。 name が空または省略された場合、ローカルホストを指定したとみなします。完全修飾ドメイン名の取得にはまず gethostbyaddr() でチェックし、次に可能であればエイリアスを調べ、名前にピリオドを含む最初の名前を値として返します。完全修飾ドメイン名を取得できない場合、 gethostname() で返されるホスト名を返します。
socket.gethostbyname(hostname)
ホスト名を '100.50.200.5' のようなIPv4形式のアドレスに変換します。ホスト名としてIPv4アドレスを指定した場合、その値は変換せずにそのまま返ります。 gethostbyname() APIへのより完全なインターフェイスが必要であれば、 gethostbyname_ex() を参照してください。 gethostbyname() は、IPv6名前解決をサポートしていません。IPv4/ v6のデュアルスタックをサポートする場合は getaddrinfo() を使用します。
socket.gethostbyname_ex(hostname)
ホスト名から、IPv4形式の各種アドレス情報を取得します。戻り値は (hostname, aliaslist, ipaddrlist) のタプルで、 hostname は ip_address で指定したホストの正式名、 aliaslist は同じアドレスの別名のリスト(空の場合もある)、 ipaddrlist は同じホスト上の同一インターフェイスのIPv4アドレスのリスト(ほとんどの場合は単一のアドレスのみ) を示します。 gethostbyname_ex() は、IPv6名前解決をサポートしていません。IPv4/v6のデュアルスタックをサポートする場合は getaddrinfo() を使用します。
socket.gethostname()
Pythonインタープリタを現在実行しているマシンのホスト名を含む文字列を返します。
注意: gethostname() は完全修飾ドメイン名を返すとは限りません。完全修飾ドメイン名が必要であれば、getfqdn() を使用してください。
socket.gethostbyaddr(ip_address)
(hostname, aliaslist, ipaddrlist) のタプルを返し、 hostname は ip_address で指定したホストの正式名、 aliaslist は同じアドレスの別名のリスト(空の場合もある)、 ipaddrlist は同じホスト上の同一インターフェイスのIPv4アドレスのリスト(ほとんどの場合は単一のアドレスのみ)を示します。完全修飾ドメイン名が必要であれば、 getfqdn() を使用してください。 gethostbyaddr() は、IPv4/IPv6の両方をサポートしています。
socket.getnameinfo(sockaddr, flags)
ソケットアドレス sockaddr から、 (host, port) のタプルを取得します。 flags の設定に従い、 host は完全修飾ドメイン名または数値形式アドレスとなります。同様に、 port は文字列のポート名または数値のポート番号となります。
socket.getprotobyname(protocolname)
('icmp' のような) インターネットプロトコル名を、 socket() の 第三引数として指定する事ができる定数に変換します。これは主にソケットを "raw" モード(SOCK_RAW)でオープンする場合には必要ですが、通常の ソケットモードでは第三引数に0を指定するか省略すれば正しいプロトコルが自動的に選択されます。
socket.getservbyname(servicename[, protocolname])
インターネットサービス名とプロトコルから、そのサービスのポート番号を取得します。省略可能なプロトコル名として、 'tcp' か 'udp' のどちらかを指定することができます。指定がなければどちらのプロトコルにもマッチします。
socket.getservbyport(port[, protocolname])
インターネットポート番号とプロトコル名から、サービス名を取得します。省略可能なプロトコル名として、 'tcp' か 'udp' のどちらかを指定することができます。指定がなければどちらのプロトコルにもマッチします。
socket.ntohl(x)
32ビットの正の整数のバイトオーダを、ネットワークバイトオーダからホストバイトオーダに変換します。ホストバイトオーダとネットワークバイトオーダが一致するマシンでは、この関数は何もしません。それ以外の場合は4バイトのスワップを行います。
socket.ntohs(x)
16ビットの正の整数のバイトオーダを、ネットワークバイトオーダからホストバイトオーダに変換します。ホストバイトオーダとネットワークバイトオーダが一致するマシンでは、この関数は何もしません。それ以外の場合は2バイトのスワップを行います。
バージョン 3.7 で非推奨: In case x does not fit in 16-bit unsigned integer, but does fit in a positive C int, it is silently truncated to 16-bit unsigned integer. This silent truncation feature is deprecated, and will raise an exception in future versions of Python.
socket.htonl(x)
32ビットの正の整数のバイトオーダを、ホストバイトオーダからネットワークバイトオーダに変換します。ホストバイトオーダとネットワークバイトオーダが一致するマシンでは、この関数は何もしません。それ以外の場合は4バイトのスワップを行います。
socket.htons(x)
16ビットの正の整数のバイトオーダを、ホストバイトオーダからネットワークバイトオーダに変換します。ホストバイトオーダとネットワークバイトオーダが一致するマシンでは、この関数は何もしません。それ以外の場合は2バイトのスワップを行います。
バージョン 3.7 で非推奨: In case x does not fit in 16-bit unsigned integer, but does fit in a positive C int, it is silently truncated to 16-bit unsigned integer. This silent truncation feature is deprecated, and will raise an exception in future versions of Python.
socket.inet_aton(ip_string)
ドット記法によるIPv4アドレス('123.45.67.89' など)を32ビットにパックしたバイナリ形式に変換し、長さ4のバイト列オブジェクトとして返します。この関数が返す値は、標準Cライブラリの struct in_addr 型を使用する関数に渡す事ができます。
inet_aton() はドットが 3 個以下の文字列も受け取ります; 詳細については Unix のマニュアル inet(3) を参照してください。
IPv4アドレス文字列が不正であれば、 OSError が発生します。このチェックは、この関数で使用しているCの実装 inet_aton() で行われます。
inet_aton() は、IPv6をサポートしません。IPv4/v6のデュアルスタックをサポートする場合は inet_pton() を使用します。
socket.inet_ntoa(packed_ip)
32 ビットにパックされた IPv4 アドレス (長さ 4 バイトの bytes-like object) を、標準的なドット記法による 4 桁の文字列 ('123.45.67.89' など) に変換します。この関数は、struct in_addr 型を使用する標準 C ライブラリのプログラムとやりとりする場合に便利です。struct in_addr 型は、この関数が引数として受け取る 32 ビットにパックされたバイナリデータに対する C の型です。
この関数に渡すバイトシーケンスの長さが4バイト以外であれば、 OSError が発生します。 inet_ntoa() は、IPv6をサポートしません。IPv4/v6のデュアルスタックをサポートする場合は inet_ntop() を使用します。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
socket.inet_pton(address_family, ip_string)
IPアドレスを、アドレスファミリ固有の文字列からパックしたバイナリ形式に変換します。 inet_pton() は、 struct in_addr 型 (inet_aton() と同様)や struct in6_addr を使用するライブラリやネットワークプロトコルを呼び出す際に使用することができます。
現在サポートされている address_family は、 AF_INET と AF_INET6 です。 ip_string に不正なIPアドレス文字列を指定すると、 OSError が発生します。有効な ip_string は、 address_family と inet_pton() の実装によって異なります。
バージョン 3.4 で変更: Windowsで利用可能になりました
socket.inet_ntop(address_family, packed_ip)
パックしたIPアドレス (数バイトからなる bytes-like オブジェクト ) を、 '7.10.0.5' や '5aef:2b::8' などの標準的な、アドレスファミリ固有の文字列形式に変換します。 inet_ntop() は (inet_ntoa() と同様に)、 struct in_addr 型や struct in6_addr 型のオブジェクトを返すライブラリやネットワークプロトコル等で使用することができます。
現在サポートされている address_family の値は、 AF_INET と AF_INET6 です。バイトオブジェクトの packed_ip の長さが、指定したアドレスファミリで適切な長さでない場合、 ValueError が発生します。 inet_ntop() の呼び出しでエラーが起こると、 OSError が発生します。
バージョン 3.4 で変更: Windowsで利用可能になりました
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
socket.CMSG_LEN(length)
指定された length にある制御メッセージ（CMSG）から、末尾のパディングを除いた全体の長さを返します。この値は多くの場合、 recvmsg() が制御メッセージの一連の要素を受信するためのバッファサイズとして使用できますが、バッファの末尾が要素である場合であってもパディングは含まれるので、バッファサイズを取得するには RFC 3542 で求められているように、 CMSG_SPACE() を使用した移植可能なアプリケーションが必要です。通常 length は定数であり、許容範囲外の値が指定された場合は OverflowError 例外が送出されます。
バージョン 3.3 で追加.
socket.CMSG_SPACE(length)
指定された length の制御メッセージ（CMSG）の要素を recvmsg() が受信するために必要な、パディングを含めたバッファサイズを返します。複数の項目を受信するために必要なバッファスペースは、 CMSG_SPACE() が返すそれぞれの要素の長さの合計です。通常 length は定数であり、許容範囲外の値が指定された場合は OverflowError 例外が送出されます。
一部のシステムではこの関数を提供せずに制御メッセージをサポートする可能性があることに注意してください。また、この関数の返り値を使用して設定するバッファサイズは、受信する制御メッセージの量を正確に規定しないことがあり、その後に受信するデータがパディング領域に合う場合があることに注意してください。
バージョン 3.3 で追加.
socket.getdefaulttimeout()
新規に生成されたソケットオブジェクトの、デフォルトのタイムアウト値を浮動小数点形式の秒数で返します。タイムアウトを使用しない場合には None を返します。最初に socket モジュールがインポートされた時の初期値は None です。
socket.setdefaulttimeout(timeout)
新規に生成されるソケットオブジェクトの、デフォルトのタイムアウト値を秒数 (float 型) で設定します。最初に socket モジュールがインポートされた時の初期値は None です。指定可能な値とその意味については settimeout() メソッドを参照してください。
socket.sethostname(name)
マシンのホスト名を name に設定します。必要な権限がない場合は OSError を送出します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
socket.if_nameindex()
ネットワークインターフェース情報 (index int, name string)のタプルを返します。システムコールが失敗した場合、 OSError 例外を送出します。
Availability: Unix, Windows。
バージョン 3.3 で追加.
バージョン 3.8 で変更: Windows support was added.
注釈 On Windows network interfaces have different names in different contexts (all names are examples):
UUID: {FB605B73-AAC2-49A6-9A2F-25416AEA0573}
name: ethernet_32770
friendly name: vEthernet (nat)
description: Hyper-V Virtual Ethernet Adapter
socket.if_nametoindex(if_name)
インターフェース名 if_name に対応するネットワークインターフェースのインデックス番号を返します。対応するインターフェースが存在しない場合は OSError 例外を送出します。
Availability: Unix, Windows。
バージョン 3.3 で追加.
バージョン 3.8 で変更: Windows support was added.
参考 "Interface name" is a name as documented in if_nameindex().
socket.if_indextoname(if_index)
インターフェースインデックス番号 if_index に対応するネットワークインターフェース名を返します。対応するインターフェースが存在しない場合は OSError 例外を送出します。
Availability: Unix, Windows。
バージョン 3.3 で追加.
バージョン 3.8 で変更: Windows support was added.
参考 "Interface name" is a name as documented in if_nameindex().
socket オブジェクト
ソケットオブジェクトは以下のメソッドを持ちます。 makefile() 以外のメソッドは、Unixのソケット用システムコールに対応しています。
バージョン 3.2 で変更: context manager プロトコルのサポートが追加されました。コンテキストマネージャを終了することは、 close() を呼ぶことと同一です。
socket.accept()
接続を受け付けます。ソケットはアドレスにbind済みで、listen中である必要があります。戻り値は (conn, address) のペアで、 conn は接続を通じてデータの送受信を行うための 新しい ソケットオブジェクト、 address は接続先でソケットにbindしているアドレスを示します。
新たに作成されたソケットは 継承不可 です。
バージョン 3.4 で変更: ソケットが 継承不可 になりました。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.bind(address)
ソケットを address にbindします。bind済みのソケットを再バインドする事はできません。(address のフォーマットはアドレスファミリによって異なります -- 前述。)
socket.close()
ソケットを閉じられたものとしてマークします。 makefile() が返したファイルオブジェクトを閉じる時、対応する下層のシステムリソース（例：ファイル記述子）もすべて閉じます。一度この操作をすると、その後、このソケットオブジェクトに対するすべての操作が失敗します。キューに溜まったデータがフラッシュされた後は、リモート側の端点ではそれ以上のデータを受信しません。
ソケットはガベージコレクション時に自動的にクローズされます。しかし、明示的に close() するか、 with 文の中でソケットを使うことを推奨します。
バージョン 3.6 で変更: 下層の close() が呼び出される時、OSError が送出されるようになりました。
注釈 close() は接続に関連付けられたリソースを解放しますが、接続をすぐに切断するとは限りません。接続を即座に切断したい場合は、 close() の前に shutdown() を呼び出してください。
socket.connect(address)
address で示されるリモートソケットに接続します。(address のフォーマットはアドレスファミリによって異なります --- 前述。)
接続が信号によって中断された場合、このメソッドは接続が完了するまで待機するか、タイムアウト時に socket.timeout を送出します。タイムアウトは、信号ハンドラが例外を送出せず、ソケットがブロックするかタイムアウトが設定されている場合に起こります。非ブロックソケットでは、接続が信号によって中断された場合 (あるいは信号ハンドラにより例外が送出された場合)、このメソッドは InterruptedError 例外を送出します。
バージョン 3.5 で変更: このメソッドは、接続が信号によって中断され、信号ハンドラが例外を送出せず、ソケットがブロックであるかタイムアウトが設定されている場合、InterruptedError 例外を送出する代わりに、接続を完了するまで待機するようになりました (論拠については PEP 475 を参照してください)。
socket.connect_ex(address)
connect(address) と同様ですが、C言語の connect() 関数の呼び出しでエラーが発生した場合には例外を送出せずにエラーを戻り値として返します。(これ以外の、"host not found,"等のエラーの場合には例外が発生します。)処理が正常に終了した場合には 0 を返し、エラー時には errno の値を返します。この関数は、非同期接続をサポートする場合などに使用することができます。
socket.detach()
実際にファイル記述子を閉じることなく、ソケットオブジェクトを閉じた状態にします。ファイル記述子は返却され、他の目的に再利用することができます。
バージョン 3.2 で追加.
socket.dup()
ソケットを複製します。
新たに作成されたソケットは 継承不可 です。
バージョン 3.4 で変更: ソケットが 継承不可 になりました。
socket.fileno()
ソケットのファイル記述子を短い整数型で返します。失敗時には、-1 を返します。ファイル記述子は、 select.select() などで使用します。
Windowsではこのメソッドで返された小整数をファイル記述子を扱う箇所 (os.fdopen() など) で利用できません。 Unix にはこの制限はありません。
socket.get_inheritable()
ソケットのファイル記述子またはソケットのハンドルの 継承可能フラグ を取得します。ソケットが子プロセスへ継承可能なら True 、継承不可なら False を返します。
バージョン 3.4 で追加.
socket.getpeername()
ソケットが接続しているリモートアドレスを返します。この関数は、リモート IPv4/v6ソケットのポート番号を調べる場合などに使用します。 address のフォーマットはアドレスファミリによって異なります(前述)。この関数をサポートしていないシステムも存在します。
socket.getsockname()
ソケット自身のアドレスを返します。この関数は、IPv4/v6ソケットのポート番号を調べる場合などに使用します。(address のフォーマットはアドレスファミリによって異なります --- 前述。)
socket.getsockopt(level, optname[, buflen])
ソケットに指定されたオプションを返します(Unixのマニュアルページ getsockopt(2) を参照)。 SO_* 等のシンボルは、このモジュールで定義しています。 buflen を省略した場合、取得するオブションは整数とみなし、整数型の値を戻り値とします。 buflen を指定した場合、長さ buflen のバッファでオプションを受け取り、このバッファをバイト列オブジェクトとして返します。このバッファは、呼び出し元プログラムで struct モジュール等を利用して内容を読み取ることができます。
socket.getblocking()
バージョン 3.7 で追加.
socket.gettimeout()
ソケットに指定されたタイムアウト値を取得します。タイムアウト値が設定されている場合には浮動小数点型で秒数が、設定されていなければ None が返ります。この値は、最後に呼び出された setblocking() または settimeout() によって設定されます。
socket.ioctl(control, option)
プラットフォーム
Windows
ioctl() メソッドは WSAIoctl システムインタフェースへの制限されたインタフェースです。詳しい情報については、 Win32 documentation を参照してください。
他のプラットフォームでは一般的な fcntl.fcntl() と fcntl.ioctl() が使われるでしょう; これらの関数は第 1 引数としてソケットオブジェクトを取ります。
現在、以下のコントロールコードのみがサポートされています。 SIO_RCVALL, SIO_KEEPALIVE_VALS, SIO_LOOPBACK_FAST_PATH。
バージョン 3.6 で変更: SIO_LOOPBACK_FAST_PATH が追加されました。
socket.listen([backlog])
サーバーを有効にして、接続を受け付けるようにします。backlog が指定されている場合、少なくとも 0 以上でなければなりません (それより低い場合、0 に設定されます)。システムが新しい接続を拒否するまでに許可する未受付の接続の数を指定します。指定しない場合、デフォルトの妥当な値が選択されます。
バージョン 3.5 で変更: backlog 引数が任意になりました。
socket.makefile(mode='r', buffering=None, *, encoding=None, errors=None, newline=None)
ソケットに関連付けられた ファイルオブジェクト を返します。戻り値の正確な型は、 makefile() に指定した引数によります。これらの引数は、組み込み関数 open() の引数と同様に解釈されます。ただし、mode の値は 'r' (デフォルト), 'w', 'b' のみがサポートされています。
ソケットはブロッキングモードでなければなりません。タイムアウトを設定することはできますが、タイムアウトが発生すると、ファイルオブジェクトの内部バッファが矛盾した状態になることがあります。
makefile() でファイルオブジェクトにソケットを関連づけた場合、ソケットを閉じるには、関連づけられたすべてのファイルオブジェクトを閉じたあとで、元のソケットの socket.close() を呼び出さなければなりません。
注釈 Windows では subprocess.Popen() の stream 引数などファイルディスクリプタつき file オブジェクトが期待されている場所では、 makefile() によって作成される file-like オブジェクトは使用できません。
socket.recv(bufsize[, flags])
ソケットからデータを受信し、結果を bytes オブジェクトで返します。一度に受信するデータは、最大でも bufsize で指定した量です。オプション引数 flags に指定するフラグの意味については、 Unix のマニュアルページ recv(2) を参照してください。 flags のデフォルトは 0 です。
注釈 ハードウェアおよびネットワークの現実に最大限マッチするように、 bufsize の値は比較的小さい2の累乗、たとえば 4096、にすべきです。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.recvfrom(bufsize[, flags])
ソケットからデータを受信し、結果をタプル (bytes, address) として返します。 bytes は受信データの bytes オブジェクトで、 address は送信元のアドレスを示します。オプション引数 flags については、 Unix のマニュアルページ recv(2) を参照してください。デフォルトは0です。 (address のフォーマットはアドレスファミリによって異なります(前述))
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
バージョン 3.7 で変更: For multicast IPv6 address, first item of address does not contain %scope_id part anymore. In order to get full IPv6 address use getnameinfo().
socket.recvmsg(bufsize[, ancbufsize[, flags]])
ソケットから通常のデータ (最大 bufsize バイト) と補助的なデータを受信します。ancbufsize 引数により、補助的なデータの受信に使用される内部バッファのバイト数として、サイズが設定されます。このデフォルトは 0 で、補助的なデータを受信しないことを意味します。CMSG_SPACE() または CMSG_LEN() を使用して、補助的なデータの適切なサイズを計算することができ、バッファ内に収まらないアイテムは、短縮されるか破棄されます。flags 引数はデフォルトでは 0 で、recv() での意味と同じ意味を持ちます。
戻り値は 4 要素のタプル (data, ancdata, msg_flags, address) です。data アイテムは、受信した非付属的データを保持する bytes オブジェクトです。ancdata アイテムは、ゼロ以上のタプル (cmsg_level, cmsg_type, cmsg_data) からなるリストで、受信する付属的なデータ (制御メッセージ) を表します。cmsg_level と cmsg_type はそれぞれ、プロトコルレベルとプロトコル固有のタイプを指定する整数で、cmsg_data は関連するデータを保持する bytes オブジェクトです。msg_flags アイテムは、受信したメッセージの条件を示す様々なフラグのビット OR です。詳細は、システムのドキュメントを参照してください。受信ソケットが接続されていない場合、address は、送信ソケットが利用できる場合にはそのアドレスで、利用できない場合、その値は未指定になります。
一部のシステムでは、sendmsg() と recvmsg() を使用して、プロセス間で AF_UNIX ソケットを経由してファイル記述子を渡すことができます。この機能を使用する場合 (しばしば SOCK_STREAM ソケットに限定されます)、recvmsg() は、付属的なデータ中に、(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds) という形式のアイテムを返します。ここで、fds は、新しいファイル記述子をネイティブ C の int 型のバイナリ配列として表します。システムコールが返った後 recvmsg() が例外を送出する場合、まずこのメカニズムを経由して受信したファイル記述子を全て閉じようと試みます。
一部のシステムでは、部分的に受信した付属的なデータアイテムの短縮された長さが示されません。アイテムがバッファの末尾を超えているようである場合、recvmsg() は RuntimeWarning を送出し、関連するデータの開始位置より前で途切れていない場合、バッファ内の付属的なデータの一部を返します。
SCM_RIGHTS メカニズムをサポートするシステム上では、次の関数が最大 maxfds のファイル記述子を受信し、メッセージデータと記述子を含むリストを返しま(無関係な制御メッセージを受信した場合など、予期しない条件は無視します)。 sendmsg() も参照してください。
import socket, array
def recv_fds(sock, msglen, maxfds):
    fds = array.array("i")   # Array of ints
    msg, ancdata, flags, addr = sock.recvmsg(msglen, socket.CMSG_LEN(maxfds * fds.itemsize))
    for cmsg_level, cmsg_type, cmsg_data in ancdata:
        if cmsg_level == socket.SOL_SOCKET and cmsg_type == socket.SCM_RIGHTS:
            # Append data, ignoring any truncated integers at the end.
            fds.frombytes(cmsg_data[:len(cmsg_data) - (len(cmsg_data) % fds.itemsize)])
    return msg, list(fds)
バージョン 3.3 で追加.
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.recvmsg_into(buffers[, ancbufsize[, flags]])
recvmsg() と同様に動作してソケットから通常のデータと付属的なデータを受信しますが、非付属的データは新しいバイトオブジェクトとして返すのではなく、一連のバッファとして返します。buffers 引数は書き込み可能なバッファをエクスポートするオブジェクトのイテラブルでなければなりません (例: bytearray オブジェクト)。これらは、全てに書き込まれるか、残りバッファがなくなるまで、非付属的データの連続チャンクで埋められます。オペレーティングシステムによって、使用できるバッファの数が制限 (sysconf() 値 SC_IOV_MAX) されている場合があります。ancbufsize 引数と flags 引数は、recvmsg() での意味と同じ意味を持ちます。
戻り値は 4 要素のタプル (nbytes, ancdata, msg_flags, address) です。ここで、nbytes はバッファに書き込まれた非付属的データの総数で、ancdata、msg_flags、address は recvmsg() と同様です。
以下はプログラム例です:
>>>
>>> import socket
>>> s1, s2 = socket.socketpair()
>>> b1 = bytearray(b'----')
>>> b2 = bytearray(b'0123456789')
>>> b3 = bytearray(b'--------------')
>>> s1.send(b'Mary had a little lamb')
22
>>> s2.recvmsg_into([b1, memoryview(b2)[2:9], b3])
(22, [], 0, None)
>>> [b1, b2, b3]
[bytearray(b'Mary'), bytearray(b'01 had a 9'), bytearray(b'little lamb---')]
バージョン 3.3 で追加.
socket.recvfrom_into(buffer[, nbytes[, flags]])
ソケットからデータを受信し、そのデータを新しいバイト文字列として返す代わりに buffer に書きます。戻り値は (nbytes, address) のペアで、 nbytes は受信したデータのバイト数を、 address はデータを送信したソケットのアドレスです。オプション引数 flags (デフォルト:0) の意味については、 Unix マニュアルページ recv(2) を参照してください。(address のフォーマットは前述のとおりアドレスファミリーに依存します。)
socket.recv_into(buffer[, nbytes[, flags]])
nbytes バイトまでのデータをソケットから受信して、そのデータを新しいバイト文字列にするのではなく buffer に保存します。 nbytes が指定されない(あるいは0が指定された)場合、 buffer の利用可能なサイズまで受信します。受信したバイト数を返り値として返します。オプション引数 flags (デフォルト:0) の意味については、 Unix マニュアルページ recv(2) を参照してください。
socket.send(bytes[, flags])
ソケットにデータを送信します。ソケットはリモートソケットに接続済みでなければなりません。オプション引数 flags の意味は、上記 recv() と同じです。戻り値として、送信したバイト数を返します。アプリケーションでは、必ず戻り値をチェックし、全てのデータが送られた事を確認する必要があります。データの一部だけが送信された場合、アプリケーションで残りのデータを再送信してください。 ソケットプログラミング HOWTO に、さらに詳しい情報があります。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.sendall(bytes[, flags])
ソケットにデータを送信します。ソケットはリモートソケットに接続済みでなければなりません。オプション引数 flags の意味は、上記 recv() と同じです。 send() と異なり、このメソッドは bytes の全データを送信するか、エラーが発生するまで処理を継続します。正常終了の場合は None を返し、エラー発生時には例外が発生します。エラー発生時、送信されたバイト数を調べる事はできません。
バージョン 3.5 で変更: ソケットのタイムアウトは、データが正常に送信される度にリセットされなくなりました。ソケットのタイムアウトは、すべてのデータを送る最大の合計時間となります。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.sendto(bytes, address)
socket.sendto(bytes, flags, address)
ソケットにデータを送信します。このメソッドでは接続先を address で指定するので、接続済みではいけません。オプション引数 flags の意味は、上記 recv() と同じです。戻り値として、送信したバイト数を返します。(address のフォーマットはアドレスファミリによって異なります --- 前述。)
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.sendmsg(buffers[, ancdata[, flags[, address]]])
非付属的なデータを一連のバッファから集め、単一のメッセージにまとめることで、通常のデータと付属的なデータをソケットに送信します。buffers 引数は、非付属的なデータを bytes-like objects (例: bytes オブジェクト) のイテラブルとして指定します。オペレーティングシステムによって、使用できるバッファの数が制限 (sysconf() 値 SC_IOV_MAX) されている場合があります。ancdata 引数は付属的なデータ (制御メッセージ) をゼロ以上のタプル (cmsg_level, cmsg_type, cmsg_data) のイテラブルとして指定します。ここで、cmsg_level と cmsg_type はそれぞれプロトコルレベルとプロトコル固有のタイプを指定する整数で、cmsg_data は関連データを保持するバイトライクオブジェクトです。一部のシステム (特に CMSG_SPACE() を持たないシステム) では、一度の呼び出しで一つの制御メッセージの送信しかサポートされていない場合があります。flags 引数のデフォルトは 0 であり、send() での意味と同じ意味を持ちます。None 以外の address が渡された場合、メッセージの目的地のアドレスを設定します。戻り値は、送信された非付属的データのバイト数です。
以下の関数は、SCM_RIGHTS メカニズムをサポートするシステムで、ファイル記述子 fds を AF_UNIX ソケット経由で送信します。recvmsg() も参照してください。
import socket, array
def send_fds(sock, msg, fds):
    return sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, array.array("i", fds))])
バージョン 3.3 で追加.
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、このメソッドは InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
socket.sendmsg_afalg([msg, ]*, op[, iv[, assoclen[, flags]]])
sendmsg() の AF_ALG ソケット用に特化したバージョンです。AF_ALG ソケットの、モード、IV、AEAD に関連づけられたデータ長、フラグを設定します。
バージョン 3.6 で追加.
socket.send_fds(sock, buffers, fds[, flags[, address]])
バージョン 3.9 で追加.
socket.recv_fds(sock, bufsize, maxfds[, flags])
バージョン 3.9 で追加.
注釈 Any truncated integers at the end of the list of file descriptors.
socket.sendfile(file, offset=0, count=None)
高性能の os.sendfile を使用して、ファイルを EOF まで送信し、送信されたバイトの総数を返します。file は、バイナリモードで開かれた標準的なファイルオブジェクトです。os.sendfile が使用できない場合 (例: Windows)、または file が標準的なファイルでない場合、代わりに send() が使用されます。offset は、ファイルの読み出し開始位置を指定します。count が指定されている場合、ファイルを EOF まで送信するのではなく、転送するバイトの総数を指定します。ファイルの位置は、返る時に更新されます。あるいは、エラー時には file.tell()  を使用して送信されたバイトの数を確認することができます。ソケットは SOCK_STREAM タイプでなければなりません。非ブロックソケットはサポートされていません。
バージョン 3.5 で追加.
socket.set_inheritable(inheritable)
ソケットのファイル記述子、またはソケットのハンドルの、 継承可能フラグ を立てます。
バージョン 3.4 で追加.
socket.setblocking(flag)
ソケットをブロッキングモード、または非ブロッキングモードに設定します。flag が False の場合にはソケットは非ブロッキングモードになり、True の場合にはブロッキングモードになります。
このメソッドは、次の settimeout() 呼び出しの省略表記です:
sock.setblocking(True) は sock.settimeout(None) と等価です
sock.setblocking(False) は sock.settimeout(0.0) と等価です
バージョン 3.7 で変更: The method no longer applies SOCK_NONBLOCK flag on socket.type.
socket.settimeout(value)
ブロッキングソケットの処理のタイムアウト値を指定します。 value には float 型で非負の秒数を指定するか、 None を指定します。ゼロ以外の値を指定した場合、ソケットの処理が完了する前に value で指定した秒数が経過すれば timeout 例外を送出します。ゼロを指定した場合、ソケットは非ブロッキングモード状態に置かれます。 None を指定した場合、ソケットのタイムアウトを無効にします。
詳しくは ソケットタイムアウトの注意事項 を参照してください。
バージョン 3.7 で変更: The method no longer toggles SOCK_NONBLOCK flag on socket.type.
socket.setsockopt(level, optname, value: int)
socket.setsockopt(level, optname, value: buffer)
socket.setsockopt(level, optname, None, optlen: int)
指定されたソケットオプションの値を設定します (Unix のマニュアルページ setsockopt(2) を参照)。必要なシンボリック定数は、socket モジュール (SO_* など) で定義されています。この値は、整数、None、またはバッファを表す bytes-like object のいずれかです。バイトライクオブジェクトの場合、バイト文字列に適切なビットが含まれていることを確認するのは呼び出し元の仕事です (C 構造をバイト文字列としてエンコードする方法については、オプションの組み込みモジュール struct を参照)。値が None に設定されている場合、optlen 引数が必須です。これは、 optval=NULL と optlen=optlen で setsockopt() C 関数を呼び出すのと同一です。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
バージョン 3.6 で変更: setsockopt(level, optname, None, optlen: int) の形式が追加されました。
socket.shutdown(how)
接続の片方向、または両方向を切断します。 how が SHUT_RD の場合、以降は受信を行えません。 how が SHUT_WR の場合、以降は送信を行えません。 how が SHUT_RDWR の場合、以降は送受信を行えません。
socket.share(process_id)
ソケットを複製し、対象のプロセスと共有するための bytes オブジェクトを返します。対象のプロセスを process_id で指定しなければなりません。戻り値の bytes オブジェクトは、何らかのプロセス間通信を使って対象のプロセスに伝えます。対象のプロセス側では、 fromshare() を使って複製されたソケットをとらえます。オペレーティング・システムは対象のプロセスに対してソケットを複製するため、このメソッドを呼び出した後であれば、元のソケットをクローズしても、対象のプロセスに渡ったソケットには影響がありません。
利用可能な環境: Windows 。
バージョン 3.3 で追加.
read() メソッドと write() メソッドは存在しませんので注意してください。代わりに flags を省略した recv() と send() を使うことができます。
ソケットオブジェクトには以下の socket コンストラクタに渡された値に対応した (読み出し専用) 属性があります。
socket.family
ソケットファミリー。
socket.type
ソケットタイプ。
socket.proto
ソケットプロトコル。
ソケットタイムアウトの注意事項
ソケットオブジェクトは、ブロッキングモード、非ブロッキングモード、タイムアウトモードのうち、いずれか1つのモードをとります。デフォルトでは、ソケットは常にブロッキングモードで作成されますが、 setdefaulttimeout() で標準のモードを変更することができます。
ブロッキングモード での操作は、完了するか、または（接続がタイムアウトするなどして）システムがエラーを返すまで、ブロックされます。
非ブロッキングモード での操作は、ただちに完了できない場合、例外を送出して失敗します。この場合の例外の種類は、システムに依存するため、ここに記すことができません。 select モジュールの関数を使って、ソケットの読み書きが利用可能かどうか、可能な場合はいつ利用できるかを調べることができます。
タイムアウトモード での操作は、指定されたタイムアウトの時間内に完了しなければ、 timeout 例外を送出します。タイムアウトの時間内にシステムがエラーを返した場合は、そのエラーを返します。
注釈 オペレーティング・システムのレベルでは、 タイムアウトモード のソケットには、内部的に非ブロッキングモードが設定されています。またブロッキングモードとタイムアウトモードの指定は、ファイル記述子と、「そのファイル記述子と同じネットワーク端点を参照するソケットオブジェクト」との間で共有されます。このことは、例えばソケットの fileno() を使うことにした場合に、明らかな影響を与えます。
タイムアウトと connect メソッド
connect() もタイムアウト設定に従います。一般的に、 settimeout() を connect() の前に呼ぶか、 create_connection() にタイムアウト引数を渡すことが推奨されます。ただし、システムのネットワークスタックが Python のソケットタイムアウトの設定を無視して、自身の接続タイムアウトエラーを返すこともあります。
タイムアウトと accept メソッド
getdefaulttimeout() が None でない場合、 accept() メソッドが返すソケットでは、そのタイムアウトが継承されます。 None である場合、待機中のソケットの設定によって動作は異なります。
待機中のソケットが ブロッキングモード または タイムアウトモード である場合、accept() が返すソケットは、ブロッキングモード になります。
待機中のソケットが 非ブロッキングモード である場合、accept() が返すソケットは、オペレーティングシステムによってブロッキングモードまたは非ブロッキングモードになります。クロスプラットフォームの動作を確保したい場合、この設定を手動でオーバーライドすることをお勧めします。
使用例
以下は TCP/IP プロトコルの簡単なサンプルとして、受信したデータをクライアントにそのまま返送するサーバ (接続可能なクライアントは一件のみ) と、サーバに接続するクライアントの例を示します。サーバでは、 socket() ・ bind() ・ listen() ・ accept() を実行し (複数のクライアントからの接続を受け付ける場合、 accept() を複数回呼び出します)、クライアントでは socket() と connect() だけを呼び出しています。サーバでは sendall() / recv() メソッドは listen 中のソケットで実行するのではなく、 accept() で取得したソケットに対して実行している点にも注意してください。
次のクライアントとサーバは、IPv4 のみをサポートしています。
# Echo server program
import socket
HOST = ''                 # Symbolic name meaning all available interfaces
PORT = 50007              # Arbitrary non-privileged port
with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
    s.bind((HOST, PORT))
    s.listen(1)
    conn, addr = s.accept()
    with conn:
        print('Connected by', addr)
        while True:
            data = conn.recv(1024)
            if not data: break
            conn.sendall(data)
# Echo client program
import socket
HOST = 'daring.cwi.nl'    # The remote host
PORT = 50007              # The same port as used by the server
with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
    s.connect((HOST, PORT))
    s.sendall(b'Hello, world')
    data = s.recv(1024)
print('Received', repr(data))
次のサンプルは上記のサンプルとほとんど同じですが、IPv4 と IPv6 の両方をサポートしています。サーバでは、IPv4/v6 の両方ではなく、利用可能な最初のアドレスファミリだけを listen しています。ほとんどの IPv6 対応システムでは IPv6 が先に現れるため、サーバは IPv4 には応答しません。クライアントでは名前解決の結果として取得したアドレスに順次接続を試み、最初に接続に成功したソケットにデータを送信しています。
# Echo server program
import socket
import sys
HOST = None               # Symbolic name meaning all available interfaces
PORT = 50007              # Arbitrary non-privileged port
s = None
for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC,
                              socket.SOCK_STREAM, 0, socket.AI_PASSIVE):
    af, socktype, proto, canonname, sa = res
    try:
        s = socket.socket(af, socktype, proto)
    except OSError as msg:
        s = None
        continue
    try:
        s.bind(sa)
        s.listen(1)
    except OSError as msg:
        s.close()
        s = None
        continue
    break
if s is None:
    print('could not open socket')
    sys.exit(1)
conn, addr = s.accept()
with conn:
    print('Connected by', addr)
    while True:
        data = conn.recv(1024)
        if not data: break
        conn.send(data)
# Echo client program
import socket
import sys
HOST = 'daring.cwi.nl'    # The remote host
PORT = 50007              # The same port as used by the server
s = None
for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC, socket.SOCK_STREAM):
    af, socktype, proto, canonname, sa = res
    try:
        s = socket.socket(af, socktype, proto)
    except OSError as msg:
        s = None
        continue
    try:
        s.connect(sa)
    except OSError as msg:
        s.close()
        s = None
        continue
    break
if s is None:
    print('could not open socket')
    sys.exit(1)
with s:
    s.sendall(b'Hello, world')
    data = s.recv(1024)
print('Received', repr(data))
次の例は、Windowsで raw socket を利用して非常にシンプルなネットワークスニファーを書きます。このサンプルを実行するには、インタフェースを操作するための管理者権限が必要です:
import socket
# the public network interface
HOST = socket.gethostbyname(socket.gethostname())
# create a raw socket and bind it to the public interface
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
s.bind((HOST, 0))
# Include IP headers
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
# receive all packages
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
# receive a package
print(s.recvfrom(65565))
# disabled promiscuous mode
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
The next example shows how to use the socket interface to communicate to a CAN network using the raw socket protocol. To use CAN with the broadcast manager protocol instead, open a socket with:
socket.socket(socket.AF_CAN, socket.SOCK_DGRAM, socket.CAN_BCM)
ソケットの束縛 (CAN_RAW) または (CAN_BCM) 接続を行ったあと、ソケットオブジェクトで socket.send() と socket.recv() 操作 (とそのカウンターパート) を通常通りに使用することができます。
This last example might require special privileges:
import socket
import struct
# CAN frame packing/unpacking (see 'struct can_frame' in <linux/can.h>)
can_frame_fmt = "=IB3x8s"
can_frame_size = struct.calcsize(can_frame_fmt)
def build_can_frame(can_id, data):
    can_dlc = len(data)
    data = data.ljust(8, b'\x00')
    return struct.pack(can_frame_fmt, can_id, can_dlc, data)
def dissect_can_frame(frame):
    can_id, can_dlc, data = struct.unpack(can_frame_fmt, frame)
    return (can_id, can_dlc, data[:can_dlc])
# create a raw socket and bind it to the 'vcan0' interface
s = socket.socket(socket.AF_CAN, socket.SOCK_RAW, socket.CAN_RAW)
s.bind(('vcan0',))
while True:
    cf, addr = s.recvfrom(can_frame_size)
    print('Received: can_id=%x, can_dlc=%x, data=%s' % dissect_can_frame(cf))
    try:
        s.send(cf)
    except OSError:
        print('Error sending CAN frame')
    try:
        s.send(build_can_frame(0x01, b'\x01\x02\x03'))
    except OSError:
        print('Error sending CAN frame')
この例を、ほとんど間を空けずに複数回実行すると、以下のエラーが発生する場合があります:
OSError: [Errno 98] Address already in use
これは以前の実行がソケットを TIME_WAIT 状態のままにし、すぐには再利用できないことで起こります。
これを防ぐのに、 socket フラグの socket.SO_REUSEADDR があります:
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
s.bind((HOST, PORT))
SO_REUSEADDR フラグは、 TIME_WAIT 状態にあるローカルソケットをそのタイムアウト期限が自然に切れるのを待つことなく再利用することをカーネルに伝えます。
参考 C 言語によるソケットプログラミングの基礎については、以下の資料を参照してください。
An Introductory 4.3BSD Interprocess Communication Tutorial, by Stuart Sechrest
An Advanced 4.3BSD Interprocess Communication Tutorial, by Samuel J. Leffler et al,
両書とも UNIX Programmer's Manual, Supplementary Documents 1 (PS1:7章 PS1:8章)。ソケットの詳細については、各プラットフォームのソケット関連システムコールに関するドキュメントも参照してください。Unix ではマニュアルページ、WindowsではWinSock (または WinSock2) 仕様書をご覧ください。IPv6 対応の API については、 RFC 3493 "Basic Socket Interface Extensions for IPv6" を参照してください。
ssl --- ソケットオブジェクトに対する TLS/SSL ラッパー
Source code: Lib/ssl.py
このモジュールは Transport Layer Security ( "Secure Sockets Layer" という名前でよく知られています) 暗号化と、クライアントサイド、サーバサイド両方のネットワークソケットのためのピア認証の仕組みを提供しています。このモジュールは OpenSSL ライブラリを利用しています。 OpenSSL は、すべてのモダンな Unix システム、 Windows 、 Mac OS X 、その他幾つかの OpenSSL がインストールされているプラットフォームで利用できます。
注釈 OSのソケットAPIに対して実装されているので、幾つかの挙動はプラットフォーム依存になるかもしれません。インストールされているOpenSSLのバージョンの違いも挙動の違いの原因になるかもしれません。例えば、TLSv1.1, TLSv1.2 は openssl version 1.0.1 以降でのみ利用できます。
警告 セキュリティで考慮すべき点 を読まずにこのモジュールを使用しないでください。SSL のデフォルト設定はアプリケーションに十分ではないので、読まない場合はセキュリティに誤った意識を持ってしまうかもしれません。
このセクションでは、 ssl モジュールのオブジェクトと関数を解説します。 TLS, SSL, 証明書に関するより一般的な情報は、末尾にある "See Also" のセクションを参照してください。
このモジュールは ssl.SSLSocket クラスを提供します。このクラスは socket.socket 型を継承していて、ソケットで通信されるデータをSSLで暗号化・復号するソケットに似たラッパーになります。また、このクラスは、接続の相手側からの証明書を取得する getpeercert() メソッドや、セキュア接続で使うための暗号方式を取得する cipher() メソッドのような追加のメソッドをサポートしています。
より洗練されたアプリケーションのために、 ssl.SSLContext クラスが設定と証明書の管理の助けとなるでしょう。それは SSLContext.wrap_socket() メソッドを通して SSL ソケットを作成することで引き継がれます。
バージョン 3.5.3 で変更: Updated to support linking with OpenSSL 1.1.0
バージョン 3.6 で変更: OpenSSL 0.9.8, 1.0.0, 1.0.1 は廃止されており、もはやサポートされていません。ssl モジュールは、将来的に OpenSSL 1.0.2 または 1.1.0 を必要とするようになります。
関数、定数、例外
ソケットの作成
Client socket example with default context and IPv4/IPv6 dual stack:
import socket
import ssl
hostname = 'www.python.org'
context = ssl.create_default_context()
with socket.create_connection((hostname, 443)) as sock:
    with context.wrap_socket(sock, server_hostname=hostname) as ssock:
        print(ssock.version())
Client socket example with custom context and IPv4:
hostname = 'www.python.org'
# PROTOCOL_TLS_CLIENT requires valid cert chain and hostname
context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
context.load_verify_locations('path/to/cabundle.pem')
with socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0) as sock:
    with context.wrap_socket(sock, server_hostname=hostname) as ssock:
        print(ssock.version())
Server socket example listening on localhost IPv4:
context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)
context.load_cert_chain('/path/to/certchain.pem', '/path/to/private.key')
with socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0) as sock:
    sock.bind(('127.0.0.1', 8443))
    sock.listen(5)
    with context.wrap_socket(sock, server_side=True) as ssock:
        conn, addr = ssock.accept()
        ...
コンテキストの作成
コンビニエンス関数が、共通の目的で使用される SSLContext オブジェクトを作成するのに役立ちます。
ssl.create_default_context(purpose=Purpose.SERVER_AUTH, cafile=None, capath=None, cadata=None)
新規の SSLContext オブジェクトを、与えられた purpose のデフォルト設定で返します。設定は ssl モジュールで選択され、通常は SSLContext のコンストラクタを直接呼び出すよりも高いセキュリティレベルを表現します。
cafile, capath, cadata は証明書の検証で信用するオプションの CA 証明書で、 SSLContext.load_verify_locations() のものと同じです。これら 3 つすべてが None であれば、この関数は代わりにシステムのデフォルトの CA 証明書を信用して選択することができます。
設定は、 PROTOCOL_TLS, OP_NO_SSLv2, RC4 と非認証暗号化スイート以外の、高度暗号化スイートを利用した OP_NO_SSLv3 です。SERVER_AUTH を purpose として渡すと、verify_mode を CERT_REQUIRED に設定し、 CA 証明書をロードする (cafile, capath, cadata の少なくとも1つが与えられている場合) か、SSLContext.load_default_certs() を使用してデフォルトの CA 証明書をロードします。
注釈 プロトコル、オプション、暗号方式その他の設定は、事前に非推奨の状態にすることなく、もっと制限の強い値に変更される場合があります。これらの値は、互換性と安全性との妥当なバランスをとって決められます。
もしもあなたのアプリケーションが特定の設定を必要とする場合、 SSLContext を作って自分自身で設定を適用すべきです。
注釈 ある種の古いクライアントやサーバが接続しようと試みてきた場合に、この関数で作られた SSLContext が "Protocol or cipher suite mismatch" で始まるエラーを起こすのを目撃したらそれは、この関数が OP_NO_SSLv3 を使って除外している SSL 3.0 しかサポートしていないのでしょう。SSL 3.0 は 完璧にぶっ壊れている ことが広く知られています。それでもまだこの関数を使って、ただし SSL 3.0 接続を許可したいと望むならば、これをこのように再有効化できます:
ctx = ssl.create_default_context(Purpose.CLIENT_AUTH)
ctx.options &= ~ssl.OP_NO_SSLv3
バージョン 3.4 で追加.
バージョン 3.4.4 で変更: デフォルトの暗号設定から RC4 が除かれました。
バージョン 3.6 で変更: デフォルトの暗号化文字列に ChaCha20/Poly1305 が追加されました。
デフォルトの暗号化文字列から 3DES が除かれました。
バージョン 3.8 で変更: Support for key logging to SSLKEYLOGFILE was added.
例外
exception ssl.SSLError
(現在のところ OpenSSL ライブラリによって提供されている)下層の SSL 実装からのエラーを伝えるための例外です。このエラーは、低レベルなネットワークの上に載っている、高レベルな暗号化と認証レイヤーでの問題を通知します。このエラーは OSError のサブタイプです。 SSLError インスタンスのエラーコードとメッセージは OpenSSL ライブラリによるものです。
バージョン 3.3 で変更: SSLError は以前は socket.error のサブタイプでした。
library
エラーが起こった OpenSSL サブモジュールを示すニーモニック文字列で、 SSL, PEM, X509 などです。取り得る値は OpenSSL のバージョンに依存します。
バージョン 3.3 で追加.
reason
エラーが起こった原因を示すニーモニック文字列で、 CERTIFICATE_VERIFY_FAILED などです。取り得る値は OpenSSL のバージョンに依存します。
バージョン 3.3 で追加.
exception ssl.SSLZeroReturnError
読み出しあるいは書き込みを試みようとした際に SSL コネクションが行儀よく閉じられてしまった場合に送出される SSLError サブクラス例外です。これは下層の転送(read TCP)が閉じたことは意味しないことに注意してください。
バージョン 3.3 で追加.
exception ssl.SSLWantReadError
読み出しあるいは書き込みを試みようとした際に、リクエストが遂行される前に下層の TCP 転送で受け取る必要があるデータが不足した場合に non-blocking SSL socket によって送出される SSLError サブクラス例外です。
バージョン 3.3 で追加.
exception ssl.SSLWantWriteError
読み出しあるいは書き込みを試みようとした際に、リクエストが遂行される前に下層の TCP 転送が送信する必要があるデータが不足した場合に non-blocking SSL socket によって送出される SSLError サブクラス例外です。
バージョン 3.3 で追加.
exception ssl.SSLSyscallError
SSL ソケット上で操作を遂行しようとしていてシステムエラーが起こった場合に送出される SSLError サブクラス例外です。残念ながら元となった errno 番号を調べる簡単な方法はありません。
バージョン 3.3 で追加.
exception ssl.SSLEOFError
SSL コネクションが唐突に打ち切られた際に送出される SSLError サブクラス例外です。一般的に、このエラーが起こったら下層の転送を再利用しようと試みるべきではありません。
バージョン 3.3 で追加.
exception ssl.SSLCertVerificationError
バージョン 3.7 で追加.
verify_code
verify_message
exception ssl.CertificateError
バージョン 3.7 で変更: The exception is now an alias for SSLCertVerificationError.
乱数生成
ssl.RAND_bytes(num)
暗号学的に強固な擬似乱数の num バイトを返します。擬似乱数生成器に十分なデータでシードが与えられていない場合や、現在の RANDOM メソッドに操作がサポートされていない場合は SSLError を送出します。 RAND_status() を使って擬似乱数生成器の状態をチェックできます。 RAND_add() を使って擬似乱数生成器にシードを与えることができます。
ほとんどすべてのアプリケーションでは os.urandom() が望ましいです。
バージョン 3.3 で追加.
ssl.RAND_pseudo_bytes(num)
(bytes, is_cryptographic) タプルを返却: bytes は長さ num の擬似乱数バイト列、 is_cryptographic は、生成されたバイト列が暗号として強ければ True 。 操作が現在使われている RAND メソッドでサポートされていなければ、 SSLError が送出されます。
生成される擬似乱数バイトシーケンスは十分な長さであれば一意にはなるでしょうが、必ずしも予測不可能とは言えません。これは非暗号目的、あるいは暗号化プロトコルでの若干の用途に使われますが、普通は鍵生成などには使いません。
ほとんどすべてのアプリケーションでは os.urandom() が望ましいです。
バージョン 3.3 で追加.
バージョン 3.6 で非推奨: OpenSSL は ssl.RAND_pseudo_bytes() を廃止しました。代わりに ssl.RAND_bytes() を使用してください。
ssl.RAND_status()
SSL 擬似乱数生成器が十分なランダム性(randomness)を受け取っている時に True を、それ以外の場合は False を返します。 ssl.RAND_egd() と ssl.RAND_add() を使って擬似乱数生成機にランダム性を加えることができます。
ssl.RAND_egd(path)
もしエントロピー収集デーモン(EGD=entropy-gathering daemon)が動いていて、 path がEGDへのソケットのパスだった場合、この関数はそのソケットから 256バイトのランダム性を読み込み、SSL擬似乱数生成器にそれを渡すことで、生成される暗号鍵のセキュリティを向上させることができます。これは、より良いランダム性のソースが無いシステムでのみ必要です。
エントロピー収集デーモンについては、 http://egd.sourceforge.net/ や http://prngd.sourceforge.net/ を参照してください。
ssl.RAND_add(bytes, entropy)
与えられた bytes をSSL擬似乱数生成器に混ぜます。 entropy 引数(float値)は、その文字列に含まれるエントロピーの下限(lower bound)です。 (なので、いつでも 0.0 を使うことができます。) エントロピーのソースについてのより詳しい情報は、 RFC 1750 を参照してください。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
証明書の取り扱い
ssl.match_hostname(cert, hostname)
失敗すれば CertificateError が送出されます。成功すれば、この関数は何も返しません:
>>>
>>> cert = {'subject': ((('commonName', 'example.com'),),)}
>>> ssl.match_hostname(cert, "example.com")
>>> ssl.match_hostname(cert, "example.org")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/home/py3k/Lib/ssl.py", line 130, in match_hostname
ssl.CertificateError: hostname 'example.org' doesn't match 'example.com'
バージョン 3.2 で追加.
バージョン 3.3.3 で変更: この関数は RFC 6125 の section 6.4.3 に従うようになりましたので、マルチプルワイルドカード(例. *.*.com や *a*.example.org) にも国際化ドメイン名 (IDN=internationalized domain name)フラグメント内部に含まれるワイルドカードのどちらにも合致しません。 www*.xn--pthon-kva.org のような IDN A-labels はまだサポートしますが、 x*.python.org はもはや xn--tda.python.org には合致しません。
バージョン 3.5 で変更: 認定書の subjectAltName フィールドで提示されている場合、IP アドレスの一致がサポートされるようになりました。
バージョン 3.7 で変更: The function is no longer used to TLS connections. Hostname matching is now performed by OpenSSL.
バージョン 3.7 で非推奨.
ssl.cert_time_to_seconds(cert_time)
cert_time として証明書内の "notBefore" や "notAfter" の "%b %d %H:%M:%S %Y %Z" strptime フォーマット (C locale) 日付を渡すと、エポックからの積算秒を返します。
例です。 :
>>> import ssl
>>> timestamp = ssl.cert_time_to_seconds("Jan  5 09:34:43 2018 GMT")
>>> timestamp  
1515144883
>>> from datetime import datetime
>>> print(datetime.utcfromtimestamp(timestamp))  
2018-01-05 09:34:43
"notBefore" や "notAfter" の日付には GMT を使わなければなりません(RFC 5280)。
バージョン 3.5 で変更: 入力文字列に指定された 'GMT' タイムゾーンを UTC として解釈するようになりました。以前はローカルタイムで解釈していました。また、整数を返すようになりました(入力に含まれる秒の端数を含まない)。
ssl.get_server_certificate(addr, ssl_version=PROTOCOL_TLS, ca_certs=None)
バージョン 3.3 で変更: この関数はIPv6互換になりました。
バージョン 3.5 で変更: ssl_version のデフォルトが、最近のサーバへの最大限の互換性のために PROTOCOL_SSLv3 から PROTOCOL_TLS に変更されました。
ssl.DER_cert_to_PEM_cert(DER_cert_bytes)
DERエンコードされたバイト列として与えられた証明書から、 PEMエンコードされたバージョンの同じ証明書を返します。
ssl.PEM_cert_to_DER_cert(PEM_cert_string)
PEM 形式のASCII文字列として与えられた証明書から、同じ証明書をDERエンコードしたバイト列を返します。
ssl.get_default_verify_paths()
OpenSSL デフォルトの cafile, capath を指すパスを名前付きタプルで返します。パスは SSLContext.set_default_verify_paths() で使われるものと同じです。戻り値は named tuple DefaultVerifyPaths です:
cafile - cafile の解決済みパス、またはファイルが存在しない場合は None
capath - capath の解決済みパス、またはディレクトリが存在しない場合は None
openssl_cafile_env - cafile を指す OpenSSL の環境変数
openssl_cafile - OpenSSL にハードコードされた cafile のパス
openssl_capath_env - capath を指す OpenSSL の環境変数
openssl_capath - OpenSSL にハードコードされた capath のパス
バージョン 3.4 で追加.
ssl.enum_certificates(store_name)
Windows のシステム証明書ストアより証明書を抽出します。 store_name は CA, ROOT, MY のうちどれか一つでしょう。Windows は追加の証明書ストアを提供しているかもしれません。
この関数はタプル (cert_bytes, encoding_type, trust) のリストで返します。encoding_type は cert_bytes のエンコーディングを表します。X.509 ASN.1 に対する x509_asn か PKCS#7 ASN.1 データに対する pkcs_7_asn のいずれかです。trust は、証明書の目的を、OIDS を内容に持つ set として表すか、または証明書がすべての目的で信頼できるならば True です。
以下はプログラム例です:
>>>
>>> ssl.enum_certificates("CA")
[(b'data...', 'x509_asn', {'1.3.6.1.5.5.7.3.1', '1.3.6.1.5.5.7.3.2'}),
 (b'data...', 'x509_asn', True)]
利用可能な環境: Windows 。
バージョン 3.4 で追加.
ssl.enum_crls(store_name)
Windows のシステム証明書ストアより CRLs を抽出します。 store_name は CA, ROOT, MY のうちどれか一つでしょう。Windows は追加の証明書ストアを提供しているかもしれません。
この関数はタプル (cert_bytes, encoding_type, trust) のリストで返します。encoding_type は cert_bytes のエンコーディングを表します。X.509 ASN.1 に対する x509_asn か PKCS#7 ASN.1 データに対する pkcs_7_asn のいずれかです。
利用可能な環境: Windows 。
バージョン 3.4 で追加.
ssl.wrap_socket(sock, keyfile=None, certfile=None, server_side=False, cert_reqs=CERT_NONE, ssl_version=PROTOCOL_TLS, ca_certs=None, do_handshake_on_connect=True, suppress_ragged_eofs=True, ciphers=None)
socket.socket のインスタンス sock を受け取り、 socket.socket のサブタイプである ssl.SSLSocket のインスタンスを返します。 ssl.SSLSocket は低レイヤのソケットをSSLコンテキストでラップします。 sock は SOCK_STREAM ソケットでなければなりません; ほかのタイプのソケットはサポートされていません。
バージョン 3.7 で非推奨: Since Python 3.2 and 2.7.9, it is recommended to use the SSLContext.wrap_socket() instead of wrap_socket(). The top-level function is limited and creates an insecure client socket without server name indication or hostname matching.
定数
すべての定数が enum.IntEnum コレクションまたは enum.IntFlag コレクションになりました。
バージョン 3.6 で追加.
ssl.CERT_NONE
このドキュメントの下の方の、 セキュリティで考慮すべき点 に関する議論を参照してください。
ssl.CERT_OPTIONAL
この設定では、正当なCA証明書のセットを SSLContext.load_verify_locations() または wrap_socket() の ca_certs パラメータのどちらかに渡す必要があります。
ssl.CERT_REQUIRED
この設定では、正当なCA証明書のセットを SSLContext.load_verify_locations() または wrap_socket() の ca_certs パラメータのどちらかに渡す必要があります。
class ssl.VerifyMode
CERT_* 定数の enum.IntEnum コレクションです。
バージョン 3.6 で追加.
ssl.VERIFY_DEFAULT
SSLContext.verify_flags に渡せる値です。このモードでは、証明書失効リスト(CRLs)はチェックされません。デフォルトでは OpenSSL は CRLs を必要ともしませんし検証にも使いません。
バージョン 3.4 で追加.
ssl.VERIFY_CRL_CHECK_LEAF
バージョン 3.4 で追加.
ssl.VERIFY_CRL_CHECK_CHAIN
SSLContext.verify_flags に渡せる値です。このモードでは、接続先の証明書チェイン内のすべての証明書についての CRLs がチェックされます。
バージョン 3.4 で追加.
ssl.VERIFY_X509_STRICT
SSLContext.verify_flags に渡せる値で、壊れた X.509 証明書に対するワークアラウンドを無効にします。
バージョン 3.4 で追加.
ssl.VERIFY_X509_TRUSTED_FIRST
SSLContext.verify_flags に渡せる値です。OpenSSL に対し、証明書検証のために信頼チェインを構築する際、信頼できる証明書を選ぶように指示します。これはデフォルトで有効にされています。
バージョン 3.4.4 で追加.
class ssl.VerifyFlags
VERIFY_* 定数の enum.IntFlag コレクションです。
バージョン 3.6 で追加.
ssl.PROTOCOL_TLS
バージョン 3.6 で追加.
ssl.PROTOCOL_TLS_CLIENT
バージョン 3.6 で追加.
ssl.PROTOCOL_TLS_SERVER
バージョン 3.6 で追加.
ssl.PROTOCOL_SSLv23
バージョン 3.6 で非推奨: 代わりに PROTOCOL_TLS を使用してください。
ssl.PROTOCOL_SSLv2
チャンネル暗号化プロトコルとして SSL バージョン2を選択します。
このプロトコルは、 OpenSSL が OPENSSL_NO_SSL2 フラグが有効な状態でコンパイルされている場合には利用できません。
警告 SSL version 2 は非セキュアです。このプロトコルは強く非推奨です。
バージョン 3.6 で非推奨: OpenSSL は SSLv2 へのサポートを打切りました。
ssl.PROTOCOL_SSLv3
チャンネル暗号化プロトコルとしてSSLバージョン3を選択します。
このプロトコルは、 OpenSSL が OPENSSL_NO_SSLv3 フラグが有効な状態でコンパイルされている場合には利用できません。
警告 SSL version 3 は非セキュアです。このプロトコルは強く非推奨です。
バージョン 3.6 で非推奨: OpenSSL は全てのバージョン固有のプロトコルを廃止しました。デフォルトプロトコルの PROTOCOL_TLS に OP_NO_SSLv3 などのフラグをつけて使用してください。
ssl.PROTOCOL_TLSv1
チャンネル暗号化プロトコルとしてTLSバージョン1.0を選択します。
バージョン 3.6 で非推奨: OpenSSL は全てのバージョン固有のプロトコルを廃止しました。デフォルトプロトコルの PROTOCOL_TLS に OP_NO_SSLv3 などのフラグをつけて使用してください。
ssl.PROTOCOL_TLSv1_1
チャンネル暗号化プロトコルとしてTLSバージョン1.1を選択します。 openssl version 1.0.1+ のみで利用可能です。
バージョン 3.4 で追加.
バージョン 3.6 で非推奨: OpenSSL は全てのバージョン固有のプロトコルを廃止しました。デフォルトプロトコルの PROTOCOL_TLS に OP_NO_SSLv3 などのフラグをつけて使用してください。
ssl.PROTOCOL_TLSv1_2
チャンネル暗号化プロトコルとしてTLSバージョン1.2を選択します。これは最も現代的で、接続の両サイドが利用できる場合は、たぶん最も安全な選択肢です。 openssl version 1.0.1+ のみで利用可能です。
バージョン 3.4 で追加.
バージョン 3.6 で非推奨: OpenSSL は全てのバージョン固有のプロトコルを廃止しました。デフォルトプロトコルの PROTOCOL_TLS に OP_NO_SSLv3 などのフラグをつけて使用してください。
ssl.OP_ALL
相手にする SSL 実装のさまざまなバグを回避するためのワークアラウンドを有効にします。このオプションはデフォルトで有効です。これを有効にする場合 OpenSSL 用の同じ意味のフラグ SSL_OP_ALL をセットする必要はありません。
バージョン 3.2 で追加.
ssl.OP_NO_SSLv2
SSLv2 接続が行われないようにします。このオプションは PROTOCOL_TLS と組み合わされている場合にのみ適用されます。ピアがプロトコルバージョンとして SSLv2 を選択しないようにします。
バージョン 3.2 で追加.
バージョン 3.6 で非推奨: SSLv2 は非推奨です
ssl.OP_NO_SSLv3
SSLv3 接続が行われないようにします。このオプションは PROTOCOL_TLS と組み合わされている場合にのみ適用されます。ピアがプロトコルバージョンとして SSLv3 を選択しないようにします。
バージョン 3.2 で追加.
バージョン 3.6 で非推奨: SSLv3 は非推奨です
ssl.OP_NO_TLSv1
TLSv1 接続が行われないようにします。このオプションは PROTOCOL_TLS と組み合わされている場合にのみ適用されます。ピアがプロトコルバージョンとして TLSv1 を選択しないようにします。
バージョン 3.2 で追加.
バージョン 3.7 で非推奨: The option is deprecated since OpenSSL 1.1.0, use the new SSLContext.minimum_version and SSLContext.maximum_version instead.
ssl.OP_NO_TLSv1_1
TLSv1.1 接続が行われないようにします。このオプションは PROTOCOL_TLS と組み合わされている場合にのみ適用されます。ピアがプロトコルバージョンとして TLSv1.1 を選択しないようにします。openssl バージョン 1.0.1 以降でのみ利用できます。
バージョン 3.4 で追加.
バージョン 3.7 で非推奨: The option is deprecated since OpenSSL 1.1.0.
ssl.OP_NO_TLSv1_2
TLSv1.2 接続が行われないようにします。このオプションは PROTOCOL_TLS と組み合わされている場合にのみ適用されます。ピアがプロトコルバージョンとして TLSv1.2 を選択しないようにします。openssl バージョン 1.0.1 以降でのみ利用できます。
バージョン 3.4 で追加.
バージョン 3.7 で非推奨: The option is deprecated since OpenSSL 1.1.0.
ssl.OP_NO_TLSv1_3
バージョン 3.7 で追加.
バージョン 3.7 で非推奨: The option is deprecated since OpenSSL 1.1.0. It was added to 2.7.15, 3.6.3 and 3.7.0 for backwards compatibility with OpenSSL 1.0.2.
ssl.OP_NO_RENEGOTIATION
バージョン 3.7 で追加.
ssl.OP_CIPHER_SERVER_PREFERENCE
暗号の優先順位として、クライアントのものではなくサーバのものを使います。このオプションはクライアントソケットと SSLv2 のサーバソケットでは効果はありません。
バージョン 3.3 で追加.
ssl.OP_SINGLE_DH_USE
SSL セッションを区別するのに同じ DH 鍵を再利用しないようにします。これはセキュリティを向上させますが、より多くの計算機リソースを必要とします。このオプションはサーバソケットに適用されます。
バージョン 3.3 で追加.
ssl.OP_SINGLE_ECDH_USE
SSL セッションを区別するのに同じ ECDH 鍵を再利用しないようにします。これはセキュリティを向上させますが、より多くの計算機リソースを必要とします。このオプションはサーバソケットに適用されます。
バージョン 3.3 で追加.
ssl.OP_ENABLE_MIDDLEBOX_COMPAT
バージョン 3.8 で追加.
ssl.OP_NO_COMPRESSION
SSL チャネルでの圧縮を無効にします。これはアプリケーションのプロトコルが自身の圧縮方法をサポートする場合に有用です。
このオプションは OpenSSL 1.0.0以降のみで使用できます。
バージョン 3.3 で追加.
class ssl.Options
OP_* 定数の enum.IntFlag コレクションです。
ssl.OP_NO_TICKET
クライアントサイドがセッションチケットをリクエストしないようにします。
バージョン 3.6 で追加.
ssl.HAS_ALPN
OpenSSL ライブラリが、組み込みで RFC 7301 で記述されている Application-Layer Protocol Negotiation TLS 拡張をサポートしているかどうか。
バージョン 3.5 で追加.
ssl.HAS_NEVER_CHECK_COMMON_NAME
バージョン 3.7 で追加.
ssl.HAS_ECDH
バージョン 3.3 で追加.
ssl.HAS_SNI
バージョン 3.2 で追加.
ssl.HAS_NPN
バージョン 3.3 で追加.
ssl.HAS_SSLv2
バージョン 3.7 で追加.
ssl.HAS_SSLv3
バージョン 3.7 で追加.
ssl.HAS_TLSv1
バージョン 3.7 で追加.
ssl.HAS_TLSv1_1
バージョン 3.7 で追加.
ssl.HAS_TLSv1_2
バージョン 3.7 で追加.
ssl.HAS_TLSv1_3
バージョン 3.7 で追加.
ssl.CHANNEL_BINDING_TYPES
サポートされている TLS のチャネルバインディングのタイプのリスト。リスト内の文字列は SSLSocket.get_channel_binding() の引数に渡せます。
バージョン 3.3 で追加.
ssl.OPENSSL_VERSION
インタプリタによってロードされた OpenSSL ライブラリのバージョン文字列:
>>>
>>> ssl.OPENSSL_VERSION
'OpenSSL 1.0.2k  26 Jan 2017'
バージョン 3.2 で追加.
ssl.OPENSSL_VERSION_INFO
OpenSSL ライブラリのバージョン情報を表す5つの整数のタプル:
>>>
>>> ssl.OPENSSL_VERSION_INFO
(1, 0, 2, 11, 15)
バージョン 3.2 で追加.
ssl.OPENSSL_VERSION_NUMBER
1つの整数の形式の、 OpenSSL ライブラリの生のバージョン番号:
>>>
>>> ssl.OPENSSL_VERSION_NUMBER
268443839
>>> hex(ssl.OPENSSL_VERSION_NUMBER)
'0x100020bf'
バージョン 3.2 で追加.
ssl.ALERT_DESCRIPTION_HANDSHAKE_FAILURE
ssl.ALERT_DESCRIPTION_INTERNAL_ERROR
ALERT_DESCRIPTION_*
RFC 5246 その他からのアラートの種類です。 IANA TLS Alert Registry にはこのリストとその意味が定義された RFC へのリファレンスが含まれています。
SSLContext.set_servername_callback() でのコールバック関数の戻り値として使われます。
バージョン 3.4 で追加.
class ssl.AlertDescription
ALERT_DESCRIPTION_* 定数の enum.IntEnum コレクションです。
バージョン 3.6 で追加.
Purpose.SERVER_AUTH
create_default_context() と SSLContext.load_default_certs() に渡すオプションです。この値はコンテキストが Web サーバの認証に使われることを示します (ですので、クライアントサイドのソケットを作るのに使うことになるでしょう)。
バージョン 3.4 で追加.
Purpose.CLIENT_AUTH
create_default_context() と SSLContext.load_default_certs() に渡すオプションです。この値はコンテキストが Web クライアントの認証に使われることを示します (ですので、サーバサイドのソケットを作るのに使うことになるでしょう)。
バージョン 3.4 で追加.
class ssl.SSLErrorNumber
SSL_ERROR_* 定数の enum.IntEnum コレクションです。
バージョン 3.6 で追加.
class ssl.TLSVersion
enum.IntEnum collection of SSL and TLS versions for SSLContext.maximum_version and SSLContext.minimum_version.
バージョン 3.7 で追加.
TLSVersion.MINIMUM_SUPPORTED
TLSVersion.MAXIMUM_SUPPORTED
TLSVersion.SSLv3
TLSVersion.TLSv1
TLSVersion.TLSv1_1
TLSVersion.TLSv1_2
TLSVersion.TLSv1_3
SSL ソケット
class ssl.SSLSocket(socket.socket)
SSL ソケットは socket オブジェクト の以下のメソッドを提供します:
accept()
bind()
close()
connect()
detach()
fileno()
getpeername(), getsockname()
getsockopt(), setsockopt()
gettimeout(), settimeout(), setblocking()
listen()
makefile()
recv(), recv_into() (非ゼロの flags は渡せません)
send(), sendall() (非ゼロの flags は渡せません)
sendfile() (ただし、 os.sendfile は平文ソケットにのみ使用されます。それ以外の場合には、 send() が使用されます。)
shutdown()
SSL(およびTLS)プロトコルは TCP の上に独自の枠組みを持っているので、SSLソケットの抽象化は、いくつかの点で通常の OSレベルのソケットの仕様から逸脱することがあります。特に ノンブロッキングソケットについての注釈 を参照してください。
バージョン 3.5 で変更: sendfile() メソッドが追加されました。
バージョン 3.5 で変更: shutdown() は、バイトが送受信されるたびにソケットのタイムアウトをリセットしません。ソケットのタイムアウトは、シャットダウンの最大合計時間になりました。
バージョン 3.6 で非推奨: SSLSocket インスタンスを直接作成することは非推奨です。ソケットをラップするために SSLContext.wrap_socket() を使用してください。
バージョン 3.7 で変更: SSLSocket instances must to created with wrap_socket(). In earlier versions, it was possible to create instances directly. This was never documented or officially supported.
SSL ソケットには、以下に示す追加のメソッドと属性もあります:
SSLSocket.read(len=1024, buffer=None)
SSL ソケットからデータの len バイトまでを読み出し、読み出した結果を bytes インスタンスで返します。 buffer を指定すると、結果は代わりに buffer に読み込まれ、読み込んだバイト数を返します。
ソケットが non-blocking で読み出しがブロックすると、 SSLWantReadError もしくは SSLWantWriteError が送出されます。
再ネゴシエーションがいつでも可能なので、 read() の呼び出しは書き込み操作も引き起こしえます。
バージョン 3.5 で変更: ソケットのタイムアウトは、バイトが送受信されるたびにリセットされません。ソケットのタイムアウトは、最大 len バイトを読むのにかかる最大合計時間になりました。
バージョン 3.6 で非推奨: read() の代わりに recv() を使用してください。
SSLSocket.write(buf)
buf を SSL ソケットに書き込み、書き込んだバイト数を返します。 buf 引数はバッファインターフェイスをサポートするオブジェクトでなければなりません。
ソケットが non-blocking で書き込みがブロックすると、 SSLWantReadError もしくは SSLWantWriteError が送出されます。
再ネゴシエーションがいつでも可能なので、 write() の呼び出しは読み出し操作も引き起こしえます。
バージョン 3.5 で変更: ソケットのタイムアウトは、バイトが送受信されるたびにリセットされません。ソケットのタイムアウトは、buf を書き込むのにかかる最大合計時間になりました。
バージョン 3.6 で非推奨: write() の代わりに send() を使用してください。
注釈 read(), write() メソッドは下位レベルのメソッドであり、暗号化されていないアプリケーションレベルのデータを読み書きし、それを復号/暗号化して暗号化された書き込みレベルのデータにします。これらのメソッドはアクティブな SSL 接続つまり、ハンドシェイクが完了していて、 SSLSocket.unwrap() が呼ばれていないことを必要とします。
通常はこれらのメソッドの代わりに recv() や send() のようなソケット API メソッドを使うべきです。
SSLSocket.do_handshake()
SSL セットアップのハンドシェイクを実行します。
バージョン 3.4 で変更: ソケットの context の属性 check_hostname が真の場合に、ハンドシェイクメソッドが match_hostname() を実行するようになりました。
バージョン 3.5 で変更: ソケットのタイムアウトは、バイトが送受信されるたびにリセットされません。ソケットのタイムアウトは、ハンドシェイクにかかる最大合計時間になりました。
バージョン 3.7 で変更: Hostname or IP address is matched by OpenSSL during handshake. The function match_hostname() is no longer used. In case OpenSSL refuses a hostname or IP address, the handshake is aborted early and a TLS alert message is send to the peer.
SSLSocket.getpeercert(binary_form=False)
接続先に証明書が無い場合、 None を返します。SSL ハンドシェイクがまだ行われていない場合は、 ValueError が送出されます。
binary_form が False で接続先から証明書を取得した場合、このメソッドは dict のインスタンスを返します。証明書が認証されていない場合、辞書は空です。証明書が認証されていた場合いくつかのキーを持った辞書を返し、 subject (証明書が発行された principal), issuer (証明書を発行した principal) を含みます。証明書が Subject Alternative Name 拡張(RFC 3280 を参照)のインスタンスを格納していた場合、 subjectAltName キーも辞書に含まれます。
subject, issuer フィールドは、証明書のそれぞれのフィールドについてのデータ構造で与えられる RDN (relative distinguishued name) のシーケンスを格納したタプルで、各 RDN は name-value ペアのシーケンスです。現実世界での例をお見せします:
{'issuer': ((('countryName', 'IL'),),
            (('organizationName', 'StartCom Ltd.'),),
            (('organizationalUnitName',
              'Secure Digital Certificate Signing'),),
            (('commonName',
              'StartCom Class 2 Primary Intermediate Server CA'),)),
 'notAfter': 'Nov 22 08:15:19 2013 GMT',
 'notBefore': 'Nov 21 03:09:52 2011 GMT',
 'serialNumber': '95F0',
 'subject': ((('description', '571208-SLe257oHY9fVQ07Z'),),
             (('countryName', 'US'),),
             (('stateOrProvinceName', 'California'),),
             (('localityName', 'San Francisco'),),
             (('organizationName', 'Electronic Frontier Foundation, Inc.'),),
             (('commonName', '*.eff.org'),),
             (('emailAddress', 'hostmaster@eff.org'),)),
 'subjectAltName': (('DNS', '*.eff.org'), ('DNS', 'eff.org')),
 'version': 3}
注釈 特定のサービスのために証明書の検証がしたければ、 match_hostname() 関数を使うことができます。
binary_form 引数が True だった場合、証明書が渡されていればこのメソッドはDERエンコードされた証明書全体をバイト列として返し、接続先が証明書を提示しなかった場合は None を返します。接続先が証明書を提供するかどうかは SSL ソケットの役割に依存します:
クライアント SSL ソケットでは、認証が要求されているかどうかに関わらず、サーバは常に証明書を提供します。
サーバ SSL ソケットでは、クライアントはサーバによって認証が要求されている場合にのみ証明書を提供します。したがって、 (CERT_OPTIONAL や CERT_REQUIRED ではなく) CERT_NONE を使用した場合 getpeercert() は None を返します。
バージョン 3.2 で変更: 返される辞書に issuer, notBefore のような追加アイテムを含むようになりました。
バージョン 3.4 で変更: ハンドシェイクが済んでいなければ ValueError を投げるようになりました。返される辞書に crlDistributionPoints, caIssuers, OCSP URI のような X509v3 拡張アイテムを含むようになりました。
バージョン 3.9 で変更: IPv6 address strings no longer have a trailing new line.
SSLSocket.cipher()
利用されている暗号の名前、その暗号の利用を定義しているSSLプロトコルのバージョン、利用されている鍵のbit長の3つの値を含むタプルを返します。もし接続が確立されていない場合、 None を返します。
SSLSocket.shared_ciphers()
ハンドシェイク中にクライアントにより共有される暗号方式のリストを返します。返されるリストの各要素は 3つの値を含むタプルで、その値はそれぞれ、暗号方式の名前、その暗号の利用を定義している SSL プロトコルのバージョン、暗号で使用される秘密鍵のビット長です。接続が確立されていないか、ソケットがクライアントソケットである場合、meth:~SSLSocket.shared_ciphers は None を返します。
バージョン 3.5 で追加.
SSLSocket.compression()
使われている圧縮アルゴリズムを文字列で返します。接続が圧縮されていなければ None を返します。
上位レベルのプロトコルが自身で圧縮メカニズムをサポートする場合、SSL レベルでの圧縮を OP_NO_COMPRESSION を使って無効にできます。
バージョン 3.3 で追加.
SSLSocket.get_channel_binding(cb_type="tls-unique")
現在の接続におけるチャネルバインディングのデータを取得します。未接続あるいはハンドシェイクが完了していなければ None を返します。
cb_type パラメータにより、望みのチャネルバインディングのタイプを選択できます。チャネルバインディングのタイプの妥当なものは CHANNEL_BINDING_TYPES でリストされています。現在のところは RFC 5929 で定義されている 'tls-unique' のみがサポートされています。未サポートのチャネルバインディングのタイプが要求された場合、 ValueError を送出します。
バージョン 3.3 で追加.
SSLSocket.selected_alpn_protocol()
TLS ハンドシェイクで選択されたプロトコルを返します。 SSLContext.set_alpn_protocols() が呼ばれていない場合、相手側が ALPN をサポートしていない場合、クライアントが提案したプロトコルのどれもソケットがサポートしない場合、あるいはハンドシェイクがまだ行われていない場合には、 None が返されます。
バージョン 3.5 で追加.
SSLSocket.selected_npn_protocol()
TLS/SSL ハンドシェイクで選択された上位レベルのプロトコルを返します。 SSLContext.set_npn_protocols() が呼ばれていない場合、相手側が NPN をサポートしていない場合、あるいはハンドシェイクがまだ行われていない場合には、 None が返されます。
バージョン 3.3 で追加.
SSLSocket.unwrap()
SSLシャットダウンハンドシェイクを実行します。これは下位レイヤーのソケットからTLSレイヤーを取り除き、下位レイヤーのソケットオブジェクトを返します。これは暗号化されたオペレーションから暗号化されていない接続に移行するときに利用されます。以降の通信には、オリジナルのソケットではなくこのメソッドが返したソケットのみを利用するべきです。
SSLSocket.verify_client_post_handshake()
注釈 Only available with OpenSSL 1.1.1 and TLS 1.3 enabled. Without TLS 1.3 support, the method raises NotImplementedError.
バージョン 3.8 で追加.
SSLSocket.version()
コネクションによって実際にネゴシエイトされた SSL プロトコルバージョンを文字列で、または、セキュアなコネクションが確立していなければ None を返します。これを書いている時点では、 "SSLv2", "SSLv3", "TLSv1", "TLSv1.1", "TLSv1.2" などが返ります。最新の OpenSSL はもっと色々な値を定義しているかもしれません。
バージョン 3.5 で追加.
SSLSocket.pending()
接続において既に復号済みで読み出し可能で保留になっているバイト列の数を返します。
SSLSocket.context
バージョン 3.2 で追加.
SSLSocket.server_side
サーバサイドのソケットに対して True 、クライアントサイドのソケットに対して False となる真偽値です。
バージョン 3.2 で追加.
SSLSocket.server_hostname
サーバのホスト名: str 型、またはサーバサイドのソケットの場合とコンストラクタで hostname が指定されなかった場合は None
バージョン 3.2 で追加.
バージョン 3.7 で変更: The attribute is now always ASCII text. When server_hostname is an internationalized domain name (IDN), this attribute now stores the A-label form ("xn--pythn-mua.org"), rather than the U-label form ("pythön.org").
SSLSocket.session
この SSL 接続に対する SSLSession です。このセッションは、TLS ハンドシェイクの実行後、クライアントサイドとサーバサイドのソケットで使用できます。クライアントソケットでは、このセッションを do_handshake() が呼ばれる前に設定して、セッションを再利用できます。
バージョン 3.6 で追加.
SSLSocket.session_reused
バージョン 3.6 で追加.
SSL コンテキスト
バージョン 3.2 で追加.
SSL コンテキストは、SSL 構成オプション、証明書(群)や秘密鍵(群)などのような、一回の SSL 接続よりも長生きするさまざまなデータを保持します。これはサーバサイドソケットの SSL セッションのキャッシュも管理し、同じクライアントからの繰り返しの接続時の速度向上に一役買います。
class ssl.SSLContext(protocol=PROTOCOL_TLS)
次のテーブルは、どのクライアントのバージョンがどのサーバのバージョンに接続できるかを示しています:
client / server
SSLv2
SSLv3
TLS 3
TLSv1
TLSv1.1
TLSv1.2
SSLv2
yes
no
no 1
no
no
no
SSLv3
no
yes
no 2
no
no
no
TLS (SSLv23) 3
no 1
no 2
yes
yes
yes
yes
TLSv1
no
no
yes
yes
no
no
TLSv1.1
no
no
yes
no
yes
no
TLSv1.2
no
no
yes
no
no
yes
脚注
1(1,2)
SSLContext では、デフォルトで OP_NO_SSLv2 によりSSLv2 が無効になっています。
2(1,2)
SSLContext では、デフォルトで OP_NO_SSLv3 により SSLv3 が無効になっています。
3(1,2)
参考 create_default_context() は ssl モジュールに、目的に合ったセキュリティ設定を選ばせます。
バージョン 3.6 で変更: このコンテキストは、安全性の高いデフォルト値で作成されます。デフォルト設定されるオプションは、 OP_NO_COMPRESSION, OP_CIPHER_SERVER_PREFERENCE, OP_SINGLE_DH_USE, OP_SINGLE_ECDH_USE, OP_NO_SSLv2 (PROTOCOL_SSLv2 以外), OP_NO_SSLv3 (PROTOCOL_SSLv3 以外) です。初期の暗号方式スイートリストには HIGH 暗号のみが含まれており、 NULL 暗号および MD5 暗号は含まれません (PROTOCOL_SSLv2 以外)。
SSLContext オブジェクトは以下のメソッドと属性を持っています:
SSLContext.cert_store_stats()
ロードされた X.509 証明書の数、CA 証明書で活性の X.509 証明書の数、証明書失効リストの数、についての統計情報を辞書として取得します。
一つの CA と他の一つの証明書を持ったコンテキストでの例です:
>>>
>>> context.cert_store_stats()
{'crl': 0, 'x509_ca': 1, 'x509': 2}
バージョン 3.4 で追加.
SSLContext.load_cert_chain(certfile, keyfile=None, password=None)
秘密鍵と対応する証明書をロードします。 certfile は、証明書と、証明書認証で必要とされる任意の数の CA 証明書を含む、PEM フォーマットの単一ファイルへのパスでなければなりません。 keyfile 文字列を指定する場合、秘密鍵が含まれるファイルを指すものでなければなりません。指定しない場合、秘密鍵も certfile から取得されます。 certfile への証明書の格納についての詳細は、 証明書 の議論を参照してください。
password 引数に、秘密鍵を復号するためのパスワードを返す関数を与えることができます。その関数は秘密鍵が暗号化されていて、なおかつパスワードが必要な場合にのみ呼び出されます。その関数は引数なしで呼び出され、string, bytes, または bytearray を返さなければなりません。戻り値が string の場合は鍵を復号化するのに使う前に UTF-8 でエンコードされます。string の代わりに bytes や bytearray を返した場合は password 引数に直接供給されます。秘密鍵が暗号化されていなかったりパスワードを必要としない場合は、指定は無視されます。
password が与えられず、そしてパスワードが必要な場合には、OpenSSL 組み込みのパスワード問い合わせメカニズムが、ユーザに対話的にパスワードを問い合わせます。
秘密鍵が証明書に合致しなければ、 SSLError が送出されます。
バージョン 3.3 で変更: 新しいオプション引数 password。
SSLContext.load_default_certs(purpose=Purpose.SERVER_AUTH)
デフォルトの場所から "認証局" (CA=certification authority) 証明書ファイル一式をロードします。Windows では、CA 証明書はシステム記憶域の CA と ROOT からロードします。それ以外のシステムでは、この関数は SSLContext.set_default_verify_paths() を呼び出します。将来的にはこのメソッドは、他の場所からも CA 証明書をロードするかもしれません。
purpose フラグでどの種類の CA 証明書をロードするかを指定します。デフォルトの Purpose.SERVER_AUTH は TLS web サーバの認証のために活性かつ信頼された証明書をロードします(クライアントサイドのソケット)。 Purpose.CLIENT_AUTH はクライアント証明書の正当性検証をサーバサイドで行うための CA 証明書をロードします。
バージョン 3.4 で追加.
SSLContext.load_verify_locations(cafile=None, capath=None, cadata=None)
verify_mode が CERT_NONE でない場合に接続先の証明書ファイルの正当性検証に使われる "認証局" (CA=certification authority) 証明書ファイル一式をロードします。少なくとも cafile か capath のどちらかは指定しなければなりません。
このメソッドは PEM または DER フォーマットの証明書失効リスト (CRLs=certification revocation lists)もロードできます。CRLs のために使うには、 SSLContext.verify_flags を適切に設定しなければなりません。
cafile を指定する場合は、PEM フォーマットで CA 証明書が結合されたファイルへのパスを指定してください。このファイル内で証明書をどのように編成すれば良いのかについての詳しい情報については、 証明書 の議論を参照してください。
cadata オブジェクトを指定する場合は、PEM エンコードの証明書一つ以上の ASCII 文字列か、DER エンコードの証明書の bytes-like object オブジェクトのどちらかを指定してください。PEM エンコードの証明書の周囲の余分な行は無視されますが、少なくとも一つの証明書が含まれている必要があります。
バージョン 3.4 で変更: 新しいオプション引数 cadata 。
SSLContext.get_ca_certs(binary_form=False)
ロードされた "認証局" (CA=certification authority) 証明書のリストを取得します。 binary_form 引数が False である場合、リストのそれぞれのエントリは SSLSocket.getpeercert() が出力するような辞書になります。True である場合、このメソッドは、DER エンコード形式の証明書のリストを返します。返却されるリストには、 SSL 接続によって証明書がリクエストおよびロードされない限り、 capath からの証明書は含まれません。
注釈 capath ディレクトリ内の証明書は一度でも使われない限りはロードされません。
バージョン 3.4 で追加.
SSLContext.get_ciphers()
有効な暗号化のリストを取得します。リストは暗号化優先度順に並びます。SSLContext.set_ciphers() を参照してください。
以下はプログラム例です:
>>>
>>> ctx = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
>>> ctx.set_ciphers('ECDHE+AESGCM:!ECDSA')
>>> ctx.get_ciphers()  # OpenSSL 1.0.x
[{'alg_bits': 256,
  'description': 'ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(256) Mac=AEAD',
  'id': 50380848,
  'name': 'ECDHE-RSA-AES256-GCM-SHA384',
  'protocol': 'TLSv1/SSLv3',
  'strength_bits': 256},
 {'alg_bits': 128,
  'description': 'ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(128) Mac=AEAD',
  'id': 50380847,
  'name': 'ECDHE-RSA-AES128-GCM-SHA256',
  'protocol': 'TLSv1/SSLv3',
  'strength_bits': 128}]
OpenSSL 1.1 以降では、暗号化辞書に以下のフィールドが追加されました。
>>>
>>> ctx.get_ciphers()  # OpenSSL 1.1+
[{'aead': True,
  'alg_bits': 256,
  'auth': 'auth-rsa',
  'description': 'ECDHE-RSA-AES256-GCM-SHA384 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(256) Mac=AEAD',
  'digest': None,
  'id': 50380848,
  'kea': 'kx-ecdhe',
  'name': 'ECDHE-RSA-AES256-GCM-SHA384',
  'protocol': 'TLSv1.2',
  'strength_bits': 256,
  'symmetric': 'aes-256-gcm'},
 {'aead': True,
  'alg_bits': 128,
  'auth': 'auth-rsa',
  'description': 'ECDHE-RSA-AES128-GCM-SHA256 TLSv1.2 Kx=ECDH     Au=RSA  '
                 'Enc=AESGCM(128) Mac=AEAD',
  'digest': None,
  'id': 50380847,
  'kea': 'kx-ecdhe',
  'name': 'ECDHE-RSA-AES128-GCM-SHA256',
  'protocol': 'TLSv1.2',
  'strength_bits': 128,
  'symmetric': 'aes-128-gcm'}]
バージョン 3.6 で追加.
SSLContext.set_default_verify_paths()
デフォルトの "認証局" (CA=certification authority) 証明書を、OpenSSL ライブラリがビルドされた際に定義されたファイルシステム上のパスからロードします。残念ながらこのメソッドが成功したかどうかを知るための簡単な方法はありません: 証明書が見つからなくてもエラーは返りません。OpenSSL ライブラリがオペレーティングシステムの一部として提供されている際にはどうやら適切に構成できるようですが。
SSLContext.set_ciphers(ciphers)
注釈 接続時に SSL ソケットの SSLSocket.cipher() メソッドが、現在選択されているその暗号を使います。
SSLContext.set_alpn_protocols(protocols)
SSL/TLS ハンドシェイク時にソケットが提示すべきプロトコルを指定します。 ['http/1.1', 'spdy/2'] のような推奨順に並べた ASCII 文字列のリストでなければなりません。プロトコルの選択は RFC 7301 に従いハンドシェイク中に行われます。ハンドシェイクが正常に終了した後、 SSLSocket.selected_alpn_protocol() メソッドは合意されたプロトコルを返します。
バージョン 3.5 で追加.
SSLContext.set_npn_protocols(protocols)
バージョン 3.3 で追加.
SSLContext.sni_callback
TLS クライアントがサーバ名表示を指定した際の、SSL/TLS サーバによって TLS Client Hello ハンドシェイクメッセージが受け取られたあとで呼び出されるコールバック関数を登録します。サーバ名表示メカニズムは RFC 6066 セクション 3 - Server Name Indication で述べられています。
このコールバックの典型的な利用方法は、 ssl.SSLSocket の SSLSocket.context 属性を、サーバ名に合致する証明書チェインを持つ新しい SSLContext オブジェクトに変更することです。
TLS 接続の初期ネゴシエーションのフェーズなので、 SSLSocket.selected_alpn_protocol(), SSLSocket.context のような限られたメソッドと属性のみ使えます。 SSLSocket.getpeercert(), SSLSocket.getpeercert(), SSLSocket.cipher(), SSLSocket.compress() メソッドは TLS 接続が TLS Client Hello よりも先に進行していることを必要としますから、これらは意味のある値を返しませんし、安全に呼び出すこともできません。
このメソッドは OpenSSL ライブラリが OPENSSL_NO_TLSEXT を定義してビルドされている場合、 NotImplementedError を送出します。
バージョン 3.7 で追加.
SSLContext.set_servername_callback(server_name_callback)
バージョン 3.4 で追加.
SSLContext.load_dh_params(dhfile)
この設定はクライアントソケットには適用されません。さらにセキュリティを改善するのに OP_SINGLE_DH_USE オプションも利用できます。
バージョン 3.3 で追加.
SSLContext.set_ecdh_curve(curve_name)
楕円曲線ディフィー・ヘルマン(ECDH)鍵交換の曲線名を指定します。ECDH はもとの DH に較べて、ほぼ間違いなく同程度に安全である一方で、顕著に高速です。 curve_name パラメータは既知の楕円曲線を表す文字列でなければなりません。例えば prime256v1 が広くサポートされている曲線です。
この設定はクライアントソケットには適用されません。さらにセキュリティを改善するのに OP_SINGLE_ECDH_USE オプションも利用できます。
このメソッドは HAS_ECDH が False の場合は利用できません。
バージョン 3.3 で追加.
参考
SSL/TLS & Perfect Forward Secrecy
SSLContext.wrap_socket(sock, server_side=False, do_handshake_on_connect=True, suppress_ragged_eofs=True, server_hostname=None, session=None)
server_side 引数は真偽値で、このソケットがサーバサイドとクライアントサイドのどちらの動作をするのかを指定します。
クライアントからの接続では、 server_hostname で接続先サービスのホスト名を指定できます。これは HTTP バーチャルホストにかなり似て、シングルサーバで複数の SSL ベースのサービスを別々の証明書でホストしているようなサーバに対して使えます。 server_side が True の場合に server_hostname を指定すると ValueError を送出します。
do_handshake_on_connect 引数は、 socket.connect() の後に自動的に SSLハンドシェイクを行うか、それともアプリケーションが明示的に SSLSocket.do_handshake() メソッドを実行するかを指定します。 SSLSocket.do_handshake() を明示的に呼びだすことで、ハンドシェイクによるソケットI/Oのブロッキング動作を制御できます。
suppress_ragged_eofs 引数は、 SSLSocket.recv() メソッドが、接続先から予期しないEOF を受け取った時に通知する方法を指定します。 True (デフォルト) の場合、下位のソケットレイヤーから予期せぬEOFエラーが来た場合、通常のEOF (空のバイト列オブジェクト)を返します。 False の場合、呼び出し元に例外を投げて通知します。
session, session を参照してください。
バージョン 3.5 で変更: OpenSSL が SNI をサポートしなくても server_hostname を許容するようになりました。
バージョン 3.6 で変更: session 引数が追加されました。
バージョン 3.7 で変更: The method returns on instance of SSLContext.sslsocket_class instead of hard-coded SSLSocket.
SSLContext.sslsocket_class
バージョン 3.7 で追加.
SSLContext.wrap_bio(incoming, outgoing, server_side=False, server_hostname=None, session=None)
server_side、 server_hostname 、 session 引数は、 SSLContext.wrap_socket() での意味と同じ意味を持ちます。
バージョン 3.6 で変更: session 引数が追加されました。
バージョン 3.7 で変更: The method returns on instance of SSLContext.sslobject_class instead of hard-coded SSLObject.
SSLContext.sslobject_class
バージョン 3.7 で追加.
SSLContext.session_stats()
Get statistics about the SSL sessions created or managed by this context. A dictionary is returned which maps the names of each piece of information to their numeric values. For example, here is the total number of hits and misses in the session cache since the context was created:
>>>
>>> stats = context.session_stats()
>>> stats['hits'], stats['misses']
(0, 0)
SSLContext.check_hostname
以下はプログラム例です:
import socket, ssl
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
context.verify_mode = ssl.CERT_REQUIRED
context.check_hostname = True
context.load_default_certs()
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
ssl_sock = context.wrap_socket(s, server_hostname='www.verisign.com')
ssl_sock.connect(('www.verisign.com', 443))
バージョン 3.4 で追加.
バージョン 3.7 で変更: verify_mode is now automatically changed to CERT_REQUIRED when hostname checking is enabled and verify_mode is CERT_NONE. Previously the same operation would have failed with a ValueError.
注釈 この機能にはOpenSSL0.9.8f以降が必要です。
SSLContext.keylog_filename
バージョン 3.8 で追加.
注釈 This features requires OpenSSL 1.1.1 or newer.
SSLContext.maximum_version
注釈 This attribute is not available unless the ssl module is compiled with OpenSSL 1.1.0g or newer.
バージョン 3.7 で追加.
SSLContext.minimum_version
注釈 This attribute is not available unless the ssl module is compiled with OpenSSL 1.1.0g or newer.
バージョン 3.7 で追加.
SSLContext.num_tickets
注釈 This attribute is not available unless the ssl module is compiled with OpenSSL 1.1.1 or newer.
バージョン 3.8 で追加.
SSLContext.options
このコンテキストで有効になっている SSL オプションを表す整数。デフォルトの値は OP_ALL ですが、 OP_NO_SSLv2 のような他の値をビット OR 演算で指定できます。
注釈 With versions of OpenSSL older than 0.9.8m, it is only possible to set options, not to clear them. Attempting to clear an option (by resetting the corresponding bits) will raise a ValueError.
バージョン 3.6 で変更: SSLContext.options は次のように Options のフラグを返します。
>>>
ssl.create_default_context().options  
<Options.OP_ALL|OP_NO_SSLv3|OP_NO_SSLv2|OP_NO_COMPRESSION: 2197947391>
SSLContext.post_handshake_auth
注釈 Only available with OpenSSL 1.1.1 and TLS 1.3 enabled. Without TLS 1.3 support, the property value is None and can't be modified
バージョン 3.8 で追加.
SSLContext.protocol
コンテキストの構築時に選択されたプロトコルバージョン。この属性は読み出し専用です。
SSLContext.hostname_checks_common_name
注釈 Only writeable with OpenSSL 1.1.0 or higher.
バージョン 3.7 で追加.
SSLContext.verify_flags
証明書の検証操作のためのフラグです。 VERIFY_CRL_CHECK_LEAF などのフラグをビット OR 演算でセットできます。デフォルトでは OpenSSL は証明書失効リスト (CRLs) を必要としませんし検証にも使いません。openssl version 0.9.8+ でのみ利用可能です。
バージョン 3.4 で追加.
バージョン 3.6 で変更: SSLContext.verify_flags は次のように VerifyFlags のフラグを返します。
>>>
ssl.create_default_context().verify_flags  
<VerifyFlags.VERIFY_X509_TRUSTED_FIRST: 32768>
SSLContext.verify_mode
接続先の証明書の検証を試みるかどうか、また、検証が失敗した場合にどのように振舞うべきかを制御します。この属性は CERT_NONE, CERT_OPTIONAL, CERT_REQUIRED のうちどれか一つでなければなりません。
バージョン 3.6 で変更: SSLContext.verify_mode は次のように VerifyMode enum (列挙) を返します。
>>>
ssl.create_default_context().verify_mode
<VerifyMode.CERT_REQUIRED: 2>
証明書
証明書を大まかに説明すると、公開鍵/秘密鍵システムの一種です。このシステムでは、各 principal (これはマシン、人、組織などです) は、ユニークな2つの暗号鍵を割り当てられます。1つは公開され、 公開鍵(public key) と呼ばれます。もう一方は秘密にされ、 秘密鍵(private key) と呼ばれます。 2つの鍵は関連しており、片方の鍵で暗号化したメッセージは、もう片方の鍵 のみ で復号できます。
Python において証明書を利用する場合、クライアントもサーバーも自分を証明するために証明書を利用することができます。ネットワーク接続の相手側に証明書の提示を要求する事ができ、そのクライアントやサーバーが認証を必要とするならその証明書を認証することができます。認証が失敗した場合、接続は例外を発生させます。認証は下位層のOpenSSLフレームワークが自動的に行います。アプリケーションは認証機構について意識する必要はありません。しかし、アプリケーションは認証プロセスのために幾つかの証明書を提供する必要があるかもしれません。
Python は証明書を格納したファイルを利用します。そのファイルは "PEM" (RFC 1422 参照) フォーマットという、ヘッダー行とフッター行の間にbase-64エンコードされた形をとっている必要があります。
-----BEGIN CERTIFICATE-----
... (certificate in base64 PEM encoding) ...
-----END CERTIFICATE-----
証明書チェイン
Pythonが利用する証明書を格納したファイルは、ときには 証明書チェイン(certificate chain) と呼ばれる証明書のシーケンスを格納します。このチェインの先頭には、まずクライアントやサーバーである principal の証明書を置き、それ以降には、その証明書の発行者(issuer)の証明書などを続け、最後に証明対象(subject)と発行者が同じ 自己署名(self-signed) 証明書で終わります。この最後の証明書は ルート証明書(root certificate と呼ばれます。これらの証明書チェインは単純に1つの証明書ファイルに結合してください。例えば、3つの証明書からなる証明書チェインがある場合、私たちのサーバーの証明書から、私たちのサーバーに署名した認証局の証明書、そして認証局の証明書を発行した機関のルート証明書と続きます:
-----BEGIN CERTIFICATE-----
... (certificate for your server)...
-----END CERTIFICATE-----
-----BEGIN CERTIFICATE-----
... (the certificate for the CA)...
-----END CERTIFICATE-----
-----BEGIN CERTIFICATE-----
... (the root certificate for the CA's issuer)...
-----END CERTIFICATE-----
CA 証明書
もし相手から送られてきた証明書の認証をしたい場合、信頼している各発行者の証明書チェインが入った "CA certs" ファイルを提供する必要があります。繰り返しますが、このファイルは単純に、各チェインを結合しただけのものです。認証のために、Pythonはそのファイルの中の最初にマッチしたチェインを利用します。SSLContext.load_default_certs() を呼び出すことでプラットフォームの証明書ファイルも使われますが、これは create_default_context() によって自動的に行われます。
秘密鍵と証明書の組み合わせ
多くの場合、証明書と同じファイルに秘密鍵も格納されています。この場合、 SSLContext.load_cert_chain(), wrap_socket() には certfile 引数だけが必要とされます。秘密鍵が証明書ファイルに格納されている場合、秘密鍵は証明書チェインの最初の証明書よりも先にないといけません。
-----BEGIN RSA PRIVATE KEY-----
... (private key in base64 encoding) ...
-----END RSA PRIVATE KEY-----
-----BEGIN CERTIFICATE-----
... (certificate in base64 PEM encoding) ...
-----END CERTIFICATE-----
自己署名証明書
SSL暗号化接続サービスを提供するサーバーを建てる場合、適切な証明書を取得するには、認証局から買うなどの幾つかの方法があります。また、自己署名証明書を作るケースもあります。 OpenSSLを使って自己署名証明書を作るには、次のようにします。
% openssl req -new -x509 -days 365 -nodes -out cert.pem -keyout cert.pem
Generating a 1024 bit RSA private key
.......++++++
.............................++++++
writing new private key to 'cert.pem'
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
-----
Country Name (2 letter code) [AU]:US
State or Province Name (full name) [Some-State]:MyState
Locality Name (eg, city) []:Some City
Organizational Unit Name (eg, section) []:My Group
Common Name (eg, YOUR name) []:myserver.mygroup.myorganization.com
Email Address []:ops@myserver.mygroup.myorganization.com
%
自己署名証明書の欠点は、それ自身がルート証明書であり、他の人はその証明書を持っていない (そして信頼しない)ことです。
使用例
SSLサポートをテストする
インストールされているPythonがSSLをサポートしているかどうかをテストするために、ユーザーコードは次のイディオムを利用することができます。
try:
    import ssl
except ImportError:
    pass
else:
    ...  # do something that requires SSL support
クライアントサイドの処理
この例では、自動的に証明書の検証を行うことを含む望ましいセキュリティ設定でクライアントソケットの SSL コンテキストを作ります:
>>>
>>> context = ssl.create_default_context()
自分自身でセキュリティ設定を調整したい場合、コンテキストを一から作ることはできます (ただし、正しくない設定をしてしまいがちなことに注意してください):
>>>
>>> context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
>>> context.load_verify_locations("/etc/ssl/certs/ca-bundle.crt")
(このスニペットはすべての CA 証明書が /etc/ssl/certs/ca-bundle.crt にバンドルされていることを仮定しています; もし違っていればエラーになりますので、適宜修正してください)
When you use the context to connect to a server, CERT_REQUIRED and check_hostname validate the server certificate: it ensures that the server certificate was signed with one of the CA certificates, checks the signature for correctness, and verifies other properties like validity and identity of the hostname:
>>>
>>> conn = context.wrap_socket(socket.socket(socket.AF_INET),
...                            server_hostname="www.python.org")
>>> conn.connect(("www.python.org", 443))
そして証明書を持ってくることができます:
>>>
>>> cert = conn.getpeercert()
証明書が、期待しているサービス (つまり、 HTTPS ホスト www.python.org) の身元を特定していることを視覚的に点検してみましょう:
>>>
>>> pprint.pprint(cert)
{'OCSP': ('http://ocsp.digicert.com',),
 'caIssuers': ('http://cacerts.digicert.com/DigiCertSHA2ExtendedValidationServerCA.crt',),
 'crlDistributionPoints': ('http://crl3.digicert.com/sha2-ev-server-g1.crl',
                           'http://crl4.digicert.com/sha2-ev-server-g1.crl'),
 'issuer': ((('countryName', 'US'),),
            (('organizationName', 'DigiCert Inc'),),
            (('organizationalUnitName', 'www.digicert.com'),),
            (('commonName', 'DigiCert SHA2 Extended Validation Server CA'),)),
 'notAfter': 'Sep  9 12:00:00 2016 GMT',
 'notBefore': 'Sep  5 00:00:00 2014 GMT',
 'serialNumber': '01BB6F00122B177F36CAB49CEA8B6B26',
 'subject': ((('businessCategory', 'Private Organization'),),
             (('1.3.6.1.4.1.311.60.2.1.3', 'US'),),
             (('1.3.6.1.4.1.311.60.2.1.2', 'Delaware'),),
             (('serialNumber', '3359300'),),
             (('streetAddress', '16 Allen Rd'),),
             (('postalCode', '03894-4801'),),
             (('countryName', 'US'),),
             (('stateOrProvinceName', 'NH'),),
             (('localityName', 'Wolfeboro'),),
             (('organizationName', 'Python Software Foundation'),),
             (('commonName', 'www.python.org'),)),
 'subjectAltName': (('DNS', 'www.python.org'),
                    ('DNS', 'python.org'),
                    ('DNS', 'pypi.org'),
                    ('DNS', 'docs.python.org'),
                    ('DNS', 'testpypi.org'),
                    ('DNS', 'bugs.python.org'),
                    ('DNS', 'wiki.python.org'),
                    ('DNS', 'hg.python.org'),
                    ('DNS', 'mail.python.org'),
                    ('DNS', 'packaging.python.org'),
                    ('DNS', 'pythonhosted.org'),
                    ('DNS', 'www.pythonhosted.org'),
                    ('DNS', 'test.pythonhosted.org'),
                    ('DNS', 'us.pycon.org'),
                    ('DNS', 'id.python.org')),
 'version': 3}
SSL チャネルは今や確立されて証明書が検証されているので、サーバとのお喋りを続けることができます:
>>>
>>> conn.sendall(b"HEAD / HTTP/1.0\r\nHost: linuxfr.org\r\n\r\n")
>>> pprint.pprint(conn.recv(1024).split(b"\r\n"))
[b'HTTP/1.1 200 OK',
 b'Date: Sat, 18 Oct 2014 18:27:20 GMT',
 b'Server: nginx',
 b'Content-Type: text/html; charset=utf-8',
 b'X-Frame-Options: SAMEORIGIN',
 b'Content-Length: 45679',
 b'Accept-Ranges: bytes',
 b'Via: 1.1 varnish',
 b'Age: 2188',
 b'X-Served-By: cache-lcy1134-LCY',
 b'X-Cache: HIT',
 b'X-Cache-Hits: 11',
 b'Vary: Cookie',
 b'Strict-Transport-Security: max-age=63072000; includeSubDomains',
 b'Connection: close',
 b'',
 b'']
このドキュメントの下の方の、 セキュリティで考慮すべき点 に関する議論を参照してください。
サーバサイドの処理
サーバサイドの処理では、通常、サーバー証明書と秘密鍵がそれぞれファイルに格納された形で必要です。最初に秘密鍵と証明書が保持されたコンテキストを作成し、クライアントがあなたの信憑性をチェックできるようにします。そののちにソケットを開き、ポートにバインドし、そのソケットの listen() を呼び、クライアントからの接続を待ちます。
import socket, ssl
context = ssl.create_default_context(ssl.Purpose.CLIENT_AUTH)
context.load_cert_chain(certfile="mycertfile", keyfile="mykeyfile")
bindsocket = socket.socket()
bindsocket.bind(('myaddr.mydomain.com', 10023))
bindsocket.listen(5)
クライアントが接続してきた場合、 accept() を呼んで新しいソケットを作成し、接続のためにサーバサイドの SSL ソケットを、コンテキストの SSLContext.wrap_socket() メソッドで作ります:
while True:
    newsocket, fromaddr = bindsocket.accept()
    connstream = context.wrap_socket(newsocket, server_side=True)
    try:
        deal_with_client(connstream)
    finally:
        connstream.shutdown(socket.SHUT_RDWR)
        connstream.close()
そして、 connstream からデータを読み、クライアントと切断する(あるいはクライアントが切断してくる)まで何か処理をします。
def deal_with_client(connstream):
    data = connstream.recv(1024)
    # empty data means the client is finished with us
    while data:
        if not do_something(connstream, data):
            # we'll assume do_something returns False
            # when we're finished with client
            break
        data = connstream.recv(1024)
    # finished with client
そして新しいクライアント接続のために listen に戻ります。 (もちろん現実のサーバは、おそらく個々のクライアント接続ごとに別のスレッドで処理するか、ソケットを ノンブロッキングモード にし、イベントループを使うでしょう。)
ノンブロッキングソケットについての注意事項
SSL ソケットはノンブロッキングモードにおいては、普通のソケットとは少し違った振る舞いをします。ですのでノンブロッキングソケットとともに使う場合、いくつか気をつけなければならない事項があります:
ほとんどの SSLSocket のメソッドは I/O 操作がブロックすると BlockingIOError ではなく SSLWantWriteError か SSLWantReadError のどちらかを送出します。 SSLWantReadError は下層のソケットで読み出しが必要な場合に送出され、 SSLWantWriteError は下層のソケットで書き込みが必要な場合に送出されます。SSL ソケットに対して 書き込み を試みると下層のソケットから最初に 読み出す 必要があるかもしれず、SSL ソケットに対して 読み出し を試みると下層のソケットに先に 書き込む 必要があるかもしれないことに注意してください。
バージョン 3.5 で変更: 以前の Python バージョンでは、 SSLSocket.send() メソッドは SSLWantWriteError または SSLWantReadError を送出するのではなく、ゼロを返していました。
select() 呼び出しは OS レベルでのソケットが読み出し可能(または書き込み可能)になったことを教えてくれますが、上位の SSL レイヤーでの十分なデータがあることを意味するわけではありません。例えば、SSL フレームの一部が届いただけかもしれません。ですから、 SSLSocket.recv() と SSLSocket.send() の失敗を処理することに備え、ほかの select() 呼び出し後にリトライしなければなりません。
反対に、SSL レイヤーは独自の枠組みを持っているため、select() が気付かない読み出し可能なデータを SSL ソケットが持っている場合があります。したがって、入手可能な可能性のあるデータをすべて引き出すために最初に SSLSocket.recv() を呼び出し、次にそれでもまだ必要な場合にだけ select() 呼び出しでブロックすべきです。
(当然のことながら、ほかのプリミティブ、例えば poll() や selectors モジュール内のものを使う際にも似た但し書きが付きます)
SSL ハンドシェイクそのものがノンブロッキングになります: SSLSocket.do_handshake() メソッドは成功するまでリトライしなければなりません。 select() を用いてソケットの準備が整うのを待つためには、およそ以下のようにします:
while True:
    try:
        sock.do_handshake()
        break
    except ssl.SSLWantReadError:
        select.select([sock], [], [])
    except ssl.SSLWantWriteError:
        select.select([], [sock], [])
参考 asyncio モジュールは ノンブロッキング SSL ソケット をサポートし、より高いレベルの API を提供しています。 selectors モジュールを使ってイベントを poll し、 SSLWantWriteError, SSLWantReadError, BlockingIOError 例外を処理します。SSL ハンドシェイクも非同期に実行します。
メモリ BIO サポート
バージョン 3.5 で追加.
Python 2.6 で SSL モジュールが導入されて以降、SSLSocket クラスは、以下の互いに関連するが別々の機能を提供してきました。
SSL プロトコル処理
ネットワーク IO
ネットワーク IO API は、socket.socket が提供するものと同じです。SSLSocket も、そのクラスから継承しています。これにより、SSL ソケットは標準のソケットをそっくりそのまま置き換えるものとして使用できるため、既存のアプリケーションを SSL に対応させるのが非常に簡単になります。
SSL プロトコルの処理とネットワーク IO を組み合わせた場合、通常は問題なく動作しますが、問題が発生する場合があります。一例を挙げると、非同期 IO フレームワークが別の多重化モデルを使用する場合、これは socket.socket と内部 OpenSSL ソケット IO ルーティンが想定する「ファイル記述子上の select/poll」モデル（準備状態ベース）とは異なります。これは、このモデルが非効率的になる Windows などのプラットフォームに主に該当します。そのため、スコープを限定した SSLSocket の変種、 SSLObject が提供されています。
class ssl.SSLObject
ネットワーク IO メソッドを含まない SSL プロトコルインスタンスを表す、スコープを限定した SSLSocket の変種です。一般的にこ、のクラスを使用するのは、メモリバッファを通じて SSL のための非同期 IO を実装するフレームワーク作成者です。
このクラスは、OpenSSL が実装する低水準 SSL オブジェクトの上にインターフェースを実装します。このオブジェクトは SSL 接続の状態をキャプチャしますが、ネットワーク IO 自体は提供しません。IO は、OpenSSL の IO 抽象レイヤである別の「BIO」オブジェクトを通じて実行する必要があります。
次のメソッドがサポートされています:
context
server_side
server_hostname
session
session_reused
read()
write()
getpeercert()
selected_alpn_protocol()
selected_npn_protocol()
cipher()
shared_ciphers()
compression()
pending()
do_handshake()
verify_client_post_handshake()
unwrap()
get_channel_binding()
version()
SSLSocket と比較すると、このオブジェクトでは以下の機能が不足しています。
do_handshake_on_connect 機構はありません。必ず手動で do_handshake() を呼んで、ハンドシェイクを開始する必要があります。
suppress_ragged_eofs は処理されません。プロトコルに違反するファイル末尾状態は、 SSLEOFError 例外を通じて報告されます。
unwrap() メソッドの呼び出しは、下層のソケットを返す SSL ソケットとは異なり、何も返しません。
SSLContext.set_servername_callback() に渡される server_name_callback コールバックは、1 つ目の引数として SSLSocket インスタンスではなく SSLObject インスタンスを受け取ります。
SSLObject の使用に関する注意:
SSLObject 上のすべての IO は non-blocking です。例えば、read() は入力 BIO が持つデータよりも多くのデータを必要とする場合、SSLWantReadError を送出します。
wrap_socket() に対して存在するような、モジュールレベルの wrap_bio() 呼び出しは存在しません。SSLObject は、常に SSLContext を経由して作成されます。
バージョン 3.7 で変更: SSLObject instances must to created with wrap_bio(). In earlier versions, it was possible to create instances directly. This was never documented or officially supported.
SSLObject は、メモリバッファを使用して外界と通信します。MemoryBIO クラスは、以下のように OpenSSL メモリ BIO (Basic IO) オブジェクトをラップし、この目的に使用できるメモリバッファを提供します。
class ssl.MemoryBIO
Python と SSL プロトコルインスタンス間でデータをやり取りするために使用できるメモリバッファ。
pending
現在メモリバッファ中にあるバイト数を返します。
eof
メモリ BIOが現在ファイルの末尾にあるかを表す真偽値です。
read(n=-1)
メモリバッファから最大 n 読み取ります。n が指定されていないか、負値の場合、すべてのバイトが返されます。
write(buf)
buf からメモリ BIO にバイトを書き込みます。buf 引数は、バッファプロトコルをサポートするオブジェクトでなければなりません。
戻り値は、書き込まれるバイト数であり、常に buf の長さと等しくなります。
write_eof()
EOF マーカーをメモリ BIO に書き込みます。このメソッドが呼び出された後に write() を呼ぶことはできません。eof 属性は、バッファ内のすべてのデータが読み出された後に True になります。
SSL セッション
バージョン 3.6 で追加.
class ssl.SSLSession
session が使用するセッションオブジェクトです。
id
time
timeout
ticket_lifetime_hint
has_ticket
セキュリティで考慮すべき点
最善のデフォルト値
クライアントでの使用 では、セキュリティポリシーによる特殊な要件がない限りは、 create_default_context() 関数を使用して SSL コンテキストを作成することを強くお勧めします。この関数は、システムの信頼済み CA 証明書をロードし、証明書の検証とホスト名のチェックを有効化し、十分にセキュアなプロトコルと暗号を選択しようとします。
例として、 smtplib.SMTP クラスを使用して SMTP サーバーに対して信頼できるセキュアな接続を行う方法を以下に示します:
>>>
>>> import ssl, smtplib
>>> smtp = smtplib.SMTP("mail.python.org", port=587)
>>> context = ssl.create_default_context()
>>> smtp.starttls(context=context)
(220, b'2.0.0 Ready to start TLS')
接続にクライアントの証明書が必要な場合、 SSLContext.load_cert_chain() によって追加できます。
対照的に、自分自身で SSLContext クラスのコンストラクタを呼び出すことによって SSL コンテキストを作ると、デフォルトでは証明書検証もホスト名チェックも有効になりません。自分で設定を行う場合は、十分なセキュリティレベルを達成するために、以下のパラグラフをお読みください。
手動での設定
証明書の検証
SSLContext のコンストラクタを直接呼び出した場合、 CERT_NONE がデフォルトとして使われます。これは接続先の身元特定をしないので安全ではありませんし、特にクライアントモードでは大抵相手となるサーバの信憑性を保障したいでしょう。ですから、クライアントモードでは CERT_REQUIRED を強くお勧めします。ですが、それだけでは不十分です; SSLSocket.getpeercert() を呼び出してサーバ証明書が望んだサービスと合致するかのチェックもしなければなりません。多くのプロトコルとアプリケーションにとって、サービスはホスト名で特定されます; この場合、 match_hostname() が使えます。これらの共通的なチェックは SSLContext.check_hostname が有効な場合、自動的に行われます。
バージョン 3.7 で変更: Hostname matchings is now performed by OpenSSL. Python no longer uses match_hostname().
サーバモードにおいて、(より上位のレベルでの認証メカニズムではなく) SSL レイヤーを使ってあなたのクライアントを認証したいならば、 CERT_REQUIRED を指定して同じようにクライアントの証明書を検証すべきでしょう。
プロトコルのバージョン
SSL バージョン 2 と 3 は安全性に欠けると考えられており、使用するのは危険です。クライアントとサーバ間の互換性を最大限に確保したい場合、プロトコルバージョンとして PROTOCOL_TLS_CLIENT または PROTOCOL_TLS_SERVER を使用してください。 SSLv2 と SSLv3 はデフォルトで無効になっています。
>>>
>>> client_context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
>>> client_context.options |= ssl.OP_NO_TLSv1
>>> client_context.options |= ssl.OP_NO_TLSv1_1
上記で作成した SSL コンテキストは、TLSv1.2 以降 (システムでサポートされている場合) でのサーバへの接続のみを許可します。PROTOCOL_TLS_CLIENT は、デフォルトで証明書の検証とホスト名のチェックを意味します。コンテキスト中に証明書をロードする必要があります。
暗号の選択
マルチプロセス化
(例えば multiprocessing や concurrent.futures を使って、)マルチプロセスアプリケーションの一部としてこのモジュールを使う場合、OpenSSL の内部の乱数発生器は fork したプロセスを適切に処理しないことに気を付けて下さい。SSL の機能を os.fork() とともに使う場合、アプリケーションは親プロセスの PRNG 状態を変更しなければなりません。 RAND_add(), RAND_bytes(), RAND_pseudo_bytes() のいずれかの呼び出し成功があれば十分です。
TLS 1.3
バージョン 3.7 で追加.
LibreSSL support
参考
socket.socket クラス
下位レイヤーの socket クラスのドキュメント
SSL/TLS Strong Encryption: An Introduction
Intro from the Apache HTTP Server documentation
RFC 1422: Privacy Enhancement for Internet Electronic Mail: Part II: Certificate-Based Key Management
Steve Kent
RFC 4086: Randomness Requirements for Security
Donald E., Jeffrey I. Schiller
RFC 5280: Internet X.509 Public Key Infrastructure Certificate and Certificate Revocation List (CRL) Profile
D. Cooper
RFC 5246: The Transport Layer Security (TLS) Protocol Version 1.2
RFC 6066: Transport Layer Security (TLS) Extensions
D. Eastlake
IANA TLS: Transport Layer Security (TLS) Parameters
IANA
select --- I/O 処理の完了を待機する
このモジュールでは、ほとんどのオペレーティングシステムで利用可能な select() および poll() 関数、Solaris やその派生で利用可能な devpoll() 、Linux 2.5+ で利用可能な epoll() 、多くのBSDで利用可能な kqueue() 関数に対するアクセスを提供しています。 Windows 上ではソケットに対してしか動作しないので注意してください; その他のオペレーティングシステムでは、他のファイル形式でも (特に Unixではパイプにも) 動作します。通常のファイルに対して適用し、最後にファイルを読み出した時から内容が増えているかを決定するために使うことはできません。
注釈 selectors モジュールにより、select モジュールプリミティブに基づく高水準かつ効率的な I/O の多重化が行うことが出来ます。 OS レベルプリミティブを使用した正確な制御を求めない限り、このモジュールの使用が推奨されます。
このモジュールは以下を定義します:
exception select.error
OSError の非推奨のエイリアスです。
バージョン 3.3 で変更: PEP 3151 に基づき、このクラスは OSError のエイリアスになりました。
select.devpoll()
(Solaris およびその派生でのみサポートされています) /dev/poll ポーリングオブジェクトを返します。 ポーリングオブジェクトが提供しているメソッドについては ポーリングオブジェクト 節を参照してください。
devpoll() オブジェクトはインスタンス化時に許されるファイル記述子の数にリンクされます。 プログラムがこの値を減らす場合 devpoll() は失敗します。 プログラムがこの値を増やす場合 devpoll() は有効なファイル記述子の不完全なリストを返すことがあります。
新しいファイル記述子は 継承不可 です。
バージョン 3.3 で追加.
バージョン 3.4 で変更: 新しいファイル記述子が継承不可になりました。
select.epoll(sizehint=-1, flags=0)
(Only supported on Linux 2.5.44 and newer.) Return an edge polling object, which can be used as Edge or Level Triggered interface for I/O events.
sizehint informs epoll about the expected number of events to be registered. It must be positive, or -1 to use the default. It is only used on older systems where epoll_create1() is not available; otherwise it has no effect (though its value is still checked).
flags is deprecated and completely ignored. However, when supplied, its value must be 0 or select.EPOLL_CLOEXEC, otherwise OSError is raised.
エッジポーリングオブジェクトが提供しているメソッドについては エッジおよびレベルトリガポーリング (epoll) オブジェクト 節を参照してください。
epoll オブジェクトはコンテキストマネジメントプロトコルをサポートしています。 with 文内で使用された場合、新たなファイル記述子はブロックの最後で自動的に閉じられます。
新しいファイル記述子は 継承不可 です。
バージョン 3.3 で変更: flags 引数が追加されました。
バージョン 3.4 で変更: with 文のサポートが追加されました。新しいファイル記述子が継承不可になりました。
バージョン 3.4 で非推奨: flags パラメータ。 現在ではデフォルトで select.EPOLL_CLOEXEC が使われます。 ファイルディスクリプタを継承可能にするには os.set_inheritable() を使ってください。
select.poll()
(全てのオペレーティングシステムでサポートされているわけではありません) ポーリングオブジェクトを返します。このオブジェクトはファイル記述子を登録したり登録解除したりすることができ、ファイル記述子に対する I/O イベント発生をポーリングすることができます; ポーリングオブジェクトが提供しているメソッドについては ポーリングオブジェクト 節を参照してください。
select.kqueue()
(BSD でのみサポート) カーネルキュー(kernel queue)オブジェクトを返します。カーネルキューオブジェクトが提供しているメソッドについては、 kqueue オブジェクト 節を参照してください。
新しいファイル記述子は 継承不可 です。
バージョン 3.4 で変更: 新しいファイル記述子が継承不可になりました。
select.kevent(ident, filter=KQ_FILTER_READ, flags=KQ_EV_ADD, fflags=0, data=0, udata=0)
(BSD でのみサポート) カーネルイベント(kernel event)オブジェクトを返します。カーネルイベントオブジェクトが提供しているメソッドについては、 kevent オブジェクト 節を参照してください。
select.select(rlist, wlist, xlist[, timeout])
This is a straightforward interface to the Unix select() system call. The first three arguments are iterables of 'waitable objects': either integers representing file descriptors or objects with a parameterless method named fileno() returning such an integer:
rlist: 読み込み可能になるまで待機
wlist: 書き込み可能になるまで待機
xlist: "例外状態 (exceptional condition)" になるまで待機 ("例外状態" については、システムのマニュアルページを参照してください)
戻り値は準備完了状態のオブジェクトからなる 3 つのリストです: したがってこのリストはそれぞれ関数の最初の 3 つの引数のサブセットになります。ファイル記述子のいずれも準備完了にならないままタイムアウトした場合、3 つの空のリストが返されます。
注釈 select() は Windows のファイルオブジェクトを受理しませんが、ソケットは受理します。 Windows では、背後の select() 関数は WinSock ライブラリで提供されており、 WinSock によって生成されたものではないファイル記述子を扱うことができないのです。
バージョン 3.5 で変更: この関数は、シグナルによって中断された時に、 InterruptedError を上げる代わりに再計算されたタイムアウトによってリトライするようになりました。ただし、シグナルハンドラが例外を起こした場合を除きます (この論理的根拠については PEP 475 を見てください)。
select.PIPE_BUF
select(), poll() またはこのモジュールの別のインタフェースによってパイプが書き込む準備ができていると報告された時に、ブロックせずにパイプに書き込むことのできる最小のバイト数。これはソケットなどの他の種類の file-like オブジェクトには適用されません。
Availability: Unix
バージョン 3.2 で追加.
/dev/poll ポーリングオブジェクト
Solaris とその派生は、/dev/poll を持っています。 select() が O(最大のファイル記述子) 、 poll() が O(ファイル記述子の数) である一方、 /dev/poll は O(アクティブなファイル記述子) です。
/dev/poll の挙動は標準的な poll() オブジェクトに非常に近いです。
devpoll.close()
ポーリングオブジェクトのファイル記述子を閉じます。
バージョン 3.4 で追加.
devpoll.closed
ポーリングオブジェクトが閉じている場合 True です。
バージョン 3.4 で追加.
devpoll.fileno()
ポーリングオブジェクトのファイル記述子番号を返します。
バージョン 3.4 で追加.
devpoll.register(fd[, eventmask])
ファイル記述子をポーリングオブジェクトに登録します。これ以降の poll() メソッド呼び出しでは、そのファイル記述子に処理待ち中の I/O イベントがあるかどうかを監視します。 fd は整数か、整数値を返す fileno() メソッドを持つオブジェクトを取ります。ファイルオブジェクトも fileno() を実装しているので、引数として使うことができます。
eventmask はオプションのビットマスクで、どの種類の I/O イベントを監視したいかを記述します。 poll() オブジェクトと同じ定数が使われます。デフォルト値は定数 POLLIN 、 POLLPRI 、および POLLOUT の組み合わせです。
警告 登録済みのファイル記述子を登録してもエラーにはなりませんが、結果は未定義です。適切なアクションは、最初に unregister するか modify することです。これは poll() と比較した場合の重要な違いです。
devpoll.modify(fd[, eventmask])
このメソッドは unregister() に続いて register() を行います。 同じことを明示的に行うよりも (少し) 効率的です。
devpoll.unregister(fd)
ポーリングオブジェクトによって追跡中のファイル記述子を登録解除します。 register() メソッドと同様に、 fd は整数か、整数値を返す fileno() メソッドを持つオブジェクトを取ります。
登録されていないファイル記述子の削除を試みるのは安全に無視されます。
devpoll.poll([timeout])
登録されたファイル記述子に対してポーリングを行い、報告すべき I/O イベントまたはエラーの発生したファイル記述子毎に 2 要素のタプル (fd, event) からなるリストを返します。リストは空になることもあります。 fd はファイル記述子で、 event は該当するファイル記述子について報告されたイベントを表すビットマスクです --- 例えば POLLIN は入力待ちを示し、 POLLOUT はファイル記述子に対する書き込みが可能を示す、などです。空のリストは呼び出しがタイムアウトしたか、報告すべきイベントがどのファイル記述子でも発生しなかったことを示します。 timeout が与えられた場合、処理を戻すまで待機する時間の長さをミリ秒単位で指定します。 timeout が省略されたり、 -1 であったり、あるいは None の場合、そのポーリングオブジェクトが監視している何らかのイベントが発生するまでブロックします。
バージョン 3.5 で変更: この関数は、シグナルによって中断された時に、 InterruptedError を上げる代わりに再計算されたタイムアウトによってリトライするようになりました。ただし、シグナルハンドラが例外を起こした場合を除きます (この論理的根拠については PEP 475 を見てください)。
エッジおよびレベルトリガポーリング (epoll) オブジェクト
https://linux.die.net/man/4/epoll
eventmask
定数
意味
EPOLLIN
読み込み可能
EPOLLOUT
書き込み可能
EPOLLPRI
緊急の読み出しデータ
EPOLLERR
設定された fd にエラー状態が発生した
EPOLLHUP
設定された fd がハングアップした
EPOLLET
エッジトリガ動作に設定する。デフォルトではレベルトリガ動作
EPOLLONESHOT
1ショット動作に設定する。1回イベントが取り出されたら、その fd が内部で無効になる
EPOLLEXCLUSIVE
関連づけられた fd にイベントがある場合、1 つの epoll オブジェクトのみを起こします。デフォルトでは (このフラグが設定されていない場合には)、fd に対してポーリングするすべての epoll オブジェクトを起こします。
EPOLLRDHUP
ストリームソケットの他端が接続を切断したか、接続の書き込み側のシャットダウンを行った。
EPOLLRDNORM
EPOLLIN と同じ
EPOLLRDBAND
優先データバンドを読み込める。
EPOLLWRNORM
EPOLLOUT と同じ
EPOLLWRBAND
優先データに書き込みできる。
EPOLLMSG
無視される。
バージョン 3.6 で追加: EPOLLEXCLUSIVE was added. It's only supported by Linux Kernel 4.5 or later.
epoll.close()
epoll オブジェクトの制御用ファイル記述子を閉じます。
epoll.closed
epoll オブジェクトが閉じている場合 True です。
epoll.fileno()
制御用ファイル記述子の番号を返します。
epoll.fromfd(fd)
fd から epoll オブジェクトを作成します。
epoll.register(fd[, eventmask])
epoll オブジェクトにファイル記述子 fd を登録します。
epoll.modify(fd, eventmask)
登録されたファイル記述子変更します。
epoll.unregister(fd)
epoll オブジェクトから登録されたファイル記述子 fd を削除します。
バージョン 3.9 で変更: The method no longer ignores the EBADF error.
epoll.poll(timeout=None, maxevents=-1)
イベントを待機します。timeout はタイムアウト時間で、単位は秒 (float型) です。
バージョン 3.5 で変更: この関数は、シグナルによって中断された時に、 InterruptedError を上げる代わりに再計算されたタイムアウトによってリトライするようになりました。ただし、シグナルハンドラが例外を起こした場合を除きます (この論理的根拠については PEP 475 を見てください)。
ポーリングオブジェクト
poll() システムコールはほとんどの Unix システムでサポートされており、非常に多数のクライアントに同時にサービスを提供するようなネットワークサーバが高いスケーラビリティを持てるようにしています。 poll() は対象のファイル記述子を列挙するだけでよいため、良くスケールします。一方、 select() はビット対応表を構築し、対象ファイルの記述子に対応するビットを立て、その後全ての対応表の全てのビットを線形探索します。 select() は O(最大のファイル記述子番号) なのに対し、 poll() は O(対象とするファイル記述子の数) で済みます。
poll.register(fd[, eventmask])
ファイル記述子をポーリングオブジェクトに登録します。これ以降の poll() メソッド呼び出しでは、そのファイル記述子に処理待ち中の I/O イベントがあるかどうかを監視します。 fd は整数か、整数値を返す fileno() メソッドを持つオブジェクトを取ります。ファイルオブジェクトも fileno() を実装しているので、引数として使うことができます。
eventmask はオプションのビットマスクで、どの種類の I/O イベントを監視したいかを記述します。この値は以下の表で述べる定数 POLLIN 、 POLLPRI 、および POLLOUT の組み合わせにすることができます。ビットマスクを指定しない場合、標準の値が使われ、 3 種類のイベント全てに対して監視が行われます。
定数
意味
POLLIN
読み出し可能なデータが存在する
POLLPRI
緊急の読み出し可能なデータが存在する
POLLOUT
書き出しの準備ができている: 書き出し処理がブロックしない
POLLERR
何らかのエラー状態
POLLHUP
ハングアップ
POLLRDHUP
ストリームソケットの他端が接続を切断したか、接続の書き込み側のシャットダウンを行った。
POLLNVAL
無効な要求: 記述子が開かれていない
登録済みのファイル記述子を登録してもエラーにはならず、一度だけ登録した場合と同じ効果になります。
poll.modify(fd, eventmask)
登録されているファイル記述子 fd を変更する。これは、 register(fd, eventmask) と同じ効果を持ちます。登録されていないファイル記述子に対してこのメソッドを呼び出すと、 errno ENOENT で OSError 例外が発生します。
poll.unregister(fd)
ポーリングオブジェクトによって追跡中のファイル記述子を登録解除します。 register() メソッドと同様に、 fd は整数か、整数値を返す fileno() メソッドを持つオブジェクトを取ります。
登録されていないファイル記述子を登録解除しようとすると KeyError 例外が送出されます。
poll.poll([timeout])
登録されたファイル記述子に対してポーリングを行い、報告すべき I/O イベントまたはエラーの発生したファイル記述子毎に 2 要素のタプル (fd, event) からなるリストを返します。リストは空になることもあります。 fd はファイル記述子で、 event は該当するファイル記述子について報告されたイベントを表すビットマスクです --- 例えば POLLIN は入力待ちを示し、 POLLOUT はファイル記述子に対する書き込みが可能を示す、などです。空のリストは呼び出しがタイムアウトしたか、報告すべきイベントがどのファイル記述子でも発生しなかったことを示します。 timeout が与えられた場合、処理を戻すまで待機する時間の長さをミリ秒単位で指定します。 timeout が省略されたり、負の値であったり、あるいは None の場合、そのポーリングオブジェクトが監視している何らかのイベントが発生するまでブロックします。
バージョン 3.5 で変更: この関数は、シグナルによって中断された時に、 InterruptedError を上げる代わりに再計算されたタイムアウトによってリトライするようになりました。ただし、シグナルハンドラが例外を起こした場合を除きます (この論理的根拠については PEP 475 を見てください)。
kqueue オブジェクト
kqueue.close()
kqueue オブジェクトの制御用ファイル記述子を閉じる。
kqueue.closed
kqueue オブジェクトが閉じている場合 True です。
kqueue.fileno()
制御用ファイル記述子の番号を返します。
kqueue.fromfd(fd)
与えられたファイル記述子から、kqueue オブジェクトを作成する。
kqueue.control(changelist, max_events[, timeout]) → eventlist
kevent に対する低水準のインタフェース
changelist must be an iterable of kevent objects or None
max_events は 0 または正の整数
timeout in seconds (floats possible); the default is None, to wait forever
バージョン 3.5 で変更: この関数は、シグナルによって中断された時に、 InterruptedError を上げる代わりに再計算されたタイムアウトによってリトライするようになりました。ただし、シグナルハンドラが例外を起こした場合を除きます (この論理的根拠については PEP 475 を見てください)。
kevent オブジェクト
https://www.freebsd.org/cgi/man.cgi?query=kqueue&sektion=2
kevent.ident
イベントを特定するための値。この値は、フィルタにもよりますが、大抵の場合はファイル記述子です。コンストラクタでは、 ident として、整数値か fileno() メソッドを持ったオブジェクトを渡せます。 kevent は内部で整数値を保存します。
kevent.filter
カーネルフィルタの名前。
定数
意味
KQ_FILTER_READ
記述子を受け取り、読み込めるデータが存在する時に戻る
KQ_FILTER_WRITE
記述子を受け取り、書き込み可能な時に戻る
KQ_FILTER_AIO
AIO リクエスト
KQ_FILTER_VNODE
fflag で監視されたイベントが1つ以上発生したときに戻る
KQ_FILTER_PROC
プロセスID上のイベントを監視する
KQ_FILTER_NETDEV
ネットワークデバイス上のイベントを監視する (Mac OS X では利用不可)
KQ_FILTER_SIGNAL
監視しているシグナルがプロセスに届いたときに戻る
KQ_FILTER_TIMER
任意のタイマを設定する
kevent.flags
フィルタアクション。
定数
意味
KQ_EV_ADD
イベントを追加または修正する
KQ_EV_DELETE
キューからイベントを取り除く
KQ_EV_ENABLE
control() がイベントを返すのを許可する
KQ_EV_DISABLE
イベントを無効にする
KQ_EV_ONESHOT
イベントを最初の発生後無効にする
KQ_EV_CLEAR
イベントを受け取った後で状態をリセットする
KQ_EV_SYSFLAGS
内部イベント
KQ_EV_FLAG1
内部イベント
KQ_EV_EOF
フィルタ依存のEOF状態
KQ_EV_ERROR
戻り値を参照
kevent.fflags
フィルタ依存のフラグ。
KQ_FILTER_READ と KQ_FILTER_WRITE フィルタのフラグ:
定数
意味
KQ_NOTE_LOWAT
ソケットバッファの最低基準値
KQ_FILTER_VNODE フィルタのフラグ:
定数
意味
KQ_NOTE_DELETE
unlink() が呼ばれた
KQ_NOTE_WRITE
書き込みが発生した
KQ_NOTE_EXTEND
ファイルのサイズが拡張された
KQ_NOTE_ATTRIB
属性が変更された
KQ_NOTE_LINK
リンクカウントが変更された
KQ_NOTE_RENAME
ファイル名が変更された
KQ_NOTE_REVOKE
ファイルアクセスが破棄された
KQ_FILTER_PROC フィルタフラグ:
定数
意味
KQ_NOTE_EXIT
プロセスが終了した
KQ_NOTE_FORK
プロセスが fork() を呼び出した
KQ_NOTE_EXEC
プロセスが新しいプロセスを実行した
KQ_NOTE_PCTRLMASK
内部フィルタフラグ
KQ_NOTE_PDATAMASK
内部フィルタフラグ
KQ_NOTE_TRACK
fork() の呼び出しを超えてプロセスを監視する
KQ_NOTE_CHILD
NOTE_TRACK に対して子プロセスに渡される
KQ_NOTE_TRACKERR
子プロセスにアタッチできなかった
KQ_FILTER_NETDEV フィルタフラグ (Mac OS X では利用不可):
定数
意味
KQ_NOTE_LINKUP
リンクアップしている
KQ_NOTE_LINKDOWN
リンクダウンしている
KQ_NOTE_LINKINV
リンク状態が不正
kevent.data
フィルタ固有のデータ。
kevent.udata
ユーザー定義値。
selectors --- 高水準の I/O 多重化
バージョン 3.4 で追加.
ソースコード: Lib/selectors.py
はじめに
このモジュールにより、select モジュールプリミティブに基づく高水準かつ効率的な I/O の多重化が行えます。OS 水準のプリミティブを使用した正確な制御を求めない限り、このモジュールの使用が推奨されます。
このモジュールは BaseSelector 抽象基底クラスと、いくつかの具象実装 (KqueueSelector, EpollSelector...) を定義しており、これらは複数のファイルオブジェクトの I/O の準備状況の通知の待機に使用できます。以下では、 "ファイルオブジェクト" は、fileno() メソッドを持つあらゆるオブジェクトか、あるいは Raw ファイル記述子を意味します。ファイルオブジェクト を参照してください。
DefaultSelector は、現在のプラットフォームで利用できる、もっとも効率的な実装の別名になります: これはほとんどのユーザーにとってのデフォルトの選択になるはずです。
注釈 プラットフォームごとにサポートされているファイルオブジェクトのタイプは異なります: Windows ではソケットはサポートされますが、パイプはされません。Unix では両方がサポートされます (その他の fifo やスペシャルファイルデバイスなどのタイプもサポートされます)。
参考
select
低水準の I/O 多重化モジュールです。
クラス
クラス階層:
BaseSelector
+-- SelectSelector
+-- PollSelector
+-- EpollSelector
+-- DevpollSelector
+-- KqueueSelector
以下では、events は与えられたファイルオブジェクトを待機すべき I/O イベントを示すビット単位のマスクになります。これには以下のモジュール定数の組み合わせを設定できます:
定数
意味
EVENT_READ
読み込み可能
EVENT_WRITE
書き込み可能
class selectors.SelectorKey
SelectorKey はそれの下層のファイルディスクリプタ、選択したイベントマスク、および付属データへのファイルオブジェクトの関連付けに使用される namedtuple です。いくつかの BaseSelector メソッドを返します。
fileobj
登録されたファイルオブジェクトです。
fd
下層のファイル記述子です。
events
このファイルオブジェクトで待機しなければならないイベントです。
data
このファイルオブジェクトに関連付けられたオプションの不透明型 (Opaque) データです。例えば、これはクライアントごとのセッション ID を格納するために使用できます。
class selectors.BaseSelector
BaseSelector は複数のファイルオブジェクトの I/O イベントの準備状況の待機に使用されます。これはファイルストリームを登録、登録解除、およびこれらのストリームでの I/O イベントを待機 (オプションでタイムアウト) するメソッドをサポートします。これは抽象基底クラスであるため、インスタンスを作成できません。使用する実装を明示的に指定したい、そしてプラットフォームがそれをサポートしている場合は、代わりに DefaultSelector を使用するか、SelectSelector や KqueueSelector などの一つを使用します。BaseSelector とその具象実装は コンテキストマネージャー プロトコルをサポートしています。
abstractmethod register(fileobj, events, data=None)
I/O イベントを監視するファイルオブジェクトをセレクションに登録します。
fileobj は監視するファイルオブジェクトです。これは整数のファイル記述子か、fileno() メソッドを持つオブジェクトのどちらかになります。events は監視するイベントのビット幅マスクになります。data は不透明型 (Opaque) オブジェクトです。
これは新しい SelectorKey インスタンスを返します。不正なイベントマスク化ファイル記述子のときは ValueError が、ファイルオブジェクトがすでに登録済みのときは KeyError が送出されます。
abstractmethod unregister(fileobj)
ファイルオブジェクトのセレクション登録を解除し、監視対象から外します。ファイルオブジェクトの登録解除はそのクローズより前に行われます。
fileobj は登録済みのファイルオブジェクトでなければなりません。
関連付けられた SelectorKey インスタンスを返します。fileobj が登録されていない場合 KeyError を送出します。fileobj が不正な場合 (例えば fileobj に fileno() メソッドが無い場合や fileno() メソッドの戻り値が不正な場合) ValueError を送出します。
modify(fileobj, events, data=None)
登録されたファイルオブジェクトの監視されたイベントや付属データを変更します。
より効率的に実装できる点を除けば、 BaseSelector.unregister(fileobj)() に続けて BaseSelector.register(fileobj, events, data)() を行うのと等価です。
新たな SelectorKey インスタンスを返します。 イベントマスクやファイル記述子が不正な場合は ValueError を、ファイルオブジェクトが登録されていない場合は KeyError を送出します。
abstractmethod select(timeout=None)
登録されたいくつかのファイルオブジェクトが準備できたか、タイムアウトするまで待機します。
timeout > 0 の場合、最大待機時間を秒で指定します。 timeout <= 0 の場合、この関数の呼び出しはブロックせず、 現在準備できているファイルオブジェクトを報告します。 timeout が None の場合、監視しているファイルオブジェクトの一つが準備できるまでブロックします。
この関数は (key, events) タプルのリストを返します。準備できたファイルオブジェクトにつき1タプルです。
key は準備状態のファイルオブジェクトに対応する SelectorKey インスタンスです。 events はそのファイルオブジェクトで準備が完了したイベントのビットマスクです。
注釈 このメソッドは、現在のプロセスで信号を受信した場合、どのファイルオブジェクトも準備完了にならないうちに、またはタイムアウトが経過する前に返ることがあります。その場合、空のリストが返されます。
バージョン 3.5 で変更: このセレクタは、シグナルによって中断された時に、シグナルハンドラが例外を起こさなかった場合、空のイベントリストを返すのではなく、再計算されたタイムアウトによってリトライするようになりました (この論拠については PEP 475 を参照してください)。
close()
セレクタを閉じます。
下層のリソースがすべて解放されたことを確かめるために呼ばれなければなりません。一旦閉じられたセレクタは使ってはいけません。
get_key(fileobj)
登録されたファイルオブジェクトに関連付けられたキーを返します。
そのファイルオブジェクトに関連付けられた SelectorKey インスタンスを返します。そのファイルオブジェクトが登録されていない場合 KeyError を送出します。
abstractmethod get_map()
ファイルオブジェクトからセレクタキーへのマッピングを返します。
これは、登録済みのファイルオブジェクトを、それらに関連づけられた SelectorKey インスタンスにマッピングする Mapping のインスタンスを返します。
class selectors.DefaultSelector
デフォルトの selector クラスで、現在のプラットフォームで利用できる最も効率的な実装を使用しています。大半のユーザはこれをデフォルトにすべきです。
class selectors.SelectSelector
select.select() を基底とするセレクタです。
class selectors.PollSelector
select.poll() を基底とするセレクタです。
class selectors.EpollSelector
select.epoll() を基底とするセレクタです。
fileno()
下層の select.epoll() オブジェクトが使用しているファイル記述子を返します。
class selectors.DevpollSelector
select.devpoll() を基底とするセレクタです。
fileno()
下層の select.devpoll() オブジェクトが使用しているファイル記述子を返します。
バージョン 3.5 で追加.
class selectors.KqueueSelector
select.kqueue() を基底とするセレクタです。
fileno()
下層の select.kqueue() オブジェクトが使用しているファイル記述子を返します。
使用例
簡単なエコーサーバの実装です:
import selectors
import socket
sel = selectors.DefaultSelector()
def accept(sock, mask):
    conn, addr = sock.accept()  # Should be ready
    print('accepted', conn, 'from', addr)
    conn.setblocking(False)
    sel.register(conn, selectors.EVENT_READ, read)
def read(conn, mask):
    data = conn.recv(1000)  # Should be ready
    if data:
        print('echoing', repr(data), 'to', conn)
        conn.send(data)  # Hope it won't block
    else:
        print('closing', conn)
        sel.unregister(conn)
        conn.close()
sock = socket.socket()
sock.bind(('localhost', 1234))
sock.listen(100)
sock.setblocking(False)
sel.register(sock, selectors.EVENT_READ, accept)
while True:
    events = sel.select()
    for key, mask in events:
        callback = key.data
        callback(key.fileobj, mask)
asyncore --- 非同期ソケットハンドラ
ソースコード: Lib/asyncore.py
バージョン 3.6 で非推奨: 代わりに asyncio を使ってください。
注釈 このモジュールは後方互換性のためだけに存在します。新しいコードでは asyncio を利用することを推奨します。
このモジュールは、非同期ソケットサービスのクライアント・サーバを開発するための基盤として使われます。
CPUが一つしかない場合、プログラムが"二つのことを同時に"実行する方法は二つしかありません。もっとも簡単で一般的なのはマルチスレッドを利用する方法ですが、これとはまったく異なるテクニックで、一つのスレッドだけでマルチスレッドと同じような効果を得られるテクニックがあります。このテクニックはI/O処理が中心である場合にのみ有効で、CPU負荷の高いプログラムでは効果が無く、この場合にはプリエンプティブなスケジューリングが可能なスレッドが有効でしょう。しかし、多くの場合、ネットワークサーバではCPU負荷よりはIO負荷が問題となります。
もしOSのI/Oライブラリがシステムコール select() をサポートしている場合（ほとんどの場合はサポートされている）、I/O処理は"バックグラウンド"で実行し、その間に他の処理を実行すれば、複数の通信チャネルを同時にこなすことができます。一見、この戦略は奇妙で複雑に思えるかもしれませんが、いろいろな面でマルチスレッドよりも理解しやすく、制御も容易です。 asyncore は多くの複雑な問題を解決済みなので、洗練され、パフォーマンスにも優れたネットワークサーバとクライアントを簡単に開発することができます。とくに、 asynchat のような、対話型のアプリケーションやプロトコルには非常に有効でしょう。
基本的には、この二つのモジュールを使う場合は一つ以上のネットワーク チャネル を asyncore.dispatcher クラス、または asynchat.async_chat のインスタンスとして作成します。作成されたチャネルはグローバルマップに登録され、 loop() 関数で参照されます。 loop() には、専用の マップ を渡す事も可能です。
チャネルを生成後、 loop() を呼び出すとチャネル処理が開始し、最後のチャネル（非同期処理中にマップに追加されたチャネルを含む）が閉じるまで継続します。
asyncore.loop([timeout[, use_poll[, map[, count]]]])
ポーリングループを開始し、count 回が過ぎるか、全てのオープン済みチャネルがクローズされた場合のみ終了します。全ての引数はオプションです。引数 count のデフォルト値は None で、ループは全てのチャネルがクローズされた場合のみ終了します。引数 timeout は select() または poll() の引数 timeout として渡され、秒単位で指定します。デフォルト値は 30 秒です。引数 use_poll が真の場合、 select() ではなく poll() が使われます (デフォルト値は False です)。
引数 map には、監視するチャネルをアイテムとして格納した辞書を指定します。チャネルがクローズされた時に map からそのチャネルが削除されます。 map が省略された場合、グローバルなマップが使用されます。チャネル (asyncore.dispatcher, asynchat.async_chat とそのサブクラス) は自由に混ぜて map に入れることができます。
class asyncore.dispatcher
dispatcher クラスは、低レベルソケットオブジェクトの薄いラッパーです。便宜上、非同期ループから呼び出されるイベント処理メソッドを追加していますが、これ以外の点では、non-blockingなソケットと同様です。
非同期ループ内で低レベルイベントが発生した場合、発生のタイミングやコネクションの状態から特定の高レベルイベントへと置き換えることができます。例えばソケットを他のホストに接続する場合、最初の書き込み可能イベントが発生すれば接続が完了した事が分かります(この時点で、ソケットへの書き込みは成功すると考えられる)。このように判定できる高レベルイベントを以下に示します:
Event
説明
handle_connect()
最初にreadもしくはwriteイベントが発生した時
handle_close()
読み込み可能なデータなしでreadイベントが発生した時
handle_accepted()
listen中のソケットでreadイベントが発生した時
非同期処理中、マップに登録されたチャネルの readable() メソッドと writable() メソッドが呼び出され、 select() か poll() でread/writeイベントを検出するリストに登録するか否かを判定します。
このようにして、チャネルでは低レベルなソケットイベントの種類より多くの種類のイベントを検出する事ができます。以下にあげるイベントは、サブクラスでオーバライドすることが可能です:
handle_read()
非同期ループで、チャネルのソケットの read() メソッドの呼び出しが成功した時に呼び出されます。
handle_write()
非同期ループで、書き込み可能ソケットが実際に書き込み可能になった時に呼び出されます。このメソッドでは、しばしばパフォーマンスの向上のために必要なバッファリングを実装します。例:
def handle_write(self):
    sent = self.send(self.buffer)
    self.buffer = self.buffer[sent:]
handle_expt()
out of band (OOB)データが検出された時に呼び出されます。OOBはあまりサポートされておらず、また滅多に使われないので、handle_expt() が呼び出されることはほとんどありません。
handle_connect()
ソケットの接続が確立した時に呼び出されます。"welcome"バナーの送信、プロトコルネゴシエーションの初期化などを行います。
handle_close()
ソケットが閉じた時に呼び出されます。
handle_error()
捕捉されない例外が発生した時に呼び出されます。デフォルトでは、短縮したトレースバック情報が出力されます。
handle_accept()
listen 中のチャネル (受動的にオープンしたもの) がリモートホストからの connect() で接続され、接続が確立した時に呼び出されます。 バージョン 3.2 で非推奨になりました; 代わりに handle_accepted() を使ってください。
バージョン 3.2 で非推奨.
handle_accepted(sock, addr)
listen 中のチャネル (受動的にオープンしたもの) がリモートホストからの connect() で接続され、接続が確立した時に呼び出されます。 sock はその接続でデータを送受信するのに使える 新しい ソケットオブジェクトで、 addr は接続の対向のソケットに bind されているアドレスです。
バージョン 3.2 で追加.
readable()
非同期ループ中に呼び出され、readイベントの監視リストに加えるか否かを決定します。デフォルトのメソッドでは True を返し、readイベントの発生を監視します。
writable()
非同期ループ中に呼び出され、writeイベントの監視リストに加えるか否かを決定します。デフォルトのメソッドでは True を返し、writeイベントの発生を監視します。
さらに、チャネルにはソケットのメソッドとほぼ同じメソッドがあり、チャネルはソケットのメソッドの多くを委譲・拡張しており、ソケットとほぼ同じメソッドを持っています。
create_socket(family=socket.AF_INET, type=socket.SOCK_STREAM)
引数も含め、通常のソケット生成と同一です。ソケットの生成については、 socket モジュールのドキュメントを参照してください。
バージョン 3.3 で変更: family 引数と type 引数が省略可能になりました。
connect(address)
通常のソケットオブジェクトと同様、address には一番目の値が接続先ホスト、2番目の値がポート番号であるタプルを指定します。
send(data)
リモート側の端点に data を送出します。
recv(buffer_size)
リモート側の端点より、最大 buffer_size バイトのデータを読み込みます。長さ0のバイト列オブジェクトが返ってきた場合、チャネルはリモートから切断された事を示します。
select.select() や select.poll() がソケットが読み込みできる状態にあると報告したとしても、 recv() が BlockingIOError を送出する場合があります。
listen(backlog)
ソケットへの接続を待ちます。引数 backlog は、キューに追加できるコネクションの最大数 (1 以上) を指定します。最大値はシステムに依存します（通常は5)。
bind(address)
ソケットを address にバインドします。ソケットはバインド済みであってはなりません。 (address の形式は、アドレスファミリに依存します。 socket モジュールを参照のこと。) ソケットを再利用可能にする (SO_REUSEADDR オプションを設定する) には、 dispatcher オブジェクトの set_reuse_addr() メソッドを呼び出してください。
accept()
接続を受け入れます。ソケットはアドレスにバインド済みであり、listen() で接続待ち状態でなければなりません。戻り値は None か (conn, address) のペアで、conn はデータの送受信を行う 新しい ソケットオブジェクト、address は接続先ソケットがバインドされているアドレスです。None が返された場合、接続が起こらなかったことを意味します。その場合、サーバーはこのイベントを無視して後続の接続を待ち続けるべきです。
close()
ソケットをクローズします。以降の全ての操作は失敗します。リモート端点では、キューに溜まったデータ以外、これ以降のデータ受信は行えません。ソケットはガベージコレクト時に自動的にクローズされます。
class asyncore.dispatcher_with_send
dispatcher のサブクラスで、シンプルなバッファされた出力機能を持ちます。シンプルなクライアントプログラムに適しています。もっと高レベルな場合には asynchat.async_chat を利用してください。
class asyncore.file_dispatcher
file_dispatcher はファイルデスクリプタか ファイルオブジェクト とオプションとして map を引数にとって、 poll() か loop() 関数で利用できるようにラップします。与えられたファイルオブジェクトなどが fileno() メソッドを持っているとき、そのメソッドが呼び出されて戻り値が file_wrapper のコンストラクタに渡されます。
利用可能な環境: Unix。
class asyncore.file_wrapper
file_wrapper は整数のファイルデスクリプタを受け取って os.dup() を呼び出してハンドルを複製するので、元のハンドルは file_wrapper と独立してclose されます。このクラスは file_dispatcher クラスが使うために必要なソケットをエミュレートするメソッドを実装しています。
利用可能な環境: Unix。
asyncoreの例: 簡単なHTTPクライアント
基本的なサンプルとして、以下に非常に単純なHTTPクライアントを示します。このHTTPクライアントは dispatcher クラスでソケットを利用しています:
import asyncore
class HTTPClient(asyncore.dispatcher):
    def __init__(self, host, path):
        asyncore.dispatcher.__init__(self)
        self.create_socket()
        self.connect( (host, 80) )
        self.buffer = bytes('GET %s HTTP/1.0\r\nHost: %s\r\n\r\n' %
                            (path, host), 'ascii')
    def handle_connect(self):
        pass
    def handle_close(self):
        self.close()
    def handle_read(self):
        print(self.recv(8192))
    def writable(self):
        return (len(self.buffer) > 0)
    def handle_write(self):
        sent = self.send(self.buffer)
        self.buffer = self.buffer[sent:]
client = HTTPClient('www.python.org', '/')
asyncore.loop()
基本的な echo サーバーの例
この例の基本的な echoサーバーは、 dispatcher を利用して接続を受けつけ、接続をハンドラーにディスパッチします:
import asyncore
class EchoHandler(asyncore.dispatcher_with_send):
    def handle_read(self):
        data = self.recv(8192)
        if data:
            self.send(data)
class EchoServer(asyncore.dispatcher):
    def __init__(self, host, port):
        asyncore.dispatcher.__init__(self)
        self.create_socket()
        self.set_reuse_addr()
        self.bind((host, port))
        self.listen(5)
    def handle_accepted(self, sock, addr):
        print('Incoming connection from %s' % repr(addr))
        handler = EchoHandler(sock)
server = EchoServer('localhost', 8080)
asyncore.loop()
asynchat --- 非同期ソケットコマンド/レスポンスハンドラ
ソースコード: Lib/asynchat.py
バージョン 3.6 で非推奨: 代わりに asyncio を使ってください。
注釈 このモジュールは後方互換性のためだけに存在します。新しいコードでは asyncio を利用することを推奨します。
asynchat を使うと、 asyncore を基盤とした非同期なサーバ・クライアントをより簡単に開発する事ができます。 asynchat では、プロトコルの要素が任意の文字列で終了するか、または可変長の文字列であるようなプロトコルを容易に制御できるようになっています。 asynchat は、抽象クラス async_chat を定義しており、 async_chat を継承して collect_incoming_data() メソッドと found_terminator() メソッドを実装すれば使うことができます。 async_chat と asyncore は同じ非同期ループを使用しており、 asyncore.dispatcher も asynchat.async_chat も同じチャネルマップに登録する事ができます。通常、 asyncore.dispatcher はサーバチャネルとして使用し、リクエストの受け付け時に asynchat.async_chat オブジェクトを生成します。
class asynchat.async_chat
このクラスは、 asyncore.dispatcher から継承した抽象クラスです。使用する際には async_chat のサブクラスを作成し、 collect_incoming_data() と found_terminator() を定義しなければなりません。 asyncore.dispatcher のメソッドを使用する事もできますが、メッセージ/レスポンス処理を中心に行う場合には使えないメソッドもあります。
asyncore.dispatcher と同様に、 async_chat も select() 呼出し後のソケットの状態からイベントを生成します。ポーリングループ開始後、イベント処理フレームワークが自動的に async_chat のメソッドを呼び出しますので、プログラマが処理を記述する必要はありません。
パフォーマンスの向上やメモリの節約のために、2つのクラス属性を調整することができます。
ac_in_buffer_size
非同期入力バッファサイズ (デフォルト値: 4096)。
ac_out_buffer_size
非同期出力バッファサイズ (デフォルト値: 4096)。
async_chat のサブクラスでは、入力メソッド collect_incoming_data() と found_terminator() を定義し、チャネルが非同期に受信するデータを処理します。これらのメソッドについては後ろで解説します。
async_chat.close_when_done()
async_chat.collect_incoming_data(data)
チャネルが受信した不定長のデータを data に指定して呼び出されます。このメソッドは必ずオーバライドする必要があり、デフォルトの実装では、 NotImplementedError 例外を送出します。
async_chat.discard_buffers()
async_chat.found_terminator()
入力データストリームが、 set_terminator() で指定した終了条件と一致した場合に呼び出されます。このメソッドは必ずオーバライドする必要があり、デフォルトの実装では、 NotImplementedError 例外を送出します。入力データを参照する必要がある場合でも引数としては与えられないため、入力バッファをインスタンス属性として参照しなければなりません。
async_chat.get_terminator()
現在のチャネルの終了条件を返します。
async_chat.push(data)
async_chat.push_with_producer(producer)
async_chat.set_terminator(term)
チャネルで検出する終了条件を設定します。term は入力プロトコルデータの処理方式によって以下の3つの型の何れかを指定します。
term
説明
string
入力ストリーム中でstringが検出された時、 found_terminator() を呼び出します
integer
指定された文字数が読み込まれた時、 found_terminator() を呼び出します
None
永久にデータを読み込みます
終了条件が成立しても、その後に続くデータは、 found_terminator() の呼出し後に再びチャネルを読み込めば取得する事ができます。
asynchat 使用例
以下のサンプルは、 async_chat でHTTPリクエストを読み込む処理の一部です。Webサーバは、クライアントからの接続毎に http_request_handler オブジェクトを作成します。最初はチャネルの終了条件に空行を指定してHTTPヘッダの末尾までを検出し、その後ヘッダ読み込み済みを示すフラグを立てています。
ヘッダ読み込んだ後、リクエストの種類がPOSTであればデータが入力ストリームに流れるため、Content-Length: ヘッダの値を数値として終了条件に指定し、適切な長さのデータをチャネルから読み込みます。
必要な入力データを全て入手したら、チャネルの終了条件に None を指定して残りのデータを無視するようにしています。この後、 handle_request() が呼び出されます。
import asynchat
class http_request_handler(asynchat.async_chat):
    def __init__(self, sock, addr, sessions, log):
        asynchat.async_chat.__init__(self, sock=sock)
        self.addr = addr
        self.sessions = sessions
        self.ibuffer = []
        self.obuffer = b""
        self.set_terminator(b"\r\n\r\n")
        self.reading_headers = True
        self.handling = False
        self.cgi_data = None
        self.log = log
    def collect_incoming_data(self, data):
        """Buffer the data"""
        self.ibuffer.append(data)
    def found_terminator(self):
        if self.reading_headers:
            self.reading_headers = False
            self.parse_headers(b"".join(self.ibuffer))
            self.ibuffer = []
            if self.op.upper() == b"POST":
                clen = self.headers.getheader("content-length")
                self.set_terminator(int(clen))
            else:
                self.handling = True
                self.set_terminator(None)
                self.handle_request()
        elif not self.handling:
            self.set_terminator(None)  # browsers sometimes over-send
            self.cgi_data = parse(self.headers, b"".join(self.ibuffer))
            self.handling = True
            self.ibuffer = []
            self.handle_request()
signal --- 非同期イベントにハンドラを設定する
このモジュールでは Python でシグナルハンドラを使うための機構を提供します。
一般的なルール
特定のシグナルに対するハンドラが一度設定されると、明示的にリセットしないかぎり設定されたままになります (Python は背後の実装系に関係なく BSD 形式のインタフェースをエミュレートします)。例外は SIGCHLD のハンドラで、この場合は背後の実装系の仕様に従います。
Python のシグナルハンドラの実行
Python のシグナルハンドラは、低水準 (C言語) のシグナルハンドラ内で実行されるわけではありません。代わりに、低水準のシグナルハンドラが virtual machine が対応する Python のシグナルハンドラを後から (例えば次の bytecode 命令時に) 実行するようにフラグを立てます:
完全にCで実装された長時間かかる計算 (大きいテキストに対する正規表現のマッチなど) は、どのシグナルを受信しても中断されないまま長時間実行され続ける可能性があります。Python のシグナルハンドラはその計算が終了してから呼び出されます。
シグナルとスレッド
モジュールの内容
バージョン 3.5 で変更: signal (SIG*), handler (SIG_DFL, SIG_IGN) and sigmask (SIG_BLOCK, SIG_UNBLOCK, SIG_SETMASK) related constants listed below were turned into enums. getsignal(), pthread_sigmask(), sigpending() and sigwait() functions return human-readable enums.
以下に signal モジュールで定義されている変数を示します:
signal.SIG_DFL
二つある標準シグナル処理オプションのうちの一つです; 単純にシグナルに対する標準の関数を実行します。例えば、ほとんどのシステムでは、 SIGQUIT に対する標準の動作はコアダンプと終了で、 SIGCHLD に対する標準の動作は単にシグナルの無視です。
signal.SIG_IGN
もう一つの標準シグナル処理オプションで、受け取ったシグナルを単に無視します。
signal.SIGABRT
signal.SIGALRM
利用可能な環境: Unix。
signal.SIGBREAK
利用可能な環境: Windows 。
signal.SIGBUS
利用可能な環境: Unix。
signal.SIGCHLD
利用可能な環境: Unix。
signal.SIGCLD
signal.SIGCONT
Continue the process if it is currently stopped
利用可能な環境: Unix。
signal.SIGFPE
参考 ZeroDivisionError is raised when the second argument of a division or modulo operation is zero.
signal.SIGHUP
利用可能な環境: Unix。
signal.SIGILL
signal.SIGINT
signal.SIGKILL
利用可能な環境: Unix。
signal.SIGPIPE
利用可能な環境: Unix。
signal.SIGSEGV
signal.SIGTERM
signal.SIGUSR1
利用可能な環境: Unix。
signal.SIGUSR2
利用可能な環境: Unix。
signal.SIGWINCH
利用可能な環境: Unix。
SIG*
signal.CTRL_C_EVENT
CTRL+C キーストロークに該当するシグナル。このシグナルは os.kill() でだけ利用できます。
利用可能な環境: Windows 。
バージョン 3.2 で追加.
signal.CTRL_BREAK_EVENT
CTRL+BREAK キーストロークに該当するシグナル。このシグナルは os.kill() でだけ利用できます。
利用可能な環境: Windows 。
バージョン 3.2 で追加.
signal.NSIG
最も大きいシグナル番号に 1 を足した値です。
signal.ITIMER_REAL
実時間でデクリメントするインターバルタイマーです。タイマーが発火したときに SIGALRM を送ります。
signal.ITIMER_VIRTUAL
プロセスの実行時間だけデクリメントするインターバルタイマーです。タイマーが発火したときに SIGVTALRM を送ります。
signal.ITIMER_PROF
プロセスの実行中と、システムがそのプロセスのために実行している時間だけデクリメントするインターバルタイマーです。ITIMER_VIRTUAL と組み合わせて、このタイマーはよくアプリケーションがユーザー空間とカーネル空間で消費した時間のプロファイリングに利用されます。タイマーが発火したときに SIGPROF を送ります。
signal.SIG_BLOCK
pthread_sigmask() の how 引数に渡せる値で、シグナルがブロックされることを意味します。
バージョン 3.3 で追加.
signal.SIG_UNBLOCK
pthread_sigmask() の how 引数に渡せる値で、シグナルがブロック解除されることを意味します。
バージョン 3.3 で追加.
signal.SIG_SETMASK
pthread_sigmask() の how 引数に渡せる値で、シグナルが置換されることを意味します。
バージョン 3.3 で追加.
signal モジュールは1つの例外を定義しています:
exception signal.ItimerError
背後の setitimer() または getitimer() 実装からエラーを通知するために送出されます。無効なインタバルタイマーや負の時間が setitimer() に渡された場合、このエラーを予期してください。このエラーは OSError を継承しています。
バージョン 3.3 で追加: このエラーは以前は IOError のサブタイプでしたが、 OSError のエイリアスになりました。
signal モジュールでは以下の関数を定義しています:
signal.alarm(time)
signal.getsignal(signalnum)
シグナル signalnum に対する現在のシグナルハンドラを返します。戻り値は呼び出し可能な Python オブジェクトか、 signal.SIG_IGN、 signal.SIG_DFL、および None といった特殊な値のいずれかです。ここで signal.SIG_IGN は以前そのシグナルが無視されていたことを示し、 signal.SIG_DFL は以前そのシグナルの標準の処理方法が使われていたことを示し、 None はシグナルハンドラがまだ Python によってインストールされていないことを示します。
signal.strsignal(signalnum)
バージョン 3.8 で追加.
signal.valid_signals()
バージョン 3.8 で追加.
signal.pause()
sigwait(), sigwaitinfo(), sigtimedwait() sigpending() も参照してください。
signal.raise_signal(signum)
バージョン 3.8 で追加.
signal.pidfd_send_signal(pidfd, sig, siginfo=None, flags=0)
Availability: Linux 5.1+
バージョン 3.9 で追加.
signal.pthread_kill(thread_id, signalnum)
os.kill() を参照してください。
バージョン 3.3 で追加.
signal.pthread_sigmask(how, mask)
これを呼び出すスレッドにセットされているシグナルマスクを取り出したり変更したりします。シグナルマスクは、呼び出し側のために現在どのシグナルの配送がブロックされているかを示す集合 (set) です。呼び出し前のもとのシグナルマスクを集合として返却します。
この関数の振る舞いは how に依存して以下のようになります。
SIG_BLOCK: mask で指定されるシグナルが現時点のシグナルマスクに追加されます。
SIG_UNBLOCK: mask で指定されるシグナルが現時点のシグナルマスクから取り除かれます。もともとブロックされていないシグナルをブロック解除しようとしても問題ありません。
SIG_SETMASK: シグナルマスク全体を mask としてセットします。
mask is a set of signal numbers (e.g. {signal.SIGINT, signal.SIGTERM}). Use valid_signals() for a full mask including all signals.
呼び出しスレッドにセットされたシグナルマスクを問い合わせるには例えば signal.pthread_sigmask(signal.SIG_BLOCK, []) とします。
pause(), sigpending(), sigwait() も参照して下さい。
バージョン 3.3 で追加.
signal.setitimer(which, seconds, interval=0.0)
インターバルタイマーが起動したとき、シグナルがプロセスに送られます。送られるシグナルは利用されたタイマーの種類に依存します。 signal.ITIMER_REAL の場合は SIGALRM が、 signal.ITIMER_VIRTUAL の場合は SIGVTALRM が、 signal.ITIMER_PROF の場合は SIGPROF が送られます。
以前の値が (delay, interval) のタプルとして返されます。
利用可能な環境: Unix。
signal.getitimer(which)
利用可能な環境: Unix。
signal.set_wakeup_fd(fd, *, warn_on_full_buffer=True)
バージョン 3.5 で変更: Windowsで、この関数はソケットハンドルをサポートするようになりました。
バージョン 3.7 で変更: Added warn_on_full_buffer parameter.
signal.siginterrupt(signalnum, flag)
signal() を使ってシグナルハンドラを設定したときに、暗黙のうちに flag に true を指定して siginterrupt() が実行されるため、中断に対するリスタートの動作がリセットされることに注意してください。
signal.signal(signalnum, handler)
Set the handler for signal signalnum to the function handler. handler can be a callable Python object taking two arguments (see below), or one of the special values signal.SIG_IGN or signal.SIG_DFL. The previous signal handler will be returned (see the description of getsignal() above). (See the Unix man page signal(2) for further information.)
handler は二つの引数とともに呼び出されます: シグナル番号、および現在のスタックフレーム (None またはフレームオブジェクト; フレームオブジェクトについての記述は 標準型の階層における説明 か、 inspect モジュールの属性の説明を参照してください)。
signal.sigpending()
呼び出しスレッドで配送が保留されているシグナル (つまり配送がブロックされている間に発生したシグナル) の集合を調べます。保留中のシグナルの集合を返します。
pause(), pthread_sigmask(), sigwait() も参照して下さい。
バージョン 3.3 で追加.
signal.sigwait(sigset)
sigset 集合で指定されたシグナルのうちどれか一つが届くまで呼び出しスレッドを一時停止します。この関数はそのシグナルを受け取ると (それを保留シグナルリストから取り除いて) そのシグナル番号を返します。
pause(), pthread_sigmask(), sigpending(), sigwaitinfo(), sigtimedwait() も参照して下さい。
バージョン 3.3 で追加.
signal.sigwaitinfo(sigset)
pause(), sigwait(), sigtimedwait() も参照して下さい。
バージョン 3.3 で追加.
バージョン 3.5 で変更: The function is now retried if interrupted by a signal not in sigset and the signal handler does not raise an exception (see PEP 475 for the rationale).
signal.sigtimedwait(sigset, timeout)
pause(), sigwait(), sigwaitinfo() も参照して下さい。
バージョン 3.3 で追加.
バージョン 3.5 で変更: The function is now retried with the recomputed timeout if interrupted by a signal not in sigset and the signal handler does not raise an exception (see PEP 475 for the rationale).
使用例
以下は最小限のプログラム例です。この例では alarm() を使ってファイルを開く処理を待つのに費やす時間を制限します; 例えば、電源の入っていないシリアルデバイスを開こうとすると、通常 os.open() は未定義の期間ハングアップしてしまいますが、この方法はそうした場合に便利です。ここではファイルを開くまで 5 秒間のアラームを設定することで解決しています; ファイルを開く処理が長くかかりすぎると、アラームシグナルが送信され、ハンドラが例外を送出するようになっています。
import signal, os
def handler(signum, frame):
    print('Signal handler called with signal', signum)
    raise OSError("Couldn't open device!")
# Set the signal handler and a 5-second alarm
signal.signal(signal.SIGALRM, handler)
signal.alarm(5)
# This open() may hang indefinitely
fd = os.open('/dev/ttyS0', os.O_RDWR)
signal.alarm(0)          # Disable the alarm
Note on SIGPIPE
Piping output of your program to tools like head(1) will cause a SIGPIPE signal to be sent to your process when the receiver of its standard output closes early. This results in an exception like BrokenPipeError: [Errno 32] Broken pipe. To handle this case, wrap your entry point to catch this exception as follows:
import os
import sys
def main():
    try:
        # simulate large output (your code replaces this loop)
        for x in range(10000):
            print("y")
        # flush output here to force SIGPIPE to be triggered
        # while inside this try block.
        sys.stdout.flush()
    except BrokenPipeError:
        # Python flushes standard streams on exit; redirect remaining output
        # to devnull to avoid another BrokenPipeError at shutdown
        devnull = os.open(os.devnull, os.O_WRONLY)
        os.dup2(devnull, sys.stdout.fileno())
        sys.exit(1)  # Python exits with error code 1 on EPIPE
if __name__ == '__main__':
    main()
mmap --- メモリマップファイル
メモリにマップされたファイルオブジェクトは、 bytearray と ファイルオブジェクト の両方のように振舞います。しかし通常の文字列オブジェクトとは異なり、これらは可変です。 bytearray が期待されるほとんどの場所で mmap オブジェクトを利用できます。例えば、メモリマップファイルを探索するために re モジュールを使うことができます。それらは可変なので、 obj[index] = 97 のように文字を変換できますし、スライスを使うことで obj[i1:i2] = b'...' のように部分文字列を変換することができます。現在のファイル位置をデータの始めとする読込みや書込み、ファイルの異なる位置へ seek() することもできます。
メモリマップドファイルは Unix と Windows で異なる mmap コンストラクタで生成されます。どちらの場合も、更新用に開かれたファイルディスクリプタを渡さなければなりません。既存の Python ファイルオブジェクトをマップしたければ、 fileno() メソッドを使って fileno パラメータの正しい値を取得してください。そうでなければ、 os.open() 関数を使ってファイルを開けます。この関数はファイルディスクリプタを直接返します(処理が終わったら、やはりファイルを閉じる必要があります)。
注釈 書き込み可能でバッファされたファイルへのメモリマップファイルを作りたいのであれば、まず最初にファイルの flush() を呼び出すべきです。これはバッファへのローカルな修正がマッピングで実際に利用可能になることを保障するために必要です。
バージョン 3.7 で変更: Added ACCESS_DEFAULT constant.
無名メモリ(anonymous memory)にマップするためには fileno として -1 を渡し、length を与えてください。
class mmap.mmap(fileno, length, tagname=None, access=ACCESS_DEFAULT[, offset])
(Windows バージョン) ファイルハンドル fileno によって指定されたファイルから length バイトをマップして、 mmap オブジェクトを生成します。 length が現在のファイルサイズより大きな場合、ファイルサイズは length を含む大きさにまで拡張されます。 length が 0 の場合、マップの最大の長さは現在のファイルサイズになります。ただし、ファイル自体が空のときは Windows が例外を送出します (Windows では空のマップを作成することができません)。
tagname は、 None 以外で指定された場合、マップのタグ名を与える文字列となります。 Windows は同じファイルに対する様々なマップを持つことを可能にします。既存のタグの名前を指定すればそのタグがオープンされ、そうでなければこの名前の新しいタグが作成されます。もしこのパラメータを省略したり None を与えたりしたならば、マップは名前なしで作成されます。タグ・パラメータの使用の回避は、あなたのコードを Unix と Windows の間で移植可能にしておくのを助けてくれるでしょう。
offset は非負整数のオフセットとして指定できます。mmap の参照はファイルの先頭からのオフセットに相対的になります。offset のデフォルトは 0 です。offset は ALLOCATIONGRANULARITY の倍数でなければなりません。
class mmap.mmap(fileno, length, flags=MAP_SHARED, prot=PROT_WRITE|PROT_READ, access=ACCESS_DEFAULT[, offset])
(Unix バージョン) ファイルディスクリプタ fileno で指定されたファイルから length バイトをマップし、mmap オブジェクトを返します。length が 0 の場合、マップの最大の長さは mmap が呼ばれた時点でのファイルサイズになります。
flags はマップの種類を指定します。 MAP_PRIVATE はプライベートな copy-on-write(書込み時コピー)のマップを作成します。従って、mmap オブジェクトの内容への変更はこのプロセス内にのみ有効です。 MAP_SHARED はファイルの同じ領域をマップする他のすべてのプロセスと共有されたマップを作成します。デフォルトは MAP_SHARED です。
prot が指定された場合、希望のメモリ保護を与えます。 2つの最も有用な値は、 PROT_READ と PROT_WRITE です。これは、読込み可能または書込み可能を指定するものです。 prot のデフォルトは PROT_READ | PROT_WRITE です。
access はオプションのキーワード・パラメータとして、 flags と prot の代わりに指定してもかまいません。 flags, prot と access の両方を指定することは間違っています。このパラメータの使用法についての情報は、先に述べた access の記述を参照してください。
offset may be specified as a non-negative integer offset. mmap references will be relative to the offset from the beginning of the file. offset defaults to 0. offset must be a multiple of ALLOCATIONGRANULARITY which is equal to PAGESIZE on Unix systems.
Mac OS X と OpenVMS において、作成された memory mapping の正当性を確実にするために fileno で指定されたファイルディスクリプタは内部で自動的に物理的なストレージ (physical backing store) と同期されます。
この例は mmap の簡潔な使い方を示すものです:
import mmap
# write a simple example file
with open("hello.txt", "wb") as f:
    f.write(b"Hello Python!\n")
with open("hello.txt", "r+b") as f:
    # memory-map the file, size 0 means whole file
    mm = mmap.mmap(f.fileno(), 0)
    # read content via standard file methods
    print(mm.readline())  # prints b"Hello Python!\n"
    # read content via slice notation
    print(mm[:5])  # prints b"Hello"
    # update content using slice notation;
    # note that new content must have same size
    mm[6:] = b" world!\n"
    # ... and read again using standard file methods
    mm.seek(0)
    print(mm.readline())  # prints b"Hello  world!\n"
    # close the map
    mm.close()
mmap は with 文の中でコンテキストマネージャとしても使えます:
import mmap
with mmap.mmap(-1, 13) as mm:
    mm.write(b"Hello world!")
バージョン 3.2 で追加: コンテキストマネージャのサポート。
次の例では無名マップを作り親プロセスと子プロセスの間でデータのやりとりをしてみせます:
import mmap
import os
mm = mmap.mmap(-1, 13)
mm.write(b"Hello world!")
pid = os.fork()
if pid == 0:  # In a child process
    mm.seek(0)
    print(mm.readline())
    mm.close()
メモリマップファイルオブジェクトは以下のメソッドをサポートしています:
close()
メモリマップファイルを閉じます。この呼出しの後にオブジェクトの他のメソッドの呼出すことは、 ValueError 例外の送出を引き起こします。このメソッドは開いたファイルのクローズはしません。
closed
ファイルが閉じている場合 True となります。
バージョン 3.2 で追加.
find(sub[, start[, end]])
オブジェクト内の [start, end] の範囲に含まれている部分シーケンス sub が見つかった場所の最も小さいインデックスを返します。オプションの引数 start と end はスライスに使われるときのように解釈されます。失敗したときには -1 を返します。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
flush([offset[, size]])
バージョン 3.8 で変更: Previously, a nonzero value was returned on success; zero was returned on error under Windows. A zero value was returned on success; an exception was raised on error under Unix.
madvise(option[, start[, length]])
バージョン 3.8 で追加.
move(dest, src, count)
オフセット src から始まる count バイトをインデックス dest の位置へコピーします。もし mmap が ACCESS_READ で作成されていた場合、 TypeError 例外を発生させます。
read([n])
現在のファイル位置からの最大 n バイトを含む bytes を返します。引数が省略されるか、 None もしくは負の値が指定された場合、現在のファイル位置からマップ終端までの全てのバイト列を返します。ファイル位置は返されたバイト列の直後を指すように更新されます。
バージョン 3.3 で変更: 引数が省略可能になり、 None も受け付けるようになりました。
read_byte()
現在のファイル位置のバイトを整数値として返し、ファイル位置を 1 進めます。
readline()
resize(newsize)
マップと元ファイル(がもしあれば)のサイズを変更します。もし mmap が ACCESS_READ または ACCESS_COPY で作成されたならば、マップサイズの変更は TypeError 例外を発生させます。
rfind(sub[, start[, end]])
オブジェクト内の [start, end] の範囲に含まれている部分シーケンス sub が見つかった場所の最も大きいインデックスを返します。オプションの引数 start と end はスライスに使われるときのように解釈されます。失敗したときには -1 を返します。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
seek(pos[, whence])
ファイルの現在位置をセットします。 whence 引数はオプションであり、デフォルトは os.SEEK_SET つまり 0 (絶対位置)です。その他の値として、 os.SEEK_CUR つまり 1 (現在位置からの相対位置)と os.SEEK_END つまり 2 (ファイルの終わりからの相対位置)があります。
size()
ファイルの長さを返します。メモリマップ領域のサイズより大きいかもしれません。
tell()
ファイルポインタの現在位置を返します。
write(bytes)
メモリ内のファイルポイントの現在位置に bytes のバイト列を書き込み、書き込まれたバイト数を返します(もし書き込みが失敗したら ValueError が送出されるため、len(bytes) より少なくなりません)。ファイル位置はバイト列が書き込まれた位置に更新されます。もしmmapが:const:ACCESS_READ とともに作成されていた場合は、書き込みは TypeError 例外を送出するでしょう。
バージョン 3.5 で変更: 書き込み可能な bytes-like object を使用できるようになりました。
バージョン 3.6 で変更: 書きこまれたバイト数を返すようになりました。
write_byte(byte)
メモリ内のファイル・ポインタの現在位置に整数 byte を書き込みます。ファイル位置は 1 だけ進みます。もし mmap が ACCESS_READ で作成されていた場合、書き込み時に TypeError 例外を発生させるでしょう。
MADV_* Constants
mmap.MADV_NORMAL
mmap.MADV_RANDOM
mmap.MADV_SEQUENTIAL
mmap.MADV_WILLNEED
mmap.MADV_DONTNEED
mmap.MADV_REMOVE
mmap.MADV_DONTFORK
mmap.MADV_DOFORK
mmap.MADV_HWPOISON
mmap.MADV_MERGEABLE
mmap.MADV_UNMERGEABLE
mmap.MADV_SOFT_OFFLINE
mmap.MADV_HUGEPAGE
mmap.MADV_NOHUGEPAGE
mmap.MADV_DONTDUMP
mmap.MADV_DODUMP
mmap.MADV_FREE
mmap.MADV_NOSYNC
mmap.MADV_AUTOSYNC
mmap.MADV_NOCORE
mmap.MADV_CORE
mmap.MADV_PROTECT
バージョン 3.8 で追加.
os --- 雑多なオペレーティングシステムインタフェース
ソースコード: Lib/os.py
このモジュールは、 OS 依存の機能を利用するポータブルな方法を提供します。単純なファイルの読み書きについては、 open() を参照してください。パス操作については、 os.path モジュールを参照してください。コマンドラインに与えられたすべてのファイルから行を読み込んでいくには、 fileinput モジュールを参照してください。一時ファイルや一時ディレクトリの作成については、 tempfile モジュールを参照してください。高水準のファイルとディレクトリの操作については、 shutil モジュールを参照してください。
利用可能性に関する注意 :
Python の、すべての OS 依存モジュールの設計方針は、可能な限り同一のインタフェースで同一の機能を利用できるようにする、というものです。例えば、 os.stat(path) は path に関する stat 情報を、 (POSIX を元にした ) 同じフォーマットで返します。
特定のオペレーティングシステム固有の拡張も os を介して利用することができますが、これらの利用はもちろん、可搬性を脅かします。
パスやファイル名を受け付けるすべての関数は、バイト列型および文字列型両方のオブジェクトを受け付け、パスやファイル名を返す時は、同じ型のオブジェクトを返します。
VxWorks では、os.fork, os.execv および os.spawn*p* はサポートされていません。
注釈 このモジュール内のすべての関数は、間違った、あるいはアクセス出来ないファイル名やファイルパス、その他型が合っていても OS が受理しない引数に対して、 OSError (またはそのサブクラス)を送出します。
exception os.error
組み込みの OSError 例外に対するエイリアスです。
os.name
import されているオペレーティングシステムに依存するモジュールの名前です。現在次の名前が登録されています: 'posix', 'nt', 'java'。
参考 sys.platform はより細かな粒度を持っています。 os.uname() はシステム依存のバージョン情報を提供します。
platform モジュールはシステムの詳細な識別情報をチェックする機能を提供しています。
ファイル名、コマンドライン引数、および環境変数
Python では、ファイル名、コマンドライン引数、および環境変数を表すのに文字列型を使用します。一部のシステムでは、これらをオペレーティングシステムに渡す前に、文字列からバイト列へ、またはその逆のデコードが必要です。Python はこの変換を行うためにファイルシステムのエンコーディングを使用します (sys.getfilesystemencoding() 参照)。
バージョン 3.1 で変更: 一部のシステムでは、ファイルシステムのエンコーディングを使用して変換すると失敗する場合があります。この場合、Python は surrogateescape エンコーディングエラーハンドラー を使用します。これは、デコード時にデコードできないバイト列は Unicode 文字 U+DCxx に置き換えられ、それらはエンコード時に再び元のバイト列に変換されることを意味します。
ファイルシステムのエンコーディングでは、すべてが 128 バイト以下に正常にデコードされることが保証されなくてはなりません。ファイルシステムのエンコーディングでこれが保証されなかった場合は、API 関数が UnicodeError を送出します。
プロセスのパラメーター
これらの関数とデータアイテムは、現在のプロセスおよびユーザーに対する情報提供および操作のための機能を提供しています。
os.ctermid()
プロセスの制御端末に対応するファイル名を返します。
利用可能な環境: Unix。
os.environ
文字列の環境を表す マップ型 オブジェクトです。例えば、 environ['HOME'] は (一部のプラットフォームでは) ホームディレクトリのパス名であり、 C における getenv("HOME") と等価です。
このマップ型の内容は、 os モジュールの最初の import の時点、通常は Python の起動時に site.py が処理される中で取り込まれます。それ以後に変更された環境変数は os.environ を直接変更しない限り os.environ には反映されません。
このマップ型オブジェクトは環境変数に対する変更に使うこともできます。 putenv() はマップ型オブジェクトが修正される時に、自動的に呼ばれることになります。
Unix では、キーと値に sys.getfilesystemencoding()、エラーハンドラーに 'surrogateescape' を使用します。異なるエンコーディングを使用したい場合は environb を使用します。
注釈 putenv() を直接呼び出しても os.environ の内容は変わらないので、 os.environ を直接変更する方が良いです。
注釈 FreeBSD と Mac OS X を含む一部のプラットフォームでは、 environ の値を変更するとメモリリークの原因になる場合があります。システムの putenv() に関するドキュメントを参照してください。
このマップ型オブジェクトからアイテムを削除することで環境変数を消すことができます。 unsetenv() は os.environ からアイテムが取り除かれた時に自動的に呼ばれます。 pop() または clear() が呼ばれた時も同様です。
バージョン 3.9 で変更: 更新され PEP 584 の合成演算子 (|) と更新演算子 (|=) がサポートされました。
os.environb
environ のバイト列版です。環境変数をバイト文字列で表す マップ型 オブジェクトです。environ と environb は同期されます。(environb を変更すると environ が更新され、逆の場合も同様に更新されます)。
environb は supports_bytes_environ が True の場合のみ利用可能です。
バージョン 3.2 で追加.
バージョン 3.9 で変更: 更新され PEP 584 の合成演算子 (|) と更新演算子 (|=) がサポートされました。
os.chdir(path)
os.fchdir(fd)
os.getcwd()
これらの関数は、 ファイルとディレクトリ 節で説明されています。
os.fsencode(filename)
path-like な filename をファイルシステムのエンコーディングにエンコードします。エラーハンドラーに 'surrogateescape' (Windows の場合は 'strict') が指定されます; 未変更の bytes オブジェクトを返します。
fsdecode() はこの逆変換を行う関数です。
バージョン 3.2 で追加.
バージョン 3.6 で変更: os.PathLike インタフェースを実装したオブジェクトを受け入れるようになりました。
os.fsdecode(filename)
ファイルシステムのエンコーディングから path-like な filename にデコードします。エラーハンドラーに 'surrogateescape' (Windows の場合は 'strict') が指定されます; 未変更の bytes オブジェクトを返します。
fsencode() はこの逆変換を行う関数です。
バージョン 3.2 で追加.
バージョン 3.6 で変更: os.PathLike インタフェースを実装したオブジェクトを受け入れるようになりました。
os.fspath(path)
path のファイルシステム表現を返します。
もし str か bytes: のオブジェクトが渡された場合は、変更せずにそのまま返します。さもなければ、 __fspath__() が呼び出され、その戻り値が str か bytes のオブジェクトであれば、その値を返します。他のすべてのケースでは TypeError が送出されます。
バージョン 3.6 で追加.
class os.PathLike
ファイルシステムパスを表すオブジェクト(例: pathlib.PurePath) 向けの abstract base class です。
バージョン 3.6 で追加.
abstractmethod __fspath__()
このオブジェクトが表現するファイルシステムパスを返します。
このメソッドは str か bytes のオブジェクトのみを返す必要があります(str が好まれます)。
os.getenv(key, default=None)
環境変数 key が存在すればその値を返し、存在しなければ default を返します。key、default、および返り値は文字列です。
Unix では、キーと値は sys.getfilesystemencoding()、エラーハンドラー 'surrogateescape' でデコードされます。異なるエンコーディングを使用したい場合は os.getenvb() を使用します。
利用できる環境: 主なUnix互換環境、 Windows。
os.getenvb(key, default=None)
環境変数 key が存在すればその値を返し、存在しなければ default を返します。key、default、および返り値はバイト列型です。
getenvb() は supports_bytes_environ が ``True``の場合のみ利用可能です。
利用できる環境: 主なUnix互換環境。
バージョン 3.2 で追加.
os.get_exec_path(env=None)
プロセスを起動する時に名前付き実行ファイルを検索するディレクトリのリストを返します。 env が指定されると、それを環境変数の辞書とみなし、その辞書からキー PATH の値を探します。 デフォルトでは env は None であり、environ が使用されます。
バージョン 3.2 で追加.
os.getegid()
現在のプロセスの実効グループ id を返します。この id は現在のプロセスで実行されているファイルの "set id" ビットに対応します。
利用可能な環境: Unix。
os.geteuid()
現在のプロセスの実効ユーザー id を返します。
利用可能な環境: Unix。
os.getgid()
現在のプロセスの実グループ id を返します。
利用可能な環境: Unix。
os.getgrouplist(user, group)
user が所属するグループ id のリストを返します。group がリストにない場合、それを追加します。通常、group にはユーザー user のパスワードレコードに書かれているグループ ID を指定します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.getgroups()
現在のプロセスに関連付けられた従属グループ id のリストを返します。
利用可能な環境: Unix。
注釈 Mac OS X では getgroups() の挙動は他の Unix プラットフォームとはいくぶん異なります。 Python のインタープリタが 10.5 以前の Deployment Target でビルドされている場合、 getgroups() は現在のユーザープロセスに関連付けられている実効グループ id を返します。このリストはシステムで定義されたエントリ数 ( 通常は 16) に制限され、適切な特権があれば setgroups() の呼び出しによって変更することができます。 10.5 より新しい Deployment Target でビルドされている場合、 getgroups() はプロセスの実効ユーザー id に関連付けられたユーザーの現在のグループアクセスリストを返します。このグループアクセスリストは、プロセスのライフタイムで変更される可能性があり、 setgroups() の呼び出しの影響を受けず、長さ 16 の制限を受けません。 Deployment Target の値 MACOSX_DEPLOYMENT_TARGET は、 sysconfig.get_config_var() で取得することができます。
os.getlogin()
プロセスの制御端末にログインしているユーザー名を返します。ほとんどの場合、getpass.getuser() を使う方が便利です。なぜなら、getpass.getuser() は、ユーザーを見つけるために、環境変数 LOGNAME や USERNAME を調べ、さらには pwd.getpwuid(os.getuid())[0] まで調べに行くからです。
Availability: Unix, Windows。
os.getpgid(pid)
プロセス id pid のプロセスのプロセスグループ id を返します。 pid が 0 の場合、現在のプロセスのプロセスグループ id を返します。
利用可能な環境: Unix。
os.getpgrp()
現在のプロセスグループの id を返します。
利用可能な環境: Unix。
os.getpid()
現在のプロセス id を返します。
os.getppid()
親プロセスのプロセス id を返します。親プロセスが終了していた場合、Unix では init プロセスの id (1) が返され、Windows では親のプロセス id だったもの (別のプロセスで再利用されているかもしれない) がそのまま返されます。
Availability: Unix, Windows。
バージョン 3.2 で変更: Windows サポートが追加されました。
os.getpriority(which, who)
プログラムのスケジューリング優先度を取得します。which の値は PRIO_PROCESS、PRIO_PGRP、あるいは PRIO_USER のいずれか一つで、who の値は which に応じて解釈されます (PRIO_PROCESS であればプロセス識別子、PRIO_PGRP であればプロセスグループ識別子、そして PRIO_USER であればユーザー ID)。who の値がゼロの場合、呼び出したプロセス、呼び出したプロセスのプロセスグループ、および呼び出したプロセスの実ユーザー id を (それぞれ) 意味します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.PRIO_PROCESS
os.PRIO_PGRP
os.PRIO_USER
getpriority() と setpriority() 用のパラメータです。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.getresuid()
現在のプロセスの実ユーザー id 、実効ユーザー id 、および保存ユーザー id を示す、 (ruid, euid, suid) のタプルを返します。
利用可能な環境: Unix。
バージョン 3.2 で追加.
os.getresgid()
現在のプロセスの実グループ id 、実効グループ id 、および保存グループ id を示す、 (rgid, egid, sgid) のタプルを返します。
利用可能な環境: Unix。
バージョン 3.2 で追加.
os.getuid()
現在のプロセスの実ユーザー id を返します。
利用可能な環境: Unix。
os.initgroups(username, gid)
システムの initgroups() を呼び出し、指定された username がメンバーである全グループと gid で指定されたグループでグループアクセスリストを初期化します。
利用可能な環境: Unix。
バージョン 3.2 で追加.
os.putenv(key, value)
key という名前の環境変数に文字列 value を設定します。このような環境変数の変更は、os.system()、popen()、または fork() と execv() で起動されたサブプロセスに影響を与えます。
os.environ のアイテムに対する代入を行うと、自動的に putenv() の対応する呼び出しに変換されます。直接 putenv() を呼び出した場合 os.environ は更新されないため、実際には os.environ のアイテムに代入する方が望ましい操作です。
注釈 FreeBSD と Mac OS X を含む一部のプラットフォームでは、 environ の値を変更するとメモリリークの原因になる場合があります。システムの putenv() に関するドキュメントを参照してください。
引数 key, value を指定して 監査イベント os.putenv を送出します。
バージョン 3.9 で変更: 常に利用出来るようになりました。
os.setegid(egid)
現在のプロセスに実効グループ id をセットします。
利用可能な環境: Unix。
os.seteuid(euid)
現在のプロセスに実効ユーザー id をセットします。
利用可能な環境: Unix。
os.setgid(gid)
現在のプロセスにグループ id をセットします。
利用可能な環境: Unix。
os.setgroups(groups)
現在のグループに関連付けられた従属グループ id のリストを groups に設定します。 groups はシーケンス型でなくてはならず、各要素はグループを特定する整数でなくてはなりません。通常、この操作はスーパユーザーしか利用できません。
利用可能な環境: Unix。
注釈 Mac OS X では、 groups の長さはシステムで定義された実効グループ id の最大数 ( 通常は 16) を超えない場合があります。 setgroups() 呼び出しで設定されたものと同じグループリストが返されないケースについては、 getgroups() のドキュメントを参照してください。
os.setpgrp()
システムコール setpgrp() か setpgrp(0, 0) のどちらか(実装されているもの)を呼び出します。機能については UNIX マニュアルを参照して下さい。
利用可能な環境: Unix。
os.setpgid(pid, pgrp)
システムコール setpgid() を呼び出してプロセス id pid のプロセスのプロセスグループ id を pgrp に設定します。この動作に関しては Unix のマニュアルを参照してください。
利用可能な環境: Unix。
os.setpriority(which, who, priority)
プログラムのスケジューリング優先度を設定します。which は PRIO_PROCESS、PRIO_PGRP、あるいは PRIO_USER のいずれか一つで、who の値は which に応じて解釈されます (PRIO_PROCESS であればプロセス識別子、PRIO_PGRP であればプロセスグループ識別子、そして PRIO_USER であればユーザー ID)。who の値がゼロの場合、呼び出したプロセス、呼び出したプロセスのプロセスグループ、および呼び出したプロセスの実ユーザー id を (それぞれ) 意味します。priority は -20 から 19 の整数値で、デフォルトの優先度は 0 です。小さい数値ほど優先されるスケジューリングとなります。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.setregid(rgid, egid)
現在のプロセスの実グループ id および実効グループ id を設定します。
利用可能な環境: Unix。
os.setresgid(rgid, egid, sgid)
現在のプロセスの、実グループ id 、実効グループ id 、および保存グループ id を設定します。
利用可能な環境: Unix。
バージョン 3.2 で追加.
os.setresuid(ruid, euid, suid)
現在のプロセスの実ユーザー id 、実効ユーザー id 、および保存ユーザー id を設定します。
利用可能な環境: Unix。
バージョン 3.2 で追加.
os.setreuid(ruid, euid)
現在のプロセスの実ユーザー id および実効ユーザー id を設定します。
利用可能な環境: Unix。
os.getsid(pid)
getsid() システムコールを呼び出します。機能については Unix のマニュアルを参照してください。
利用可能な環境: Unix。
os.setsid()
setsid() システムコールを呼び出します。機能については Unix のマニュアルを参照してください。
利用可能な環境: Unix。
os.setuid(uid)
現在のプロセスのユーザー id を設定します。
利用可能な環境: Unix。
os.strerror(code)
エラーコード code に対応するエラーメッセージを返します。未知のエラーコードの対して strerror() が NULL を返すプラットフォームでは、 ValueError が送出されます。
os.supports_bytes_environ
環境のネイティブ OS タイプがバイト型の場合、 True です (例: Windows では、 False です)。
バージョン 3.2 で追加.
os.umask(mask)
現在の数値 umask を設定し、以前の umask 値を返します。
os.uname()
現在のオペレーティングシステムを識別する情報を返します。返り値は 5 個の属性を持つオブジェクトです:
sysname - OS の名前
nodename - (実装時に定義された) ネットワーク上でのマシン名
release - OS のリリース
version - OS のバージョン
machine - ハードウェア識別子
後方互換性のため、このオブジェクトはイテラブルでもあり、sysname、nodename、release、version、および machine の 5 個の要素をこの順序で持つタプルのように振る舞います。
一部のシステムでは、nodename はコンポーネントを読み込むために 8 文字または先頭の要素だけに切り詰められます; ホスト名を取得する方法としては、socket.gethostname() を使う方がよいでしょう。あるいは socket.gethostbyaddr(socket.gethostname()) でもかまいません。
利用できる環境: 最近のUnix互換環境。
バージョン 3.3 で変更: 返り値の型が、タプルから属性名のついたタプルライクオブジェクトに変更されました。
os.unsetenv(key)
key という名前の環境変数を unset (削除) します。このような環境変数の変更は、os.system()、popen()、または fork() と execv() で起動されたサブプロセスに影響を与えます。
os.environ のアイテムの削除を行うと、自動的に unsetenv() の対応する呼び出しに変換されます。直接 unsetenv() を呼び出した場合 os.environ は更新されないため、実際には os.environ のアイテムを削除する方が望ましい操作です。
引数 key を指定して 監査イベント os.unsetenv を送出します。
バージョン 3.9 で変更: 常に関数は利用出来るようになりました。
ファイルオブジェクトの生成
以下の関数は新しい ファイルオブジェクト を作成します。(ファイル記述子のオープンについては open() も参照してください)
os.fdopen(fd, *args, **kwargs)
ファイル記述子 fd に接続し、オープンしたファイルオブジェクトを返します。これは組み込み関数 open() の別名であり、同じ引数を受け取ります。唯一の違いは fdopen() の第一引数が常に整数でなければならないことです。
ファイル記述子の操作
これらの関数は、ファイル記述子を使って参照されている I/O ストリームを操作します。
ファイル記述子とは現在のプロセスで開かれたファイルに対応する小さな整数です。例えば、標準入力のファイル記述子は通常 0 で、標準出力は 1 、標準エラーは 2 です。プロセスから開かれたその他のファイルには 3 、 4 、 5 と割り振られていきます。「ファイル記述子」という名称は少し誤解を与えるものかもしれません。Unix プラットフォームでは、ソケットやパイプもファイル記述子によって参照されます。
fileno() メソッドを使用して、必要な場合に file object に関連付けられているファイル記述子を取得することができます。ファイル記述子を直接使用すると、ファイルオブジェクトのメソッドが使用されないため、データの内部バッファなどの性質は無視されることに注意してください。
os.close(fd)
ファイル記述子 fd をクローズします。
注釈 この関数は低水準の I/O 向けのもので、 os.open() や pipe() が返すファイル記述子に対して使用しなければなりません。 組み込み関数 open() や popen() 、 fdopen() が返す "ファイルオブジェクト" を閉じるには、オブジェクトの close() メソッドを使用してください。
os.closerange(fd_low, fd_high)
fd_low 以上 fd_high 未満のすべてのファイル記述子をエラーを無視してクローズします。以下のコードと等価です:
for fd in range(fd_low, fd_high):
    try:
        os.close(fd)
    except OSError:
        pass
os.copy_file_range(src, dst, count, offset_src=None, offset_dst=None)
ファイル記述子 src の offset_src から count バイトを、ファイル記述子 dst の offset_dst にコピーします。もし offset_src が None の場合は src は現在の位置から読まれます。 offset_dst についても同様です。src および dst のファイルは同じファイルシステム上になければなりません。違う場合には errno を errno.EXDEV として OSError が送出されます。
このコピーは、カーネルからユーザースペースにデータを転送した後カーネルに戻すという追加のコスト無しに完了します。 加えて、追加の最適化ができるファイルシステムもあります。 このコピーはファイルが両方ともバイナリファイルとして開かれたかのように行われます。
返り値はコピーされたバイトの量です。 この値は、要求した量より少なくなることもあります。
Availability: Linux kernel >= 4.5 または glibc >= 2.27。
バージョン 3.8 で追加.
os.device_encoding(fd)
fd に関連付けられたデバイスが端末 (ターミナル) に接続されている場合に、そのデバイスのエンコーディングを表す文字列を返します。端末に接続されていない場合、 None を返します。
os.dup(fd)
ファイル記述子 fd の複製を返します。新しいファイル記述子は 継承不可 です。
Windows では、標準ストリーム (0: 標準入力、1: 標準出力、2: 標準エラー出力) を複製する場合、新しいファイル記述子は 継承可能 です。
バージョン 3.4 で変更: 新しいファイル記述子が継承不可になりました。
os.dup2(fd, fd2, inheritable=True)
ファイル記述子 fd を fd2 に複製し、必要な場合には後者を先に閉じます。 fd2 が返ります。 新しいファイル記述子はデフォルトでは 継承可能 で、inheritable が False の場合は継承不可です。
バージョン 3.4 で変更: オプションの inheritable 引数が追加されました。
バージョン 3.7 で変更: 成功したときは fd2 が返ります。 以前は常に None が返っていました。
os.fchmod(fd, mode)
fd で指定されたファイルのモードを mode に変更します。mode に指定できる値については、chmod() のドキュメントを参照してください。Python 3.3 以降では os.chmod(fd, mode) と等価です。
引数 path, mode, dir_fd を指定して 監査イベント os.chmod を送出します。
利用可能な環境: Unix。
os.fchown(fd, uid, gid)
fd で指定されたファイルの所有者 id およびグループ id を数値 uid および gid に変更します。いずれかの id を変更せずにおくにはその値として -1 を指定します。chown() を参照してください。Python 3.3 以降では os.chown(fd, uid, gid) と等価です。
引数 path, uid, gid, dir_fd を指定して 監査イベント os.chown を送出します。
利用可能な環境: Unix。
os.fdatasync(fd)
ファイル記述子 fd を持つファイルのディスクへの書き込みを強制します。メタデータの更新は強制しません。
利用可能な環境: Unix。
注釈 この関数は MacOS では利用できません。
os.fpathconf(fd, name)
開いているファイルに関連するシステム設定情報を返します。 name は取得する設定名を指定します。これは、いくつかの標準 (POSIX.1 、 Unix 95 、 Unix 98 その他 ) で定義された定義済みのシステム値名の文字列である場合があります。プラットフォームによっては別の名前も定義されています。ホストオペレーティングシステムの関知する名前は pathconf_names 辞書で与えられています。このマップ型オブジェクトに含まれていない構成変数については、 name に整数を渡してもかまいません。
name が不明の文字列である場合、 ValueError を送出します。 name の特定の値がホストシステムでサポートされていない場合、 pathconf_names に含まれていたとしても、 errno.EINVAL をエラー番号として OSError を送出します。
Python 3.3 以降では os.pathconf(fd, name) と等価です。
利用可能な環境: Unix。
os.fstat(fd)
ファイル記述子 fd の状態を取得します。stat_result オブジェクトを返します。
Python 3.3 以降では os.stat(fd) と等価です。
参考 stat() 関数。
os.fstatvfs(fd)
statvfs() と同様に、ファイル記述子 fd に関連付けられたファイルが格納されているファイルシステムに関する情報を返します。Python 3.3 以降では os.statvfs(fd) と等価です。
利用可能な環境: Unix。
os.fsync(fd)
ファイル記述子 fd を持つファイルのディスクへの書き込みを強制します。 Unix では、ネイティブの fsync() 関数を、 Windows では _commit() 関数を呼び出します。
Python の ファイルオブジェクト f を使う場合、f の内部バッファを確実にディスクに書き込むために、まず f.flush() を、その後 os.fsync(f.fileno()) を実行してください。
Availability: Unix, Windows。
os.ftruncate(fd, length)
ファイル記述子 fd に対応するファイルを、サイズが最長で length バイトになるように切り詰めます。Python 3.3 以降では os.truncate(fd, length) と等価です。
引数 fd, length を指定して 監査イベント os.truncate を送出します。
Availability: Unix, Windows。
バージョン 3.5 で変更: Windows サポートを追加しました。
os.get_blocking(fd)
記述子のブロッキングモードを取得します。 O_NONBLOCK フラグが設定されている場合は False で、フラグがクリアされている場合は True です。
set_blocking() および socket.socket.setblocking() も参照してください。
利用可能な環境: Unix。
バージョン 3.5 で追加.
os.isatty(fd)
ファイル記述子 fd がオープンされていて、 tty (のような) デバイスに接続されている場合、 True を返します。そうでない場合は False を返します。
os.lockf(fd, cmd, len)
オープンされたファイル記述子に対して、POSIX ロックの適用、テスト、解除を行います。fd はオープンされたファイル記述子です。cmd には使用するコマンド (F_LOCK、F_TLOCK、F_ULOCK、あるいは F_TEST のいずれか一つ) を指定します。len にはロックするファイルのセクションを指定します。
引数 fd, cmd, len を指定して 監査イベント os.lockf を送出します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.F_LOCK
os.F_TLOCK
os.F_ULOCK
os.F_TEST
lockf() がとる動作を指定するフラグです。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.lseek(fd, pos, how)
ファイル記述子 fd の現在の位置を pos に設定します。 pos の意味は how で次のように修飾されます。ファイルの先頭からの相対位置には SEEK_SET か 0 を、現在の位置からの相対位置には SEEK_CUR か 1 を、ファイルの末尾からの相対位置には SEEK_END か 2 を設定します。戻り値は、新しいカーソル位置のファイルの先頭からのバイト数です。
os.SEEK_SET
os.SEEK_CUR
os.SEEK_END
lseek() 関数に渡すパラメーター。値は順に 0, 1, 2 です。
バージョン 3.3 で追加: 一部のオペレーティングシステムは os.SEEK_HOLE や os.SEEK_DATA など、追加の値をサポートすることがあります。
os.open(path, flags, mode=0o777, *, dir_fd=None)
ファイル path を開き、flag に従って様々なフラグを設定し、可能なら mode に従ってファイルモードを設定します。mode を計算する際、まず現在の umask 値でマスクされます。新たに開いたファイルのファイル記述子を返します。新しいファイル記述子は 継承不可 です。
フラグとファイルモードの値についての詳細は C ランタイムのドキュメントを参照してください; (O_RDONLY や O_WRONLY のような) フラグ定数は os モジュールでも定義されています。特に、Windows ではバイナリモードでファイルを開く時に O_BINARY を加える必要があります。
この関数は dir_fd パラメタで ディレクトリ記述子への相対パス をサポートしています。
引数 path, mode, flags を指定して 監査イベント open を送出します。
バージョン 3.4 で変更: 新しいファイル記述子が継承不可になりました。
注釈 この関数は低水準の I/O 向けのものです。 通常の利用では、組み込み関数 open() を使用してください。 open() は read() や write() (そしてさらに多くの) メソッドを持つ ファイルオブジェクト を返します。 ファイル記述子をファイルオブジェクトでラップするには fdopen() を使用してください。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、この関数は InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
以下の定数は open() 関数の flags 引数に利用します。これらの定数は、ビット単位に OR 演算子 | で組み合わせることができます。一部、すべてのプラットフォームでは使用できない定数があります。利用可能かどうかや使い方については、Unix では open(2)、Windows では MSDN を参照してください。
os.O_RDONLY
os.O_WRONLY
os.O_RDWR
os.O_APPEND
os.O_CREAT
os.O_EXCL
os.O_TRUNC
上記の定数は Unix および Windows で利用可能です。
os.O_DSYNC
os.O_RSYNC
os.O_SYNC
os.O_NDELAY
os.O_NONBLOCK
os.O_NOCTTY
os.O_CLOEXEC
上記の定数は Unix でのみ利用可能です。
バージョン 3.3 で変更: 定数 O_CLOEXEC が追加されました。
os.O_BINARY
os.O_NOINHERIT
os.O_SHORT_LIVED
os.O_TEMPORARY
os.O_RANDOM
os.O_SEQUENTIAL
os.O_TEXT
上記の定数は Windows でのみ利用可能です。
os.O_ASYNC
os.O_DIRECT
os.O_DIRECTORY
os.O_NOFOLLOW
os.O_NOATIME
os.O_PATH
os.O_TMPFILE
os.O_SHLOCK
os.O_EXLOCK
上記の定数は拡張仕様であり、Cライブラリで定義されていない場合は利用できません。
バージョン 3.4 で変更: O_PATH を、それをサポートするシステムで追加しました。また、 O_TMPFILE を追加しました (Linux Kernel 3.11 以降でのみ利用可能です)。
os.openpty()
新しい擬似端末のペアを開きます。pty および tty を表すファイル記述子のペア (master, slave) を返します。新しいファイル記述子は 継承不可 です。(若干) 可搬性の高いアプローチには pty を使用してください。
利用できる環境: 一部の Unix 互換環境。
バージョン 3.4 で変更: 新しいファイル記述子が継承不可になりました。
os.pipe()
パイプを作成します。読み込み、書き込みに使うことの出来るファイル記述子のペア (r, w) を返します。新しいファイル記述子は 継承不可 です。
Availability: Unix, Windows。
バージョン 3.4 で変更: 新しいファイル記述子が継承不可になりました。
os.pipe2(flags)
flags を設定したパイプをアトミックに作成します。flags には値 O_NONBLOCK と O_CLOEXEC を一つ以上論理和指定できます。読み込み、書き込みに使うことの出来るファイル記述子のペア (r, w) を返します。
利用できる環境: 一部の Unix 互換環境。
バージョン 3.3 で追加.
os.posix_fallocate(fd, offset, len)
fd で指定されたファイルに対し、開始位置 offset から len バイト分割り当てるに十分なディスクスペースを確保します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.posix_fadvise(fd, offset, len, advice)
データへアクセスする意思を、パターンを指定して宣言します。これによりカーネルが最適化を行えるようになります。advice は fd で指定されたファイルに対し、開始位置 offset から len バイト分の領域に適用されます。advice には POSIX_FADV_NORMAL、POSIX_FADV_SEQUENTIAL、POSIX_FADV_RANDOM、POSIX_FADV_NOREUSE、POSIX_FADV_WILLNEED、または POSIX_FADV_DONTNEED のいずれか一つを指定します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.POSIX_FADV_NORMAL
os.POSIX_FADV_SEQUENTIAL
os.POSIX_FADV_RANDOM
os.POSIX_FADV_NOREUSE
os.POSIX_FADV_WILLNEED
os.POSIX_FADV_DONTNEED
posix_fadvise() において、使われるであろうアクセスパターンを指定する advice に使用できるフラグです。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.pread(fd, n, offset)
ファイル記述子の位置 offset から最大で n バイトを読み出します。 ファイルオフセットは変化しません。
読み込んだバイト分のバイト列を返します。 fd が参照しているファイルの終端に達した場合、空のバイト列が返されます。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.preadv(fd, buffers, offset, flags=0)
ファイル記述子 fd の offset の位置から、可変な bytes-like オブジェクト buffers にオフセットを変更せずに読み込みます。 データをそれぞれのバッファがいっぱいになるまで移し、いっぱいになったらシーケンスの次のバッファに処理を移し、残りのデータを読み込ませます。
flags 引数にはゼロあるいは次のフラグのバイトごとの OR を取った結果が保持されています。
RWF_HIPRI
RWF_NOWAIT
オペレーティングシステムは、使用可能なバッファの個数に基づいて上限 (sysconf() の 'SC_IOV_MAX' の値) を設定することがあります。
バージョン 3.7 で追加.
os.RWF_NOWAIT
利用可能な環境: Linux 4.14以上。
バージョン 3.7 で追加.
os.RWF_HIPRI
利用可能な環境: Linux 4.6以上。
バージョン 3.7 で追加.
os.pwrite(fd, str, offset)
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.pwritev(fd, buffers, offset, flags=0)
flags 引数にはゼロあるいは次のフラグのバイトごとの OR を取った結果が保持されています。
RWF_DSYNC
RWF_SYNC
実際に書き込まれた合計バイト数を返します。
オペレーティングシステムは、使用可能なバッファの個数に基づいて上限 (sysconf() の 'SC_IOV_MAX' の値) を設定することがあります。
バージョン 3.7 で追加.
os.RWF_DSYNC
利用可能な環境: Linux 4.7以上。
バージョン 3.7 で追加.
os.RWF_SYNC
利用可能な環境: Linux 4.7以上。
バージョン 3.7 で追加.
os.read(fd, n)
読み込んだバイト分のバイト列を返します。 fd が参照しているファイルの終端に達した場合、空のバイト列が返されます。
注釈 この関数は低水準の I/O 向けのもので、 os.open() や pipe() が返すファイル記述子に対して使用されなければなりません。 組み込み関数 open() や popen() 、 fdopen() 、あるいは sys.stdin が返す "ファイルオブジェクト" を読み込むには、オブジェクトの read() か readline() メソッドを使用してください。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、この関数は InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
os.sendfile(out_fd, in_fd, offset, count)
os.sendfile(out_fd, in_fd, offset, count, headers=(), trailers=(), flags=0)
前者の関数表記は sendfile() が定義されているすべてのプラットフォームでサポートされています。
Linux では、offset に None が与えられると、バイト列は in_fd の現在の位置から読み込まれ、in_fd の位置は更新されます。
後者は Mac OS X および FreeBSD で使用される場合があります。headers および trailers は任意のバッファのシーケンス型オブジェクトで、in_fd からのデータが書き出される前と後に書き出されます。返り値は前者と同じです。
Mac OS X と FreeBSD では、count の値に 0 を指定すると、 in_fd の末尾に達するまで送信します。
全てのプラットフォームはソケットをファイル記述子 out_fd としてサポートし、あるプラットフォームは他の種類 (例えば、通常のファイル、パイプ) も同様にサポートします。
クロスプラットフォームのアプリケーションは headers、trailers ならびに flags 引数を使用するべきではありません。
利用可能な環境: Unix。
注釈 sendfile() のより高水準のラッパについては socket.socket.sendfile() を参照してください。
バージョン 3.3 で追加.
バージョン 3.9 で変更: Parameters out and in was renamed to out_fd and in_fd.
os.set_blocking(fd, blocking)
指定されたファイル記述子のブロッキングモードを設定します。 ブロッキングが False の場合 O_NONBLOCK フラグを設定し、そうでない場合はクリアします。
get_blocking() および socket.socket.setblocking() も参照してください。
利用可能な環境: Unix。
バージョン 3.5 で追加.
os.SF_NODISKIO
os.SF_MNOWAIT
os.SF_SYNC
実装がサポートしている場合 sendfile() 関数に渡すパラメーターです。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.readv(fd, buffers)
オペレーティングシステムは、使用可能なバッファの個数に基づいて上限 (sysconf() の 'SC_IOV_MAX' の値) を設定することがあります。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.tcgetpgrp(fd)
fd (os.open() が返すオープンしたファイル記述子 ) で与えられる端末に関連付けられたプロセスグループを返します。
利用可能な環境: Unix。
os.tcsetpgrp(fd, pg)
fd (os.open() が返すオープンしたファイル記述子 ) で与えられる端末に関連付けられたプロセスグループを pg に設定します。
利用可能な環境: Unix。
os.ttyname(fd)
ファイル記述子 fd に関連付けられている端末デバイスを特定する文字列を返します。 fd が端末に関連付けられていない場合、例外が送出されます。
利用可能な環境: Unix。
os.write(fd, str)
str のバイト列をファイル記述子 fd に書き出します。
注釈 この関数は低水準の I/O 向けのもので、 os.open() や pipe() が返すファイル記述子に対して使用しなければなりません。 組み込み関数 open() や popen() 、 fdopen() 、あるいは sys.stdout や sys.stderr が返す "ファイルオブジェクト" に書き込むには、オブジェクトの write() メソッドを使用してください。
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、この関数は InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
os.writev(fd, buffers)
buffers の内容をファイル記述子 fd へ書き出します。 buffers は bytes-like オブジェクト のシーケンスでなければなりません。バッファは配列の順番で処理されます。最初のバッファの内容全体は 2 番目のバッファに進む前に書き込まれ、その次も同様です。
実際に書き込まれた合計バイト数を返します。
オペレーティングシステムは、使用可能なバッファの個数に基づいて上限 (sysconf() の 'SC_IOV_MAX' の値) を設定することがあります。
利用可能な環境: Unix。
バージョン 3.3 で追加.
ターミナルのサイズの問い合わせ
バージョン 3.3 で追加.
os.get_terminal_size(fd=STDOUT_FILENO)
ターミナル (端末) のサイズ (columns, lines) を、terminal_size 型のタプルで返します。
オプションの引数 fd には問い合わせるファイル記述子を指定します (デフォルトは STDOUT_FILENO、または標準出力)。
ファイル記述子が接続されていなかった場合、 OSError が送出されます。
通常は高水準関数である shutil.get_terminal_size() を使用してください。os.get_terminal_size は低水準の実装です。
Availability: Unix, Windows。
class os.terminal_size
ターミナルウィンドウのサイズ (columns, lines) を保持するタプルのサブクラスです。
columns
ターミナルウィンドウの横幅 (文字数) です。
lines
ターミナルウィンドウの高さ (文字数) です。
ファイル記述子の継承
バージョン 3.4 で追加.
ファイル記述子には「継承可能 (inheritable)」フラグというものがあって、これにより子プロセスにファイル記述子が引き継がれるかどうかが決定されます。Python 3.4 より、 Python によって作成されるファイル記述子はデフォルトで継承不可 (non-inheritable) となりました。
UNIX の場合、継承不可のファイル記述子は新規プロセス実行時にクローズされ、そうでないファイル記述子は引き継がれます。
Windows の場合は、標準ストリームを除き、継承不可のハンドルと継承不可のファイル記述子は子プロセスでクローズされます。標準ストリーム (ファイル記述子の 0, 1, 2: 標準入力, 標準出力, 標準エラー出力) は常に引き継がれます。 spawn* 関数を使う場合、全ての継承可能なハンドルと全ての継承可能なファイル記述子は引き継がれます。 subprocess モジュールを使う場合、標準ストリームを除く全てのファイル記述子はクローズされ、継承可能なハンドルは close_fds 引数が False の場合にのみ引き継がれます。
os.get_inheritable(fd)
指定したファイル記述子の「継承可能 (inheritable)」フラグを取得します (boolean)。
os.set_inheritable(fd, inheritable)
指定したファイル記述子の「継承可能 (inheritable)」フラグをセットします。
os.get_handle_inheritable(handle)
指定したハンドルの「継承可能 (inheritable)」フラグを取得します (boolean)。
利用可能な環境: Windows 。
os.set_handle_inheritable(handle, inheritable)
指定したハンドルの「継承可能 (inheritable)」フラグをセットします。
利用可能な環境: Windows 。
ファイルとディレクトリ
一部の Unix プラットフォームでは、このセクションの関数の多くが以下の機能を一つ以上サポートしています。
specifying a file descriptor: Normally the path argument provided to functions in the os module must be a string specifying a file path. However, some functions now alternatively accept an open file descriptor for their path argument. The function will then operate on the file referred to by the descriptor. (For POSIX systems, Python will call the variant of the function prefixed with f (e.g. call fchdir instead of chdir).)
その関数が引数に dir_fd または follow_symlinks もサポートしている場合、path にファイル記述子を指定した時にそれらのいずれかを指定するとエラーになります。
paths relative to directory descriptors: If dir_fd is not None, it should be a file descriptor referring to a directory, and the path to operate on should be relative; path will then be relative to that directory. If the path is absolute, dir_fd is ignored. (For POSIX systems, Python will call the variant of the function with an at suffix and possibly prefixed with f (e.g. call faccessat instead of access).
not following symlinks: If follow_symlinks is False, and the last element of the path to operate on is a symbolic link, the function will operate on the symbolic link itself rather than the file pointed to by the link. (For POSIX systems, Python will call the l... variant of the function.)
そのプラットフォーム上で特別な関数に follow_symlinks がサポートされているかどうかは、os.supports_follow_symlinks で確認できます。利用できない場合 NotImplementedError が送出されます。
os.access(path, mode, *, dir_fd=None, effective_ids=False, follow_symlinks=True)
実 uid/gid を使って path に対するアクセスが可能か調べます。ほとんどのオペレーティングシステムは実効 uid/gid を使うため、このルーチンは suid/sgid 環境において、プログラムを起動したユーザーが path に対するアクセス権をもっているかを調べるために使われます。 path が存在するかどうかを調べるには mode を F_OK にします。ファイルアクセス権限 ( パーミッション ) を調べるには、 R_OK, W_OK, X_OK から一つまたはそれ以上のフラグを論理和指定でとることもできます。アクセスが許可されている場合 True を、そうでない場合 False を返します。詳細は access(2) の Unix マニュアルページを参照してください。
この関数は ディレクトリ記述子への相対パス および シンボリックリンクをたどらない をサポートしています。
effective_ids が True の場合、access() は実 uid/gid ではなく実効 uid/gid を使用してアクセス権を調べます。プラットフォームによっては effective_ids がサポートされていない場合があります; サポートされているかどうかは os.supports_effective_ids で確認できます。利用できない場合 NotImplementedError が送出されます。
注釈 ユーザーが、例えばファイルを開く権限を持っているかどうかを調べるために実際に open() を行う前に access() を使用することはセキュリティホールの原因になります。なぜなら、調べた時点とオープンした時点との時間差を利用してそのユーザーがファイルを不当に操作してしまうかもしれないからです。その場合は EAFP テクニックを利用するのが望ましいやり方です。例えば
if os.access("myfile", os.R_OK):
    with open("myfile") as fp:
        return fp.read()
return "some default data"
このコードは次のように書いたほうが良いです
try:
    fp = open("myfile")
except PermissionError:
    return "some default data"
else:
    with fp:
        return fp.read()
注釈 I/O 操作は access() が成功を示した時でも失敗することがあります。特にネットワークファイルシステムが通常の POSIX のパーミッションビットモデルをはみ出すアクセス権限操作を備える場合にはそのようなことが起こりえます。
バージョン 3.3 で変更: 引数 dir_fd、effective_ids、および follow_symlinks が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.F_OK
os.R_OK
os.W_OK
os.X_OK
access() で path をテストする時に mode 引数に渡す値です。上からそれぞれ、ファイルの存在、読み込み許可、書き込み許可、および実行許可になります。
os.chdir(path)
現在の作業ディレクトリを path に設定します。
この関数は ファイル記述子の指定 をサポートしています。記述子は、オープンしているファイルではなく、オープンしているディレクトリを参照していなければなりません。
引数 path を指定して 監査イベント os.chdir を送出します。
バージョン 3.3 で追加: 一部のプラットフォームで、path にファイル記述子の指定をサポートしました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.chflags(path, flags, *, follow_symlinks=True)
path のフラグを flags に変更します。 flags は、以下の値 (stat モジュールで定義されているもの ) をビット単位の論理和で組み合わせることができます :
stat.UF_NODUMP
stat.UF_IMMUTABLE
stat.UF_APPEND
stat.UF_OPAQUE
stat.UF_NOUNLINK
stat.UF_COMPRESSED
stat.UF_HIDDEN
stat.SF_ARCHIVED
stat.SF_IMMUTABLE
stat.SF_APPEND
stat.SF_NOUNLINK
stat.SF_SNAPSHOT
この関数は シンボリックリンクをたどらない をサポートしています。
利用可能な環境: Unix。
バージョン 3.3 で追加: 引数 follow_symlinks を追加しました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.chmod(path, mode, *, dir_fd=None, follow_symlinks=True)
path のモードを数値 mode に変更します。 mode は、 (stat モジュールで定義されている ) 以下の値のいずれかまたはビット単位の論理和で組み合わせた値を取り得ます :
stat.S_ISUID
stat.S_ISGID
stat.S_ENFMT
stat.S_ISVTX
stat.S_IREAD
stat.S_IWRITE
stat.S_IEXEC
stat.S_IRWXU
stat.S_IRUSR
stat.S_IWUSR
stat.S_IXUSR
stat.S_IRWXG
stat.S_IRGRP
stat.S_IWGRP
stat.S_IXGRP
stat.S_IRWXO
stat.S_IROTH
stat.S_IWOTH
stat.S_IXOTH
この関数は ファイル記述子の指定 、 ディレクトリ記述子への相対パス 、および シンボリックリンクをたどらない をサポートしています。
注釈 Windows は chmod() をサポートしていますが、ファイルの読み出し専用フラグを (stat.S_IWRITE および stat.S_IREAD 定数または対応する整数値によって) 設定できるだけです。その他のビットはすべて無視されます。
引数 path, mode, dir_fd を指定して 監査イベント os.chmod を送出します。
バージョン 3.3 で追加: path にオープンしているファイル記述子の指定のサポート、および引数 dir_fd と follow_symlinks を追加しました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.chown(path, uid, gid, *, dir_fd=None, follow_symlinks=True)
path の所有者 id およびグループ id を、数値 uid および gid に変更します。いずれかの id を変更せずにおくには、その値として -1 を指定します。
この関数は ファイル記述子の指定 、 ディレクトリ記述子への相対パス 、および シンボリックリンクをたどらない をサポートしています。
数値 id の他に名前でも受け取る高水準関数の shutil.chown() を参照してください。
引数 path, uid, gid, dir_fd を指定して 監査イベント os.chown を送出します。
利用可能な環境: Unix。
バージョン 3.3 で追加: path にオープンしているファイル記述子の指定のサポート、および引数 dir_fd と follow_symlinks を追加しました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.chroot(path)
現在のプロセスのルートディレクトリを path に変更します。
利用可能な環境: Unix。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.fchdir(fd)
現在の作業ディレクトリをファイル記述子 fd が表すディレクトリに変更します。記述子はオープンしているファイルではなく、オープンしたディレクトリを参照していなければなりません。Python 3.3 以降では os.chdir(fd) と等価です。
引数 path を指定して 監査イベント os.chdir を送出します。
利用可能な環境: Unix。
os.getcwd()
現在の作業ディレクトリを表す文字列を返します。
os.getcwdb()
現在の作業ディレクトリを表すバイト列を返します。
バージョン 3.8 で変更: The function now uses the UTF-8 encoding on Windows, rather than the ANSI code page: see PEP 529 for the rationale. The function is no longer deprecated on Windows.
os.lchflags(path, flags)
path のフラグを数値 flags に設定します。chflags() に似ていますが、シンボリックリンクをたどりません。Python 3.3 以降では os.chflags(path, flags, follow_symlinks=False) と等価です。
利用可能な環境: Unix。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.lchmod(path, mode)
path のモードを数値 mode に変更します。パスがシンボリックリンクの場合はそのリンク先ではなくシンボリックリンクそのものに対して作用します。mode に指定できる値については chmod() のドキュメントを参照してください。Python 3.3 以降では os.chmod(path, mode, follow_symlinks=False) と等価です。
引数 path, mode, dir_fd を指定して 監査イベント os.chmod を送出します。
利用可能な環境: Unix。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.lchown(path, uid, gid)
path の所有者 id およびグループ id を、数値 uid および gid に変更します。この関数はシンボリックリンクをたどりません。Python 3.3 以降では os.chown(path, uid, gid, follow_symlinks=False) と等価です。
引数 path, uid, gid, dir_fd を指定して 監査イベント os.chown を送出します。
利用可能な環境: Unix。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.link(src, dst, *, src_dir_fd=None, dst_dir_fd=None, follow_symlinks=True)
src を指し示すハードリンク dst を作成します。
この関数は src_dir_fd と dst_dir_fd の両方またはどちらかに対し ディレクトリ記述子への相対パス および シンボリックリンクをたどらない をサポートしています。
Availability: Unix, Windows。
バージョン 3.2 で変更: Windows サポートを追加しました。
バージョン 3.3 で追加: 引数 src_dir_fd、dst_dir_fd、および follow_symlinks を追加しました。
バージョン 3.6 で変更: src と dst が path-like object を受け付けるようになりました。
os.listdir(path='.')
path may be a path-like object. If path is of type bytes (directly or indirectly through the PathLike interface), the filenames returned will also be of type bytes; in all other circumstances, they will be of type str.
この関数は ファイル記述子の指定 もサポートしています; ファイル記述子はディレクトリを参照していなくてはなりません。
引数 path を指定して 監査イベント os.listdir を送出します。
注釈 文字列型 のファイル名を バイト列型 にエンコードするには、fsencode() を使用します。
参考 ディレクトリエントリに加えてファイル属性情報も返す scandir() 関数の方が、多くの一般的な用途では使い勝手が良くなります。
バージョン 3.2 で変更: 引数 path は任意になりました。
バージョン 3.3 で追加: Added support for specifying path as an open file descriptor.
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.lstat(path, *, dir_fd=None)
与えられたパスに対して lstat() システムコールと同じ処理を行います。stat() と似ていますが、シンボリックリンクをたどりません。 stat_result オブジェクトを返します。
シンボリックリンクをサポートしていないプラットフォームでは stat() の別名です。
Python 3.3 以降では os.stat(path, dir_fd=dir_fd, follow_symlinks=False) と等価です。
この関数は ディレクトリ記述子への相対パス もサポートすることができます。
参考 stat() 関数。
バージョン 3.2 で変更: Windows 6.0 (Vista) のシンボリックリンクをサポートしました。
バージョン 3.3 で変更: 引数 dir_fd を追加しました。
バージョン 3.6 で変更: src と dst が path-like object を受け付けるようになりました。
バージョン 3.8 で変更: On Windows, now opens reparse points that represent another path (name surrogates), including symbolic links and directory junctions. Other kinds of reparse points are resolved by the operating system as for stat().
os.mkdir(path, mode=0o777, *, dir_fd=None)
ディレクトリ path を数値モード mode で作成します。
すでにディレクトリが存在したら、 FileExistsError が上げられます。
いくつかのシステムにおいては mode は無視されます。それが使われる時には、最初に現在の umask 値でマスクされます。もし最後の 9 ビット (つまり mode の8進法表記の最後の3桁) を除いたビットが設定されていたら、それらの意味はプラットフォームに依存します。いくつかのプラットフォームではそれらは無視され、それらを設定するためには明示的に chmod() を呼ぶ必要があるでしょう。
この関数は ディレクトリ記述子への相対パス もサポートすることができます。
一時ディレクトリを作成することもできます : tempfile モジュールの tempfile.mkdtemp() 関数を参照してください。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.makedirs(name, mode=0o777, exist_ok=False)
再帰的にディレクトリを作成する関数です。mkdir() と似ていますが、末端ディレクトリを作成するために必要なすべての中間ディレクトリも作成します。
注釈 作成するパス要素に pardir (UNIX では "..") が含まれる場合、makedirs() は混乱します。
この関数は UNC パスを正しく扱えるようになりました。
バージョン 3.2 で追加: 引数 exist_ok が追加されました。
バージョン 3.4.1 で変更: Python 3.4.1 より前、 exist_ok が True でそのディレクトリが既存の場合でも、 makedirs() は mode が既存ディレクトリのモードと合わない場合にはエラーにしようとしていました。このモードチェックの振る舞いを安全に実装することが出来なかったため、 Python 3.4.1 でこのチェックは削除されました。 bpo-21082 を参照してください。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.7 で変更: The mode argument no longer affects the file permission bits of newly-created intermediate-level directories.
os.mkfifo(path, mode=0o666, *, dir_fd=None)
FIFO (名前付きパイプ) path を数値モード mode で作成します。先に現在の umask 値でマスクされます。
この関数は ディレクトリ記述子への相対パス もサポートすることができます。
FIFO は通常のファイルのようにアクセスできるパイプです。 FIFO は ( 例えば os.unlink() を使って ) 削除されるまで存在しつづけます。一般的に、 FIFO は " クライアント " と " サーバー " 形式のプロセス間でランデブーを行うために使われます : この時、サーバーは FIFO を読み込み用に、クライアントは書き出し用にオープンします。 mkfifo() は FIFO をオープンしない --- 単にランデブーポイントを作成するだけ --- なので注意してください。
利用可能な環境: Unix。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.mknod(path, mode=0o600, device=0, *, dir_fd=None)
path という名前で、ファイルシステムノード (ファイル、デバイス特殊ファイル、または名前つきパイプ) を作成します。mode は、作成するノードのアクセス権限とタイプの両方を stat.S_IFREG、stat.S_IFCHR、stat.S_IFBLK、および stat.S_IFIFO の組み合わせ (ビット単位の論理和) で指定します (これらの定数は stat で利用可能です)。stat.S_IFCHR と stat.S_IFBLK を指定した場合、devide は新しく作成されたデバイス特殊ファイルを (おそらく os.makedev() を使って) 定義し、それ以外の定数を指定した場合は無視されます。
この関数は ディレクトリ記述子への相対パス もサポートすることができます。
利用可能な環境: Unix。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.major(device)
RAW デバイス番号から、デバイスのメジャー番号を取り出します ( 通常 stat の st_dev か st_rdev フィールドです ) 。
os.minor(device)
RAW デバイス番号から、デバイスのマイナー番号を取り出します ( 通常 stat の st_dev か st_rdev フィールドです ) 。
os.makedev(major, minor)
メジャーおよびマイナーデバイス番号から、新しく RAW デバイス番号を作成します。
os.pathconf(path, name)
名前付きファイルに関連するシステム設定情報を返します。 name には取得したい設定名を指定します ; これは定義済みのシステム値名の文字列で、多くの標準 (POSIX.1 、 Unix 95 、 Unix 98 その他 ) で定義されています。プラットフォームによっては別の名前も定義しています。ホストオペレーティングシステムの関知する名前は pathconf_names 辞書で与えられています。このマップ型オブジェクトに入っていない設定変数については、 name に整数を渡してもかまいません。
name が不明の文字列である場合、 ValueError を送出します。 name の特定の値がホストシステムでサポートされていない場合、 pathconf_names に含まれていたとしても、 errno.EINVAL をエラー番号として OSError を送出します。
この関数は ファイル記述子の指定 をサポートしています。
利用可能な環境: Unix。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.pathconf_names
pathconf() および fpathconf() が受理するシステム設定名を、ホストオペレーティングシステムで定義されている整数値に対応付けている辞書です。この辞書はシステムでどの設定名が定義されているかを知るために利用できます。
利用可能な環境: Unix。
os.readlink(path, *, dir_fd=None)
シンボリックリンクが指しているパスを表す文字列を返します。返される値は絶対パスにも、相対パスにもなり得ます ; 相対パスの場合、 os.path.join(os.path.dirname(path), result) を使って絶対パスに変換することができます。
この関数は ディレクトリ記述子への相対パス もサポートすることができます。
Availability: Unix, Windows。
バージョン 3.2 で変更: Windows 6.0 (Vista) のシンボリックリンクをサポートしました。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: Accepts a path-like object on Unix.
バージョン 3.8 で変更: Accepts a path-like object and a bytes object on Windows.
バージョン 3.8 で変更: Added support for directory junctions, and changed to return the substitution path (which typically includes \\?\ prefix) rather than the optional "print name" field that was previously returned.
os.remove(path, *, dir_fd=None)
この関数は ディレクトリ記述子への相対パス をサポートしています。
Windows では、使用中のファイルを削除しようとすると例外を送出します; Unixでは、ディレクトリエントリは削除されますが、記憶装置上に割り当てられたファイル領域は元のファイルが使われなくなるまで残されます。
この関数は意味論的に unlink() と同一です。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.removedirs(name)
再帰的なディレクトリ削除関数です。 rmdir() と同じように動作しますが、末端ディレクトリがうまく削除できるかぎり、 removedirs() は path に現れる親ディレクトリをエラーが送出されるまで ( このエラーは通常、指定したディレクトリの親ディレクトリが空でないことを意味するだけなので無視されます ) 順に削除することを試みます。例えば、 os.removedirs('foo/bar/baz') では最初にディレクトリ 'foo/bar/baz' を削除し、次に 'foo/bar' さらに 'foo' をそれらが空ならば削除します。末端のディレクトリが削除できなかった場合には OSError が送出されます。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None)
Rename the file or directory src to dst. If dst exists, the operation will fail with an OSError subclass in a number of cases:
この関数は src_dir_fd と dst_dir_fd のどちらかまたは両方の指定に ディレクトリ記述子への相対パス をサポートしています。
対象の上書きがクロスプラットフォームになる場合は replace() を使用してください。
バージョン 3.3 で追加: 引数 src_dir_fd および dst_dir_fd が追加されました。
バージョン 3.6 で変更: src と dst が path-like object を受け付けるようになりました。
os.renames(old, new)
再帰的にディレクトリやファイル名を変更する関数です。 rename() のように動作しますが、新たなパス名を持つファイルを配置するために必要な途中のディレクトリ構造をまず作成しようと試みます。名前変更の後、元のファイル名のパス要素は removedirs() を使って右側から順に削除されます。
注釈 この関数はコピー元の末端のディレクトリまたはファイルを削除する権限がない場合には失敗します。
バージョン 3.6 で変更: old と new が path-like object を受け付けるようになりました。
os.replace(src, dst, *, src_dir_fd=None, dst_dir_fd=None)
ファイルまたはディレクトリ src の名前を dst へ変更します。dst がディレクトリの場合 OSError が送出されます。dst が存在し、かつファイルの場合、ユーザーの権限がある限り暗黙のうちに置き換えられます。src と dst が異なるファイルシステム上にあると失敗することがあります。ファイル名の変更が成功する場合はアトミック操作となります (これは POSIX 要求仕様です)。
この関数は src_dir_fd と dst_dir_fd のどちらかまたは両方の指定に ディレクトリ記述子への相対パス をサポートしています。
バージョン 3.3 で追加.
バージョン 3.6 で変更: src と dst が path-like object を受け付けるようになりました。
os.rmdir(path, *, dir_fd=None)
この関数は ディレクトリ記述子への相対パス をサポートしています。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.scandir(path='.')
listdir() の代わりに scandir() を使用すると、ファイルタイプや属性情報も必要とするコードのパフォーマンスが大幅に向上します。これは、オペレーティングシステムがディレクトリのスキャン中にこの情報を提供した場合、os.DirEntry オブジェクトがその情報を公開するからです。すべての os.DirEntry メソッドはシステムコールを実行する場合がありますが、is_dir() と is_file() は、通常はシンボリックリンクにしかシステムコールを必要としません。os.DirEntry.stat() は、Unix 上では常にシステムコールを必要としますが、Windows ではシンボリックリンク用にシステムコールを一つ必要とするだけです。
path may be a path-like object. If path is of type bytes (directly or indirectly through the PathLike interface), the type of the name and path attributes of each os.DirEntry will be bytes; in all other circumstances, they will be of type str.
この関数は ファイル記述子の指定 もサポートしています; ファイル記述子はディレクトリを参照していなくてはなりません。
scandir() イテレータは、 コンテキストマネージャ プロトコルをサポートし、次のメソッドを持ちます。
scandir.close()
イテレータを閉じ、獲得した資源を開放します。
この関数は、イテレータがすべて消費されるか、ガーベージコレクトされた、もしくはイテレート中にエラーが発生した際に自動的に呼び出されます。しかし、 with 文を用いるか、明示的に呼び出すことを推奨します。
バージョン 3.6 で追加.
次の単純な例では、scandir() を使用して、指定した path 内の先頭が '.' でないすべてのファイル (ディレクトリを除く) をすべて表示します。entry.is_file() を呼び出しても、通常は追加のシステムコールは行われません:
with os.scandir(path) as it:
    for entry in it:
        if not entry.name.startswith('.') and entry.is_file():
            print(entry.name)
注釈 On Unix-based systems, scandir() uses the system's opendir() and readdir() functions. On Windows, it uses the Win32 FindFirstFileW and FindNextFileW functions.
バージョン 3.5 で追加.
バージョン 3.6 で追加: Added support for the context manager protocol and the close() method. If a scandir() iterator is neither exhausted nor explicitly closed a ResourceWarning will be emitted in its destructor.
関数が path-like object を受け入れるようになりました。
バージョン 3.7 で変更: Added support for file descriptors on Unix.
class os.DirEntry
ディレクトリエントリのファイルパスとその他のファイル属性を公開するために、scandir() が yield するオブジェクトです。
scandir() は、追加のシステムコールを実行することなく、この情報をできるだけ多く提供します。stat() または lstat() システムコールが実行された場合、os.DirEntry オブジェクトは結果をキャッシュします。
os.DirEntry インスタンスは、寿命の長いデータ構造に保存されることは想定されていません。ファイルメタデータが変更された場合や、 scandir() が呼び出されてから長時間が経過した場合は、 os.stat(entry.path) を呼び出して最新の情報を取得してください。
os.DirEntry のメソッドはオペレーティングシステムコールを実行する場合があるため、それらは OSError も送出する場合があります。エラーを細かく制御する必要がある場合、 os.DirEntry のメソッドの一つの呼び出し時に OSError を捕捉して、適切な処理を行うことができます。
os.DirEntry インスタンスの属性とメソッドは以下の通りです:
name
scandir() の path 引数に対して相対的な、エントリのベースファイル名です。
path
inode()
項目の inode 番号を返します。
結果は os.DirEntry オブジェクトにキャッシュされます。最新の情報を取得するには os.stat(entry.path, follow_symlinks=False).st_ino を使用してください。
Windows 上では、最初のキャッシュされていない呼び出しでシステムコールが必要ですが、 Unix 上では必要ありません。
is_dir(*, follow_symlinks=True)
この項目がディレクトリまたはディレクトリへのシンボリックリンクである場合、 True を返します。項目がそれ以外のファイルやそれ以外のファイルへのシンボリックリンクである場合や、もはや存在しない場合は False を返します。
follow_symlinks が False の場合、項目がディレクトリ (シンボリックリンクはたどりません) の場合にのみ True を返します。項目がディレクトリ以外のファイルである場合や、項目がもはや存在しない場合は False を返します。
結果は os.DirEntry オブジェクトにキャッシュされます。follow_symlinks が True の場合と False の場合とでは、別のオブジェクトにキャッシュされます。最新の情報を取得するには stat.S_ISDIR() と共に os.stat() を呼び出してください。
多くの場合、最初のキャッシュされない呼び出しでは、システムコールは必要とされません。具体的には、シンボリックリンク以外では、Windows も Unix もシステムコールを必要としません。ただし、dirent.d_type == DT_UNKNOWN を返す、ネットワークファイルシステムなどの特定の Unix ファイルシステムは例外です。項目がシンボリックリンクの場合、follow_symlinks が False の場合を除き、シンボリックリンクをたどるためにシステムコールが必要となります。
このメソッドは PermissionError のような OSError を送出することがありますが、 FileNotFoundError は捕捉され送出されません。
is_file(*, follow_symlinks=True)
この項目がファイルまたはファイルへのシンボリックリンクである場合、 True を返します。項目がディレクトリやファイル以外の項目へのシンボリックリンクである場合や、もはや存在しない場合は False を返します。
follow_symlinks が False の場合、項目がファイル (シンボリックリンクはたどりません) の場合にのみ True を返します。項目がディレクトリやその他のファイル以外の項目である場合や、項目がもはや存在しない場合は False を返します。
結果は os.DirEntry オブジェクトにキャッシュされます。キャッシュ、システムコール、例外は、is_dir() と同様に行われます。
is_symlink()
この項目がシンボリックリンクの場合 (たとえ破損していても)、True を返します。項目がディレクトリやあらゆる種類のファイルの場合、またはもはや存在しない場合は False を返します。
結果は os.DirEntry オブジェクトにキャッシュされます。 最新の情報をフェッチするには os.path.islink() を呼び出してください。
多くの場合、最初のキャッシュされない呼び出しでは、システムコールは必要とされません。具体的には、Windows も Unix もシステムコールを必要としません。ただし、dirent.d_type == DT_UNKNOWN を返す、ネットワークファイルシステムなどの特定の Unix ファイルシステムは例外です。
このメソッドは PermissionError のような OSError を送出することがありますが、 FileNotFoundError は捕捉され送出されません。
stat(*, follow_symlinks=True)
この項目の stat_result オブジェクトを返します。このメソッドは、デフォルトでシンボリックリンクをたどります。シンボリックリンクを開始するには、 follow_symlinks=False 引数を追加します。
Windows では、stat_result の st_ino 、 st_dev 、 st_nlink 属性は常にゼロに設定されます。これらの属性を取得するには、 os.stat() を呼び出します。
結果は os.DirEntry オブジェクトにキャッシュされます。follow_symlinks が True の場合と False の場合とでは、別のオブジェクトにキャッシュされます。最新の情報を取得するには、 os.stat() を呼び出してください。
os.DirEntry と pathlib.Path では、いくつかの属性やメソッドがよい対応関係にあります。特に、 name 属性は同じ意味を持ちます。is_dir() 、 is_file() 、 is_symlink() 、 stat() メソッドも同じ意味を持ちます。
バージョン 3.5 で追加.
バージョン 3.6 で変更: PathLike インターフェースをサポートしました。Windowsで:class:bytes パスをサポートしました。
os.stat(path, *, dir_fd=None, follow_symlinks=True)
この関数は通常はシンボリックリンクをたどります。シンボリックリンクに対して stat したい場合は follow_symlinks=False とするか、 lstat() を利用してください。
この関数は ファイル記述子の指定 および シンボリックリンクをたどらない をサポートしています。
以下はプログラム例です:
>>>
>>> import os
>>> statinfo = os.stat('somefile.txt')
>>> statinfo
os.stat_result(st_mode=33188, st_ino=7876932, st_dev=234881026,
st_nlink=1, st_uid=501, st_gid=501, st_size=264, st_atime=1297230295,
st_mtime=1297230027, st_ctime=1297230027)
>>> statinfo.st_size
264
参考 fstat() と lstat()。
バージョン 3.3 で追加: dir_fd, follow_symlinks 引数の追加、ファイル記述子の指定の追加。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.8 で変更: On Windows, all reparse points that can be resolved by the operating system are now followed, and passing follow_symlinks=False disables following all name surrogate reparse points. If the operating system reaches a reparse point that it is not able to follow, stat now returns the information for the original path as if follow_symlinks=False had been specified instead of raising an error.
class os.stat_result
おおむね stat 構造体のメンバーに対応する属性を持つオブジェクトです。os.stat() 、 os.fstat() 、 os.lstat() の結果に使用されます。
属性:
st_mode
ファイルモード。ファイルタイプとファイルモードのビット （権限）。
st_ino
Platform dependent, but if non-zero, uniquely identifies the file for a given value of st_dev. Typically:
the inode number on Unix,
the file index on Windows
st_dev
このファイルが存在するデバイスの識別子。
st_nlink
ハードリンクの数。
st_uid
ファイル所有者のユーザ識別子。
st_gid
ファイル所有者のグループ識別子。
st_size
ファイルが通常のファイルまたはシンボリックリンクの場合、そのファイルのバイト単位でのサイズです。シンボリックリンクのサイズは、含まれるパス名の長さで、null バイトで終わることはありません。
タイムスタンプ:
st_atime
秒で表した最終アクセス時刻。
st_mtime
秒で表した最終内容更新時刻。
st_ctime
プラットフォーム依存:
Unix ではメタデータの最終更新時刻
Windows では作成時刻、単位は秒
st_atime_ns
ナノ秒 (整数) で表した最終アクセス時刻。
st_mtime_ns
ナノ秒 (整数) で表した最終内容更新時刻。
st_ctime_ns
プラットフォーム依存:
Unix ではメタデータの最終更新時刻
Windows で、ナノ秒 (整数) で表した作成時刻。
注釈 st_atime 、 st_mtime 、および st_ctime 属性の厳密な意味や精度はオペレーティングシステムやファイルシステムによって変わります。例えば、 FAT や FAT32 ファイルシステムを使用している Windows システムでは、 st_mtime の精度は 2 秒であり、 st_atime の精度は 1 日に過ぎません。詳しくはお使いのオペレーティングシステムのドキュメントを参照してください。
同じように、st_atime_ns、st_mtime_ns、および st_ctime_ns は常にナノ秒で表されますが、多くのシステムではナノ秒単位の精度では提供していません。ナノ秒単位の精度を提供するシステムであっても、st_atime、st_mtime、および st_ctime についてはそれらが格納される浮動小数点オブジェクトがそのすべてを保持できず、それ自体が少々不正確です。正確なタイムスタンプが必要な場合は、st_atime_ns、st_mtime_ns、および st_ctime_ns を使用するべきです。
(Linux のような ) 一部の Unix システムでは、以下の属性が利用できる場合があります :
st_blocks
ファイルに対して割り当てられている 512 バイトのブロックの数です。ファイルにホール (hole) が含まれている場合、st_size/512 より小さくなる場合があります。
st_blksize
効率的なファイルシステム I/O のための「推奨される」ブロックサイズです。ファイルに、これより小さいチャンクで書き込むと、非効率的な読み込み、編集、再書き込みが起こる場合があります。
st_rdev
inode デバイスの場合デバイスタイプ
st_flags
ファイルのユーザ定義フラグ
他の (FreeBSD のような ) Unix システムでは、以下の属性が利用できる場合があります ( ただし root ユーザ以外が使うと値が入っていない場合があります ):
st_gen
ファイル生成番号
st_birthtime
ファイル作成時刻
On Solaris and derivatives, the following attributes may also be available:
st_fstype
Mac OS システムでは、以下の属性も利用できる場合があります:
st_rsize
ファイルの実際のサイズ
st_creator
ファイルの作成者
st_type
ファイルタイプ
On Windows systems, the following attributes are also available:
st_file_attributes
Windows のファイルの属性。GetFileInformationByHandle() の返す BY_HANDLE_FILE_INFORMATION 構造の dwFileAttributes メンバーです。stat モジュールの FILE_ATTRIBUTE_* 定数を参照してください。
st_reparse_tag
標準モジュール stat は stat 構造体からの情報の取り出しに役立つ関数と定数を定義しています。 (Windows では、一部のアイテムにダミー値が入ります )
後方互換性のため、stat_result インスタンスには、 stat 構造体の最も重要な (そして移植性の高い) メンバーを表す少なくとも 10 個の整数からなるタプルとしてもアクセス可能です。このタプルは、 st_mode、st_ino、st_dev、st_nlink、st_uid、st_gid、st_size、st_atime、st_mtime、st_ctime の順になります。実装によってはそれ以上のアイテムが末尾に追加されます。古いバージョンの Python との互換性のため、 stat_result にタプルとしてアクセスすると、常に整数を返します。
バージョン 3.3 で追加: st_atime_ns、st_mtime_ns、st_ctime_ns メンバが追加されました。
バージョン 3.5 で追加: Windows において st_file_attributes メンバが追加されました。
バージョン 3.5 で変更: Windows now returns the file index as st_ino when available.
バージョン 3.7 で追加: Added the st_fstype member to Solaris/derivatives.
バージョン 3.8 で追加: Added the st_reparse_tag member on Windows.
バージョン 3.8 で変更: On Windows, the st_mode member now identifies special files as S_IFCHR, S_IFIFO or S_IFBLK as appropriate.
os.statvfs(path)
f_flag 属性のビットフラグ用に 2 つのモジュールレベル定数が定義されています: ST_RDONLY が設定されるとファイルシステムは読み出し専用でマウントされ、ST_NOSUID が設定されると setuid/setgid ビットの動作は無効になるか、サポートされません。
GNU/glibc ベースのシステム用に、追加のモジュールレベルの定数が次のように定義されています。 ST_NODEV (デバイス特殊ファイルへのアクセスを許可しない) 、 ST_NOEXEC (プログラムの実行を許可しない) 、 ST_SYNCHRONOUS (書き込みが一度に同期される) 、ST_MANDLOCK (ファイルシステムで強制的なロックを許可する) 、 ST_WRITE (ファイル/ディレクトリ/シンボリックリンクに書き込む) 、 ST_APPEND (追記のみのファイル) 、ST_IMMUTABLE (変更不能なファイル) 、 ST_NOATIME (アクセス時刻を更新しない) 、ST_NODIRATIME (ディレクトリアクセス時刻を更新しない) 、ST_RELATIME (mtime/ctimeに対して相対的に atime を更新する)。
この関数は ファイル記述子の指定 をサポートしています。
利用可能な環境: Unix。
バージョン 3.2 で変更: 定数 ST_RDONLY および ST_NOSUID が追加されました。
バージョン 3.3 で追加: Added support for specifying path as an open file descriptor.
バージョン 3.4 で変更: ST_NODEV, ST_NOEXEC, ST_SYNCHRONOUS, ST_MANDLOCK, ST_WRITE, ST_APPEND, ST_IMMUTABLE, ST_NOATIME, ST_NODIRATIME, ST_RELATIME 定数が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.7 で追加: Added f_fsid.
os.supports_dir_fd
A set object indicating which functions in the os module accept an open file descriptor for their dir_fd parameter. Different platforms provide different features, and the underlying functionality Python uses to implement the dir_fd parameter is not available on all platforms Python supports. For consistency's sake, functions that may support dir_fd always allow specifying the parameter, but will throw an exception if the functionality is used when it's not locally available. (Specifying None for dir_fd is always supported on all platforms.)
To check whether a particular function accepts an open file descriptor for its dir_fd parameter, use the in operator on supports_dir_fd. As an example, this expression evaluates to True if os.stat() accepts open file descriptors for dir_fd on the local platform:
os.stat in os.supports_dir_fd
現在 dir_fd 引数は Unix プラットフォームでのみ動作します。Windows で動作する関数はありません。
バージョン 3.3 で追加.
os.supports_effective_ids
This expression evaluates to True if os.access() supports effective_ids=True on the local platform:
os.access in os.supports_effective_ids
バージョン 3.3 で追加.
os.supports_fd
To determine whether a particular function permits specifying an open file descriptor for its path parameter, use the in operator on supports_fd. As an example, this expression evaluates to True if os.chdir() accepts open file descriptors for path on your local platform:
os.chdir in os.supports_fd
バージョン 3.3 で追加.
os.supports_follow_symlinks
A set object indicating which functions in the os module accept False for their follow_symlinks parameter on the local platform. Different platforms provide different features, and the underlying functionality Python uses to implement follow_symlinks is not available on all platforms Python supports. For consistency's sake, functions that may support follow_symlinks always allow specifying the parameter, but will throw an exception if the functionality is used when it's not locally available. (Specifying True for follow_symlinks is always supported on all platforms.)
To check whether a particular function accepts False for its follow_symlinks parameter, use the in operator on supports_follow_symlinks. As an example, this expression evaluates to True if you may specify follow_symlinks=False when calling os.stat() on the local platform:
os.stat in os.supports_follow_symlinks
バージョン 3.3 で追加.
os.symlink(src, dst, target_is_directory=False, *, dir_fd=None)
src を指し示すシンボリックリンク dst を作成します。
この関数は ディレクトリ記述子への相対パス をサポートしています。
注釈 On newer versions of Windows 10, unprivileged accounts can create symlinks if Developer Mode is enabled. When Developer Mode is not available/enabled, the SeCreateSymbolicLinkPrivilege privilege is required, or the process must be run as an administrator.
この関数が特権を持たないユーザーに呼び出されると、OSError が送出されます。
Availability: Unix, Windows。
バージョン 3.2 で変更: Windows 6.0 (Vista) のシンボリックリンクをサポートしました。
バージョン 3.3 で追加: 引数 dir_fd が追加され、非 Windows プラットフォームでの target_is_directory 指定がサポートされました。
バージョン 3.6 で変更: src と dst が path-like object を受け付けるようになりました。
バージョン 3.8 で変更: Added support for unelevated symlinks on Windows with Developer Mode.
os.sync()
ディスクキャッシュのディスクへの書き出しを強制します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.truncate(path, length)
path に対応するファイルを、サイズが最大で length バイトになるよう切り詰めます。
この関数は ファイル記述子の指定 をサポートしています。
Availability: Unix, Windows。
バージョン 3.3 で追加.
バージョン 3.5 で変更: Windows サポートを追加しました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.unlink(path, *, dir_fd=None)
ファイル path を削除します。意味上は remove() と等価です。 unlink の名前は伝統的な Unix の関数名です。詳細は remove() のドキュメントを参照してください。
バージョン 3.3 で追加: 引数 dir_fd が追加されました。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.utime(path, times=None, *, [ns, ]dir_fd=None, follow_symlinks=True)
path で指定されたファイルに最終アクセス時刻および最終修正時刻を設定します。
utime() は 2 つの任意引数 times と ns をとります。これらは path に設定する時刻を指定し、以下のように使用されます:
ns を指定する場合、ナノ秒を表す整数値をメンバーとして使用して、 (atime_ns, mtime_ns) の形式の 2 要素タプルを指定する必要があります。
times が None ではない場合、(atime, mtime) の形式で各メンバーは単位を秒で表す整数か浮動小数点値のタプルを指定しなければなりません。
times が None で、 ns が指定されていない場合、これは両方の時間を現在時刻として ns=(atime_ns, mtime_ns) を指定することと等価です。
times と ns の両方にタプルが指定されるとエラーになります。
この関数は ファイル記述子の指定 、 ディレクトリ記述子への相対パス 、および シンボリックリンクをたどらない をサポートしています。
バージョン 3.3 で追加: Added support for specifying path as an open file descriptor, and the dir_fd, follow_symlinks, and ns parameters.
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.walk(top, topdown=True, onerror=None, followlinks=False)
ディレクトリツリー以下のファイル名を、ツリーをトップダウンもしくはボトムアップに走査することで作成します。ディレクトリ top を根に持つディレクトリツリーに含まれる、各ディレクトリ (top 自身を含む ) ごとに、タプル (dirpath, dirnames, filenames) を yield します。
dirpath is a string, the path to the directory. dirnames is a list of the names of the subdirectories in dirpath (excluding '.' and '..'). filenames is a list of the names of the non-directory files in dirpath. Note that the names in the lists contain no path components. To get a full path (which begins with top) to a file or directory in dirpath, do os.path.join(dirpath, name). Whether or not the lists are sorted depends on the file system. If a file is removed from or added to the dirpath directory during generating the lists, whether a name for that file be included is unspecified.
オプション引数 topdown が True であるか、指定されなかった場合、各ディレクトリからタプルを生成した後で、サブディレクトリからタプルを生成します。 ( ディレクトリはトップダウンで生成 ) 。 topdown が False の場合、ディレクトリに対応するタプルは、そのディレクトリ以下の全てのサブディレクトリに対応するタプルの後で ( ボトムアップで ) 生成されます。 topdown の値によらず、サブディレクトリのリストは、ディレクトリとそのサブディレクトリのタプルを生成する前に取り出されます。
topdown が True のとき、呼び出し側は dirnames リストを、インプレースで ( たとえば、 del やスライスを使った代入で ) 変更でき、 walk() は dirnames に残っているサブディレクトリ内のみを再帰します。これにより、検索を省略したり、特定の訪問順序を強制したり、呼び出し側が walk() を再開する前に、呼び出し側が作った、または名前を変更したディレクトリを、 walk() に知らせたりすることができます。 topdown が False のときに dirnames を変更しても効果はありません。ボトムアップモードでは dirpath 自身が生成される前に dirnames 内のディレクトリの情報が生成されるからです。
デフォルトでは、 walk() はディレクトリへのシンボリックリンクをたどりません。 followlinks に True を指定すると、ディレクトリへのシンボリックリンクをサポートしているシステムでは、シンボリックリンクの指しているディレクトリを走査します。
注釈 followlinks に True を指定すると、シンボリックリンクが親ディレクトリを指していた場合に、無限ループになることに注意してください。 walk() はすでにたどったディレクトリを管理したりはしません。
注釈 相対パスを渡した場合、 walk() が再開されるまでの間に現在の作業ディレクトリを変更しないでください。 walk() はカレントディレクトリを変更しませんし、呼び出し側もカレントディレクトリを変更しないと仮定しています。
以下の例では、最初のディレクトリ以下にある各ディレクトリに含まれる、非ディレクトリファイルのバイト数を表示します。ただし、 CVS サブディレクトリ以下は見に行きません
import os
from os.path import join, getsize
for root, dirs, files in os.walk('python/Lib/email'):
    print(root, "consumes", end=" ")
    print(sum(getsize(join(root, name)) for name in files), end=" ")
    print("bytes in", len(files), "non-directory files")
    if 'CVS' in dirs:
        dirs.remove('CVS')  # don't visit CVS directories
次の例 (shutil.rmtree() の単純な実装) では、ツリーをボトムアップで走査することが不可欠になります; rmdir() はディレクトリが空になるまで削除を許さないからです:
# Delete everything reachable from the directory named in "top",
# assuming there are no symbolic links.
# CAUTION:  This is dangerous!  For example, if top == '/', it
# could delete all your disk files.
import os
for root, dirs, files in os.walk(top, topdown=False):
    for name in files:
        os.remove(os.path.join(root, name))
    for name in dirs:
        os.rmdir(os.path.join(root, name))
バージョン 3.5 で変更: この関数は、今では os.listdir() ではなく os.scandir() を呼び出します。これにより、 os.stat() の呼び出し回数を削減でき、動作が高速化します。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.fwalk(top='.', topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None)
挙動は walk() と同じですが、dir_fd をサポートし、タプル (dirpath, dirnames, filenames, dirfd) を yield します。
dirpath、dirnames、および filenames は walk() の出力と同じで、dirfd は dirpath を参照するファイル記述子です。
この関数は常に ディレクトリ記述子への相対パス および シンボリックリンクをたどらない をサポートしています。ただし、他の関数と異なり、fwalk() での follow_symlinks のデフォルト値は False になることに注意してください。
注釈 fwalk() はファイル記述子を yield するため、それらが有効なのは次のイテレートステップまでです。それ以後も保持したい場合は dup() などを使って複製して使用してください。
以下の例では、最初のディレクトリ以下にある各ディレクトリに含まれる、非ディレクトリファイルのバイト数を表示します。ただし、 CVS サブディレクトリ以下は見に行きません
import os
for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):
    print(root, "consumes", end="")
    print(sum([os.stat(name, dir_fd=rootfd).st_size for name in files]),
          end="")
    print("bytes in", len(files), "non-directory files")
    if 'CVS' in dirs:
        dirs.remove('CVS')  # don't visit CVS directories
次の例では、ツリーをボトムアップで走査することが不可欠になります ; rmdir() はディレクトリが空になるまで削除を許さないからです
# Delete everything reachable from the directory named in "top",
# assuming there are no symbolic links.
# CAUTION:  This is dangerous!  For example, if top == '/', it
# could delete all your disk files.
import os
for root, dirs, files, rootfd in os.fwalk(top, topdown=False):
    for name in files:
        os.unlink(name, dir_fd=rootfd)
    for name in dirs:
        os.rmdir(name, dir_fd=rootfd)
利用可能な環境: Unix。
バージョン 3.3 で追加.
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
バージョン 3.7 で変更: Added support for bytes paths.
os.memfd_create(name[, flags=os.MFD_CLOEXEC])
バージョン 3.8 で追加.
os.MFD_CLOEXEC
os.MFD_ALLOW_SEALING
os.MFD_HUGETLB
os.MFD_HUGE_SHIFT
os.MFD_HUGE_MASK
os.MFD_HUGE_64KB
os.MFD_HUGE_512KB
os.MFD_HUGE_1MB
os.MFD_HUGE_2MB
os.MFD_HUGE_8MB
os.MFD_HUGE_16MB
os.MFD_HUGE_32MB
os.MFD_HUGE_256MB
os.MFD_HUGE_512MB
os.MFD_HUGE_1GB
os.MFD_HUGE_2GB
os.MFD_HUGE_16GB
バージョン 3.8 で追加.
Linux 拡張属性
バージョン 3.3 で追加.
以下の関数はすべて Linux でのみ使用可能です。
os.getxattr(path, attribute, *, follow_symlinks=True)
この関数は ファイル記述子の指定 および シンボリックリンクをたどらない をサポートしています。
バージョン 3.6 で変更: path と attribute が path-like object を受け付けるようになりました。
os.listxattr(path=None, *, follow_symlinks=True)
path の拡張ファイルシステム属性のリストを返します。リスト内の属性はファイルシステムのエンコーディングでデコードされた文字列で表されます。path が None の場合、listxattr() はカレントディレクトリを調べます。
この関数は ファイル記述子の指定 および シンボリックリンクをたどらない をサポートしています。
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.removexattr(path, attribute, *, follow_symlinks=True)
この関数は ファイル記述子の指定 および シンボリックリンクをたどらない をサポートしています。
バージョン 3.6 で変更: path と attribute が path-like object を受け付けるようになりました。
os.setxattr(path, attribute, value, flags=0, *, follow_symlinks=True)
この関数は ファイル記述子の指定 および シンボリックリンクをたどらない をサポートしています。
注釈 Linux カーネル 2.6.39 以前では、バグのため一部のファイルシステムで引数 flags が無視されます。
バージョン 3.6 で変更: path と attribute が path-like object を受け付けるようになりました。
os.XATTR_SIZE_MAX
拡張属性の値にできる最大サイズです。現在、Linux では 64 キロバイトです。
os.XATTR_CREATE
setxattr() の引数 flags に指定できる値です。その操作で属性を作成しなければならないことを意味します。
os.XATTR_REPLACE
setxattr() の引数 flags に指定できる値です。その操作で既存の属性を置き換えなければならないことを意味します。
プロセス管理
以下の関数はプロセスの生成や管理に利用できます。
さまざまな exec* 関数は、プロセス内にロードされる新しいプログラムに与えるための、引数のリストを取ります。どの関数の場合でも、新しいプログラムに渡されるリストの最初の引数は、ユーザがコマンドラインで入力する引数ではなく、そのプログラム自体の名前です。 C プログラマならば、プログラムの main() に渡される argv[0] だと考えれば良いでしょう。たとえば、 os.execv('/bin/echo', ['foo', 'bar']) が標準出力に出力するのは bar だけで、 foo は無視されたかのように見えることになります。
os.abort()
SIGABRT シグナルを現在のプロセスに対して生成します。 Unix では、デフォルトの動作はコアダンプの生成です ; Windows では、プロセスは即座に終了コード 3 を返します。この関数の呼び出しは signal.signal() を使って SIGABRT に対し登録された Python シグナルハンドラーを呼び出さないことに注意してください。
os.add_dll_directory(path)
利用可能な環境: Windows 。
バージョン 3.8 で追加: Previous versions of CPython would resolve DLLs using the default behavior for the current process. This led to inconsistencies, such as only sometimes searching PATH or the current working directory, and OS functions such as AddDllDirectory having no effect.
os.execl(path, arg0, arg1, ...)
os.execle(path, arg0, arg1, ..., env)
os.execlp(file, arg0, arg1, ...)
os.execlpe(file, arg0, arg1, ..., env)
os.execv(path, args)
os.execve(path, args, env)
os.execvp(file, args)
os.execvpe(file, args, env)
これらの関数はすべて、現在のプロセスを置き換える形で新たなプログラムを実行します ; 現在のプロセスは返り値を返しません。 Unix では、新たに実行される実行コードは現在のプロセス内に読み込まれ、呼び出し側と同じプロセス ID を持つことになります。エラーは OSError 例外として報告されます。
現在のプロセスは瞬時に置き換えられます。開かれているファイルオブジェクトやファイル記述子はフラッシュされません。そのため、バッファ内にデータが残っているかもしれない場合、 exec* 関数を実行する前に sys.stdout.flush() か os.fsync() を利用してバッファをフラッシュしておく必要があります。
"l" および "v" のついた exec* 関数は、コマンドライン引数をどのように渡すかが異なります。 "l" 型は、コードを書くときにパラメタ数が決まっている場合に、おそらくもっとも簡単に利用できます。個々のパラメタは単に execl*() 関数の追加パラメタとなります。 "v" 型は、パラメタの数が可変の時に便利で、リストかタプルの引数が args パラメタとして渡されます。どちらの場合も、子プロセスに渡す引数は動作させようとしているコマンドの名前から始まるべきですが、これは強制されません。
末尾近くに "p" をもつ型 (execlp(), execlpe(), execvp(), および execvpe()) は、プログラム file を探すために環境変数 PATH を利用します。環境変数が ( 次の段で述べる exec*e 型関数で ) 置き換えられる場合、環境変数は PATH を決定する上の情報源として使われます。その他の型、 execl(), execle(), execv(), および execve() では、実行コードを探すために PATH を使いません。 path には適切に設定された絶対パスまたは相対パスが入っていなくてはなりません。
execle() 、 execlpe() 、 execve() 、および execvpe() (すべて末尾に "e" がついています) では、 env 引数は新たなプロセスで利用される環境変数を定義するためのマップ型でなくてはなりません ( 現在のプロセスの環境変数の代わりに利用されます ); execl() 、 execlp() 、 execv() 、および execvp() では、すべて新たなプロセスは現在のプロセスの環境を引き継ぎます。
一部のプラットフォームの execve() では、path はオープンしているファイル記述子で指定することもできます。この機能をサポートしていないプラットフォームもあります; os.supports_fd を使うことで利用可能かどうか調べることができます。利用できない場合、NotImplementedError が送出されます。
Availability: Unix, Windows。
バージョン 3.3 で追加: Added support for specifying path as an open file descriptor for execve().
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os._exit(n)
終了ステータス n でプロセスを終了します。この時クリーンアップハンドラーの呼び出しや、標準入出力バッファのフラッシュなどは行いません。
注釈 終了する標準的な方法は sys.exit(n) です。 _exit() は通常、 fork() された後の子プロセスでのみ使われます。
以下の終了コードは必須ではありませんが _exit() で使うことができます。一般に、メールサーバーの外部コマンド配送プログラムのような、 Python で書かれたシステムプログラムに使います。
注釈 いくつかのバリエーションがあって、これらのすべてがすべての Unix プラットフォームで使えるわけではありません。以下の定数は下層のプラットフォームで定義されていれば定義されます。
os.EX_OK
エラーが起きなかったことを表す終了コード。
利用可能な環境: Unix。
os.EX_USAGE
誤った個数の引数が渡された時など、コマンドが間違って使われたことを表す終了コード。
利用可能な環境: Unix。
os.EX_DATAERR
入力データが誤っていたことを表す終了コード。
利用可能な環境: Unix。
os.EX_NOINPUT
入力ファイルが存在しなかった、または、読み込み不可だったことを表す終了コード。
利用可能な環境: Unix。
os.EX_NOUSER
指定されたユーザーが存在しなかったことを表す終了コード。
利用可能な環境: Unix。
os.EX_NOHOST
指定されたホストが存在しなかったことを表す終了コード。
利用可能な環境: Unix。
os.EX_UNAVAILABLE
要求されたサービスが利用できないことを表す終了コード。
利用可能な環境: Unix。
os.EX_SOFTWARE
内部ソフトウェアエラーが検出されたことを表す終了コード。
利用可能な環境: Unix。
os.EX_OSERR
fork できない、 pipe の作成ができないなど、オペレーティングシステムのエラーが検出されたことを表す終了コード。
利用可能な環境: Unix。
os.EX_OSFILE
システムファイルが存在しなかった、開けなかった、あるいはその他のエラーが起きたことを表す終了コード。
利用可能な環境: Unix。
os.EX_CANTCREAT
ユーザーには作成できない出力ファイルを指定したことを表す終了コード。
利用可能な環境: Unix。
os.EX_IOERR
ファイルの I/O を行っている途中にエラーが発生した時の終了コード。
利用可能な環境: Unix。
os.EX_TEMPFAIL
一時的な失敗が発生したことを表す終了コード。これは、再試行可能な操作の途中に、ネットワークに接続できないというような、実際にはエラーではないかも知れないことを意味します。
利用可能な環境: Unix。
os.EX_PROTOCOL
プロトコル交換が不正、不適切、または理解不能なことを表す終了コード。
利用可能な環境: Unix。
os.EX_NOPERM
操作を行うために十分な許可がなかった（ファイルシステムの問題を除く）ことを表す終了コード。
利用可能な環境: Unix。
os.EX_CONFIG
設定エラーが起こったことを表す終了コード。
利用可能な環境: Unix。
os.EX_NOTFOUND
"an entry was not found" のようなことを表す終了コード。
利用可能な環境: Unix。
os.fork()
子プロセスを fork します。子プロセスでは 0 が返り、親プロセスでは子プロセスの id が返ります。エラーが発生した場合は、 OSError を送出します。
バージョン 3.8 で変更: Calling fork() in a subinterpreter is no longer supported (RuntimeError is raised).
警告 SSL モジュールを fork() とともに使うアプリケーションについて、 ssl を参照して下さい。
利用可能な環境: Unix。
os.forkpty()
子プロセスを fork します。この時新しい擬似端末を子プロセスの制御端末として使います。親プロセスでは (pid, fd) からなるペアが返り、 fd は擬似端末のマスター側のファイル記述子となります。可搬性のあるアプローチを取るには、 pty モジュールを利用してください。エラーが発生した場合は、 OSError を送出します。
バージョン 3.8 で変更: Calling forkpty() in a subinterpreter is no longer supported (RuntimeError is raised).
利用できる環境: 一部の Unix 互換環境。
os.kill(pid, sig)
プロセス pid にシグナル sig を送ります。ホストプラットフォームで利用可能なシグナルを特定する定数は signal モジュールで定義されています。
Windows: signal.CTRL_C_EVENT と signal.CTRL_BREAK_EVENT は、同じコンソールウィンドウを共有しているコンソールプロセス ( 例 : 子プロセス ) にだけ送ることができる特別なシグナルです。その他の値を sig に与えると、そのプロセスが無条件に TerminateProcess API によって kill され、終了コードが sig に設定されます。 Windows の kill() は kill するプロセスのハンドルも受け取ります。
signal.pthread_kill() も参照してください。
バージョン 3.2 で追加: Windows をサポートしました。
os.killpg(pgid, sig)
プロセスグループ pgid にシグナル sig を送ります。
利用可能な環境: Unix。
os.nice(increment)
プロセスの "nice 値 " に increment を加えます。新たな nice 値を返します。
利用可能な環境: Unix。
os.pidfd_open(pid, flags=0)
Availability: Linux 5.3+
バージョン 3.9 で追加.
os.plock(op)
プログラムのセグメントをメモリ内にロックします。 op (<sys/lock.h> で定義されています ) にはどのセグメントをロックするかを指定します。
利用可能な環境: Unix。
os.popen(cmd, mode='r', buffering=-1)
コマンド cmd への、または cmd からのパイプ入出力を開きます。戻り値はパイプに接続されている開かれたファイルオブジェクトで、 mode が 'r' (デフォルト) または 'w' かによって読み出しまたは書き込みを行うことができます。引数 bufsize は、組み込み関数 open() における対応する引数と同じ意味を持ちます。 返されるファイルオブジェクトは、バイトではなくテキスト文字列を読み書きします。
close メソッドは、サブプロセスが正常に終了した場合は None を返し、エラーが発生した場合にはサブプロセスの返りコードを返します。POSIX システムでは、返りコードが正の場合、そのコードは1バイト左にシフトしてプロセスが終了したことを示します。返りコードが負の場合、プロセスは返りコードの符号を変えた信号により終了します 。 (例えば、サブプロセスが kill された場合、返り値は - signal.SIGKILL となる場合があります。) Windows システムでは、返り値には子プロセスからの符号のついた整数の返りコードを含まれます。
これは、subprocess.Popen を使用して実装されています。サブプロセスを管理し、サブプロセスと通信を行うためのより強力な方法については、クラスのドキュメンテーションを参照してください。
os.posix_spawn(path, argv, env, *, file_actions=None, setpgroup=None, resetids=False, setsid=False, setsigmask=(), setsigdef=(), scheduler=None)
The file_actions argument may be a sequence of tuples describing actions to take on specific file descriptors in the child process between the C library implementation's fork() and exec() steps. The first item in each tuple must be one of the three type indicator listed below describing the remaining tuple elements:
os.POSIX_SPAWN_OPEN
(os.POSIX_SPAWN_OPEN, fd, path, flags, mode)
os.POSIX_SPAWN_CLOSE
(os.POSIX_SPAWN_CLOSE, fd)
os.POSIX_SPAWN_DUP2
(os.POSIX_SPAWN_DUP2, fd, new_fd)
バージョン 3.8 で追加.
利用可能な環境: Unix。
os.posix_spawnp(path, argv, env, *, file_actions=None, setpgroup=None, resetids=False, setsid=False, setsigmask=(), setsigdef=(), scheduler=None)
バージョン 3.8 で追加.
os.register_at_fork(*, before=None, after_in_parent=None, after_in_child=None)
before is a function called before forking a child process.
after_in_parent is a function called from the parent process after forking a child process.
after_in_child is a function called from the child process.
利用可能な環境: Unix。
バージョン 3.7 で追加.
os.spawnl(mode, path, ...)
os.spawnle(mode, path, ..., env)
os.spawnlp(mode, file, ...)
os.spawnlpe(mode, file, ..., env)
os.spawnv(mode, path, args)
os.spawnve(mode, path, args, env)
os.spawnvp(mode, file, args)
os.spawnvpe(mode, file, args, env)
新たなプロセス内でプログラム path を実行します。
(subprocess モジュールが、新しいプロセスを実行して結果を取得するための、より強力な機能を提供しています。この関数の代わりに subprocess モジュールを利用することが推奨されています。 subprocess モジュールのドキュメントの、 古い関数を subprocess モジュールで置き換える セクションを参照してください )
mode が P_NOWAIT の場合、この関数は新たなプロセスのプロセス ID を返します ; mode が P_WAIT の場合、子プロセスが正常に終了するとその終了コードが返ります。そうでない場合にはプロセスを kill したシグナル signal に対して -signal が返ります。 Windows では、プロセス ID は実際にはプロセスハンドル値になるので、 waitpid() 関数で使えます。
"l" および "v" のついた spawn* 関数は、コマンドライン引数をどのように渡すかが異なります。 "l" 型は、コードを書くときにパラメタ数が決まっている場合に、おそらくもっとも簡単に利用できます。個々のパラメタは単に spawnl*() 関数の追加パラメタとなります。 "v" 型は、パラメタの数が可変の時に便利で、リストかタプルの引数が args パラメタとして渡されます。どちらの場合も、子プロセスに渡す引数は動作させようとしているコマンドの名前から始まらなければなりません。
末尾近くに "p" をもつ型 (spawnlp(), spawnlpe(), spawnvp(), spawnvpe()) は、プログラム file を探すために環境変数 PATH を利用します。環境変数が ( 次の段で述べる spawn*e 型関数で ) 置き換えられる場合、環境変数は PATH を決定する上の情報源として使われます。その他の型、 spawnl(), spawnle(), spawnv(), および spawnve() では、実行コードを探すために PATH を使いません。 path には適切に設定された絶対パスまたは相対パスが入っていなくてはなりません。
spawnle(), spawnlpe(), spawnve(), および spawnvpe() (すべて末尾に "e" がついています) では、 env 引数は新たなプロセスで利用される環境変数を定義するためのマップ型でなくてはなりません ; spawnl() 、 spawnlp() 、 spawnv() 、および spawnvp() では、すべて新たなプロセスは現在のプロセスの環境を引き継ぎます。 env 辞書のキーと値はすべて文字列である必要があります。不正なキーや値を与えると関数が失敗し、 127 を返します。
例えば、以下の spawnlp() および spawnvpe() 呼び出しは等価です
import os
os.spawnlp(os.P_WAIT, 'cp', 'cp', 'index.html', '/dev/null')
L = ['cp', 'index.html', '/dev/null']
os.spawnvpe(os.P_WAIT, 'cp', L, os.environ)
バージョン 3.6 で変更: path-like object を受け入れるようになりました。
os.P_NOWAIT
os.P_NOWAITO
spawn* 関数ファミリに対する mode パラメタとして取れる値です。この値のいずれかを mode として与えた場合、 spawn*() 関数は新たなプロセスが生成されるとすぐに、プロセスの ID を戻り値として返ります。
Availability: Unix, Windows。
os.P_WAIT
spawn* 関数ファミリに対する mode パラメタとして取れる値です。この値を mode として与えた場合、 spawn*() 関数は新たなプロセスを起動して完了するまで返らず、プロセスがうまく終了した場合には終了コードを、シグナルによってプロセスが kill された場合には -signal を返します。
Availability: Unix, Windows。
os.P_DETACH
os.P_OVERLAY
spawn* 関数ファミリに対する mode パラメタとして取れる値です。これらの値は上の値よりもやや可搬性において劣っています。 P_DETACH は P_NOWAIT に似ていますが、新たなプロセスは呼び出しプロセスのコンソールから切り離され (detach) ます。 P_OVERLAY が使われた場合、現在のプロセスは置き換えられます。したがって spawn* は返りません。
利用可能な環境: Windows 。
os.startfile(path[, operation])
ファイルを関連付けられたアプリケーションを使ってスタートします。
operation が指定されないか、または 'open' である時、この動作は、 Windows の Explorer 上でのファイルをダブルクリックした、あるいはコマンドプロンプト上でファイル名を start コマンドの引数としての実行した場合と等価です : ファイルは拡張子が関連付けされているアプリケーション ( が存在する場合 ) を使って開かれます。
他の operation が与えられる場合、それはファイルに対して何がなされるべきかを表す "command verb" ( コマンドを表す動詞 ) でなければなりません。 Microsoft が文書化している動詞は、 'print' と 'edit' ( ファイルに対して ) および 'explore' と 'find' ( ディレクトリに対して ) です。
startfile() は関連付けされたアプリケーションが起動すると同時に返ります。アプリケーションが閉じるまで待機させるためのオプションはなく、アプリケーションの終了状態を取得する方法もありません。引数 path はカレントディレクトリからの相対パスです。絶対パスで指定したい場合は、最初の文字はスラッシュ ('/') ではないので注意してください。最初の文字がスラッシュの場合、下層の Win32 ShellExecute() 関数は動作しません。 os.path.normpath() 関数を使って、 Win32 用に正しくコード化されたパスになるようにしてください。
インタープリタの起動時のオーバーヘッドを削減するため、この関数が最初に呼ばれるまで、Win32 ShellExecute() 関数は決定されません。関数を決定できない場合、 NotImplementedError が送出されます。
利用可能な環境: Windows 。
os.system(command)
サブシェル内でコマンド (文字列) を実行します。この関数は標準 C 関数 system() を使って実装されており、system() と同じ制限があります。sys.stdin などに対する変更を行っても、実行されるコマンドの環境には反映されません。command が何らかの出力を生成した場合、インタープリターの標準出力ストリームに送られます。
Unix では、返り値はプロセスの終了ステータスで、 wait() で定義されている書式にコード化されています。 POSIX は system() 関数の返り値の意味について定義していないので、 Python の system() における返り値はシステム依存となることに注意してください。
Windows では、返り値は command を実行した後にシステムシェルから返される値です。シェルは通常 cmd.exe であり、返す値は実行したコマンドの終了ステータスになります。シェルの種類は Windows の環境変数 COMSPEC: に指定されています。ネイティブでないシェルを使用している場合は、そのドキュメントを参照してください。
subprocess モジュールは、新しいプロセスを実行して結果を取得するためのより強力な機能を提供しています。この関数の代わりに subprocess モジュールを利用することが推奨されています。 subprocess モジュールのドキュメントの 古い関数を subprocess モジュールで置き換える 節のレシピを参考にして下さい。
Availability: Unix, Windows。
os.times()
現在の全体的なプロセス時間を返します。返り値は 5 個の属性を持つオブジェクトになります:
user - ユーザー時間
system - システム時間
children_user - すべての子プロセスのユーザー時間
children_system - すべての子プロセスのシステム時間
elapsed - 去のある固定時点からの経過実時間
後方互換性のため、このオブジェクトは 5 個のアイテム user 、 system 、 children_user 、 children_system 、および elapsed を持つタプルのようにも振る舞います。
Availability: Unix, Windows。
バージョン 3.3 で変更: 返り値の型が、タプルから属性名のついたタプルライクオブジェクトに変更されました。
os.wait()
子プロセスの実行完了を待機し、子プロセスの pid と終了コードインジケーター --- 16 ビットの数値で、下位バイトがプロセスを kill したシグナル番号、上位バイトが終了ステータス ( シグナル番号がゼロの場合 ) --- の入ったタプルを返します ; コアダンプファイルが生成された場合、下位バイトの最上桁ビットが立てられます。
waitstatus_to_exitcode() can be used to convert the exit status into an exit code.
利用可能な環境: Unix。
参考 waitpid() can be used to wait for the completion of a specific child process and has more options.
os.waitid(idtype, id, options)
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.P_PID
os.P_PGID
os.P_ALL
waitid() の idtype に指定できる値です。これらは id がどう解釈されるかに影響します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.P_PIDFD
Availability: Linux 5.4+
バージョン 3.9 で追加.
os.WEXITED
os.WSTOPPED
os.WNOWAIT
waitid() の options で使用できるフラグです。子プロセスのどのシグナルを待機するかを指定します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
os.CLD_EXITED
os.CLD_KILLED
os.CLD_DUMPED
os.CLD_TRAPPED
os.CLD_STOPPED
os.CLD_CONTINUED
waitid() の返り値の si_code に設定され得る値です。
利用可能な環境: Unix。
バージョン 3.3 で追加.
バージョン 3.9 で変更: Added CLD_KILLED and CLD_STOPPED values.
os.waitpid(pid, options)
この関数の詳細は Unix と Windows で異なります。
Unix の場合 : プロセス id pid で与えられた子プロセスの完了を待機し、子プロセスのプロセス id と (wait() と同様にコード化された ) 終了ステータスインジケーターからなるタプルを返します。この関数の動作は options によって変わります。通常の操作では 0 にします。
pid が 0 よりも大きい場合、 waitpid() は特定のプロセスのステータス情報を要求します。 pid が 0 の場合、現在のプロセスグループ内の任意の子プロセスの状態に対する要求です。 pid が -1 の場合、現在のプロセスの任意の子プロセスに対する要求です。 pid が -1 よりも小さい場合、プロセスグループ -pid ( すなわち pid の絶対値 ) 内の任意のプロセスに対する要求です。
システムコールが -1 を返した時、 OSError を errno と共に送出します。
Windows では、プロセスハンドル pid を指定してプロセスの終了を待って、 pid と、終了ステータスを 8bit 左シフトした値のタプルを返します。 ( シフトは、この関数をクロスプラットフォームで利用しやすくするために行われます ) 0 以下の pid は Windows では特別な意味を持っておらず、例外を発生させます。 options の値は効果がありません。 pid は、子プロセスで無くても、プロセス ID を知っているどんなプロセスでも参照することが可能です。 spawn* 関数を P_NOWAIT と共に呼び出した場合、適切なプロセスハンドルが返されます。
waitstatus_to_exitcode() can be used to convert the exit status into an exit code.
バージョン 3.5 で変更: システムコールが中断されシグナルハンドラが例外を送出しなかった場合、この関数は InterruptedError 例外を送出する代わりにシステムコールを再試行するようになりました (論拠については PEP 475 を参照してください)。
os.wait3(options)
waitpid() に似ていますが、プロセス id を引数に取らず、子プロセス id 、終了ステータスインジケータ、リソース使用情報の 3 要素からなるタプルを返します。リソース使用情報の詳しい情報は resource. getrusage() を参照してください。 オプション引数は waitpid() および wait4() と同じです。
waitstatus_to_exitcode() can be used to convert the exit status into an exitcode.
利用可能な環境: Unix。
os.wait4(pid, options)
waitpid() に似ていますが、子プロセス id 、終了ステータスインジケータ、リソース使用情報の 3 要素からなるタプルを返します。リソース使用情報の詳しい情報は resource. getrusage() を参照してください。 wait4() の引数は waitpid() に与えられるものと同じです。
waitstatus_to_exitcode() can be used to convert the exit status into an exitcode.
利用可能な環境: Unix。
os.waitstatus_to_exitcode(status)
On Unix:
参考 WIFEXITED(), WEXITSTATUS(), WIFSIGNALED(), WTERMSIG(), WIFSTOPPED(), WSTOPSIG() functions.
バージョン 3.9 で追加.
os.WNOHANG
子プロセス状態がすぐに取得できなかった場合に直ちに終了するようにするための waitpid() のオプションです。この場合、関数は (0, 0) を返します。
利用可能な環境: Unix。
os.WCONTINUED
このオプションによって子プロセスは前回状態が報告された後にジョブ制御による停止状態から実行を再開された場合に報告されるようになります。
os.WUNTRACED
このオプションによって子プロセスは停止されていながら停止されてから状態が報告されていない場合に報告されるようになります。
利用可能な環境: Unix。
以下の関数は system() 、 wait() 、あるいは waitpid() が返すプロセス状態コードを引数にとります。これらの関数はプロセスの配置を決めるために利用できます。
os.WCOREDUMP(status)
プロセスに対してコアダンプが生成されていた場合には True を、それ以外の場合は False を返します。
利用可能な環境: Unix。
os.WIFCONTINUED(status)
利用可能な環境: Unix。
os.WIFSTOPPED(status)
利用可能な環境: Unix。
os.WIFSIGNALED(status)
利用可能な環境: Unix。
os.WIFEXITED(status)
利用可能な環境: Unix。
os.WEXITSTATUS(status)
利用可能な環境: Unix。
os.WSTOPSIG(status)
プロセスを停止させたシグナル番号を返します。
利用可能な環境: Unix。
os.WTERMSIG(status)
利用可能な環境: Unix。
スケジューラーへのインターフェイス
以下の関数は、オペレーティングシステムがプロセスに CPU 時間を割り当てる方法を制御します。これらは一部の Unix プラットフォームでのみ利用可能です。詳しくは Unix マニュアルページを参照してください。
バージョン 3.3 で追加.
次のスケジューリングポリシーは、オペレーティングシステムでサポートされていれば公開されます。
os.SCHED_OTHER
デフォルトのスケジューリングポリシーです。
os.SCHED_BATCH
常にCPUに負荷のかかる (CPU-intensive) プロセス用のポリシーです。他の対話式プロセスなどの応答性を維持するよう試みます。
os.SCHED_IDLE
非常に優先度の低いバックグラウンドタスク用のスケジューリングポリシーです。
os.SCHED_SPORADIC
散発的なサーバープログラム用のスケジューリングポリシーです。
os.SCHED_FIFO
FIFO (First In, First Out) 型のスケジューリングポリシーです。
os.SCHED_RR
ラウンドロビン型のスケジューリングポリシーです。
os.SCHED_RESET_ON_FORK
このフラグは他のスケジューリングポリシーとともに論理和指定できます。このフラグが与えられたプロセスが fork されると、その子プロセスのスケジューリングポリシーおよび優先度はデフォルトにリセットされます。
class os.sched_param(sched_priority)
このクラスは、sched_setparam()、sched_setscheduler()、および sched_getparam() で使用される、調節可能なスケジューリングパラメーターを表します。これはイミュータブルです。
現在、一つの引数のみ指定できます:
sched_priority
スケジューリングポリシーのスケジューリング優先度です。
os.sched_get_priority_min(policy)
policy の最小優先度値を取得します。policy には上記のスケジューリングポリシー定数の一つを指定します。
os.sched_get_priority_max(policy)
policy の最大優先度値を取得します。policy には上記のスケジューリングポリシー定数の一つを指定します。
os.sched_setscheduler(pid, policy, param)
PID pid のプロセスのスケジューリングポリシーを設定します。pid が 0 の場合、呼び出しプロセスを意味します。policy には上記のスケジューリングポリシー定数の一つを指定します。param は sched_param のインスタンスです。
os.sched_getscheduler(pid)
PID pid のプロセスのスケジューリングポリシーを返します。pid が 0 の場合、呼び出しプロセスを意味します。返り値は上記のスケジューリングポリシー定数の一つになります。
os.sched_setparam(pid, param)
PID pid のプロセスのスケジュールパラメーターを設定します。pid が 0 の場合、呼び出しプロセスを意味します。param は sched_param のインスタンスです。
os.sched_getparam(pid)
PID pid のプロセスのスケジューリングパラメーターを sched_param のインスタンスとして返します。pid が 0 の場合、呼び出しプロセスを意味します。
os.sched_rr_get_interval(pid)
PID pid のプロセスのラウンドロビンクォンタム (秒) を返します。pid が 0 の場合、呼び出しプロセスを意味します。
os.sched_yield()
自発的に CPU を解放します。
os.sched_setaffinity(pid, mask)
PID pid のプロセス (0 であれば現在のプロセス) を CPU の集合に制限します。mask はプロセスを制限する CPU の集合を表す整数のイテラブルなオブジェクトです。
os.sched_getaffinity(pid)
PID pid のプロセス (0 の場合、現在のプロセス) が制限されている CPU の集合を返します。
雑多なシステム情報
os.confstr(name)
システム設定値を文字列で返します。 name には取得したい設定名を指定します ; この値は定義済みのシステム値名を表す文字列にすることができます ; 名前は多くの標準 (POSIX.1 、 Unix 95 、 Unix 98 その他 ) で定義されています。ホストオペレーティングシステムの関知する名前は confstr_names 辞書のキーとして与えられています。このマップ型オブジェクトに入っていない設定変数については、 name に整数を渡してもかまいません。
name に指定された設定値が定義されていない場合、 None を返します。
name が文字列で、かつ不明の場合、 ValueError を送出します。 name の指定値がホストシステムでサポートされておらず、 confstr_names にも入っていない場合、 errno.EINVAL をエラー番号として OSError を送出します。
利用可能な環境: Unix。
os.confstr_names
confstr() が受理する名前を、ホストオペレーティングシステムで定義されている整数値に対応付けている辞書です。この辞書はシステムでどの設定名が定義されているかを決定するために利用できます。
利用可能な環境: Unix。
os.cpu_count()
システムの CPU 数を返します。未定の場合は None を返します。
この数は現在のプロセスが使える CPU 数と同じものではありません。 使用可能な CPU 数は len(os.sched_getaffinity(0)) で取得できます。
バージョン 3.4 で追加.
os.getloadavg()
過去 1 分、 5 分、および 15 分間の、システムの実行キューの平均プロセス数を返します。平均負荷が得られない場合には OSError を送出します。
利用可能な環境: Unix。
os.sysconf(name)
整数値のシステム設定値を返します。 name で指定された設定値が定義されていない場合、 -1 が返されます。 name に関するコメントとしては、 confstr() で述べた内容が同様に当てはまります ; 既知の設定名についての情報を与える辞書は sysconf_names で与えられています。
利用可能な環境: Unix。
os.sysconf_names
sysconf() が受理する名前を、ホストオペレーティングシステムで定義されている整数値に対応付けている辞書です。この辞書はシステムでどの設定名が定義されているかを決定するために利用できます。
利用可能な環境: Unix。
以下のデータ値はパス名編集操作をサポートするために利用されます。これらの値はすべてのプラットフォームで定義されています。
パス名に対する高水準の操作は os.path モジュールで定義されています。
os.curdir
現在のディレクトリ参照するためにオペレーティングシステムで使われる文字列定数です。 POSIX と Windows では '.' になります。 os.path からも利用できます。
os.pardir
親ディレクトリを参照するためにオペレーティングシステムで使われる文字列定数です。 POSIX と Windows では '..' になります。 os.path からも利用できます。
os.sep
パス名を要素に分割するためにオペレーティングシステムで利用されている文字です。例えば POSIX では '/' で、 Windows では '\\' です。しかし、このことを知っているだけではパス名を解析したり、パス名同士を結合したりするには不十分です --- こうした操作には os.path.split() や os.path.join() を使用してください --- が、たまに便利なこともあります。 os.path からも利用できます。
os.altsep
文字パス名を要素に分割する際にオペレーティングシステムで利用されるもう一つの文字で、分割文字が一つしかない場合には None になります。この値は sep がバックスラッシュとなっている DOS や Windows システムでは '/' に設定されています。 os.path からも利用できます。
os.extsep
ベースのファイル名と拡張子を分ける文字です。例えば、 os.py であれば '.' です。 os.path からも利用できます。
os.pathsep
(PATH のような ) サーチパス内の要素を分割するためにオペレーティングシステムが慣習的に用いる文字で、 POSIX における ':' や DOS および Windows における ';' に相当します。 os.path からも利用できます。
os.defpath
exec*p* や spawn*p* において、環境変数辞書内に 'PATH' キーがない場合に使われる標準設定のサーチパスです。 os.path からも利用できます。
os.linesep
現在のプラットフォーム上で行を分割 ( あるいは終端 ) するために用いられている文字列です。この値は例えば POSIX での '\n' や Mac OS での '\r' のように、単一の文字にもなりますし、例えば Windows での '\r\n' のように複数の文字列にもなります。テキストモードで開いたファイルに書き込む時には、 os.linesep を利用しないでください。すべてのプラットフォームで、単一の '\n' を使用してください。
os.devnull
ヌルデバイスのファイルパスです。例えば POSIX では '/dev/null' で、 Windows では 'nul' です。この値は os.path からも利用できます。
os.RTLD_LAZY
os.RTLD_NOW
os.RTLD_GLOBAL
os.RTLD_LOCAL
os.RTLD_NODELETE
os.RTLD_NOLOAD
os.RTLD_DEEPBIND
setdlopenflags() 関数と getdlopenflags() 関数と一緒に使用するフラグ。それぞれのフラグの意味については、Unix マニュアルの dlopen(3) ページを参照してください。
バージョン 3.3 で追加.
乱数
os.getrandom(size, flags=0)
最大で size バイトからなるランダムなバイト列を返します。この関数は要求されたバイト数よりも少ないバイト数を返すことがあります。
バイト列は、ユーザー空間の乱数生成器や暗号目的ののシードとして利用できます。
getrandom() はデバイスドライバや他の環境ノイズ源から収集されたエントロピーに頼っています。不必要な大量のデータの読出しは、/dev/random と /dev/urandom デバイスの他のユーザーに負の影響を与えるでしょう。
Linux getrandom() manual page も参照してください。
バージョン 3.6 で追加.
os.urandom(size)
暗号に関する用途に適した size バイトからなるランダムな文字列を返します。
この関数は OS 固有の乱数発生源からランダムなバイト列を生成して返します。この関数の返すデータは暗号を用いたアプリケーションで十分利用できる程度に予測不能ですが、実際のクオリティは OS の実装によって異なります。
Windowsで、 CryptGenRandom() を使用します。
参考 The secrets module provides higher level functions. For an easy-to-use interface to the random number generator provided by your platform, please see random.SystemRandom.
バージョン 3.6.0 で変更: Linuxで、 セキュリティを高めるために、getrandom() をブロッキングモードで使用するようになりました。
バージョン 3.5.2 で変更: Linux において、 getrandom() システムコールがブロックするなら (urandom エントロピープールが初期化されていなければ) 、 /dev/urandom を読む方法にフォールバックします。
バージョン 3.5 で変更: Linux 3.17 以降では、使用可能な場合に getrandom() システムコールが使用されるようになりました。OpenBSD 5.6 以降では、C getentropy() 関数が使用されるようになりました。これらの関数は、内部ファイル記述子を使用しません。
os.GRND_NONBLOCK
バージョン 3.6 で追加.
os.GRND_RANDOM
バージョン 3.6 で追加.
io --- ストリームを扱うコアツール
ソースコード: Lib/io.py
概要
io モジュールは様々な種類の I/O を扱う Python の主要な機能を提供しています。 I/O には主に3つの種類があります; テキスト I/O, バイナリ I/O, raw I/O です。これらは汎用的なカテゴリで、各カテゴリには様々なストレージが利用されます。これらのいずれかのカテゴリに属する具象オブジェクトは全て file object と呼ばれます。他によく使われる用語として ストリーム と file-like オブジェクト があります。
それぞれの具象ストリームオブジェクトは、カテゴリに応じた機能を持ちます。ストリームは読み込み専用、書き込み専用、読み書き可能のいずかになります。任意のランダムアクセス（前方、後方の任意の場所にシークする）が可能かもしれませんし、シーケンシャルアクセスしかできないかもしれません（例えばソケットやパイプなど）。
全てのストリームは、与えられたデータの型に対して厳密です。例えば、バイナリストリームの write() メソッドに対して str オブジェクトを渡すと TypeError 例外を発生させます。テキストストリームの write() メソッドに bytes オブジェクトを渡しても同じです。
バージョン 3.3 で変更: 以前 IOError を送出していた操作が OSError を送出するようになりました。 IOError は今は OSError の別名です。
テキスト I/O
テキスト I/O は、 str オブジェクトを受け取り、生成します。すなわち、背後にあるストレージがバイト列 (例えばファイルなど) を格納するときは常に、透過的にデータのエンコード・デコードを行ない、オプションでプラットフォーム依存の改行文字変換を行います。
テキストストリームを作る一番簡単な方法は、オプションでエンコーディングを指定して、 open() を利用することです:
f = open("myfile.txt", "r", encoding="utf-8")
StringIO オブジェクトはインメモリーのテキストストリームです:
f = io.StringIO("some initial text data")
テキストストリームの API は TextIOBase のドキュメントで詳しく解説します。
バイナリ I/O
バイナリー I/O (buffered I/O とも呼ばれます) は bytes-like オブジェクト を受け取り bytes オブジェクトを生成します。エンコード、デコード、改行文字変換は一切行いません。このカテゴリのストリームは全ての非テキストデータや、テキストデータの扱いを手動で管理したい場合に利用することができます。
バイナリーストリームを生成する一番簡単な方法は、 open() の mode 文字列に 'b' を指定することです:
f = open("myfile.jpg", "rb")
BytesIO はインメモリーのバイナリストリームです:
f = io.BytesIO(b"some initial binary data: \x00\x01")
バイナリーストリーム API は BufferedIOBase のドキュメントで詳しく解説します。
他のライブラリモジュールが、別のテキスト・バイナリーストリームを生成する方法を提供しています。例えば socket.socket.makefile() などです。
Raw I/O
Raw I/O (unbuffered I/O とも呼ばれます) は、バイナリーストリームやテキストストリームの低水準の部品としてよく利用されます。ユーザーコードで直接 raw ストリームを扱うべき場面は滅多にありません。とはいえ、バッファリングを無効にしてファイルをバイナリーモードで開くことで raw ストリームを作ることができます:
f = open("myfile.jpg", "rb", buffering=0)
raw ストリーム API は RawIOBase のドキュメントで詳しく解説します。
高水準のモジュールインターフェイス
io.DEFAULT_BUFFER_SIZE
このモジュールの buffered I/O クラスで利用されるデフォルトのバッファーサイズを表す整数です。可能であれば、open() は file の blksize (os.stat() で取得される) を利用します。
io.open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)
組み込みの open() 関数のエイリアスです。
引数 path, mode, flags を指定して 監査イベント open を送出します。
io.open_code(path)
path should be a str and an absolute path.
バージョン 3.8 で追加.
exception io.BlockingIOError
互換性のための、組み込みの BlockingIOError 例外のエイリアスです。
exception io.UnsupportedOperation
OSError と ValueError を継承した例外です。ストリームがサポートしていない操作を行おうとした時に送出されます。
インメモリー ストリーム
str や bytes-like オブジェクト を、読み書き可能なファイルのように扱うことができます。 StringIO は文字列に対して、テキストモードで開かれたファイルのように使うことができます。 BytesIO はバイナリーモードで開いたファイルのように扱うことができます。この2つのクラスは、読み書き可能で、ランダムアクセス可能です。
参考
sys
標準 IO ストリームを持っています: sys.stdin, sys.stdout, sys.stderr。
クラス階層
I/O ストリームの実装はクラス階層に分けて整理されています。まずストリームのカテゴリを分類するための 抽象基底クラス (ABC) があり、続いて標準のストリーム実装を行う具象クラス群があります。
注釈 抽象基底クラス群は、具象ストリームクラスの実装を助けるために、いくつかのデフォルトの実装を提供しています。例えば、 BufferedIOBase は readinto() と readline() の最適化されていない実装を提供しています。
I/O 階層の最上位には抽象基底クラスの IOBase があります。 IOBase ではストリームに対して基本的なインタフェースを定義しています。 しかしながら、ストリームに対する読み込みと書き込みが分離されていないことに注意してください。 実装においては与えられた操作をサポートしない場合は UnsupportedOperation を送出することが許されています。
RawIOBase ABC は IOBase を拡張します。このクラスはストリームからの bytes の読み書きを扱います。 FileIO は、 RawIOBase を継承してマシンのファイルシステム中のファイルへのインタフェースを提供します。
引数名は規約に含まれていません。 そして open() の引数だけがキーワード引数として用いられることが意図されています。
次のテーブルは io モジュールが提供する ABC の概要です:
ABC
継承元
スタブメソッド
Mixin するメソッドとプロパティ
IOBase
fileno, seek, truncate
close, closed, __enter__, __exit__, flush, isatty, __iter__, __next__, readable, readline, readlines, seekable, tell, writable, writelines
RawIOBase
IOBase
readinto, write
IOBase から継承したメソッド、 read, readall
BufferedIOBase
IOBase
detach, read, read1, write
IOBase から継承したメソッド、 readinto, readinto1
TextIOBase
IOBase
detach, read, readline, write
IOBase から継承したメソッド、 encoding, errors, newlines
I/O 基底クラス
class io.IOBase
すべての I/O クラスの抽象基底クラスです。バイトストリームへの操作を行います。パブリックなコンストラクタはありません。
継承先のクラスが選択的にオーバライドできるように、このクラスは多くのメソッドに空の抽象実装をしています。デフォルトの実装では、読み込み、書き込み、シークができないファイルを表現します。
IOBase では read(), write() が宣言されていませんが、これはシグナチャが変化するためで、実装やクライアントはこれらのメソッドをインタフェースの一部として考えるべきです。 また、実装はサポートしていない操作を呼び出されたときは ValueError (または UnsupportedOperation) を発生させるかもしれません。
ファイルへのバイナリデータの読み書きに用いられる基本型は bytes です。 他の bytes-like オブジェクト もメソッドの引数として受け付けられます。 テキスト I/O クラスは str データを扱います。
閉じられたストリームに対するメソッド呼び出しは (問い合わせであっても) 未定義です。この場合、実装は ValueError を送出することがあります。
IOBase (とそのサブクラス) はイテレータプロトコルをサポートします。 IOBase オブジェクトをイテレートすると、ストリーム内の行が yield されます。ストリーム内の行の定義は、そのストリームが (バイト列を yield する) バイナリストリームか (文字列を yield する) テキストストリームかによって、 少し異なります。下の readline() を参照してください。
IOBase はコンテキストマネージャでもあります。そのため with 構文をサポートします。 次の例では、 with 構文が終わった後で---たとえ例外が発生した場合でも、 file は閉じられます。
with open('spam.txt', 'w') as file:
    file.write('Spam and eggs!')
IOBase は以下のデータ属性とメソッドを提供します:
close()
このストリームをフラッシュして閉じます。このメソッドはファイルが既に閉じられていた場合は特に何の効果もありません。いったんファイルが閉じられると、すべてのファイルに対する操作 (例えば読み込みや書き込み) で ValueError が発生します。
利便性のためにこのメソッドを複数回呼ぶことは許されています。しかし、効果があるのは最初の1回だけです。
closed
ストリームが閉じられていた場合 True になります。
fileno()
ストリームが保持しているファイル記述子 (整数値) が存在する場合はそれを返します。もし IO オブジェクトがファイル記述子を使っていない場合は OSError が発生します。
flush()
適用可能であればストリームの書き込みバッファをフラッシュします。読み出し専用や非ブロッキングストリームでは何もしません。
isatty()
ストリームが対話的であれば (つまりターミナルや tty デバイスにつながっている場合) True を返します。
readable()
ストリームが読み込める場合 True を返します。 False の場合は read() は OSError を発生させます。
readline(size=-1)
ストリームから 1 行読み込んで返します。もし size が指定された場合、最大で size バイトが読み込まれます。
バイナリファイルでは行末文字は常に b'\n' となります。テキストファイルでは、認識される行末文字を選択するために open() に対する newline 引数が使われます。
readlines(hint=-1)
ストリームから行のリストを読み込んで返します。 hint を指定することで、読み込む行数を制御できます。もし読み込んだすべての行のサイズ (バイト数、もしくは文字数) が hint の値を超えた場合、読み込みをそこで終了します。
ただし、 file.readlines() を呼びださなくても for line in file: ... のように file オブジェクトを直接イテレートすることができます。
seek(offset, whence=SEEK_SET)
ストリーム位置を指定された offset バイトに変更します。offset は whence で指定された位置からの相対位置として解釈されます。 whence のデフォルト値は SEEK_SET です。 whence に指定できる値は:
SEEK_SET または 0 -- ストリームの先頭 (デフォルト)。 offset は 0 もしくは正の値でなければなりません。
SEEK_CUR または 1 -- 現在のストリーム位置。 offset は負の値も可能です。
SEEK_END または 2 -- ストリームの末尾。 offset は通常負の値です。
新しい絶対位置を返します。
バージョン 3.1 で追加: SEEK_* 定数.
バージョン 3.3 で追加: 一部のオペレーティングシステムは os.SEEK_HOLE や os.SEEK_DATA など、追加の値をサポートすることがあります。ファイルに対して利用できる値は、そのファイルがテキストモードで開かれたかバイナリモードで開かれたかに依存します。
seekable()
ストリームがランダムアクセスをサポートしている場合、 True を返します。 False の場合、 seek()、 tell()、 truncate() を使用すると OSError を発生させます。
tell()
現在のストリーム位置を返します。
truncate(size=None)
ストリームのサイズを、指定された size バイト (または size が指定されていない場合、現在位置) に変更します。現在のストリーム位置は変更されません。このサイズ変更により、現在のファイルサイズを拡大または縮小させることができます。拡大の場合には、新しいファイル領域の内容はプラットホームによって異なります (ほとんどのシステムでは、追加のバイトが 0 で埋められます)。新しいファイルサイズが返されます。
バージョン 3.5 で変更: Windows で、拡大時に追加領域を 0 で埋めるようになりました。
writable()
ストリームが書き込みをサポートしている場合 True を返します。 False の場合は write()、 truncate() は OSError を返します。
writelines(lines)
ストリームに行のリストを書き込みます。行区切り文字は追加されないので、書き込む各行の行末に行区切り文字を含ませるのが一般的です。
__del__()
オブジェクトの破壊の用意をします。このメソッドはインスタンスの close() メソッドを呼びます。 IOBase はこのメソッドのデフォルトの実装を提供します
class io.RawIOBase
RawIOBase provides these methods in addition to those from IOBase:
read(size=-1)
オブジェクトを size バイトまで読み込み、それを返します。 簡単のため、 size が指定されていないか -1 の場合は、 EOF までの全てのバイトを返します。 そうでない場合は、システムコール呼び出しが一度だけ行われます。 オペレーティングシステムコールから返ってきたものが size バイトより少なければ、 size バイトより少ない返り値になることがあります。
size が 0 でないのに 0 バイトが返った場合、それはファイルの終端を表します。オブジェクトがノンブロッキングモードで、1 バイトも読み込めなければ、None が返されます。
デフォルトの実装は readall() と readinto() に従います。
readall()
EOF までストリームからすべてのバイトを読み込みます。必要な場合はストリームに対して複数の呼び出しをします。
readinto(b)
あらかじめ確保された書き込み可能な bytes 類オブジェクト b にバイト列を読み込み、読み込んだバイト数を返します。 例えば、 b は bytearray です。 オブジェクトがノンブロッキングモードで、 1 バイトも読み込めなければ、 None が返されます。
write(b)
与えられた bytes-like オブジェクト b を生ストリームに書き込み、書き込んだバイト数を返します。これは、根底の生ストリームの性質や、特にノンブロッキングである場合に、 b のバイト数より小さくなることがあります。生ストリームがブロックされないように設定されていて、かつ1バイトも即座に書き込むことができなければ、 None が返されます。このメソッドから返った後で呼び出し元は b を解放したり変更したりするかもしれないので、実装はメソッド呼び出しの間だけ b にアクセスすべきです。
class io.BufferedIOBase
何らかのバッファリングをサポートするバイナリストリームの基底クラスです。 IOBase を継承します。パブリックなコンストラクタはありません。
RawIOBase との主な違いは、メソッド read()、 readinto() および write() は 、ことによると複数回のシステムコールを行って、(それぞれ) 要求されただけの入力を読み込もうとしたり与えられた出力の全てを消費しようとしたりする点です。
加えて、元になる生ストリームが非ブロッキングモードでかつ準備ができていない場合に、これらのメソッドは、 BlockingIOError を送出するかもしれません。対応する RawIOBase バージョンと違って、 None を返すことはありません。
さらに、 read() メソッドは、 readinto() に従うデフォルト実装を持ちません。
通常の BufferedIOBase 実装は RawIOBase 実装を継承せずに、 BufferedWriter と BufferedReader がするようにこれをラップすべきです。
BufferedIOBase provides or overrides these data attributes and methods in addition to those from IOBase:
raw
BufferedIOBase が扱う根底の生ストリーム (RawIOBase インスタンス) を返します。これは BufferedIOBase API には含まれず、よって実装に含まれないことがあります。
detach()
根底の生ストリームをバッファから分離して返します。
生ストリームが取り外された後、バッファは使用不能状態になります。
バッファには、 BytesIO など、このメソッドで返される単体のストリームという概念を持たないものがあります。これらは UnsupportedOperation を送出します。
バージョン 3.1 で追加.
read(size=-1)
最大で size バイト読み込んで返します。 引数が省略されるか、 None か、または負の値であった場合、 データは EOF に到達するまで読み込まれます。 ストリームが既に EOF に到達していた場合は空の bytes オブジェクトが返されます。
引数が正で、元になる生ストリームが対話的でなければ、必要なバイト数を満たすように複数回の生 read が発行されるかもしれません (先に EOF に到達しない限りは)。対話的な場合は、最大で一回の raw read しか発行されず、短い結果でも EOF に達したことを意味しません。
元になる生ストリームがノンブロッキングモードで、呼び出された時点でデータを持っていなければ、 BlockingIOError が送出されます。
read1([size])
根底の raw ストリームの read() (または readinto() ) メソッドを高々 1 回呼び出し、最大で size バイト読み込み、返します。これは、 BufferedIOBase オブジェクトの上に独自のバッファリングを実装するときに便利です。
size に ``-1``（デフォルト値)を指定すると任意バイト長を返します（EOFに到達していなければ返されるバイト数は 0 より大きくなります）
readinto(b)
あらかじめ確保された書き込み可能な bytes 類オブジェクト b にバイト列を読み込み、読み込んだバイト数を返します。 例えば、 b は bytearray です。
read() と同様に、下層の raw ストリームが対話的でない限り、複数の読み込みは下層の raw ストリームに与えられるかもしれません。
元になる生ストリームがノンブロッキングモードで、呼び出された時点でデータを持っていなければ、 BlockingIOError が送出されます。
readinto1(b)
根底の raw ストリームの read() (または readinto()) メソッドを高々 1 回呼び出し、あらかじめ確保された書き込み可能な bytes-like オブジェクト b にバイト列を読み込みます。読み込んだバイト数を返します。
元になる生ストリームがノンブロッキングモードで、呼び出された時点でデータを持っていなければ、 BlockingIOError が送出されます。
バージョン 3.5 で追加.
write(b)
与えられた bytes-like オブジェクト b を書き込み、書き込んだバイト数を返します (これは常に b のバイト数と等しくなります。なぜなら、もし書き込みに失敗した場合は OSError が発生するからです)。実際の実装に依存して、これらのバイト列は根底のストリームに即座に書き込まれることもあれば、パフォーマンスやレイテンシの関係でバッファに保持されることもあります。
ノンブロッキングモードであるとき、バッファが満杯で根底の生ストリームが書き込み時点でさらなるデータを受け付けられない場合 BlockingIOError が送出されます。
このメソッドが戻った後で、呼び出し元は b を解放、または変更するかもしれないので、実装はメソッド呼び出しの間だけ b にアクセスすべきです。
生ファイルI/O
class io.FileIO(name, mode='r', closefd=True, opener=None)
name は、次の 2 つのいずれかです。
開くファイルへのパスを表す文字列または bytes オブジェクト。 この場合、closefd は True (デフォルト) でなければなりません。 True でない場合、エラーが送出されます。
結果の FileIO オブジェクトがアクセスを与える、既存の OS レベルファイル記述子の数を表す整数。FileIO オブジェクトが閉じられると、closefd が False に設定されていない場合、この fd も閉じられます。
mode は 読み込み（デフォルト）、書き込み、排他的作成、追記に対し 'r' 、 'w' 、 'x' 、 'a' です。ファイルは書き込みや追記で開かれたときに存在しない場合作成されます。書き込みのときにファイルの内容は破棄されます。作成時に既に存在する場合は FileExistsError が送出されます。作成のためにファイルを開くのは暗黙的に書き込みなので、このモードは 'w' と同じように振る舞います。読み込みと書き込みを同時に許可するにはモードに '+' を加えてください。
このクラスの read() (正の引数で呼び出されたとき), readinto() および write() メソッドは、単にシステムコールを一度呼び出します。
呼び出し可能オブジェクトを opener として与えることで、カスタムのオープナーが使えます。そしてファイルオブジェクトの基底のファイルディスクリプタは、opener を (name, flags) で呼び出して得られます。opener は開いたファイルディスクリプタを返さなければなりません。 (os.open を opener として渡すと、None を渡したのと同様の機能になります。)
新たに作成されたファイルは 継承不可 です。
opener 引数を使う例については open() 組み込み関数を参照してください。
バージョン 3.3 で変更: opener 引数が追加されました。'x' モードが追加されました。
バージョン 3.4 で変更: ファイルが継承不可になりました。
FileIO provides these data attributes in addition to those from RawIOBase and IOBase:
mode
コンストラクタに渡されたモードです。
name
ファイル名。コンストラクタに名前が渡されなかったときはファイル記述子になります。
バッファ付きストリーム
バッファ付き I/O ストリームは、I/O デバイスに生 I/O より高レベルなインタフェースを提供します。
class io.BytesIO([initial_bytes])
省略可能な引数 initial_bytes は、初期データを含んだ bytes-like オブジェクト です。
BytesIO は BufferedIOBase または IOBase からのメソッドに加えて、以下のメソッドを提供もしくはオーバーライドします:
getbuffer()
バッファの内容をコピーすることなく、その内容の上に、読み込み及び書き込みが可能なビューを返します。また、このビューを変更すると、バッファの内容は透過的に更新されます:
>>>
>>> b = io.BytesIO(b"abcdef")
>>> view = b.getbuffer()
>>> view[2:4] = b"56"
>>> b.getvalue()
b'ab56ef'
注釈 ビューが存在する限り、BytesIO オブジェクトはリサイズやクローズされません。
バージョン 3.2 で追加.
getvalue()
バッファの全内容を含む bytes を返します。
read1([size])
BytesIO においては、このメソッドは read() と同じです。
バージョン 3.7 で変更: size 引数が任意になりました。
readinto1(b)
BytesIO においては、このメソッドは readinto() と同じです。
バージョン 3.5 で追加.
class io.BufferedReader(raw, buffer_size=DEFAULT_BUFFER_SIZE)
このコンストラクタは与えられた raw ストリームと buffer_size に対し BufferedReader を生成します。 buffer_size が省略された場合、代わりに DEFAULT_BUFFER_SIZE が使われます。
BufferedReader は BufferedIOBase または IOBase からのメソッドに加えて、以下のメソッドを提供もしくはオーバーライドします:
peek([size])
位置を進めずにストリームからバイト列を返します。これを果たすために生ストリームに対して行われる read は高々一度だけです。返されるバイト数は、要求より少ないかもしれませんし、多いかもしれません。
read([size])
size バイトを読み込んで返します。size が与えられないか負の値ならば、EOF まで、または非ブロッキングモード中で read 呼び出しがブロックされるまでを返します。
read1([size])
raw ストリームに対しただ一度の呼び出しで最大 size バイトを読み込んで返します。少なくとも 1 バイトがバッファされていれば、バッファされているバイト列だけが返されます。それ以外の場合は raw ストリームの読み込みが一回呼び出されます。
バージョン 3.7 で変更: size 引数が任意になりました。
class io.BufferedWriter(raw, buffer_size=DEFAULT_BUFFER_SIZE)
When writing to this object, data is normally placed into an internal buffer. The buffer will be written out to the underlying RawIOBase object under various conditions, including:
保留中の全データに対してバッファが足りなくなったとき;
flush() が呼び出されたとき;
seek() が (BufferedRandom オブジェクトに対して) 呼び出されたとき;
BufferedWriter オブジェクトが閉じられたり破棄されたりしたとき。
このコンストラクタは与えられた書き込み可能な raw ストリームに対し BufferedWriter を生成します。 buffer_size が省略された場合、 DEFAULT_BUFFER_SIZE がデフォルトになります。
BufferedWriter は BufferedIOBase または IOBase からのメソッドに加えて、以下のメソッドを提供もしくはオーバーライドします:
flush()
バッファに保持されたバイト列を生ストリームに強制的に流し込みます。生ストリームがブロックした場合 BlockingIOError が送出されます。
write(b)
bytes-like オブジェクト b を書き込み、書き込んだバイト数を返します。ノンブロッキング時、バッファが書き込まれるべきなのに生ストリームがブロックした場合 BlockingIOError が送出されます。
class io.BufferedRandom(raw, buffer_size=DEFAULT_BUFFER_SIZE)
このコンストラクタは第一引数として与えられるシーク可能な生ストリームに対し、リーダーおよびライターを作成します。 buffer_size が省略された場合、 DEFAULT_BUFFER_SIZE がデフォルトになります。
class io.BufferedRWPair(reader, writer, buffer_size=DEFAULT_BUFFER_SIZE)
reader と writer はそれぞれ読み込み可能、書き込み可能な RawIOBase オブジェクトです。 buffer_size が省略された場合 DEFAULT_BUFFER_SIZE がデフォルトになります。
BufferedRWPair は、 UnsupportedOperation を送出する detach() を除く、 BufferedIOBase の全てのメソッドを実装します。
警告 BufferedRWPair は下層の生ストリームのアクセスを同期しようとはしません。同じオブジェクトをリーダとライタとして渡してはいけません。その場合は代わりに BufferedRandom を使用してください。
テキスト I/O
class io.TextIOBase
IOBase から継承した属性とメソッドに加えて、 TextIOBase は以下のデータ属性とメソッドを提供しています:
encoding
エンコーディング名で、ストリームのバイト列を文字列にデコードするとき、また文字列をバイト列にエンコードするときに使われます。
errors
このエンコーダやデコーダのエラー設定です。
newlines
文字列、文字列のタプル、または None で、改行がどのように読み換えられるかを指定します。実装や内部コンストラクタのフラグに依って、これは利用できないことがあります。
buffer
TextIOBase が扱う根底のバイナリバッファ (BufferedIOBase インスタンス) です。これは TextIOBase API には含まれず、よって実装に含まれない場合があります。
detach()
根底のバイナリバッファを TextIOBase から分離して返します。
根底のバッファが取り外された後、 TextIOBase は使用不能状態になります。
TextIOBase 実装には、 StringIO など、根底のバッファという概念を持たないものがあります。これらを呼び出すと UnsupportedOperation を送出します。
バージョン 3.1 で追加.
read(size=-1)
最大 size 文字をストリームから読み込み、一つの str にして返します。 size が負の値または None ならば、 EOF まで読みます。
readline(size=-1)
改行または EOF まで読み込み、一つの str を返します。ストリームが既に EOF に到達している場合、空文字列が返されます。
size が指定された場合、最大 size 文字が読み込まれます。
seek(offset, whence=SEEK_SET)
指定された offset にストリーム位置を変更します。 挙動は whence 引数によります。 whence のデフォルト値は SEEK_SET です。:
SEEK_SET または 0: ストリームの先頭からシークします (デフォルト)。 offset は TextIOBase.tell() が返す数か0のどちらかでなければなりません。それ以外の offset 値は未定義の挙動を起こします。
SEEK_CUR または 1: 現在の位置に "シークします"。 offset は 0 でなければなりません。つまり何もしません (他の値はサポートされていません)。
SEEK_END または 2: ストリーム終端へシークします。 offset は 0 でなければなりません (他の値はサポートされていません)．
新しい絶対位置を、不透明な数値で返します。
バージョン 3.1 で追加: SEEK_* 定数.
tell()
ストリームの現在位置を不透明な数値で返します。この値は根底のバイナリストレージ内でのバイト数を表すとは限りません。
write(s)
文字列 s をストリームに書き出し、書き出された文字数を返します。
class io.TextIOWrapper(buffer, encoding=None, errors=None, newline=None, line_buffering=False, write_through=False)
encoding はストリームがエンコードやデコードされるエンコード名です。デフォルトは locale.getpreferredencoding(False) です。
errors はオプションの文字列で、エンコードやデコードの際のエラーをどのように扱うかを指定します。エンコードエラーがあったときに ValueError 例外を送出させるには 'strict' を渡します (デフォルトの None でも同じです)。エラーを無視させるには 'ignore' を渡します。 (エンコーディングエラーを無視するとデータを喪失する可能性があることに注意してください。) 'replace' は不正な形式の文字の代わりにマーカ (たとえば '?') を挿入させます。'backslashreplace' を指定すると、不正な形式のデータをバックスラッシュ付きのエスケープシーケンスに置換します。書き込み時には 'xmlcharrefreplace' (適切な XML 文字参照に置換) や 'namereplace' (\N{...} エスケープシーケンスに置換) も使えます。他にも codecs.register_error() で登録されたエラー処理名が有効です。
newline は行末をどのように処理するかを制御します 。None, '', '\n', '\r', '\r\n' のいずれかです。これは以下のように動作します:
ストリームへの出力の書き込み時、newline が None の場合、全ての '\n' 文字はシステムのデフォルトの行セパレータ os.linesep に変換されます。 newline が '' または '\n' の場合は変換されません。newline がその他の正当な値の場合、全ての '\n' 文字は与えられた文字列に変換されます。
line_buffering が True の場合、 write への呼び出しが改行文字もしくはキャリッジリターンを含んでいれば、暗黙的に flush() が呼び出されます。
write_through が True の場合、write() の呼び出しはバッファされないことが保証されます。 TextIOWrapper オブジェクトに書かれた全てのデータは直ちに下層のバイナリ buffer に処理されます。
バージョン 3.3 で変更: write_through 引数が追加されました。
バージョン 3.3 で変更: encoding の規定値が locale.getpreferredencoding() から locale.getpreferredencoding(False) になりました。 locale.setlocale() を用いてロケールのエンコーディングを一時的に変更してはいけません。ユーザが望むエンコーディングではなく現在のロケールのエンコーディングを使用してください。
TextIOWrapper provides these data attributes and methods in addition to those from TextIOBase and IOBase:
line_buffering
行バッファリングが有効かどうか。
write_through
書き込みが、根柢のバイナリバッファに即座に渡されるかどうか。
バージョン 3.7 で追加.
reconfigure(*[, encoding][, errors][, newline][, line_buffering][, write_through])
このテキストストリームを encoding, errors, newline, line_buffering と write_through を新しい設定として再設定します。
encoding が指定されており、errors が指定されていないときに、 errors='strict' が使われている場合を除き、指定されなかったパラメータは現在の設定が保持されます。
ストリームからすでにデータが読み出されていた場合、encodingとnewlineは変更できません。一方で、書き込み後にencodingを変更することはできます。
このメソッドは、新しい設定を適用するまえにストリームをフラッシュします。
バージョン 3.7 で追加.
class io.StringIO(initial_value='', newline='\n')
バッファの初期値を initial_value で与えることが出来ます。改行変換を有効にすると、改行コードは write() によってエンコードされます。ストリームはバッファの開始位置に配置されます。
StringIO provides this method in addition to those from TextIOBase and IOBase:
getvalue()
バッファの全内容を含む str を返します。改行コードのデコードは read() によって行われますが、これによるストリーム位置の変更は起こりません。
使用例:
import io
output = io.StringIO()
output.write('First line.\n')
print('Second line.', file=output)
# Retrieve file contents -- this will be
# 'First line.\nSecond line.\n'
contents = output.getvalue()
# Close object and discard memory buffer --
# .getvalue() will now raise an exception.
output.close()
class io.IncrementalNewlineDecoder
改行を universal newlines モードにデコードするヘルパーコーデックです。 codecs.IncrementalDecoder を継承しています。
性能
このセクションでは与えられた具体的な I/O 実装の性能について議論します。
バイナリ I/O
バッファ付き I/O は、ユーザが 1 バイトだけ要求した場合でさえ、データを大きな塊でのみ読み書きします。これにより、オペレーティングシステムのバッファ無し I/O ルーチンを呼び出して実行する非効率性はすべて隠されます。その成果は、OS と、実行される I/O の種類によって異なります。例えば、Linux のような現行の OS では、バッファ無しディスク I/O がバッファ付き I/O と同じくらい早いことがあります。しかし、どのプラットフォームとデバイスにおいても、バッファ付き I/O は最低でも予測可能なパフォーマンスを提供します。ですから、バイナリデータに対しては、バッファ無し I/O を使用するより、バッファ付きの I/O を使用するほうが望ましい場合がほとんどです。
テキスト I/O
(ファイルなどの) バイナリストレージ上のテキスト I/O は、同じストレージ上のバイナリ I/O より非常に遅いです。なぜならこれには、文字コーデックを使った Unicode とバイナリデータ間の変換を必要とするからです。これは大量のテキストデータ、例えば大きなログファイルを扱うときに顕著に成り得ます。同様に、 TextIOWrapper.tell() や TextIOWrapper.seek() はどちらも、使われている復元アルゴリズムのために遅くなります。
しかし StringIO は、ネイティブなインメモリ Unicode コンテナで、 BytesIO と同程度の速度を示します。
マルチスレッディング
(Unix における read(2) のような) オペレーティングシステムコールの、それがラッピングするものがスレッドセーフであるような範囲内では、 FileIO オブジェクトもまた、スレッドセーフです。
バイナリバッファ付きオブジェクト (BufferedReader, BufferedWriter, BufferedRandom および BufferedRWPair のインスタンス) は、その内部構造をロックを使って保護します。このため、これらを複数のスレッドから同時に呼び出しても安全です。
TextIOWrapper オブジェクトはスレッドセーフではありません。
リエントラント性
バイナリバッファ付きオブジェクト (BufferedReader, BufferedWriter, BufferedRandom および BufferedRWPair のインスタンス) は、リエントラント (再入可能) ではありません。リエントラントな呼び出しは普通の状況では起こりませんが、 I/O を signal ハンドラで行なっているときに起こりえます。スレッドが、すでにアクセスしているバッファ付きオブジェクトに再び入ろうとすると RuntimeError が送出されます。これは、バッファ付きオブジェクトに複数のスレッドから入ることを禁止するわけではありません。
time --- 時刻データへのアクセスと変換
このモジュールでは、時刻に関するさまざまな関数を提供します。関連した機能について、datetime, calendar モジュールも参照してください。
このモジュールは常に利用可能ですが、すべての関数がすべてのプラットフォームで利用可能なわけではありません。このモジュールで定義されているほとんどの関数は、プラットフォーム上の同名の C ライブラリ関数を呼び出します。これらの関数に対する意味付けはプラットフォーム間で異なるため、プラットフォーム提供のドキュメントを読んでおくと便利でしょう。
まずいくつかの用語の説明と慣習について整理します。
エポック (epoch) は時刻の起点のことで、これはプラットフォーム依存です。 Unix では、エポックは (UTC で) 1970 年 1 月 1 日 0 時 0 分 0 秒です。 与えられたプラットフォームでエポックが何なのかを知るには、 time.gmtime(0) の値を見てください。
エポック秒 (seconds since the epoch) は、エポックからの総経過秒数を示していますが、たいていはうるう秒 (leap seconds) は含まれていません。 全ての POSIX 互換のプラットフォームで、うるう秒はこの総秒数には含まれません。
このモジュールの中の関数は、エポック以前あるいは遠い未来の日付や時刻を扱うことができません。将来カットオフ（関数が正しく日付や時刻を扱えなくなる）が起きる時点は、C ライブラリによって決まります。32-bit システムではカットオフは通常 2038 年です。
UTC は協定世界時 (Coordinated Universal Time) のことです (以前はグリニッジ標準時または GMT として知られていました)。UTC の頭文字の並びは誤りではなく、英仏の妥協によるものです。
DST は夏時間 (Daylight Saving Time) のことで、一年のうちの一定期間に 1 時間タイムゾーンを修正することです。DST のルールは不可思議で (地域ごとに法律で定められています)、年ごとに変わることもあります。C ライブラリはローカルルールを記したテーブルを持っており (柔軟に対応するため、たいていはシステムファイルから読み込まれます)、この点に関しては唯一の真実の知識の源です。
多くの現時刻を返す関数 (real-time functions) の精度は、値や引数を表現するために使う単位から想像されるよりも低いかも知れません。例えば、ほとんどの Unix システムにおいて、クロックの 1 ティックの精度は 50 から 100 分の 1 秒に過ぎません。
一方、time() および sleep() は Unix の同等の関数よりましな精度を持っています。時刻は浮動小数点数で表され、time() は可能なかぎり最も正確な時刻を (Unix の gettimeofday() があればそれを使って) 返します。また sleep() にはゼロでない端数を与えることができます (Unix の select() があれば、それを使って実装しています)。
gmtime(), localtime(), strptime() が返す時刻値、および asctime(), mktime(), strftime() がとる時刻値は 9 個の整数からなるシーケンスです。gmtime(), localtime(), strptime() の戻り値は個々の値を属性名で取得することもできます。
これらのオブジェクトについての解説は struct_time を参照してください。
バージョン 3.3 で変更: struct_time オブジェクトは、プラットフォームが、対応する struct tm メンバーをサポートしている場合、tm_gmtoff および tm_zone 属性が拡張されるようになりました。
バージョン 3.6 で変更: struct_time の属性 tm_gmtoff および tm_zone が全てのプラットフォームで利用できるようになりました。
時間の表現を変換するには、以下の関数を利用してください:
対象
変換先
関数
エポックからの秒数
UTC の struct_time
gmtime()
エポックからの秒数
ローカル時間の struct_time
localtime()
UTC の struct_time
エポックからの秒数
calendar.timegm()
ローカル時間の struct_time
エポックからの秒数
mktime()
関数
time.asctime([t])
注釈 同名の C の関数と違って、asctime() は末尾に改行文字を加えません。
time.pthread_getcpuclockid(thread_id)
警告 Passing an invalid or expired thread_id may result in undefined behavior, such as segmentation fault.
利用可能な環境: Unix (更なる情報については pthread_getcpuclockid(3) の man を参照してください)。
バージョン 3.7 で追加.
time.clock_getres(clk_id)
指定された clk_id クロックの分解能(精度)を返します。 clk_id として受け付けられる値の一覧は Clock ID Constants を参照してください。
利用可能な環境: Unix。
バージョン 3.3 で追加.
time.clock_gettime(clk_id) → float
指定された clk_id クロックの時刻を返します。 clk_id として受け付けられる値の一覧は Clock ID Constants を参照してください。
利用可能な環境: Unix。
バージョン 3.3 で追加.
time.clock_gettime_ns(clk_id) → int
clock_gettime() に似ていますが、ナノ秒単位の時刻を返します。
利用可能な環境: Unix。
バージョン 3.7 で追加.
time.clock_settime(clk_id, time: float)
指定された clk_id クロックの時刻を設定します。 現在、 CLOCK_REALTIME は clk_id が受け付ける唯一の値です。
利用可能な環境: Unix。
バージョン 3.3 で追加.
time.clock_settime_ns(clk_id, time: int)
clock_settime() に似ていますが、ナノ秒単位の時刻を設定します。
利用可能な環境: Unix。
バージョン 3.7 で追加.
time.ctime([secs])
time.get_clock_info(name)
指定されたクロックの情報を名前空間オブジェクトとして取得します。サポートされているクロック名およびそれらの値を取得する関数は以下の通りです:
'monotonic': time.monotonic()
'perf_counter': time.perf_counter()
'process_time': time.process_time()
'thread_time': time.thread_time()
'time': time.time()
結果は以下の属性をもちます:
adjustable: 自動 (NTP デーモンによるなど) またはシステム管理者による手動で変更できる場合は True、それ以外の場合は False になります。
implementation: クロック値を取得するために内部で使用している C 関数の名前です。 使える値については Clock ID Constants を参照してください。
monotonic: クロック値が後戻りすることがない場合 True が、そうでない場合は False になります。
resolution: クロックの分解能を秒 (float) で表します。
バージョン 3.3 で追加.
time.gmtime([secs])
エポックからの経過時間で表現された時刻を、UTC で struct_time に変換します。このとき dst フラグは常にゼロとして扱われます。secs を指定しないか None を指定した場合、time() が返す値を現在の時刻として使用します。秒の端数は無視されます。struct_time オブジェクトについては前述の説明を参照してください。calendar.timegm() はこの関数と逆の変換を行います。
time.localtime([secs])
gmtime() に似ていますが、ローカル時間に変換します。secs を指定しないか None を指定した場合、time() が返す値を現在の時刻として使用します。DST が適用されている場合は dst フラグには 1 が設定されます。
time.mktime(t)
localtime() の逆を行う関数です。引数は struct_time か 9 個の要素すべての値を持つ完全なタプル (dst フラグも必要です; 時刻に DST が適用されるか不明の場合は -1 を使用してください) で、UTC ではなく ローカル 時間を指定します。戻り値は time() との互換性のために浮動小数点数になります。入力した値を正しい時刻として表現できない場合、例外 OverflowError または ValueError が送出されます (どちらが送出されるかは、無効な値を受け取ったのが Python と下層の C ライブラリのどちらなのかによって決まります)。この関数で時刻を生成できる最も古い日付はプラットフォームに依存します。
time.monotonic() → float
バージョン 3.3 で追加.
バージョン 3.5 で変更: この関数は、常に利用でき、常にシステム全域で使えるようになりました。
time.monotonic_ns() → int
monotonic() に似ていますが、ナノ秒単位の時刻を返します。
バージョン 3.7 で追加.
time.perf_counter() → float
バージョン 3.3 で追加.
time.perf_counter_ns() → int
perf_counter() に似ていますが、ナノ秒単位の時刻を返します。
バージョン 3.7 で追加.
time.process_time() → float
バージョン 3.3 で追加.
time.process_time_ns() → int
process_time() に似ていますが、ナノ秒単位の時刻を返します。
バージョン 3.7 で追加.
time.sleep(secs)
与えられた秒数の間、呼び出したスレッドの実行を停止します。より精度の高い実行停止時間を指定するために、引数は浮動小数点にしてもかまいません。何らかのシステムシグナルがキャッチされた場合、それに続いてシグナル処理ルーチンが実行され、sleep() を停止します。従って実際の実行停止時間は要求した時間よりも短くなるかもしれません。また、システムが他の処理をスケジュールするために、実行停止時間が要求した時間よりも多少長い時間になることもあります。
バージョン 3.5 で変更: スリープがシグナルに中断されてもシグナルハンドラが例外を送出しない限り、少なくとも secs だけスリープするようになりました (論拠については PEP 475 を参照してください)。
time.strftime(format[, t])
gmtime() や localtime() が返す時刻値タプルまたは struct_time を、format で指定した文字列形式に変換します。t が与えられていない場合、localtime() が返す値を現在の時刻として使用します。format は文字列でなくてはなりません。t のいずれかのフィールドが許容範囲外の数値であった場合、ValueError を送出します。
0 は時刻タプル内のいずれの位置の引数にも使用できます; それが一般に不正な値であれば、正しい値に強制的に置き換えられます。
format 文字列には以下のディレクティブ (指示語) を埋め込むことができます。これらはフィールド長や精度のオプションを付けずに表され、strftime() の結果の対応する文字列に置き換えられます:
ディレクティブ
意味
注釈
%a
ロケールの短縮された曜日名になります。
%A
ロケールの曜日名になります。
%b
ロケールの短縮された月名になります。
%B
ロケールの月名になります。
%c
ロケールの日時を適切な形式で表します。
%d
月中の日にちの 10 進表記になります [01,31]。
%H
時 (24 時間表記) の 10 進表記になります [00,23]。
%I
時 (12 時間表記) の 10 進表記になります [01,12]。
%j
年中の日にちの 10 進表記になります [001,366]。
%m
月の 10 進表記になります [01,12]。
%M
分の 10 進表記になります [00,59]。
%p
ロケールの AM もしくは PM と等価な文字列になります。
(1)
%S
秒の 10 進表記になります [00,61]。
(2)
%U
年の初めから何週目か (日曜を週の始まりとします) を表す 10 進数になります [00,53]。年が明けてから最初の日曜日までのすべての曜日は 0 週目に属すると見なされます。
(3)
%w
曜日の 10 進表記になります [0 (日曜日),6]。
%W
年の初めから何週目か (月曜を週の始まりとします) を表す 10 進数になります [00,53]。年が明けてから最初の月曜日までの全ての曜日は 0 週目に属すると見なされます。
(3)
%x
ロケールの日付を適切な形式で表します。
%X
ロケールの時間を適切な形式で表します。
%y
西暦の下 2 桁の 10 進表記になります [00,99]。
%Y
西暦 ( 4桁) の 10 進表記を表します。
%z
タイムゾーンと UTC/GMT との時差を表す正または負の時間を +HHMM、-HHMM で表します。H は時間の、M は分の 10 進表記になります [-23:59, +23:59]。
%Z
タイムゾーンの名前を表します (タイムゾーンがない場合には空文字列)。
%%
文字 '%' を表します。
注釈:
strptime() 関数で使う場合、%p ディレクティブが出力結果の時刻フィールドに影響を及ぼすのは、時刻を解釈するために %I を使ったときのみです。
値の幅は実際に 0 から 61 です; 60 は うるう秒<leap seconds> を表し、 61 は歴史的理由によりサポートされています。
strptime() 関数で使う場合、%U および %W を計算に使うのは曜日と年を指定したときだけです。
以下に RFC 2822 インターネット電子メール標準で定義されている日付表現と互換の書式の例を示します。 1
>>>
>>> from time import gmtime, strftime
>>> strftime("%a, %d %b %Y %H:%M:%S +0000", gmtime())
'Thu, 28 Jun 2001 14:17:15 +0000'
一部のプラットフォームではさらにいくつかのディレクティブがサポートされていますが、標準 ANSI C で意味のある値はここで列挙したものだけです。あなたのプラットフォームでサポートされている書式コードの全一覧については、strftime(3) のドキュメントを参照してください。
一部のプラットフォームでは、フィールドの幅や精度を指定するオプションがディレクティブの先頭の文字 '%' の直後に付けられるようになっていました; この機能も移植性はありません。フィールドの幅は通常 2 ですが、%j は例外で 3 です。
time.strptime(string[, format])
時刻を表現する文字列を書式に従って解釈します。返される値は gmtime() や localtime() が返すような struct_time です。
format パラメーターは strftime() で使うものと同じディレクティブを使います; このパラメーターの値はデフォルトでは "%a %b %d %H:%M:%S %Y" で、ctime() が返すフォーマットに一致します。string が format に従って解釈できなかった場合、例外 ValueError が送出されます。解析しようとする string が解析後に余分なデータを持っていた場合、ValueError が送出されます。欠落したデータについて、適切な値を推測できない場合はデフォルトの値で埋められ、その値は (1900, 1, 1, 0, 0, 0, 0, 1, -1) です。string も format も文字列でなければなりません。
例えば:
>>>
import time
time.strptime("30 Nov 00", "%d %b %y")   
time.struct_time(tm_year=2000, tm_mon=11, tm_mday=30, tm_hour=0, tm_min=0,
                 tm_sec=0, tm_wday=3, tm_yday=335, tm_isdst=-1)
%Z ディレクティブへのサポートは tzname に収められている値と daylight が真かどうかで決められます。このため、常に既知の (かつ夏時間でないと考えられている) UTC や GMT を認識する時以外はプラットフォーム固有の動作になります。
ドキュメント内で説明されているディレクティブだけがサポートされています。strftime() はプラットフォームごとに実装されているので、説明されていないディレクティブも利用できるかもしれません。しかし、strptime() はプラットフォーム非依存なので、ドキュメント内でサポートされているとされているディレクティブ以外は利用できません。
class time.struct_time
gmtime(), localtime() および strptime() が返す時刻値シーケンスの型です。これは 名前付きタプル のインタフェースをもったオブジェクトです。値はインデックスでも属性名でもアクセス可能です。以下の値があります:
インデックス
属性
値
0
tm_year
(例えば 1993)
1
tm_mon
[1,12] の間の数
2
tm_mday
[1,31] の間の数
3
tm_hour
[0,23] の間の数
4
tm_min
[0,59] の間の数
5
tm_sec
[0,61] の間の数 strftime() の説明にある (2) を読んで下さい
6
tm_wday
[0,6] の間の数、月曜が 0 になります
7
tm_yday
[1,366] の間の数
8
tm_isdst
0, 1 または -1; 以下を参照してください
N/A
tm_zone
タイムゾーンの短縮名
N/A
tm_gmtoff
UTC から東方向へのオフセット (秒)
C の構造体とは異なり、月の値は [0, 11] ではなく [1, 12] であることに注意してください。
mktime() の呼び出し時に、tm_isdst は夏時間が有効な場合は 1、そうでない場合は 0 に設定されることがあります。 値が -1 の場合は夏時間について不明なことを表していて、普通 tm_isdst は正しい状態に設定されます。
struct_time を引数とする関数に正しくない長さの struct_time や要素の型が正しくない struct_time を与えた場合には、 TypeError が送出されます。
time.time() → float
エポック からの秒数を浮動小数点数で返します。 エポックの具体的な日付とうるう秒 (leap seconds) の扱いはプラットフォーム依存です。 Windows とほとんどの Unix システムでは、エポックは (UTC で) 1970 年 1 月 1 日 0 時 0 分 0 秒で、うるう秒はエポック秒の時間の勘定には入りません。 これは一般に Unix 時間 と呼ばれています。 与えられたプラットフォームでエポックが何なのかを知るには、 time.gmtime(0) の値を見てください。
時刻は常に浮動小数点数で返されますが、すべてのシステムが 1 秒より高い精度で時刻を提供するとは限らないので注意してください。 この関数が返す値は通常減少していくことはありませんが、この関数を 2 回呼び出し、その呼び出しの間にシステムクロックの時刻を巻き戻して設定した場合には、以前の呼び出しよりも低い値が返ることがあります。
time() が返す数値は、 gmtime() 関数に渡されて UTC の、あるいは localtime() 関数に渡されて現地時間の、より一般的な時間のフォーマット (つまり、年、月、日、時間など) に変換されているかもしれません。 どちらの場合でも struct_time オブジェクトが返され、このオブジェクトの属性としてカレンダー日付の構成要素へアクセスできます。
time.thread_time() → float
利用可能な環境: Windows, Linux, CLOCK_THREAD_CPUTIME_ID をサポートしている Unix システム。
バージョン 3.7 で追加.
time.thread_time_ns() → int
thread_time() に似ていますが、ナノ秒単位の時刻を返します。
バージョン 3.7 で追加.
time.time_ns() → int
time() に似ていますが、時刻を epoch を基点としたナノ秒単位の整数で返します。
バージョン 3.7 で追加.
time.tzset()
利用可能な環境: Unix。
注釈 多くの場合、環境変数 TZ を変更すると、 tzset() を呼ばない限り localtime() のような関数の出力に影響を及ぼすため、値が信頼できなくなってしまいます。
TZ 環境変数には空白文字を含めてはなりません。
環境変数 TZ の標準的な書式は以下の通りです (分かりやすいように空白を入れています):
std offset [dst [offset [,start[/time], end[/time]]]]
各値は以下のようになっています:
std と dst
三文字またはそれ以上の英数字で、タイムゾーンの略称を与えます。この値は time.tzname になります。
offset
オフセットは形式: ± hh[:mm[:ss]] をとります。この表現は、UTC 時刻にするためにローカルな時間に加算する必要のある時間値を示します。'-' が先頭につく場合、そのタイムゾーンは本初子午線 (Prime Meridian) より東側にあります。それ以外の場合は本初子午線の西側です。オフセットが dst の後ろに続かない場合、夏時間は標準時より一時間先行しているものと仮定します。
start[/time], end[/time]
いつ DST に移動し、DST から戻ってくるかを示します。開始および終了日時の形式は以下のいずれかです:
Jn
ユリウス日 (Julian day) n (1 <= n <= 365) を表します。うるう日は計算に含められないため、2 月 28 日は常に 59 で、3 月 1 日は 60 になります。
n
ゼロから始まるユリウス日 (0 <= n <= 365) です。うるう日は計算に含められるため、2 月 29 日を参照することができます。
Mm.n.d
m 月の週 n における d 番目の日 (0 <= d <= 6, 1 <= n <= 5, 1 <= m <= 12) を表します。週 5 は月 m における最終週の d 番目の日を表し、第 4 週か第 5 週のどちらかになります。週 1 は日 d が最初に現れる日を指します。日 0 は日曜日です。
time は offset とほぼ同じで、先頭に符号 ('-' や '+') を付けてはいけないところだけが違います。時刻が指定されていなければ、デフォルトの値 02:00:00 になります。
>>>
>>> os.environ['TZ'] = 'EST+05EDT,M4.1.0,M10.5.0'
>>> time.tzset()
>>> time.strftime('%X %x %Z')
'02:07:36 05/08/03 EDT'
>>> os.environ['TZ'] = 'AEST-10AEDT-11,M10.5.0,M3.5.0'
>>> time.tzset()
>>> time.strftime('%X %x %Z')
'16:08:12 05/08/03 AEST'
多くの Unix システム (*BSD, Linux, Solaris, および Darwin を含む) では、システムの zoneinfo (tzfile(5)) データベースを使ったほうが、タイムゾーンごとの規則を指定する上で便利です。これを行うには、必要なタイムゾーンデータファイルへのパスをシステムの 'zoneinfo' タイムゾーンデータベースからの相対で表した値を環境変数 TZ に設定します。システムの 'zoneinfo' は通常 /usr/share/zoneinfo にあります。例えば、 'US/Eastern' 、 'Australia/Melbourne' 、 'Egypt' ないし 'Europe/Amsterdam' と指定します。
>>>
>>> os.environ['TZ'] = 'US/Eastern'
>>> time.tzset()
>>> time.tzname
('EST', 'EDT')
>>> os.environ['TZ'] = 'Egypt'
>>> time.tzset()
>>> time.tzname
('EET', 'EEST')
Clock ID Constants
time.CLOCK_BOOTTIME
バージョン 3.7 で追加.
time.CLOCK_HIGHRES
バージョン 3.3 で追加.
time.CLOCK_MONOTONIC
設定不可で、モノトニック時刻 (不特定のエポックからの単調増加な時刻) を表します。
利用可能な環境: Unix。
バージョン 3.3 で追加.
time.CLOCK_MONOTONIC_RAW
CLOCK_MONOTONIC と似ていますが、NTP の影響を受けていない、ハードウェアベースの時刻へのアクセスを提供します。
バージョン 3.3 で追加.
time.CLOCK_PROCESS_CPUTIME_ID
CPU による高分解能のプロセスごとのタイマーです。
利用可能な環境: Unix。
バージョン 3.3 で追加.
time.CLOCK_PROF
CPU による高分解能のプロセスごとのタイマーです。
バージョン 3.7 で追加.
time.CLOCK_TAI
International Atomic Time
バージョン 3.9 で追加.
time.CLOCK_THREAD_CPUTIME_ID
スレッド固有の CPU タイムクロックです。
利用可能な環境: Unix。
バージョン 3.3 で追加.
time.CLOCK_UPTIME
バージョン 3.7 で追加.
time.CLOCK_UPTIME_RAW
バージョン 3.8 で追加.
time.CLOCK_REALTIME
システム全体のリアルタイムクロックです。このクロックを設定するには適切な権限が必要です。
利用可能な環境: Unix。
バージョン 3.3 で追加.
Timezone Constants
time.altzone
time.daylight
time.timezone
time.tzname
注釈 For the above Timezone constants (altzone, daylight, timezone, and tzname), the value is determined by the timezone rules in effect at module load time or the last time tzset() is called and may be incorrect for times in the past. It is recommended to use the tm_gmtoff and tm_zone results from localtime() to obtain timezone information.
参考
datetime モジュール
日付と時刻に対する、よりオブジェクト指向のインタフェースです。
locale モジュール
国際化サービスです。ロケールの設定は strftime() および strptime() の多くの書式指定子の解釈に影響を及ぼします。
calendar モジュール
一般的なカレンダーに関する関数群です。timegm() はこのモジュールの gmtime() の逆を行う関数です。
脚注
1
%Z の使用は現在非推奨です。ただし、ここで実現したい時間および分オフセットへの展開を行ってくれる %z エスケープはすべての ANSI C ライブラリでサポートされているわけではありません。また、1982 年に提出されたオリジナルの RFC 822 標準では西暦の表現を 2 桁とするよう要求している (%Y でなく%y ) ものの、実際には 2000 年になるだいぶ以前から 4 桁の西暦表現に移行しています。その後 RFC 822 は撤廃され、4 桁の西暦表現は RFC 1123 で初めて勧告され、RFC 2822 において義務付けられました。
argparse --- コマンドラインオプション、引数、サブコマンドのパーサー
バージョン 3.2 で追加.
ソースコード: Lib/argparse.py
チュートリアル
このページは API のリファレンス情報が記載しています。argparse チュートリアル では、コマンドラインの解析についてより優しく説明しています。
argparse モジュールはユーザーフレンドリなコマンドラインインターフェースの作成を簡単にします。プログラムがどんな引数を必要としているのかを定義すると、argparse が sys.argv からそのオプションを解析する方法を見つけ出します。argparse モジュールは自動的にヘルプと使用方法メッセージを生成し、ユーザーが不正な引数をプログラムに指定したときにエラーを発生させます。
使用例
次のコードは、整数のリストを受け取って合計か最大値を返す Python プログラムです:
import argparse
parser = argparse.ArgumentParser(description='Process some integers.')
parser.add_argument('integers', metavar='N', type=int, nargs='+',
                    help='an integer for the accumulator')
parser.add_argument('--sum', dest='accumulate', action='store_const',
                    const=sum, default=max,
                    help='sum the integers (default: find the max)')
args = parser.parse_args()
print(args.accumulate(args.integers))
上の Python コードが prog.py という名前のファイルに保存されたと仮定します。コマンドラインから便利なヘルプメッセージを表示できます:
$ python prog.py -h
usage: prog.py [-h] [--sum] N [N ...]
positional arguments:
 N           an integer for the accumulator
optional arguments:
 -h, --help  show this help message and exit
 --sum       sum the integers (default: find the max)
適切な引数を与えて実行した場合、このプログラムはコマンドライン引数の整数列の合計か最大値を表示します:
$ python prog.py 1 2 3 4
4
$ python prog.py 1 2 3 4 --sum
10
不正な引数が与えられた場合、エラーを発生させます:
$ python prog.py a b c
usage: prog.py [-h] [--sum] N [N ...]
prog.py: error: argument N: invalid int value: 'a'
以降の節では、この例をひと通り説明して行きます。
パーサーを作る
argparse を使うときの最初のステップは、ArgumentParser オブジェクトを生成することです:
>>>
>>> parser = argparse.ArgumentParser(description='Process some integers.')
ArgumentParser オブジェクトはコマンドラインを解析して Python データ型にするために必要なすべての情報を保持します。
引数を追加する
ArgumentParser にプログラム引数の情報を与えるために、add_argument() メソッドを呼び出します。一般的に、このメソッドの呼び出しは ArgumentParser に、コマンドラインの文字列を受け取ってそれをオブジェクトにする方法を教えます。この情報は保存され、parse_args() が呼び出されたときに利用されます。例えば:
>>>
>>> parser.add_argument('integers', metavar='N', type=int, nargs='+',
...                     help='an integer for the accumulator')
>>> parser.add_argument('--sum', dest='accumulate', action='store_const',
...                     const=sum, default=max,
...                     help='sum the integers (default: find the max)')
あとで parse_args() を呼び出すと、integers と accumulate という2つの属性を持ったオブジェクトを返します。integers 属性は1つ以上の整数のリストで、accumulate 属性はコマンドラインから --sum が指定された場合は sum() 関数に、それ以外の場合は max() 関数になります。
引数を解析する
ArgumentParser は引数を parse_args() メソッドで解析します。このメソッドはコマンドラインを調べ、各引数を正しい型に変換して、適切なアクションを実行します。ほとんどの場合、これはコマンドラインの解析結果から、シンプルな Namespace オブジェクトを構築することを意味します:
>>>
>>> parser.parse_args(['--sum', '7', '-1', '42'])
Namespace(accumulate=<built-in function sum>, integers=[7, -1, 42])
スクリプト内では、parse_args() は通常引数なしで呼び出され、ArgumentParser は自動的に sys.argv からコマンドライン引数を取得します。
ArgumentParser オブジェクト
class argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=[], formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True, allow_abbrev=True, exit_on_error=True)
新しい ArgumentParser オブジェクトを生成します。すべての引数はキーワード引数として渡すべきです。各引数についてはあとで詳しく説明しますが、簡単に言うと:
prog - プログラム名 (デフォルト: sys.argv[0])
usage - プログラムの利用方法を記述する文字列 (デフォルト: パーサーに追加された引数から生成されます)
description - 引数のヘルプの前に表示されるテキスト (デフォルト: none)
epilog - 引数のヘルプの後で表示されるテキスト (デフォルト: none)
parents - ArgumentParser オブジェクトのリストで、このオブジェクトの引数が追加されます
formatter_class - ヘルプ出力をカスタマイズするためのクラス
prefix_chars - オプションの引数の prefix になる文字集合 (デフォルト: '-')
fromfile_prefix_chars - 追加の引数を読み込むファイルの prefix になる文字集合 (デフォルト: None)
argument_default - 引数のグローバルなデフォルト値 (デフォルト: None)
conflict_handler - 衝突するオプションを解決する方法 (通常は不要)
add_help - -h/--help オプションをパーサーに追加する (デフォルト: True)
allow_abbrev - 長いオプションが先頭の 1 文字に短縮可能 (先頭の文字が一意) である場合に短縮指定を許可する。(デフォルト: True)
exit_on_error - Determines whether or not ArgumentParser exits with error info when an error occurs. (default: True)
バージョン 3.5 で変更: allow_abbrev 引数が追加されました。
バージョン 3.8 で変更: 以前のバージョンでは、 allow_abbrev は、-vv が -v -v と等価になるような、短いフラグのグループ化を無効にしていました。
バージョン 3.9 で変更: exit_on_error 引数が追加されました。
以下の節では各オプションの利用方法を説明します。
prog
デフォルトでは、ArgumentParser オブジェクトはヘルプメッセージ中に表示するプログラム名を sys.argv[0] から取得します。 このデフォルトの動作は、プログラムがコマンドライン上の起動方法に合わせてヘルプメッセージを作成するため、ほとんどの場合望ましい挙動になります。 例えば、myprogram.py という名前のファイルに次のコードがあるとします:
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('--foo', help='foo help')
args = parser.parse_args()
このプログラムのヘルプは、プログラム名として (プログラムがどこから起動されたのかに関わらず) myprogram.py を表示します:
$ python myprogram.py --help
usage: myprogram.py [-h] [--foo FOO]
optional arguments:
 -h, --help  show this help message and exit
 --foo FOO   foo help
$ cd ..
$ python subdir/myprogram.py --help
usage: myprogram.py [-h] [--foo FOO]
optional arguments:
 -h, --help  show this help message and exit
 --foo FOO   foo help
このデフォルトの動作を変更するには、ArgumentParser の prog= 引数に他の値を指定します:
>>>
>>> parser = argparse.ArgumentParser(prog='myprogram')
>>> parser.print_help()
usage: myprogram [-h]
optional arguments:
 -h, --help  show this help message and exit
プログラム名は、sys.argv[0] から取られた場合でも prog= 引数で与えられた場合でも、ヘルプメッセージ中では %(prog)s フォーマット指定子で利用できます。
>>>
>>> parser = argparse.ArgumentParser(prog='myprogram')
>>> parser.add_argument('--foo', help='foo of the %(prog)s program')
>>> parser.print_help()
usage: myprogram [-h] [--foo FOO]
optional arguments:
 -h, --help  show this help message and exit
 --foo FOO   foo of the myprogram program
usage
デフォルトでは、 ArgumentParser は使用法メッセージを、保持している引数から生成します:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('--foo', nargs='?', help='foo help')
>>> parser.add_argument('bar', nargs='+', help='bar help')
>>> parser.print_help()
usage: PROG [-h] [--foo [FOO]] bar [bar ...]
positional arguments:
 bar          bar help
optional arguments:
 -h, --help   show this help message and exit
 --foo [FOO]  foo help
デフォルトのメッセージは usage= キーワード引数で変更できます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', usage='%(prog)s [options]')
>>> parser.add_argument('--foo', nargs='?', help='foo help')
>>> parser.add_argument('bar', nargs='+', help='bar help')
>>> parser.print_help()
usage: PROG [options]
positional arguments:
 bar          bar help
optional arguments:
 -h, --help   show this help message and exit
 --foo [FOO]  foo help
%(prog)s フォーマット指定子を、使用法メッセージ内でプログラム名として利用できます。
description
多くの場合、ArgumentParser のコンストラクターを呼び出すときに description= キーワード引数が使用されます。この引数はプログラムが何をしてどう動くのかについての短い説明になります。ヘルプメッセージで、この説明がコマンドラインの利用法と引数のヘルプメッセージの間に表示されます:
>>>
>>> parser = argparse.ArgumentParser(description='A foo that bars')
>>> parser.print_help()
usage: argparse.py [-h]
A foo that bars
optional arguments:
 -h, --help  show this help message and exit
デフォルトでは、説明は与えられたスペースに合わせて折り返されます。この挙動を変更するには、formatter_class 引数を参照してください。
epilog
いくつかのプログラムは、プログラムについての追加の説明を引数の説明の後に表示します。このテキストは ArgumentParser の epilog= 引数に指定できます:
>>>
>>> parser = argparse.ArgumentParser(
...     description='A foo that bars',
...     epilog="And that's how you'd foo a bar")
>>> parser.print_help()
usage: argparse.py [-h]
A foo that bars
optional arguments:
 -h, --help  show this help message and exit
And that's how you'd foo a bar
description 引数と同じく、epilog= テキストもデフォルトで折り返され、ArgumentParser の formatter_class 引数で動作を調整できます。
parents
ときどき、いくつかのパーサーが共通の引数セットを共有することがあります。それらの引数を繰り返し定義する代わりに、すべての共通引数を持ったパーサーを ArgumentParser の parents= 引数に渡すことができます。 parents= 引数は ArgumentParser オブジェクトのリストを受け取り、すべての位置アクションとオプションのアクションをそれらから集め、そのアクションを構築中の ArgumentParser オブジェクトに追加します:
>>>
>>> parent_parser = argparse.ArgumentParser(add_help=False)
>>> parent_parser.add_argument('--parent', type=int)
>>> foo_parser = argparse.ArgumentParser(parents=[parent_parser])
>>> foo_parser.add_argument('foo')
>>> foo_parser.parse_args(['--parent', '2', 'XXX'])
Namespace(foo='XXX', parent=2)
>>> bar_parser = argparse.ArgumentParser(parents=[parent_parser])
>>> bar_parser.add_argument('--bar')
>>> bar_parser.parse_args(['--bar', 'YYY'])
Namespace(bar='YYY', parent=None)
一番親になるパーサーに add_help=False を指定していることに注目してください。こうしないと、ArgumentParser は2つの -h/--help オプションを与えられる (1つは親から、もうひとつは子から) ことになり、エラーを発生します。
注釈 parents= に渡す前にパーサーを完全に初期化する必要があります。子パーサーを作成してから親パーサーを変更した場合、その変更は子パーサーに反映されません。
formatter_class
ArgumentParser オブジェクトは代わりのフォーマットクラスを指定することでヘルプのフォーマットをカスタマイズできます。現在、4つのフォーマットクラスがあります:
class argparse.RawDescriptionHelpFormatter
class argparse.RawTextHelpFormatter
class argparse.ArgumentDefaultsHelpFormatter
class argparse.MetavarTypeHelpFormatter
RawDescriptionHelpFormatter と RawTextHelpFormatter はどのようにテキストの説明を表示するかを指定できます。デフォルトでは ArgumentParser オブジェクトはコマンドラインヘルプの中の description と epilog を折り返して表示します:
>>>
>>> parser = argparse.ArgumentParser(
...     prog='PROG',
...     description='''this description
...         was indented weird
...             but that is okay''',
...     epilog='''
...             likewise for this epilog whose whitespace will
...         be cleaned up and whose words will be wrapped
...         across a couple lines''')
>>> parser.print_help()
usage: PROG [-h]
this description was indented weird but that is okay
optional arguments:
 -h, --help  show this help message and exit
likewise for this epilog whose whitespace will be cleaned up and whose words
will be wrapped across a couple lines
formatter_class= に RawDescriptionHelpFormatter を渡した場合、 description と epilog は整形済みとされ改行されません:
>>>
>>> parser = argparse.ArgumentParser(
...     prog='PROG',
...     formatter_class=argparse.RawDescriptionHelpFormatter,
...     description=textwrap.dedent('''\
...         Please do not mess up this text!
...         --------------------------------
...             I have indented it
...             exactly the way
...             I want it
...         '''))
>>> parser.print_help()
usage: PROG [-h]
Please do not mess up this text!
--------------------------------
   I have indented it
   exactly the way
   I want it
optional arguments:
 -h, --help  show this help message and exit
RawTextHelpFormatter は引数の説明を含めてすべての種類のヘルプテキストで空白を維持します。例外として、複数の空行はひとつにまとめられます。複数の空白行を保ちたい場合には、行に空白を含めるようにして下さい。
ArgumentDefaultsHelpFormatter は各引数のデフォルト値を自動的にヘルプに追加します:
>>>
>>> parser = argparse.ArgumentParser(
...     prog='PROG',
...     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
>>> parser.add_argument('--foo', type=int, default=42, help='FOO!')
>>> parser.add_argument('bar', nargs='*', default=[1, 2, 3], help='BAR!')
>>> parser.print_help()
usage: PROG [-h] [--foo FOO] [bar ...]
positional arguments:
 bar         BAR! (default: [1, 2, 3])
optional arguments:
 -h, --help  show this help message and exit
 --foo FOO   FOO! (default: 42)
MetavarTypeHelpFormatter は、各引数の値の表示名に type 引数の値を使用します (通常は dest の値が使用されます):
>>>
>>> parser = argparse.ArgumentParser(
...     prog='PROG',
...     formatter_class=argparse.MetavarTypeHelpFormatter)
>>> parser.add_argument('--foo', type=int)
>>> parser.add_argument('bar', type=float)
>>> parser.print_help()
usage: PROG [-h] [--foo int] float
positional arguments:
  float
optional arguments:
  -h, --help  show this help message and exit
  --foo int
prefix_chars
ほとんどのコマンドラインオプションは、-f/--foo のように接頭辞に - を使います。+f や /foo のような、他の、あるいは追加の接頭辞文字をサポートしなければならない場合、ArgumentParser のコンストラクターに prefix_chars= 引数を使って指定します:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', prefix_chars='-+')
>>> parser.add_argument('+f')
>>> parser.add_argument('++bar')
>>> parser.parse_args('+f X ++bar Y'.split())
Namespace(bar='Y', f='X')
prefix_chars= 引数のデフォルトは '-' です。- を含まない文字セットを指定すると、-f/--foo オプションが使用できなくなります。
fromfile_prefix_chars
ときどき、例えば非常に長い引数リストを扱う場合に、その引数リストを毎回コマンドラインにタイプする代わりにファイルに置いておきたい場合があります。ArgumentParser のコンストラクターに fromfile_prefix_chars= 引数が渡された場合、指定された文字のいずれかで始まる引数はファイルとして扱われ、そのファイルに含まれる引数リストに置換されます。例えば:
>>>
>>> with open('args.txt', 'w') as fp:
...     fp.write('-f\nbar')
>>> parser = argparse.ArgumentParser(fromfile_prefix_chars='@')
>>> parser.add_argument('-f')
>>> parser.parse_args(['-f', 'foo', '@args.txt'])
Namespace(f='bar')
ファイルから読み込まれる引数は、デフォルトでは1行に1つ (ただし、convert_arg_line_to_args() も参照してください) で、コマンドライン上でファイルを参照する引数があった場所にその引数があったものとして扱われます。このため、上の例では、['-f', 'foo', '@args.txt'] は ['-f', 'foo', '-f', 'bar'] と等価になります。
fromfile_prefix_chars= 引数のデフォルト値は None で、引数がファイル参照として扱われることがないことを意味しています。
argument_default
一般的には、引数のデフォルト値は add_argument() メソッドにデフォルト値を渡すか、set_defaults() メソッドに名前と値のペアを渡すことで指定します。しかしまれに、1つのパーサー全体に適用されるデフォルト引数が便利なことがあります。これを行うには、 ArgumentParser に argument_default= キーワード引数を渡します。例えば、全体で parse_args() メソッド呼び出しの属性の生成を抑制するには、argument_default=SUPPRESS を指定します:
>>>
>>> parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS)
>>> parser.add_argument('--foo')
>>> parser.add_argument('bar', nargs='?')
>>> parser.parse_args(['--foo', '1', 'BAR'])
Namespace(bar='BAR', foo='1')
>>> parser.parse_args([])
Namespace()
allow_abbrev
通常、ArgumentParser の parse_args() に引数のリストを渡すとき、長いオプションは 短縮しても認識されます。
この機能は、allow_abbrev に False を指定することで無効にできます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', allow_abbrev=False)
>>> parser.add_argument('--foobar', action='store_true')
>>> parser.add_argument('--foonley', action='store_false')
>>> parser.parse_args(['--foon'])
usage: PROG [-h] [--foobar] [--foonley]
PROG: error: unrecognized arguments: --foon
バージョン 3.5 で追加.
conflict_handler
ArgumentParser オブジェクトは同じオプション文字列に対して複数のアクションを許可していません。 デフォルトでは、ArgumentParser オブジェクトは、すでに利用されているオプション文字列を使って新しい引数をつくろうとしたときに例外を送出します:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-f', '--foo', help='old foo help')
>>> parser.add_argument('--foo', help='new foo help')
Traceback (most recent call last):
 ..
ArgumentError: argument --foo: conflicting option string(s): --foo
ときどき (例えば parents を利用する場合など)、古い引数を同じオプション文字列で上書きするほうが便利な場合があります。この動作をするには、ArgumentParser の conflict_handler= 引数に 'resolve' を渡します:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', conflict_handler='resolve')
>>> parser.add_argument('-f', '--foo', help='old foo help')
>>> parser.add_argument('--foo', help='new foo help')
>>> parser.print_help()
usage: PROG [-h] [-f FOO] [--foo FOO]
optional arguments:
 -h, --help  show this help message and exit
 -f FOO      old foo help
 --foo FOO   new foo help
ArgumentParser オブジェクトは、すべてのオプション文字列が上書きされた場合にだけアクションを削除することに注目してください。上の例では、 --foo オプション文字列だけが上書きされているので、古い -f/--foo アクションは -f アクションとして残っています。
add_help
デフォルトでは、ArgumentParser オブジェクトはシンプルにパーサーのヘルプメッセージを表示するオプションを自動的に追加します。例えば、以下のコードを含む myprogram.py ファイルについて考えてください:
import argparse
parser = argparse.ArgumentParser()
parser.add_argument('--foo', help='foo help')
args = parser.parse_args()
コマンドラインに -h か --help が指定された場合、ArgumentParser の help が表示されます:
$ python myprogram.py --help
usage: myprogram.py [-h] [--foo FOO]
optional arguments:
 -h, --help  show this help message and exit
 --foo FOO   foo help
必要に応じて、この help オプションを無効にする場合があります。これは ArgumentParser の add_help= 引数に False を渡すことで可能です:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', add_help=False)
>>> parser.add_argument('--foo', help='foo help')
>>> parser.print_help()
usage: PROG [--foo FOO]
optional arguments:
 --foo FOO  foo help
ヘルプオプションは通常 -h/--help です。例外は prefix_chars= が指定されてその中に - が無かった場合で、その場合は -h と --help は有効なオプションではありません。この場合、prefix_chars の最初の文字がヘルプオプションの接頭辞として利用されます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', prefix_chars='+/')
>>> parser.print_help()
usage: PROG [+h]
optional arguments:
  +h, ++help  show this help message and exit
exit_on_error
If the user would like catch errors manually, the feature can be enable by setting exit_on_error to False:
>>>
>>> parser = argparse.ArgumentParser(exit_on_error=False)
>>> parser.add_argument('--integers', type=int)
_StoreAction(option_strings=['--integers'], dest='integers', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help=None, metavar=None)
>>> try:
...     parser.parse_args('--integers a'.split())
... except argparse.ArgumentError:
...     print('Catching an argumentError')
...
Catching an argumentError
バージョン 3.9 で追加.
add_argument() メソッド
ArgumentParser.add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest])
1つのコマンドライン引数がどう解析されるかを定義します。各引数についての詳細は後述しますが、簡単に言うと:
name または flags - 名前か、あるいはオプション文字列のリスト (例: foo や -f, --foo)。
action - コマンドラインにこの引数があったときのアクション。
nargs - 受け取るべきコマンドライン引数の数。
const - 一部の action と nargs の組み合わせで利用される定数。
default - The value produced if the argument is absent from the command line and if it is absent from the namespace object.
type - コマンドライン引数が変換されるべき型。
choices - 引数として許される値のコンテナー。
required - コマンドラインオプションが省略可能かどうか (オプション引数のみ)。
help - 引数が何なのかを示す簡潔な説明。
metavar - 使用法メッセージの中で使われる引数の名前。
dest - parse_args() が返すオブジェクトに追加される属性名。
以下の節では各オプションの利用方法を説明します。
name または flags
add_argument() メソッドは、指定されている引数が -f や --foo のようなオプション引数なのか、ファイル名リストなどの位置引数なのかを知る必要があります。 そのため、 add_argument() に初めに渡される引数は、一連のフラグか、単一の引数名のどちらかになります。 例えば、オプション引数は次のようにして作成されます:
>>>
>>> parser.add_argument('-f', '--foo')
一方、位置引数は次のように作成します:
>>>
>>> parser.add_argument('bar')
parse_args() が呼ばれたとき、オプション引数は接頭辞 - により識別され、それ以外の引数は位置引数として扱われます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-f', '--foo')
>>> parser.add_argument('bar')
>>> parser.parse_args(['BAR'])
Namespace(bar='BAR', foo=None)
>>> parser.parse_args(['BAR', '--foo', 'FOO'])
Namespace(bar='BAR', foo='FOO')
>>> parser.parse_args(['--foo', 'FOO'])
usage: PROG [-h] [-f FOO] bar
PROG: error: the following arguments are required: bar
action
ArgumentParser オブジェクトはコマンドライン引数にアクションを割り当てます。このアクションは、割り当てられたコマンドライン引数に関してどんな処理でもできますが、ほとんどのアクションは単に parse_args() が返すオブジェクトに属性を追加するだけです。action キーワード引数は、コマンドライン引数がどう処理されるかを指定します。提供されているアクションは:
'store' - これは単に引数の値を格納します。これはデフォルトのアクションです。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo')
>>> parser.parse_args('--foo 1'.split())
Namespace(foo='1')
'store_const' - このアクションは const キーワード引数で指定された値を格納します。'store_const' アクションは、何かの種類のフラグを指定するオプション引数によく使われます。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', action='store_const', const=42)
>>> parser.parse_args(['--foo'])
Namespace(foo=42)
'store_true', 'store_false' - これらは 'store_const' の、それぞれ True と False を格納する特別版になります。加えて、これらはそれぞれデフォルト値を順に False と True にします。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', action='store_true')
>>> parser.add_argument('--bar', action='store_false')
>>> parser.add_argument('--baz', action='store_false')
>>> parser.parse_args('--foo --bar'.split())
Namespace(foo=True, bar=False, baz=True)
'append' - このアクションはリストを格納して、各引数の値をそのリストに追加します。このアクションは複数回指定を許可したいオプションに便利です。利用例:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', action='append')
>>> parser.parse_args('--foo 1 --foo 2'.split())
Namespace(foo=['1', '2'])
'append_const' - このアクションはリストを格納して、const キーワード引数に与えられた値をそのリストに追加します (const キーワード引数のデフォルト値はあまり役に立たない None であることに注意)。'append_const' アクションは、定数を同じリストに複数回格納する場合に便利です。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--str', dest='types', action='append_const', const=str)
>>> parser.add_argument('--int', dest='types', action='append_const', const=int)
>>> parser.parse_args('--str --int'.split())
Namespace(types=[<class 'str'>, <class 'int'>])
'count' - このアクションはキーワード引数の数を数えます。例えば、verboseレベルを上げるのに役立ちます:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--verbose', '-v', action='count', default=0)
>>> parser.parse_args(['-vvv'])
Namespace(verbose=3)
default は明示的に 0 と指定されない場合は None であることに注意してください。
'help' - このアクションは現在のパーサー中のすべてのオプションのヘルプメッセージを表示し、終了します。出力の生成方法の詳細については ArgumentParser を参照してください。
'version' - このアクションは add_argument() の呼び出しに version= キーワード引数を期待します。指定されたときはバージョン情報を表示して終了します:
>>>
>>> import argparse
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('--version', action='version', version='%(prog)s 2.0')
>>> parser.parse_args(['--version'])
PROG 2.0
'extend' - このアクションはリストを格納して、各引数の値でそのリストを拡張します。利用例:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument("--foo", action="extend", nargs="+", type=str)
>>> parser.parse_args(["--foo", "f1", "--foo", "f2", "f3", "f4"])
Namespace(foo=['f1', 'f2', 'f3', 'f4'])
バージョン 3.8 で追加.
You may also specify an arbitrary action by passing an Action subclass or other object that implements the same interface. The BooleanOptionalAction is available in argparse and adds support for boolean actions such as --foo and --no-foo:
>>>
>>> import argparse
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', action=argparse.BooleanOptionalAction)
>>> parser.parse_args(['--no-foo'])
Namespace(foo=False)
カスタムアクションの例です:
>>>
>>> class FooAction(argparse.Action):
...     def __init__(self, option_strings, dest, nargs=None, **kwargs):
...         if nargs is not None:
...             raise ValueError("nargs not allowed")
...         super(FooAction, self).__init__(option_strings, dest, **kwargs)
...     def __call__(self, parser, namespace, values, option_string=None):
...         print('%r %r %r' % (namespace, values, option_string))
...         setattr(namespace, self.dest, values)
...
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', action=FooAction)
>>> parser.add_argument('bar', action=FooAction)
>>> args = parser.parse_args('1 --foo 2'.split())
Namespace(bar=None, foo=None) '1' None
Namespace(bar='1', foo=None) '2' '--foo'
>>> args
Namespace(bar='1', foo='2')
詳細は Action を参照してください。
nargs
ArgumentParser オブジェクトは通常1つのコマンドライン引数を1つのアクションに渡します。nargs キーワード引数は1つのアクションにそれ以外の数のコマンドライン引数を割り当てます。指定できる値は:
N (整数) -- N 個の引数がコマンドラインから集められ、リストに格納されます。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', nargs=2)
>>> parser.add_argument('bar', nargs=1)
>>> parser.parse_args('c --foo a b'.split())
Namespace(bar=['c'], foo=['a', 'b'])
nargs=1 は1要素のリストを作ることに注意してください。これはデフォルトの、要素がそのまま属性になる動作とは異なります。
'?' -- 可能なら1つの引数がコマンドラインから取られ、1つのアイテムを作ります。コマンドライン引数が存在しない場合、default の値が生成されます。オプション引数の場合、さらにオプション引数が指定され、その後にコマンドライン引数がないというケースもありえます。この場合は const の値が生成されます。この動作の例です:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', nargs='?', const='c', default='d')
>>> parser.add_argument('bar', nargs='?', default='d')
>>> parser.parse_args(['XX', '--foo', 'YY'])
Namespace(bar='XX', foo='YY')
>>> parser.parse_args(['XX', '--foo'])
Namespace(bar='XX', foo='c')
>>> parser.parse_args([])
Namespace(bar='d', foo='d')
nargs='?' のよくある利用例の1つは、入出力ファイルの指定オプションです:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('infile', nargs='?', type=argparse.FileType('r'),
...                     default=sys.stdin)
>>> parser.add_argument('outfile', nargs='?', type=argparse.FileType('w'),
...                     default=sys.stdout)
>>> parser.parse_args(['input.txt', 'output.txt'])
Namespace(infile=<_io.TextIOWrapper name='input.txt' encoding='UTF-8'>,
          outfile=<_io.TextIOWrapper name='output.txt' encoding='UTF-8'>)
>>> parser.parse_args([])
Namespace(infile=<_io.TextIOWrapper name='<stdin>' encoding='UTF-8'>,
          outfile=<_io.TextIOWrapper name='<stdout>' encoding='UTF-8'>)
'*' -- すべてのコマンドライン引数がリストに集められます。複数の位置引数が nargs='*' を持つことにあまり意味はありませんが、複数のオプション引数が nargs='*' を持つことはありえます。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', nargs='*')
>>> parser.add_argument('--bar', nargs='*')
>>> parser.add_argument('baz', nargs='*')
>>> parser.parse_args('a b --foo x y --bar 1 2'.split())
Namespace(bar=['1', '2'], baz=['a', 'b'], foo=['x', 'y'])
'+' -- '*' と同じように、すべてのコマンドライン引数をリストに集めます。加えて、最低でも1つのコマンドライン引数が存在しない場合にエラーメッセージを生成します。例えば:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('foo', nargs='+')
>>> parser.parse_args(['a', 'b'])
Namespace(foo=['a', 'b'])
>>> parser.parse_args([])
usage: PROG [-h] foo [foo ...]
PROG: error: the following arguments are required: foo
nargs キーワード引数が指定されない場合、受け取る引数の数は action によって決定されます。通常これは、1つのコマンドライン引数は1つのアイテムになる (リストにはならない) ことを意味します。
const
add_argument() の const 引数は、コマンドライン引数から読み込まれないけれども ArgumentParser のいくつかのアクションで必要とされる値のために使われます。この引数のよくある2つの使用法は:
add_argument() が action='store_const' か action='append_const' で呼び出されたとき、これらのアクションは const の値を parse_args() が返すオブジェクトの属性に追加します。サンプルは action の説明を参照してください。
add_argument() がオプション文字列 (-f や --foo) と nargs='?' で呼び出された場合。この場合0個か1つのコマンドライン引数を取るオプション引数が作られます。オプション引数にコマンドライン引数が続かなかった場合、 const の値が代わりに利用されます。サンプルは nargs の説明を参照してください。
'store_const' と 'append_const' アクションでは、 const キーワード引数を与える必要があります。他のアクションでは、デフォルトは None になります。
default
すべてのオプション引数といくつかの位置引数はコマンドライン上で省略されることがあります。 add_argument() の default キーワード引数 (デフォルト: None) は、コマンドライン引数が存在しなかった場合に利用する値を指定します。オプション引数では、オプション文字列がコマンドライン上に存在しなかったときに default の値が利用されます:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default=42)
>>> parser.parse_args(['--foo', '2'])
Namespace(foo='2')
>>> parser.parse_args([])
Namespace(foo=42)
If the target namespace already has an attribute set, the action default will not over write it:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default=42)
>>> parser.parse_args([], namespace=argparse.Namespace(foo=101))
Namespace(foo=101)
default の値が文字列の場合、パーサーは値をコマンドライン引数のように解析します。具体的には、パーサーは返り値 Namespace の属性を設定する前に、type 変換引数が与えられていればそれらを適用します。そうでない場合、パーサーは値をそのまま使用します:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--length', default='10', type=int)
>>> parser.add_argument('--width', default=10.5, type=int)
>>> parser.parse_args()
Namespace(length=10, width=10.5)
nargs が ? か * である位置引数では、コマンドライン引数が指定されなかった場合 default の値が使われます。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('foo', nargs='?', default=42)
>>> parser.parse_args(['a'])
Namespace(foo='a')
>>> parser.parse_args([])
Namespace(foo=42)
default=argparse.SUPPRESS を渡すと、コマンドライン引数が存在しないときに属性の追加をしなくなります:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default=argparse.SUPPRESS)
>>> parser.parse_args([])
Namespace()
>>> parser.parse_args(['--foo', '1'])
Namespace(foo='1')
type
Common built-in types and functions can be used as type converters:
import argparse
import pathlib
parser = argparse.ArgumentParser()
parser.add_argument('count', type=int)
parser.add_argument('distance', type=float)
parser.add_argument('street', type=ascii)
parser.add_argument('code_point', type=ord)
parser.add_argument('source_file', type=open)
parser.add_argument('dest_file', type=argparse.FileType('w', encoding='latin-1'))
parser.add_argument('datapath', type=pathlib.Path)
User defined functions can be used as well:
>>> def hyphenated(string):
...     return '-'.join([word[:4] for word in string.casefold().split()])
...
>>> parser = argparse.ArgumentParser()
>>> _ = parser.add_argument('short_title', type=hyphenated)
>>> parser.parse_args(['"The Tale of Two Cities"'])
Namespace(short_title='"the-tale-of-two-citi')
choices
コマンドライン引数をいくつかの選択肢の中から選ばせたい場合があります。 これは add_argument() に choices キーワード引数を渡すことで可能です。コマンドラインを解析するとき、引数の値がチェックされ、その値が選択肢の中に含まれていない場合はエラーメッセージを表示します:
>>>
>>> parser = argparse.ArgumentParser(prog='game.py')
>>> parser.add_argument('move', choices=['rock', 'paper', 'scissors'])
>>> parser.parse_args(['rock'])
Namespace(move='rock')
>>> parser.parse_args(['fire'])
usage: game.py [-h] {rock,paper,scissors}
game.py: error: argument move: invalid choice: 'fire' (choose from 'rock',
'paper', 'scissors')
choices コンテナーに含まれているかどうかのチェックは、type による型変換が実行された後であることに注意してください。このため、choices に格納するオブジェクトの型は指定された type にマッチしている必要があります:
>>>
>>> parser = argparse.ArgumentParser(prog='doors.py')
>>> parser.add_argument('door', type=int, choices=range(1, 4))
>>> print(parser.parse_args(['3']))
Namespace(door=3)
>>> parser.parse_args(['4'])
usage: doors.py [-h] {1,2,3}
doors.py: error: argument door: invalid choice: 4 (choose from 1, 2, 3)
任意のコンテナを choices に渡すことができます。すなわち、list 、 set、カスタムコンテナなどはすべてサポートされています。
required
通常 argparse モジュールは、-f や --bar といったフラグは 任意 の引数 (オプション引数) だと仮定し、コマンドライン上になくても良いものとして扱います。フラグの指定を 必須 にするには、add_argument() の required= キーワード引数に True を指定します:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', required=True)
>>> parser.parse_args(['--foo', 'BAR'])
Namespace(foo='BAR')
>>> parser.parse_args([])
usage: [-h] --foo FOO
: error: the following arguments are required: --foo
上の例のように、引数が required と指定されると、parse_args() はそのフラグがコマンドラインに存在しないときにエラーを表示します。
注釈 ユーザーは、通常 フラグ の指定は 任意 であると認識しているため、必須にするのは一般的には悪いやり方で、できる限り避けるべきです。
help
help の値はその引数の簡潔な説明を含む文字列です。ユーザーが (コマンドライン上で -h か --help を指定するなどして) ヘルプを要求したとき、この help の説明が各引数に表示されます:
>>>
>>> parser = argparse.ArgumentParser(prog='frobble')
>>> parser.add_argument('--foo', action='store_true',
...                     help='foo the bars before frobbling')
>>> parser.add_argument('bar', nargs='+',
...                     help='one of the bars to be frobbled')
>>> parser.parse_args(['-h'])
usage: frobble [-h] [--foo] bar [bar ...]
positional arguments:
 bar     one of the bars to be frobbled
optional arguments:
 -h, --help  show this help message and exit
 --foo   foo the bars before frobbling
help 文字列には、プログラム名や引数の default などを繰り返し記述するのを避けるためのフォーマット指定子を含めることができます。利用できる指定子には、プログラム名 %(prog)s と、 %(default)s や %(type)s など add_argument() のキーワード引数の多くが含まれます:
>>>
>>> parser = argparse.ArgumentParser(prog='frobble')
>>> parser.add_argument('bar', nargs='?', type=int, default=42,
...                     help='the bar to %(prog)s (default: %(default)s)')
>>> parser.print_help()
usage: frobble [-h] [bar]
positional arguments:
 bar     the bar to frobble (default: 42)
optional arguments:
 -h, --help  show this help message and exit
ヘルプ文字列は %-フォーマットをサポートしているので、ヘルプ文字列内にリテラル % を表示したい場合は %% のようにエスケープしなければなりません。
argparse は help に argparse.SUPPRESS を設定することで、特定のオプションをヘルプに表示させないことができます:
>>>
>>> parser = argparse.ArgumentParser(prog='frobble')
>>> parser.add_argument('--foo', help=argparse.SUPPRESS)
>>> parser.print_help()
usage: frobble [-h]
optional arguments:
  -h, --help  show this help message and exit
metavar
ArgumentParser がヘルプメッセージを出力するとき、各引数に対してなんらかの参照方法が必要です。デフォルトでは、 ArgumentParser オブジェクトは各オブジェクトの "名前" として dest を利用します。デフォルトでは、位置引数には dest の値をそのまま 利用し、オプション引数については dest の値を大文字に変換して利用します。このため、1つの dest='bar' である位置引数は bar として参照されます。 1つのオプション引数 --foo が1つのコマンドライン引数を要求するときは、その引数は FOO として参照されます。以下に例を示します:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo')
>>> parser.add_argument('bar')
>>> parser.parse_args('X --foo Y'.split())
Namespace(bar='X', foo='Y')
>>> parser.print_help()
usage:  [-h] [--foo FOO] bar
positional arguments:
 bar
optional arguments:
 -h, --help  show this help message and exit
 --foo FOO
代わりの名前を、metavar として指定できます:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', metavar='YYY')
>>> parser.add_argument('bar', metavar='XXX')
>>> parser.parse_args('X --foo Y'.split())
Namespace(bar='X', foo='Y')
>>> parser.print_help()
usage:  [-h] [--foo YYY] XXX
positional arguments:
 XXX
optional arguments:
 -h, --help  show this help message and exit
 --foo YYY
metavar は 表示される 名前だけを変更することに注意してください。parse_args() の返すオブジェクトの属性名は dest の値のままです。
nargs を指定した場合、metavar が複数回利用されるかもしれません。metavar にタプルを渡すと、各引数に対して異なる名前を指定できます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-x', nargs=2)
>>> parser.add_argument('--foo', nargs=2, metavar=('bar', 'baz'))
>>> parser.print_help()
usage: PROG [-h] [-x X X] [--foo bar baz]
optional arguments:
 -h, --help     show this help message and exit
 -x X X
 --foo bar baz
dest
ほとんどの ArgumentParser のアクションは parse_args() が返すオブジェクトに対する属性として値を追加します。この属性の名前は add_argument() の dest キーワード引数によって決定されます。位置引数のアクションについては、 dest は通常 add_argument() の第一引数として渡します:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('bar')
>>> parser.parse_args(['XXX'])
Namespace(bar='XXX')
オプション引数のアクションについては、 dest の値は通常オプション文字列から生成されます。 ArgumentParser は最初の長いオプション文字列を選択し、先頭の -- を除去することで dest の値を生成します。長いオプション文字列が指定されていない場合、最初の短いオプション文字列から先頭の - 文字を除去することで dest を生成します。先頭以外のすべての - 文字は、妥当な属性名になるように _ 文字へ変換されます。次の例はこの動作を示しています:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('-f', '--foo-bar', '--foo')
>>> parser.add_argument('-x', '-y')
>>> parser.parse_args('-f 1 -x 2'.split())
Namespace(foo_bar='1', x='2')
>>> parser.parse_args('--foo 1 -y 2'.split())
Namespace(foo_bar='1', x='2')
dest にカスタムの属性名を与えることも可能です:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', dest='bar')
>>> parser.parse_args('--foo XXX'.split())
Namespace(bar='XXX')
Action クラス
Acrtion クラスは Action API、すなわちコマンドラインからの引数を処理する呼び出し可能オブジェクトを返す呼び出し可能オブジェクトを実装します。この API に従うあらゆるオブジェクトは action 引数として add_argument() に渡すことができます。
class argparse.Action(option_strings, dest, nargs=None, const=None, default=None, type=None, choices=None, required=False, help=None, metavar=None)
Action オブジェクトは、コマンドラインからの一つ以上の文字列から単一の引数を解析するのに必要とされる情報を表現するために ArgumentParser によって使われます。Action クラス 2 つの位置引数と、action それ自身を除く ArgumentParser.add_argument() に渡されるすべてのキーワード引数を受け付けなければなりません。
Action のインスタンス (あるいは action 引数に渡す任意の呼び出し可能オブジェクトの返り値) は、属性 "dest", "option_strings", "default", "type", "required", "help", などを定義しなければなりません。これらの属性を定義するのを確実にするためにもっとも簡単な方法は、Action.__init__ を呼び出すことです。
Action インスタンスは呼び出し可能でなければならず、したがって、サブクラスは 4 つの引数を受け取る __call__ メソッドをオーバライドしなければなりません:
parser - このアクションを持っている ArgumentParser オブジェクト。
namespace - parse_args() が返す Namespace オブジェクト。ほとんどのアクションはこのオブジェクトに属性を setattr() を使って追加します。
values - 型変換が適用された後の、関連付けられたコマンドライン引数。型変換は add_argument() メソッドの type キーワード引数で指定されます。
option_string - このアクションを実行したオプション文字列。option_string 引数はオプションで、アクションが位置引数に関連付けられた場合は渡されません。
__call__ メソッドでは任意のアクションを行えますが、 典型的にはそれは dest, values に基づく namespace に属性をセットすることでしょう。
parse_args() メソッド
ArgumentParser.parse_args(args=None, namespace=None)
引数の文字列をオブジェクトに変換し、namespace オブジェクトの属性に代入します。結果の namespace オブジェクトを返します。
事前の add_argument() メソッドの呼び出しにより、どのオブジェクトが生成されてどう代入されるかが決定されます。詳細は add_argument() のドキュメントを参照してください。
args - 解析する文字列のリスト。デフォルトでは sys.argv から取得されます。
namespace - 属性を代入するオブジェクト。デフォルトでは、新しい空の Namespace オブジェクトです。
オプション値の文法
parse_args() メソッドは、オプションの値がある場合、そのオプションの値の指定に複数の方法をサポートしています。もっとも単純な場合には、オプションとその値は次のように2つの別々の引数として渡されます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-x')
>>> parser.add_argument('--foo')
>>> parser.parse_args(['-x', 'X'])
Namespace(foo=None, x='X')
>>> parser.parse_args(['--foo', 'FOO'])
Namespace(foo='FOO', x=None)
長いオプション (1文字よりも長い名前を持ったオプション) では、オプションとその値は次のように = で区切られた1つのコマンドライン引数として渡すこともできます:
>>>
>>> parser.parse_args(['--foo=FOO'])
Namespace(foo='FOO', x=None)
短いオプション (1文字のオプション) では、オプションとその値は次のように連結して渡すことができます:
>>>
>>> parser.parse_args(['-xX'])
Namespace(foo=None, x='X')
最後の1つのオプションだけが値を要求する場合、または値を要求するオプションがない場合、複数の短いオプションは次のように1つの接頭辞 - だけで連結できます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-x', action='store_true')
>>> parser.add_argument('-y', action='store_true')
>>> parser.add_argument('-z')
>>> parser.parse_args(['-xyzZ'])
Namespace(x=True, y=True, z='Z')
不正な引数
parse_args() は、コマンドラインの解析中に、曖昧なオプション、不正な型、不正なオプション、位置引数の数の不一致などのエラーを検証します。それらのエラーが発生した場合、エラーメッセージと使用法メッセージを表示して終了します:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('--foo', type=int)
>>> parser.add_argument('bar', nargs='?')
>>> # invalid type
>>> parser.parse_args(['--foo', 'spam'])
usage: PROG [-h] [--foo FOO] [bar]
PROG: error: argument --foo: invalid int value: 'spam'
>>> # invalid option
>>> parser.parse_args(['--bar'])
usage: PROG [-h] [--foo FOO] [bar]
PROG: error: no such option: --bar
>>> # wrong number of arguments
>>> parser.parse_args(['spam', 'badger'])
usage: PROG [-h] [--foo FOO] [bar]
PROG: error: extra arguments found: badger
- を含む引数
parse_args() メソッドは、ユーザーが明らかなミスをした場合はエラーを表示しますが、いくつか本質的に曖昧な場面があります。例えば、コマンドライン引数 -1 は、オプションの指定かもしれませんし位置引数かもしれません。parse_args() メソッドはこれを次のように扱います: 負の数として解釈でき、パーサーに負の数のように解釈できるオプションが存在しない場合にのみ、- で始まる位置引数になりえます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-x')
>>> parser.add_argument('foo', nargs='?')
>>> # no negative number options, so -1 is a positional argument
>>> parser.parse_args(['-x', '-1'])
Namespace(foo=None, x='-1')
>>> # no negative number options, so -1 and -5 are positional arguments
>>> parser.parse_args(['-x', '-1', '-5'])
Namespace(foo='-5', x='-1')
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-1', dest='one')
>>> parser.add_argument('foo', nargs='?')
>>> # negative number options present, so -1 is an option
>>> parser.parse_args(['-1', 'X'])
Namespace(foo=None, one='X')
>>> # negative number options present, so -2 is an option
>>> parser.parse_args(['-2'])
usage: PROG [-h] [-1 ONE] [foo]
PROG: error: no such option: -2
>>> # negative number options present, so both -1s are options
>>> parser.parse_args(['-1', '-1'])
usage: PROG [-h] [-1 ONE] [foo]
PROG: error: argument -1: expected one argument
- で始まる位置引数があって、それが負の数として解釈できない場合、ダミーの引数 '--' を挿入して、parse_args() にそれ以降のすべてが位置引数だと教えることができます:
>>>
>>> parser.parse_args(['--', '-f'])
Namespace(foo='-f', one=None)
引数の短縮形 (先頭文字でのマッチング)
parse_args() メソッドは、デフォルトで、長いオプションに曖昧さがない (先頭の文字が一意である) かぎり、先頭の一文字に短縮して指定できます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('-bacon')
>>> parser.add_argument('-badger')
>>> parser.parse_args('-bac MMM'.split())
Namespace(bacon='MMM', badger=None)
>>> parser.parse_args('-bad WOOD'.split())
Namespace(bacon=None, badger='WOOD')
>>> parser.parse_args('-ba BA'.split())
usage: PROG [-h] [-bacon BACON] [-badger BADGER]
PROG: error: ambiguous option: -ba could match -badger, -bacon
先頭の文字が同じ引数が複数ある場合に短縮指定を行うとエラーを発生させます。この機能は allow_abbrev に False を指定することで無効にできます。
sys.argv 以外
ArgumentParser が sys.argv 以外の引数を解析できると役に立つ場合があります。その場合は文字列のリストを parse_args() に渡します。これはインタラクティブプロンプトからテストするときに便利です:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument(
...     'integers', metavar='int', type=int, choices=range(10),
...     nargs='+', help='an integer in the range 0..9')
>>> parser.add_argument(
...     '--sum', dest='accumulate', action='store_const', const=sum,
...     default=max, help='sum the integers (default: find the max)')
>>> parser.parse_args(['1', '2', '3', '4'])
Namespace(accumulate=<built-in function max>, integers=[1, 2, 3, 4])
>>> parser.parse_args(['1', '2', '3', '4', '--sum'])
Namespace(accumulate=<built-in function sum>, integers=[1, 2, 3, 4])
Namespace オブジェクト
class argparse.Namespace
parse_args() が属性を格納して返すためのオブジェクトにデフォルトで使用されるシンプルなクラスです。
デフォルトでは、 parse_args() は Namespace の新しいオブジェクトに必要な属性を設定して返します。このクラスはシンプルに設計されており、単に読みやすい文字列表現を持った object のサブクラスです。もし属性を辞書のように扱える方が良ければ、標準的な Python のイディオム vars() を利用できます:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo')
>>> args = parser.parse_args(['--foo', 'BAR'])
>>> vars(args)
{'foo': 'BAR'}
ArgumentParser が、新しい Namespace オブジェクトではなく、既存のオブジェクトに属性を設定する方が良い場合があります。これは namespace= キーワード引数を指定することで可能です:
>>>
>>> class C:
...     pass
...
>>> c = C()
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo')
>>> parser.parse_args(args=['--foo', 'BAR'], namespace=c)
>>> c.foo
'BAR'
その他のユーティリティ
サブコマンド
ArgumentParser.add_subparsers([title][, description][, prog][, parser_class][, action][, option_string][, dest][, required][, help][, metavar])
多くのプログラムは、その機能をサブコマンドへと分割します。 例えば svn プログラムは svn checkout, svn update, svn commit などのサブコマンドを利用できます。 機能をサブコマンドに分割するのは、プログラムがいくつかの異なった機能を持っていて、 それぞれが異なるコマンドライン引数を必要とする場合には良いアイデアです。 ArgumentParser は add_subparsers() メソッドによりサブコマンドを サポートしています。 add_subparsers() メソッドは通常引数なしに呼び出され、 特殊なアクションオブジェクトを返します。このオブジェクトには1つのメソッド add_parser() があり、コマンド名と ArgumentParser コンストラクターの任意の引数を受け取り、通常の方法で操作できる ArgumentParser オブジェクトを返します。
引数の説明:
title - ヘルプ出力でのサブパーサーグループのタイトルです。デフォルトは、description が指定されている場合は "subcommands" に、指定されていない場合は位置引数のタイトルになります
description - ヘルプ出力に表示されるサブパーサーグループの説明です。デフォルトは None になります
prog - サブコマンドのヘルプに表示される使用方法の説明です。デフォルトではプログラム名と位置引数の後ろに、サブパーサーの引数が続きます
parser_class - サブパーサーのインスタンスを作成するときに使用されるクラスです。デフォルトでは現在のパーサーのクラス (例: ArgumentParser) になります
action - コマンドラインにこの引数があったときの基本のアクション。
dest - サブコマンド名を格納する属性の名前です。デフォルトは None で値は格納されません
required - サブコマンドが必須であるかどうかを指定し、デフォルトは False です。(3.7 より追加)
help - ヘルプ出力に表示されるサブパーサーグループのヘルプです。デフォルトは None です
metavar - 利用可能なサブコマンドをヘルプ内で表示するための文字列です。デフォルトは None で、サブコマンドを {cmd1, cmd2, ..} のような形式で表します
いくつかの使用例:
>>>
>>> # create the top-level parser
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> parser.add_argument('--foo', action='store_true', help='foo help')
>>> subparsers = parser.add_subparsers(help='sub-command help')
>>>
>>> # create the parser for the "a" command
>>> parser_a = subparsers.add_parser('a', help='a help')
>>> parser_a.add_argument('bar', type=int, help='bar help')
>>>
>>> # create the parser for the "b" command
>>> parser_b = subparsers.add_parser('b', help='b help')
>>> parser_b.add_argument('--baz', choices='XYZ', help='baz help')
>>>
>>> # parse some argument lists
>>> parser.parse_args(['a', '12'])
Namespace(bar=12, foo=False)
>>> parser.parse_args(['--foo', 'b', '--baz', 'Z'])
Namespace(baz='Z', foo=True)
parse_args() が返すオブジェクトにはメインパーサーとコマンドラインで選択されたサブパーサーによる属性だけが設定されており、選択されなかったサブコマンドのパーサーの属性が設定されていないことに注意してください。このため、上の例では、a コマンドが指定されたときは foo, bar 属性だけが存在し、b コマンドが指定されたときは foo, baz 属性だけが存在しています。
同じように、サブパーサーにヘルプメッセージが要求された場合は、そのパーサーに対するヘルプだけが表示されます。ヘルプメッセージには親パーサーや兄弟パーサーのヘルプメッセージを表示しません。 (ただし、各サブパーサーコマンドのヘルプメッセージは、上の例にもあるように add_parser() の help= 引数によって指定できます)
>>>
>>> parser.parse_args(['--help'])
usage: PROG [-h] [--foo] {a,b} ...
positional arguments:
  {a,b}   sub-command help
    a     a help
    b     b help
optional arguments:
  -h, --help  show this help message and exit
  --foo   foo help
>>> parser.parse_args(['a', '--help'])
usage: PROG a [-h] bar
positional arguments:
  bar     bar help
optional arguments:
  -h, --help  show this help message and exit
>>> parser.parse_args(['b', '--help'])
usage: PROG b [-h] [--baz {X,Y,Z}]
optional arguments:
  -h, --help     show this help message and exit
  --baz {X,Y,Z}  baz help
add_subparsers() メソッドは title と description キーワード引数もサポートしています。どちらかが存在する場合、サブパーサーのコマンドはヘルプ出力でそれぞれのグループの中に表示されます。例えば:
>>>
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers(title='subcommands',
...                                    description='valid subcommands',
...                                    help='additional help')
>>> subparsers.add_parser('foo')
>>> subparsers.add_parser('bar')
>>> parser.parse_args(['-h'])
usage:  [-h] {foo,bar} ...
optional arguments:
  -h, --help  show this help message and exit
subcommands:
  valid subcommands
  {foo,bar}   additional help
さらに、add_parser は aliases 引数もサポートしており、同じサブパーサーに対して複数の文字列で参照することもできます。以下の例では svn のように checkout の短縮形として co を使用できるようにしています:
>>>
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers()
>>> checkout = subparsers.add_parser('checkout', aliases=['co'])
>>> checkout.add_argument('foo')
>>> parser.parse_args(['co', 'bar'])
Namespace(foo='bar')
サブコマンドを扱う1つの便利な方法は add_subparsers() メソッドと set_defaults() を組み合わせて、各サブパーサーにどの Python 関数を実行するかを教えることです。例えば:
>>>
>>> # sub-command functions
>>> def foo(args):
...     print(args.x * args.y)
...
>>> def bar(args):
...     print('((%s))' % args.z)
...
>>> # create the top-level parser
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers()
>>>
>>> # create the parser for the "foo" command
>>> parser_foo = subparsers.add_parser('foo')
>>> parser_foo.add_argument('-x', type=int, default=1)
>>> parser_foo.add_argument('y', type=float)
>>> parser_foo.set_defaults(func=foo)
>>>
>>> # create the parser for the "bar" command
>>> parser_bar = subparsers.add_parser('bar')
>>> parser_bar.add_argument('z')
>>> parser_bar.set_defaults(func=bar)
>>>
>>> # parse the args and call whatever function was selected
>>> args = parser.parse_args('foo 1 -x 2'.split())
>>> args.func(args)
2.0
>>>
>>> # parse the args and call whatever function was selected
>>> args = parser.parse_args('bar XYZYX'.split())
>>> args.func(args)
((XYZYX))
こうすると、parse_args() が引数の解析が終わってから適切な関数を呼び出すようになります。このように関数をアクションに関連付けるのは一般的にサブパーサーごとに異なるアクションを扱うもっとも簡単な方法です。ただし、実行されたサブパーサーの名前を確認する必要がある場合は、add_subparsers() を呼び出すときに dest キーワードを指定できます:
>>>
>>> parser = argparse.ArgumentParser()
>>> subparsers = parser.add_subparsers(dest='subparser_name')
>>> subparser1 = subparsers.add_parser('1')
>>> subparser1.add_argument('-x')
>>> subparser2 = subparsers.add_parser('2')
>>> subparser2.add_argument('y')
>>> parser.parse_args(['2', 'frobble'])
Namespace(subparser_name='2', y='frobble')
バージョン 3.7 で変更: 新しい required キーワード引数。
FileType オブジェクト
class argparse.FileType(mode='r', bufsize=-1, encoding=None, errors=None)
FileType ファクトリは ArgumentParser.add_argument() の type 引数に渡すことができるオブジェクトを生成します。 type が FileType オブジェクトである引数はコマンドライン引数を、指定されたモード、バッファーサイズ、エンコーディング、エラー処理でファイルとして開きます (詳細は open() 関数を参照してください。):
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--raw', type=argparse.FileType('wb', 0))
>>> parser.add_argument('out', type=argparse.FileType('w', encoding='UTF-8'))
>>> parser.parse_args(['--raw', 'raw.dat', 'file.txt'])
Namespace(out=<_io.TextIOWrapper name='file.txt' mode='w' encoding='UTF-8'>, raw=<_io.FileIO name='raw.dat' mode='wb'>)
FileType オブジェクトは擬似引数 '-' を識別し、読み込み用の FileType であれば sys.stdin を、書き込み用の FileType であれば sys.stdout に変換します:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('infile', type=argparse.FileType('r'))
>>> parser.parse_args(['-'])
Namespace(infile=<_io.TextIOWrapper name='<stdin>' encoding='UTF-8'>)
バージョン 3.4 で追加: encoding および errors キーワードが追加されました。
引数グループ
ArgumentParser.add_argument_group(title=None, description=None)
デフォルトでは、 ArgumentParser はヘルプメッセージを表示するときに、コマンドライン引数を "位置引数" と "オプション引数" にグループ化します。このデフォルトの動作よりも良い引数のグループ化方法がある場合、 add_argument_group() メソッドで適切なグループを作成できます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', add_help=False)
>>> group = parser.add_argument_group('group')
>>> group.add_argument('--foo', help='foo help')
>>> group.add_argument('bar', help='bar help')
>>> parser.print_help()
usage: PROG [--foo FOO] bar
group:
  bar    bar help
  --foo FOO  foo help
add_argument_group() メソッドは、通常の ArgumentParser と同じような add_argument() メソッドを持つ引数グループオブジェクトを返します。引数がグループに追加された時、パーサーはその引数を通常の引数のように扱いますが、ヘルプメッセージではその引数を分離されたグループの中に表示します。 add_argument_group() メソッドには、この表示をカスタマイズするための title と description 引数があります:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG', add_help=False)
>>> group1 = parser.add_argument_group('group1', 'group1 description')
>>> group1.add_argument('foo', help='foo help')
>>> group2 = parser.add_argument_group('group2', 'group2 description')
>>> group2.add_argument('--bar', help='bar help')
>>> parser.print_help()
usage: PROG [--bar BAR] foo
group1:
  group1 description
  foo    foo help
group2:
  group2 description
  --bar BAR  bar help
ユーザー定義グループにないすべての引数は通常の "位置引数" と "オプション引数" セクションに表示されます。
相互排他
ArgumentParser.add_mutually_exclusive_group(required=False)
相互排他グループを作ります。argparse は相互排他グループの中でただ1つの引数のみが存在することを確認します:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> group = parser.add_mutually_exclusive_group()
>>> group.add_argument('--foo', action='store_true')
>>> group.add_argument('--bar', action='store_false')
>>> parser.parse_args(['--foo'])
Namespace(bar=True, foo=True)
>>> parser.parse_args(['--bar'])
Namespace(bar=False, foo=False)
>>> parser.parse_args(['--foo', '--bar'])
usage: PROG [-h] [--foo | --bar]
PROG: error: argument --bar: not allowed with argument --foo
add_mutually_exclusive_group() メソッドの引数 required に True 値を指定すると、その相互排他引数のどれか 1つを選ぶことが要求さます:
>>>
>>> parser = argparse.ArgumentParser(prog='PROG')
>>> group = parser.add_mutually_exclusive_group(required=True)
>>> group.add_argument('--foo', action='store_true')
>>> group.add_argument('--bar', action='store_false')
>>> parser.parse_args([])
usage: PROG [-h] (--foo | --bar)
PROG: error: one of the arguments --foo --bar is required
現在のところ、相互排他引数グループは add_argument_group() の title と description 引数をサポートしていません。
パーサーのデフォルト値
ArgumentParser.set_defaults(**kwargs)
ほとんどの場合、 parse_args() が返すオブジェクトの属性はコマンドライン引数の内容と引数のアクションによってのみ決定されます。 set_defaults() を使うと与えられたコマンドライン引数の内容によらず追加の属性を決定することが可能です:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('foo', type=int)
>>> parser.set_defaults(bar=42, baz='badger')
>>> parser.parse_args(['736'])
Namespace(bar=42, baz='badger', foo=736)
パーサーレベルのデフォルト値は常に引数レベルのデフォルト値を上書きします:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default='bar')
>>> parser.set_defaults(foo='spam')
>>> parser.parse_args([])
Namespace(foo='spam')
パーサーレベルの default は、複数のパーサーを扱うときに特に便利です。このタイプの例については add_subparsers() メソッドを参照してください。
ArgumentParser.get_default(dest)
add_argument() か set_defaults() によって指定された、 namespace の属性のデフォルト値を取得します:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', default='badger')
>>> parser.get_default('foo')
'badger'
ヘルプの表示
ほとんどの典型的なアプリケーションでは、parse_args() が使用法やエラーメッセージのフォーマットと表示について面倒を見ます。しかし、いくつかのフォーマットメソッドが利用できます:
ArgumentParser.print_usage(file=None)
ArgumentParser がコマンドラインからどう実行されるべきかの短い説明を表示します。 file が None の時は、 sys.stdout に出力されます。
ArgumentParser.print_help(file=None)
プログラムの使用法と ArgumentParser に登録された引数についての情報を含むヘルプメッセージを表示します。 file が None の時は、 sys.stdout に出力されます。
これらのメソッドの、表示する代わりにシンプルに文字列を返すバージョンもあります:
ArgumentParser.format_usage()
ArgumentParser がコマンドラインからどう実行されるべきかの短い説明を格納した文字列を返します。
ArgumentParser.format_help()
プログラムの使用法と ArgumentParser に登録された引数についての情報を含むヘルプメッセージを格納した文字列を返します。
部分解析
ArgumentParser.parse_known_args(args=None, namespace=None)
ときどき、スクリプトがコマンドライン引数のいくつかだけを解析し、残りの引数は別のスクリプトやプログラムに渡すことがあります。こういった場合、 parse_known_args() メソッドが便利です。これは parse_args() と同じように動作しますが、余分な引数が存在してもエラーを生成しません。代わりに、評価された namespace オブジェクトと、残りの引数文字列のリストからなる2要素タプルを返します。
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo', action='store_true')
>>> parser.add_argument('bar')
>>> parser.parse_known_args(['--foo', '--badger', 'BAR', 'spam'])
(Namespace(bar='BAR', foo=True), ['--badger', 'spam'])
警告 先頭文字でのマッチング ルールは parse_known_args() にも適用されます。たとえ既知のオプションの先頭文字に過ぎない場合でも、パーサは引数リストに残さずに、オプションを受け取る場合があります。
ファイル解析のカスタマイズ
ArgumentParser.convert_arg_line_to_args(arg_line)
ファイルから引数を読み込む場合 (ArgumentParser コンストラクターの fromfile_prefix_chars キーワード引数を参照)、1行につき1つの引数を読み込みます。 convert_arg_line_to_args() を変更することでこの動作をカスタマイズできます。
このメソッドは、引数ファイルから読まれた文字列である1つの引数 arg_line を受け取ります。そしてその文字列を解析した結果の引数のリストを返します。このメソッドはファイルから1行読みこむごとに、順番に呼ばれます。
このメソッドをオーバーライドすると便利なこととして、スペースで区切られた単語を 1 つの引数として扱えます。次の例でその方法を示します:
class MyArgumentParser(argparse.ArgumentParser):
    def convert_arg_line_to_args(self, arg_line):
        return arg_line.split()
終了メソッド
ArgumentParser.exit(status=0, message=None)
このメソッドはプログラムを、status のステータスで終了させ、指定された場合は message を終了前に表示します。ユーザは、この振る舞いを違うものにするために、メソッドをオーバーライドすることができます。
class ErrorCatchingArgumentParser(argparse.ArgumentParser):
    def exit(self, status=0, message=None):
        if status:
            raise Exception(f'Exiting because of an error: {message}')
        exit(status)
ArgumentParser.error(message)
このメソッドは message を含む使用法メッセージを標準エラーに表示して、終了ステータス 2 でプログラムを終了します。
混在した引数の解析
ArgumentParser.parse_intermixed_args(args=None, namespace=None)
ArgumentParser.parse_known_intermixed_args(args=None, namespace=None)
多くの Unix コマンドは、オプション引数と位置引数を混在させることを許しています。 parse_intermixed_args() と parse_known_intermixed_args() メソッドは、このような方法での解析をサポートしています。
このパーサーは、argparse のすべての機能をサポートしておらず、対応しない機能が使われた場合、例外を送出します。特に、サブパーサーや argparse.REMAINDER、位置引数とオプション引数を両方含むような相互排他的なグループは、サポートされていません。
この例は、parse_known_args() と parse_intermixed_args() の違いを表しています: 前者は ['2', '3'] を、解析されない引数として返し、後者は全ての位置引数を rest に入れて返しています:
>>>
>>> parser = argparse.ArgumentParser()
>>> parser.add_argument('--foo')
>>> parser.add_argument('cmd')
>>> parser.add_argument('rest', nargs='*', type=int)
>>> parser.parse_known_args('doit 1 --foo bar 2 3'.split())
(Namespace(cmd='doit', foo='bar', rest=[1]), ['2', '3'])
>>> parser.parse_intermixed_args('doit 1 --foo bar 2 3'.split())
Namespace(cmd='doit', foo='bar', rest=[1, 2, 3])
parse_known_intermixed_args() は、解析した内容を含む名前空間と、残りの引数を含んだリストの、2つの要素を持つタプルを返します。 parse_intermixed_args() は、解析されない引数が残された場合にはエラーを送出します。
バージョン 3.7 で追加.
optparse からのアップグレード
もともと、argparse モジュールは optparse モジュールとの互換性を保って開発しようと試みられました。しかし、特に新しい nargs= 指定子とより良い使用法メッセージのために必要な変更のために、optparse を透過的に拡張することは難しかったのです。optparse のほとんどすべてがコピーアンドペーストされたりモンキーパッチを当てられたりしたとき、もはや後方互換性を保とうとすることは現実的ではありませんでした。
argparse モジュールは標準ライブラリ optparse モジュールを、以下を含むたくさんの方法で改善しています:
位置引数を扱う
サブコマンドのサポート
+, / のような代替オプションプレフィクスを許容する
zero-or-more スタイル、one-or-more スタイルの引数を扱う
より有益な使用方法メッセージの生成
カスタム type, カスタム action のために遥かに簡単なインターフェイスを提供する
optparse から argparse への現実的なアップグレードパス:
すべての optparse.OptionParser.add_option() の呼び出しを、ArgumentParser.add_argument() の呼び出しに置き換える。
(options, args) = parser.parse_args() を args = parser.parse_args() に置き換え、位置引数のために必要に応じて ArgumentParser.add_argument() の呼び出しを追加する。これまで options と呼ばれていたものが、argparse では args と呼ばれていることに留意してください。
optparse.OptionParser.disable_interspersed_args() を、parse_args() ではなく parse_intermixed_args() で置き換える。
コールバック・アクションと callback_* キーワード引数を type や action 引数に置き換える。
type キーワード引数に渡していた文字列の名前を、それに応じたオブジェクト (例: int, float, complex, ...) に置き換える。
optparse.Values を Namespace に置き換え、optparse.OptionError と optparse.OptionValueError を ArgumentError に置き換える。
%default や %prog などの暗黙の引数を含む文字列を、%(default)s や %(prog)s などの、通常の Python で辞書を使う場合のフォーマット文字列に置き換える。
OptionParser のコンストラクターの version 引数を、parser.add_argument('--version', action='version', version='<the version>') に置き換える
getopt --- C 言語スタイルのコマンドラインオプションパーサ
ソースコード: Lib/getopt.py
注釈 getopt モジュールは、C 言語の getopt() 関数に慣れ親しんだ人ためにデザインされた API を持つコマンドラインオプションのパーサです。getopt() 関数に慣れ親しんでない人や、コードを少なくしてよりよいヘルプメッセージを表示させたい場合は、argparse モジュールの使用を検討してください。
このモジュールは sys.argv に入っているコマンドラインオプションの構文解析を支援します。'-' や '--' の特別扱いも含めて、Unix の getopt() と同じ記法をサポートしています。3番目の引数 (省略可能) を設定することで、GNU のソフトウェアでサポートされているような長形式のオプションも利用できます。
このモジュールは2つの関数と1つの例外を提供しています:
getopt.getopt(args, shortopts, longopts=[])
コマンドラインオプションとパラメータのリストを構文解析します。args は構文解析の対象になる引数のリストです。これは先頭のプログラム名を除いたもので、通常 sys.argv[1:] で与えられます。shortopts はスクリプトで認識させたいオプション文字と、引数が必要な場合にはコロン (':') をつけます。つまり Unix の getopt() と同じフォーマットになります。
注釈 GNU の getopt() とは違って、オプションでない引数の後は全てオプションではないと判断されます。これは GNUでない、Unix システムの挙動に近いものです。
longopts は長形式のオプションの名前を示す文字列のリストです。名前には、先頭の '--' は含めません。引数が必要な場合には名前の最後に等号 ('=') を入れます。オプション引数はサポートしていません。長形式のオプションだけを受けつけるためには、shortopts は空文字列である必要があります。長形式のオプションは、該当するオプションを一意に決定できる長さまで入力されていれば認識されます。たとえば、longopts が ['foo', 'frob'] の場合、--fo は --foo にマッチしますが、--f では一意に決定できないので、GetoptError が送出されます。
返り値は2つの要素から成っています: 最初は (option, value) のタプルのリスト、2つ目はオプションリストを取り除いたあとに残ったプログラムの引数リストです (args の末尾部分のスライスになります)。それぞれの引数と値のタプルの最初の要素は、短形式の時はハイフン 1つで始まる文字列 (例: '-x')、長形式の時はハイフン2つで始まる文字列 (例: '--long-option') となり、引数が2番目の要素になります。引数をとらない場合には空文字列が入ります。オプションは見つかった順に並んでいて、複数回同じオプションを指定できます。長形式と短形式のオプションは混在できます。
getopt.gnu_getopt(args, shortopts, longopts=[])
この関数はデフォルトで GNU スタイルのスキャンモードを使う以外は getopt() と同じように動作します。つまり、オプションとオプションでない引数とを混在させることができます。getopt() 関数はオプションでない引数を見つけると解析を停止します。
オプション文字列の最初の文字を '+' にするか、環境変数 POSIXLY_CORRECT を設定することで、オプションでない引数を見つけると解析を停止するように振舞いを変えることができます。
exception getopt.GetoptError
引数リストの中に認識できないオプションがあった場合か、引数が必要なオプションに引数が与えられなかった場合に発生します。例外の引数は原因を示す文字列です。長形式のオプションについては、不要な引数が与えられた場合にもこの例外が発生します。 msg 属性と opt 属性で、エラーメッセージと関連するオプションを取得できます。特に関係するオプションが無い場合には opt は空文字列となります。
exception getopt.error
GetoptError へのエイリアスです。後方互換性のために残されています。
Unix スタイルのオプションを使った例です:
>>>
import getopt
args = '-a -b -cfoo -d bar a1 a2'.split()
args
['-a', '-b', '-cfoo', '-d', 'bar', 'a1', 'a2']
optlist, args = getopt.getopt(args, 'abc:d:')
optlist
[('-a', ''), ('-b', ''), ('-c', 'foo'), ('-d', 'bar')]
args
['a1', 'a2']
長形式のオプションを使っても同様です:
>>>
s = '--condition=foo --testing --output-file abc.def -x a1 a2'
args = s.split()
args
['--condition=foo', '--testing', '--output-file', 'abc.def', '-x', 'a1', 'a2']
optlist, args = getopt.getopt(args, 'x', [
    'condition=', 'output-file=', 'testing'])
optlist
[('--condition', 'foo'), ('--testing', ''), ('--output-file', 'abc.def'), ('-x', '')]
args
['a1', 'a2']
スクリプト中での典型的な使い方は以下のようになります:
import getopt, sys
def main():
    try:
        opts, args = getopt.getopt(sys.argv[1:], "ho:v", ["help", "output="])
    except getopt.GetoptError as err:
        # print help information and exit:
        print(err)  # will print something like "option -a not recognized"
        usage()
        sys.exit(2)
    output = None
    verbose = False
    for o, a in opts:
        if o == "-v":
            verbose = True
        elif o in ("-h", "--help"):
            usage()
            sys.exit()
        elif o in ("-o", "--output"):
            output = a
        else:
            assert False, "unhandled option"
    # ...
if __name__ == "__main__":
    main()
argparse モジュールを使えば、より良いヘルプメッセージとエラーメッセージを持った同じコマンドラインインタフェースをより少ないコードで実現できます:
import argparse
if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-o', '--output')
    parser.add_argument('-v', dest='verbose', action='store_true')
    args = parser.parse_args()
    # ... do something with args.output ...
    # ... do something with args.verbose ..
参考
argparse モジュール
別のコマンドラインオプションと引数の解析ライブラリ。
logging --- Python 用ロギング機能
ソースコード: Lib/logging/__init__.py
Important
このページには、リファレンス情報だけが含まれています。チュートリアルは、以下のページを参照してください
基本チュートリアル
上級チュートリアル
ロギングクックブック
このモジュールは、アプリケーションやライブラリのための柔軟なエラーログ記録 (logging) システムを実装するための関数やクラスを定義しています。
標準ライブラリモジュールとしてログ記録 API が提供される利点は、すべての Python モジュールがログ記録に参加できることであり、これによってあなたが書くアプリケーションのログにサードパーティーのモジュールが出力するメッセージを含ませることができます。
このモジュールは、多くの機能性と柔軟性を提供します。ロギングに慣れていないなら、つかむのに一番いいのはチュートリアルを読むことです (右のリンクを参照してください)。
モジュールで定義されている基本的なクラスと関数を、以下に列挙します。
ロガーは、アプリケーションコードが直接使うインタフェースを公開します。
ハンドラは、(ロガーによって生成された) ログ記録を適切な送信先に送ります。
フィルタは、どのログ記録を出力するかを決定する、きめ細かい機能を提供します。
フォーマッタは、ログ記録が最終的に出力されるレイアウトを指定します。
ロガーオブジェクト
ロガーには以下のような属性とメソッドがあります。 ロガーを直接インスタンス化することは 絶対に してはならず、常にモジュール関数 logging.getLogger(name) を介してインスタンス化することに注意してください。 同じ name で getLogger() を複数回呼び出すと、常に同じロガー・オブジェクトへの参照が返されます。
name は foo.bar.baz のようにピリオドで分割された (ただし単なるプレーンな foo もありえます) 潜在的に階層的な値です。階層リスト中でより下位のロガーは、上位のロガーの子です。例えば、foo という名前を持つロガーがあるとき、foo.bar, foo.bar.baz, foo.bam という名前を持つロガーはすべて foo の子孫です。ロガー名の階層は Python パッケージ階層と類似していて、推奨される構築方法 logging.getLogger(__name__) を使用してロガーをモジュール単位で構成すれば、Python パッケージ階層と同一になります。これは、モジュールの中では __name__ が Python パッケージ名前空間におけるモジュール名だからです。
class logging.Logger
propagate
この属性が真と評価された場合、このロガーに記録されたイベントは、このロガーに取り付けられた全てのハンドラに加え、上位 (祖先) ロガーのハンドラにも渡されます。 メッセージは、祖先ロガーのハンドラに直接渡されます - 今問題にしている祖先ロガーのレベルもフィルタも、どちらも考慮されません。
この値の評価結果が偽になる場合、ロギングメッセージは祖先ロガーのハンドラに渡されません。
コンストラクタはこの属性を True に設定します。
注釈 ハンドラを、あるロガー と その祖先のロガーに接続した場合、同一レコードが複数回発行される場合があります。一般的に、ハンドラを複数のロガーに接続する必要はありません。propagate 設定が True のままになっていれば、ロガーの階層において最上位にある適切なロガーにハンドラを接続するだけで、そのハンドラは全ての子孫ロガーが記録する全てのイベントを確認することができます。一般的なシナリオでは、ハンドラをルートロガーに対してのみ接続し、残りは propagate にすべて委ねます。
setLevel(level)
このロガーの閾値を level に設定します。 level よりも深刻でないログメッセージは無視されます; 深刻さが level 以上のログメッセージは、ハンドラのレベルが level より上に設定されていない限り、このロガーに取り付けられているハンドラによって投げられます。
ロガーが生成された際、レベルは NOTSET (これによりすべてのメッセージについて、ロガーがルートロガーであれば処理される、そうでなくてロガーが非ルートロガーの場合には親ロガーに委譲させる) に設定されます。 ルートロガーは WARNING レベルで生成されることに注意してください。
「親ロガーに委譲」という用語の意味は、もしロガーのレベルが NOTSET ならば、祖先ロガーの系列の中を NOTSET 以外のレベルの祖先を見つけるかルートに到達するまで辿っていく、ということです。
もし NOTSET 以外のレベルの祖先が見つかったなら、その祖先のレベルが探索を開始したロガーの実効レベルとして扱われ、ログイベントがどのように処理されるかを決めるのに使われます。
ルートに到達した場合、ルートのレベルが NOTSET ならばすべてのメッセージは処理されます。そうでなければルートのレベルが実効レベルとして使われます。
レベルの一覧については ロギングレベル を参照してください。
バージョン 3.2 で変更: level パラメータは、 INFO のような整数定数の代わりに 'INFO' のようなレベルの文字列表現も受け付けるようになりました。ただし、レベルは内部で整数として保存されますし、 getEffectiveLevel() や isEnabledFor() といったメソッドは、整数を返し、また渡されるものと期待します。
isEnabledFor(level)
getEffectiveLevel()
このロガーの実効レベルを示します。 NOTSET 以外の値が setLevel() で設定されていた場合、その値が返されます。そうでない場合、 NOTSET 以外の値が見つかるまでロガーの階層をルートロガーの方向に追跡します。見つかった場合、その値が返されます。返される値は整数で、典型的には logging.DEBUG, logging.INFO 等のうち一つです。
getChild(suffix)
このロガーの子であるロガーを、接頭辞によって決定し、返します。従って、logging.getLogger('abc').getChild('def.ghi') は、logging.getLogger('abc.def.ghi') によって返されるのと同じロガーを返すことになります。これは簡便なメソッドで、親ロガーがリテラルでなく __name__ などを使って名付けられているときに便利です。
バージョン 3.2 で追加.
debug(msg, *args, **kwargs)
exc_info は、この値の評価値が false でない場合、例外情報がロギングメッセージに追加されます。もし例外情報をあらわすタプル(sys.exc_info() 関数によって戻されるフォーマットにおいて)、または、例外情報をあらわすインスタンスが与えられていれば、それが使用されることになります。それ以外の場合には、 sys.exc_info() を呼び出して例外情報を取得します。
2つ目の省略可能なキーワード引数は stack_info で、デフォルトは False です。真の場合、実際のロギング呼び出しを含むスタック情報がロギングメッセージに追加されます。これは exc_info 指定によって表示されるスタック情報と同じものではないことに注意してください: 前者はカレントスレッド内での、一番下からロギング呼び出しまでのスタックフレームですが、後者は例外に呼応して、例外ハンドラが見つかるところまで巻き戻されたスタックフレームの情報です。
exc_info とは独立に stack_info を指定することもできます (例えば、例外が上げられなかった場合でも、コード中のある地点にどのように到着したかを単に示すために)。スタックフレームは、次のようなヘッダー行に続いて表示されます:
Stack (most recent call last):
これは、例外フレームを表示する場合に使用される Traceback (most recent call last): を模倣します。
The fourth keyword argument is extra which can be used to pass a dictionary which is used to populate the __dict__ of the LogRecord created for the logging event with user-defined attributes. These custom attributes can then be used as you like. For example, they could be incorporated into logged messages. For example:
FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'
logging.basicConfig(format=FORMAT)
d = {'clientip': '192.168.0.1', 'user': 'fbloggs'}
logger = logging.getLogger('tcpserver')
logger.warning('Protocol problem: %s', 'connection reset', extra=d)
これは以下のような出力を行います
2006-02-08 22:20:02,165 192.168.0.1 fbloggs  Protocol problem: connection reset
extra で渡される辞書のキーはロギングシステムで使われているものと衝突しないようにしなければなりません。 (どのキーがロギングシステムで使われているかについての詳細は Formatter のドキュメントを参照してください。)
このようなことは煩わしいかもしれませんが、この機能は限定された場面で使われるように意図しているものなのです。たとえば同じコードがいくつものコンテキストで実行されるマルチスレッドのサーバで、興味のある条件が現れるのがそのコンテキストに依存している (上の例で言えば、リモートのクライアント IP アドレスや認証されたユーザ名など)、というような場合です。そういった場面では、それ用の Formatter が特定の Handler と共に使われるというのはよくあることです。
バージョン 3.2 で変更: stack_info パラメータが追加されました。
バージョン 3.5 で変更: exc_info パラメータは例外インスタンスを受け入れることが可能です。
バージョン 3.8 で変更: The stacklevel parameter was added.
info(msg, *args, **kwargs)
レベル INFO のメッセージをこのロガーで記録します。引数は debug() と同じように解釈されます。
warning(msg, *args, **kwargs)
レベル WARNING のメッセージをこのロガーで記録します。引数は debug() と同じように解釈されます。
注釈 warning と機能的に等価な古いメソッド warn があります。warn は廃止予定なので使わないでください - 代わりに warning を使ってください。
error(msg, *args, **kwargs)
レベル ERROR のメッセージをこのロガーで記録します。引数は debug() と同じように解釈されます。
critical(msg, *args, **kwargs)
レベル CRITICAL のメッセージをこのロガーで記録します。引数は debug() と同じように解釈されます。
log(level, msg, *args, **kwargs)
exception(msg, *args, **kwargs)
レベル ERROR のメッセージをこのロガーで記録します。引数は debug() と同じように解釈されます。例外情報がログメッセージに追加されます。このメソッドは例外ハンドラからのみ呼び出されるべきです。
addFilter(filter)
指定されたフィルタ filter をこのロガーに追加します。
removeFilter(filter)
指定されたフィルタ filter をこのロガーから取り除きます。
filter(record)
addHandler(hdlr)
指定されたハンドラ hdlr をこのロガーに追加します。
removeHandler(hdlr)
指定されたハンドラ hdlr をこのロガーから取り除きます。
findCaller(stack_info=False, stacklevel=1)
呼び出し元のソースファイル名と行番号を調べます。ファイル名と行番号、関数名、スタック情報を 4 要素のタプルで返します。stack_info が True でなければ、スタック情報は None が返されます。
handle(record)
レコードを、このロガーおよびその上位ロガー (ただし propagate の値が false になったところまで) に関連付けられているすべてのハンドラに渡して処理します。このメソッドは、ローカルで生成されたレコードだけでなく、ソケットから受信した unpickle されたレコードに対しても同様に用いられます。 filter() によって、ロガーレベルでのフィルタが適用されます。
makeRecord(name, level, fn, lno, msg, args, exc_info, func=None, extra=None, sinfo=None)
このメソッドは、特殊な LogRecord インスタンスを生成するためにサブクラスでオーバライドできるファクトリメソッドです。
hasHandlers()
このロガーにハンドラが設定されているかどうかを調べます。 そのために、このロガーとロガー階層におけるその祖先についてハンドラ探していきます。 ハンドラが見つかれば True 、そうでなければ False を返します。 このメソッドは、'propagate' 属性が偽に設定されたロガーを見つけると、さらに上位の探索をやめます - そのロガーが、ハンドラが存在するかどうかチェックされる最後のロガー、という意味です。
バージョン 3.2 で追加.
バージョン 3.7 で変更: ロガーの pickle 化と unpickle 化ができるようになりました。
ロギングレベル
ログレベルの数値は以下の表のように与えられています。これらは基本的に自分でレベルを定義したい人のためのもので、定義するレベルを既存のレベルの間に位置づけるためには具体的な値が必要になります。もし数値が他のレベルと同じだったら、既存の値は上書きされその名前は失われます。
レベル
数値
CRITICAL
50
ERROR
40
WARNING
30
INFO
20
DEBUG
10
NOTSET
0
ハンドラオブジェクト
ハンドラ (Handler) は以下の属性とメソッドを持ちます。 Handler は直接インスタンス化されることはありません; このクラスはより便利なサブクラスの基底クラスとして働きます。しかしながら、サブクラスにおける __init__() メソッドでは、 Handler.__init__() を呼び出す必要があります。
class logging.Handler
__init__(level=NOTSET)
レベルを設定して、 Handler インスタンスを初期化します。空のリストを使ってフィルタを設定し、 I/O 機構へのアクセスを直列化するために (createLock() を使って) ロックを生成します。
createLock()
スレッドセーフでない背後の I/O 機能に対するアクセスを直列化するために用いられるスレッドロック (thread lock) を初期化します。
acquire()
createLock() で生成されたスレッドロックを獲得します。
release()
acquire() で獲得したスレッドロックを解放します。
setLevel(level)
このハンドラに対する閾値を level に設定します。 level よりも深刻でないログメッセージは無視されます。 ハンドラが生成された際、レベルは NOTSET (すべてのメッセージが処理される) に設定されます。
レベルの一覧については ロギングレベル を参照してください。
バージョン 3.2 で変更: level パラメータは、 INFO のような整数定数の代わりに 'INFO' のようなレベルの文字列表現も受け付けるようになりました。
setFormatter(fmt)
このハンドラのフォーマッタを fmt に設定します。
addFilter(filter)
指定されたフィルタ filter をこのハンドラに追加します。
removeFilter(filter)
指定されたフィルタ filter をこのハンドラから除去します。
filter(record)
flush()
すべてのログ出力がフラッシュされるようにします。このクラスのバージョンではなにも行わず、サブクラスで実装するためのものです。
close()
ハンドラで使われているすべてのリソースの後始末を行います。このバージョンでは何も出力せず、 shutdown() が呼ばれたときに閉じられたハンドラを内部リストから削除します。サブクラスではオーバライドされた close() メソッドからこのメソッドが必ず呼ばれるようにしてください。
handle(record)
ハンドラに追加されたフィルタの条件に応じて、指定されたログレコードを出力します。このメソッドは I/O スレッドロックの獲得/解放を伴う実際のログ出力をラップします。
handleError(record)
このメソッドは emit() の呼び出し中に例外に遭遇した際にハンドラから呼び出されます。モジュールレベル属性 raiseExceptions が False の場合、例外は暗黙のまま無視されます。ほとんどの場合、これがロギングシステムの望ましい動作です - というのは、ほとんどのユーザはロギングシステム自体のエラーは気にせず、むしろアプリケーションのエラーに興味があるからです。しかしながら、望むならこのメソッドを自作のハンドラと置き換えることもできます。 record には、例外発生時に処理されていたレコードが入ります。 (raiseExceptions のデフォルト値は True です。これは開発中はその方が便利だからです)。
format(record)
レコードに対する書式化を行います - フォーマッタが設定されていれば、それを使います。そうでない場合、モジュールにデフォルト指定されたフォーマッタを使います。
emit(record)
指定されたログ記録レコードを実際にログ記録する際のすべての処理を行います。このメソッドはサブクラスで実装されることを意図しており、そのためこのクラスのバージョンは NotImplementedError を送出します。
標準として含まれているハンドラについては、 logging.handlers を参照してください。
フォーマッタオブジェクト
Formatter オブジェクトは以下の属性とメソッドを持っています。 Formatter は LogRecord を (通常は) 人間か外部のシステムで解釈できる文字列に変換する役割を担っています。基底クラスの Formatter では書式文字列を指定することができます。何も指定されなかった場合、ロギングコール中のメッセージ以外の情報だけを持つ '%(message)s' の値が使われます。フォーマットされた出力に情報の要素 (タイムスタンプなど) を追加したいなら、このまま読み進めてください。
Formatter は LogRecord 属性の知識を利用できるような書式文字列を用いて初期化することができます。例えば、上で言及したデフォルト値では、ユーザによるメッセージと引数はあらかじめフォーマットされて、 LogRecord の message 属性に入っていることを利用しています。この書式文字列は、 Python 標準の % を使った変換文字列で構成されます。文字列整形に関する詳細は printf 形式の文字列書式化 を参照してください。
LogRecord の便利なマッピングキーは、 LogRecord 属性 の節で与えられます。
class logging.Formatter(fmt=None, datefmt=None, style='%', validate=True)
Formatter クラスの新たなインスタンスを返します。インスタンスは全体としてのメッセージに対する書式文字列と、メッセージの日付/時刻部分のための書式文字列を伴って初期化されます。 fmt が指定されない場合、 '%(message)s' が使われます。 datefmt が指定されない場合、 formatTime() ドキュメントで解説されている書式が使われます。
バージョン 3.2 で変更: style パラメータが追加されました。
バージョン 3.8 で変更: The validate parameter was added. Incorrect or mismatched style and fmt will raise a ValueError. For example: logging.Formatter('%(asctime)s - %(message)s', style='{').
format(record)
レコードの属性辞書が、文字列を書式化する演算で被演算子として使われます。書式化された結果の文字列を返します。辞書を書式化する前に、二つの準備段階を経ます。レコードの message 属性が msg % args を使って処理されます。書式化された文字列が '(asctime)' を含むなら、 formatTime() が呼び出され、イベントの発生時刻を書式化します。例外情報が存在する場合、 formatException() を使って書式化され、メッセージに追加されます。ここで注意していただきたいのは、書式化された例外情報は exc_text にキャッシュされるという点です。これが有用なのは例外情報がピックル化されて回線上を送ることができるからですが、しかし二つ以上の Formatter サブクラスで例外情報の書式化をカスタマイズしている場合には注意が必要になります。この場合、フォーマッタが書式化を終えるごとにキャッシュをクリアして、次のフォーマッタがキャッシュされた値を使わずに新鮮な状態で再計算するようにしなければならないことになります。
スタック情報が利用可能な場合、(必要ならば formatStack() を使って整形した上で) スタック情報が例外情報の後に追加されます。
formatTime(record, datefmt=None)
このメソッドは、フォーマッタが書式化された時間を利用したい際に、 format() から呼び出されます。 このメソッドは特定の要求を提供するためにフォーマッタで上書きすることができますが、基本的な振る舞いは以下のようになります: datefmt (文字列) が指定された場合、レコードが生成された時刻を書式化するために time.strftime() で使われます。 そうでない場合、 '%Y-%m-%d %H:%M:%S,uuu' というフォーマットが使われます。 uuu 部分はミリ秒値で、それ以外の文字は time.strftime() ドキュメントに従います。 このフォーマットの時刻の例は 2003-01-23 00:29:50,411 です。 結果の文字列が返されます。
この関数は、ユーザが設定できる関数を使って、生成時刻をタプルに変換します。デフォルトでは、 time.localtime() が使われます。特定のフォーマッタインスタンスに対してこれを変更するには、 converter 属性を time.localtime() や time.gmtime() と同じ署名をもつ関数に設定してください。すべてのフォーマッタインスタンスに対してこれを変更するには、例えば全てのロギング時刻を GMT で表示するには、 Formatter クラスの converter 属性を設定してください。
バージョン 3.3 で変更: 以前は、デフォルトのフォーマットがこの例のようにハードコーディングされていました: 2010-09-06 22:38:15,292 ここで、コンマの前の部分は strptime フォーマット文字列 ('%Y-%m-%d %H:%M:%S') によって扱われる部分で、コンマの後の部分はミリ秒値です。strptime にミリ秒のフォーマットプレースホルダーがないので、ミリ秒値は別のフォーマット文字列 '%s,%03d' を使用して追加されます。そして、これらのフォーマット文字列は両方ともこのメソッドでハードコーディングされていました。変更後は、これらの文字列はクラスレベル属性として定義され、必要ならインスタンスレベルでオーバーライドすることができます。属性の名前は default_time_format (strptime 書式文字列用) と default_msec_format (ミリ秒値の追加用) です。
バージョン 3.9 で変更: The default_msec_format can be None.
formatException(exc_info)
指定された例外情報 (sys.exc_info() が返すような標準例外のタプル) を文字列として書式化します。デフォルトの実装は単に traceback.print_exception() を使います。結果の文字列が返されます。
formatStack(stack_info)
指定されたスタック情報を文字列としてフォーマットします (traceback.print_stack() によって返される文字列ですが、最後の改行が取り除かれています)。このデフォルト実装は、単に入力値をそのまま返します。
フィルタオブジェクト
フィルタ (Filter) は、ハンドラ や ロガー によって使われ、レベルによって提供されるのよりも洗練されたフィルタリングを実現します。基底のフィルタクラスは、ロガー階層構造内の特定地点の配下にあるイベントだけを許可します。例えば、'A.B' で初期化されたフィルタは、ロガー 'A.B', 'A.B.C', 'A.B.C.D', 'A.B.D' 等によって記録されたイベントは許可しますが、'A.BB', 'B.A.B' などは許可しません。空の文字列で初期化された場合、すべてのイベントを通過させます。
class logging.Filter(name='')
Filter クラスのインスタンスを返します。 name が指定されていれば、 name はロガーの名前を表します。指定されたロガーとその子ロガーのイベントがフィルタを通過できるようになります。 name が指定されなければ、すべてのイベントを通過させます。
filter(record)
指定されたレコードがログされるべきか？no ならばばゼロを、yes ならばゼロでない値を返します。適切と判断されれば、このメソッドによってレコードはその場で修正されることがあります。
ハンドラに対するフィルタはハンドラがイベントを発行する前に試され、一方ではロガーに対するフィルタは、イベントが(debug(), info() などによって)ロギングされる際には、ハンドラにイベントが送信される前にはいつでも試されることに注意してください。そのフィルタがそれら子孫ロガーにも適用されていない限り、子孫ロガーによって生成されたイベントはロガーのフィルタ設定によってフィルタされることはありません。
実際には、Filter をサブクラス化する必要はありません。同じ意味の filter メソッドを持つ、すべてのインスタンスを通せます。
バージョン 3.2 で変更: 特殊な Filter クラスを作ったり、 filter メソッドを持つ他のクラスを使う必要はありません: 関数 (あるいは他の callable) をフィルタとして使用することができます。フィルタロジックは、フィルタオブジェクトが filter 属性を持っているかどうかチェックします: もし filter 属性を持っていたら、それは Filter であると仮定され、その filter() メソッドが呼び出されます。そうでなければ、それは callable であると仮定され、レコードを単一のパラメータとして呼び出されます。返される値は filter() によって返されるものと一致すべきです。
LogRecord オブジェクト
LogRecord インスタンスは、何かをログ記録するたびに Logger によって生成されます。また、 makeLogRecord() を通して (例えば、ワイヤを通して受け取られた pickle 化されたイベントから) 手動で生成することも出来ます。
class logging.LogRecord(name, level, pathname, lineno, msg, args, exc_info, func=None, sinfo=None)
ロギングされているイベントに適切なすべての情報を含みます。
基本的な情報は msg と args に渡され、レコードの message フィールドは msg % args による結合で生成されます。
パラメータ
name -- この LogRecord で表されるイベントをロギングするのに使われるロガーの名前です。ここで与える名前が、たとえ他の(祖先の)ロガーに結び付けられたハンドラによって発せられるとしても、与えたこの値のままであることに注意してください。
level -- このロギングイベントの数値のレベル (DEBUG, INFO などのいずれか) です。なお、これは LogRecord の 2つの 属性に変換されます。数値 levelno と、対応するレベル名 levelname です。
pathname -- ロギングの呼び出しが発せられたファイルの完全なパス名。
lineno -- ロギングの呼び出しが発せられたソース行番号。
msg -- イベント記述メッセージで、これは変数データのプレースホルダを持つフォーマット文字列になり得ます。
args -- msg 引数と組み合わせてイベント記述を得るための変数データです。
exc_info -- 現在の例外情報を含む例外タプルか、利用できる例外情報がない場合は None です。
func -- ロギングの呼び出しを行った関数またはメソッドの名前です。
sinfo -- 現在のスレッドのスタックベースからログ呼び出しまでの間のスタック情報を表わすテキスト文字列。
getMessage()
ユーザが提供した引数をメッセージに交ぜた後、この LogRecord インスタンスへのメッセージを返します。ユーザがロギングの呼び出しに与えた引数が文字列でなければ、その引数に str() が呼ばれ、文字列に変換されます。これにより、 __str__ メソッドが実際のフォーマット文字列を返せるようなユーザ定義のクラスをメッセージとして使えます。
バージョン 3.2 で変更: The creation of a LogRecord has been made more configurable by providing a factory which is used to create the record. The factory can be set using getLogRecordFactory() and setLogRecordFactory() (see this for the factory's signature).
This functionality can be used to inject your own values into a LogRecord at creation time. You can use the following pattern:
old_factory = logging.getLogRecordFactory()
def record_factory(*args, **kwargs):
    record = old_factory(*args, **kwargs)
    record.custom_attribute = 0xdecafbad
    return record
logging.setLogRecordFactory(record_factory)
このパターンでは複数のファクトリをつなぐこともできます。それらが互いの属性を上書きしたりせず、また上にリストされた標準属性を意図せず上書きしたりしない限り、驚くようなことは何も起こりません (there should be no surprises)。
LogRecord 属性
LogRecord には幾つかの属性があり、そのほとんどはコンストラクタの引数から得られます。(なお、LogRecord コンストラクタの引数と LogRecord 属性が常に厳密に対応するわけではありません。) これらの属性は、レコードからのデータをフォーマット文字列に統合するのに使えます。以下のテーブルに、属性名、意味、そして % 形式フォーマット文字列における対応するプレースホルダを (アルファベット順に) 列挙します。
{}-フォーマット (str.format()) を使用していれば、書式文字列の中でプレースホールダーとして {attrname} を使うことができます。 $-フォーマット (string.Template) を使用している場合は、 ${attrname} 形式にしてください。もちろん、両方の場合で attrname は使用したい実際の属性名に置き換えてください。
{}-フォーマットの場合には、属性名の後にフォーマットフラグを指定することができます。属性名とフォーマットフラグの間はコロンで分割します。例: プレースホールダー {msecs:03d} は、ミリセカンド値 4 を 004 としてフォーマットします。利用可能なオプション上の全詳細に関しては str.format() ドキュメンテーションを参照してください。
属性名
フォーマット
説明
args
このフォーマットを自分で使う必要はないでしょう。
msg に組み合わせて message を生成するための引数のタプル、または、マージに用いられる辞書(引数が一つしかなく、かつそれが辞書の場合)。
asctime
%(asctime)s
LogRecord が生成された時刻を人間が読める書式で表したもの。デフォルトでは "2003-07-08 16:49:45,896" 形式 (コンマ以降の数字は時刻のミリ秒部分) です。
created
%(created)f
LogRecord が生成された時刻 (time.time() によって返される形式で)。
exc_info
このフォーマットを自分で使う必要はないでしょう。
(sys.exc_info 風の) 例外タプルか、例外が起こっていない場合は None。
ファイル名
%(filename)s
pathname のファイル名部分。
funcName
%(funcName)s
ロギングの呼び出しを含む関数の名前。
levelname
%(levelname)s
メッセージのための文字のロギングレベル ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL')。
levelno
%(levelno)s
メッセージのための数値のロギングレベル (DEBUG, INFO, WARNING, ERROR, CRITICAL)。
lineno
%(lineno)d
ロギングの呼び出しが発せられたソース行番号 (利用できる場合のみ)。
message
%(message)s
msg % args として求められた、ログメッセージ。 Formatter.format() が呼び出されたときに設定されます。
module
%(module)s
モジュール (filename の名前部分)。
msecs
%(msecs)d
LogRecord が生成された時刻のミリ秒部分。
msg
このフォーマットを自分で使う必要はないでしょう。
元のロギングの呼び出しで渡されたフォーマット文字列。 args と合わせて、 message 、または任意のオブジェクトを生成します (任意のオブジェクトをメッセージに使用する 参照)。
name
%(name)s
ロギングに使われたロガーの名前。
pathname
%(pathname)s
ロギングの呼び出しが発せられたファイルの完全なパス名 (利用できる場合のみ)。
process
%(process)d
プロセス ID (利用可能な場合のみ)。
processName
%(processName)s
プロセス名 (利用可能な場合のみ)。
relativeCreated
%(relativeCreated)d
logging モジュールが読み込まれた時刻に対する、LogRecord が生成された時刻を、ミリ秒で表したもの。
stack_info
このフォーマットを自分で使う必要はないでしょう。
現在のスレッドでのスタックの底からこのレコードの生成に帰着したログ呼び出しまでのスタックフレーム情報 (利用可能な場合)。
thread
%(thread)d
スレッド ID (利用可能な場合のみ)。
threadName
%(threadName)s
スレッド名 (利用可能な場合のみ)。
バージョン 3.1 で変更: processName が追加されました。
LoggerAdapter オブジェクト
LoggerAdapter インスタンスは文脈情報をログ記録呼び出しに渡すのを簡単にするために使われます。使い方の例は コンテキスト情報をログ記録出力に付加する を参照してください。
class logging.LoggerAdapter(logger, extra)
内部で使う Logger インスタンスと辞書風 (dict-like) オブジェクトで初期化した LoggerAdapter のインスタンスを返します。
process(msg, kwargs)
文脈情報を挿入するために、ログ記録呼び出しに渡されたメッセージおよび/またはキーワード引数に変更を加えます。ここでの実装は extra としてコンストラクタに渡されたオブジェクトを取り、'extra' キーを使って kwargs に加えます。返り値は (msg, kwargs) というタプルで、(変更されているはずの) 渡された引数を含みます。
LoggerAdapter は上記に加え Logger のメソッド debug(), info(), warning(), error(), exception(), critical(), log(), isEnabledFor(), getEffectiveLevel(), setLevel(), hasHandlers() をサポートします。これらは Logger の対応するメソッドと同じシグニチャを持つため、2つのインスタンスは区別せずに利用出来ます。
バージョン 3.2 で変更: isEnabledFor(), getEffectiveLevel(), setLevel(), hasHandlers() が LoggerAdapter に追加されました。これらメソッドは元のロガーに処理を委譲します。
スレッドセーフ性
logging モジュールは、クライアントで特殊な作業を必要としない限りスレッドセーフになっています。このスレッドセーフ性はスレッドロックによって達成されています; モジュールの共有データへのアクセスを直列化するためのロックが一つ存在し、各ハンドラでも背後にある I/O へのアクセスを直列化するためにロックを生成します。
signal モジュールを使用して非同期シグナルハンドラを実装している場合、そのようなハンドラからはログ記録を使用できないかもしれません。これは、 threading モジュールにおけるロック実装が常にリエントラントではなく、そのようなシグナルハンドラから呼び出すことができないからです。
モジュールレベルの関数
上で述べたクラスに加えて、いくつかのモジュールレベルの関数が存在します。
logging.getLogger(name=None)
指定された名前のロガーを返します。名前が None であれば、ロガー階層のルート (root) にあるロガーを返します。name を指定する場合には、通常は 'a', 'a.b', 'a.b.c.d' といったドット区切りの階層的な名前にします。名前の付け方はログ機能を使う開発者次第です。
与えられた名前に対して、この関数はどの呼び出しでも同じロガーインスタンスを返します。したがって、ロガーインスタンスをアプリケーションの各部でやりとりする必要はありません。
logging.getLoggerClass()
標準の Logger クラスか、最後に setLoggerClass() に渡したクラスを返します。この関数は、新たなクラス定義の中で呼び出して、カスタマイズした Logger クラスのインストールが既に他のコードで適用したカスタマイズを取り消さないことを保証するために使われることがあります。例えば以下のようにします:
class MyLogger(logging.getLoggerClass()):
    # ... override behaviour here
logging.getLogRecordFactory()
LogRecord を生成するのに使われる callable を返します。
バージョン 3.2 で追加: この関数は、ログイベントを表現する LogRecord の構築方法に関して開発者により多くのコントロールを与えるため、 setLogRecordFactory() とともに提供されました。
このファクトリがどのように呼ばれるかに関する詳細は setLogRecordFactory() を参照してください。
logging.debug(msg, *args, **kwargs)
レベル DEBUG のメッセージをルートロガーで記録します。 msg はメッセージの書式文字列で、 args は msg に文字列書式化演算子を使って取り込むための引数です。 (これは、書式文字列の中でキーワードを使い、引数として単一の辞書を渡すことができる、ということを意味します。)
キーワード引数 kwargs からは 3 つのキーワードが調べられます。一つ目は exc_info で、この値の評価値が false でない場合、例外情報をログメッセージに追加します。 (sys.exc_info() の返す形式の) 例外情報を表すタプルや例外インスタンスが与えられていれば、それをメッセージに使います。それ以外の場合には、 sys.exc_info() を呼び出して例外情報を取得します。
2つ目の省略可能なキーワード引数は stack_info で、デフォルトは False です。真の場合、実際のロギング呼び出しを含むスタック情報がロギングメッセージに追加されます。これは exc_info 指定によって表示されるスタック情報と同じものではないことに注意してください: 前者はカレントスレッド内での、一番下からロギング呼び出しまでのスタックフレームですが、後者は例外に呼応して、例外ハンドラが見つかるところまで巻き戻されたスタックフレームの情報です。
exc_info とは独立に stack_info を指定することもできます (例えば、例外が上げられなかった場合でも、コード中のある地点にどのように到着したかを単に示すために)。スタックフレームは、次のようなヘッダー行に続いて表示されます:
Stack (most recent call last):
これは、例外フレームを表示する場合に使用される Traceback (most recent call last): を模倣します。
3番目のキーワード引数は extra で、当該ログイベント用に作られる LogRecoed の __dict__ にユーザー定義属性を加えるのに使われる辞書を渡すために用いられます。これらの属性は好きなように使えます。たとえば、ログメッセージの一部にすることもできます。以下の例を見てください:
FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'
logging.basicConfig(format=FORMAT)
d = {'clientip': '192.168.0.1', 'user': 'fbloggs'}
logging.warning('Protocol problem: %s', 'connection reset', extra=d)
これは以下のような出力を行います:
2006-02-08 22:20:02,165 192.168.0.1 fbloggs  Protocol problem: connection reset
extra で渡される辞書のキーはロギングシステムで使われているものと衝突しないようにしなければなりません。 (どのキーがロギングシステムで使われているかについての詳細は Formatter のドキュメントを参照してください。)
これらの属性をログメッセージに使うことにしたなら、少し注意が必要です。上の例では、 'clientip' と 'user' が LogRecord の属性辞書に含まれていることを期待した書式文字列で Formatter がセットアップされています。もしこれらが欠けていると、書式化例外が発生してしまうためメッセージはログに残りません。したがってこの場合、常にこれらのキーを含む extra 辞書を渡す必要があります。
このようなことは煩わしいかもしれませんが、この機能は限定された場面で使われるように意図しているものなのです。たとえば同じコードがいくつものコンテキストで実行されるマルチスレッドのサーバで、興味のある条件が現れるのがそのコンテキストに依存している (上の例で言えば、リモートのクライアント IP アドレスや認証されたユーザ名など)、というような場合です。そういった場面では、それ用の Formatter が特定の Handler と共に使われるというのはよくあることです。
バージョン 3.2 で変更: stack_info パラメータが追加されました。
logging.info(msg, *args, **kwargs)
レベル INFO のメッセージをルートロガーで記録します。引数は debug() と同じように解釈されます。
logging.warning(msg, *args, **kwargs)
レベル WARNING のメッセージをルートロガーで記録します。引数は debug() と同じように解釈されます。
注釈 warning と機能的に等価な古い関数 warn があります。warn は廃止予定なので使わないでください - 代わりに warning を使ってください。
logging.error(msg, *args, **kwargs)
レベル ERROR のメッセージをルートロガーで記録します。引数は debug() と同じように解釈されます。
logging.critical(msg, *args, **kwargs)
レベル CRITICAL のメッセージをルートロガーで記録します。引数は debug() と同じように解釈されます。
logging.exception(msg, *args, **kwargs)
レベル ERROR のメッセージをルートロガーで記録します。引数は debug() と同じように解釈されます。例外情報がログメッセージに追加されます。このメソッドは例外ハンドラからのみ呼び出されます。
logging.log(level, msg, *args, **kwargs)
レベル level のメッセージをルートロガーで記録します。その他の引数は debug() と同じように解釈されます。
注釈 上述の便利なルートロガーに処理を委譲するモジュールレベル関数は basicConfig() を呼び出して、少なくとも 1 つのハンドラが利用できることを保証します。これにより Python の 2.7.1 以前や 3.2 以前のバージョンでは、スレッドが開始される 前に 少なくともひとつのハンドラがルートロガーに加えられるのでない限り、スレッド内で使うべき ではありません 。以前のバージョンの Python では、 basicConfig() のスレッドセーフ性の欠陥により、(珍しい状況下とはいえ)ハンドラがルートロガーに複数回加えられることがあり、ログ内のメッセージが重複するという予期しない結果をもたらすことがあります。
logging.disable(level=CRITICAL)
バージョン 3.7 で変更: The level parameter was defaulted to level CRITICAL. See bpo-28524 for more information about this change.
logging.addLevelName(level, levelName)
注釈 独自のレベルを定義したい場合、 カスタムレベル のセクションを参照してください。
logging.getLevelName(level)
注釈 Levels are internally integers (as they need to be compared in the logging logic). This function is used to convert between an integer level and the level name displayed in the formatted log output by means of the %(levelname)s format specifier (see LogRecord 属性), and vice versa.
バージョン 3.4 で変更: Python 3.4以前のバージョンでは、この関数にはテキストのレベルも渡すことが出来、これは対応する数字レベルに読み替えられていました。このドキュメントされていなかった振る舞いは誤りであると判断され、Python 3.4 で一度削除されました。ただし後方互換性のために、これは 3.4.2 で元に戻されました。
logging.makeLogRecord(attrdict)
属性が attrdict で定義された、新しい LogRecord インスタンスを生成して返します。この関数は、 pickle された LogRecord 属性の辞書をソケットを介して送信し、受信端で LogRecord インスタンスとして再構成する場合に便利です。
logging.basicConfig(**kwargs)
デフォルトの Formatter を持つ StreamHandler を生成してルートロガーに追加し、ロギングシステムの基本的な環境設定を行います。関数 debug(), info(), warning(), error(), critical() は、ルートロガーにハンドラが定義されていない場合に自動的に basicConfig() を呼び出します。
注釈 この関数は、他のスレッドが開始される前にメインスレッドから呼び出されるべきです。Python の 2.7.1 や 3.2 以前のバージョンでは、この関数が複数のスレッドから呼ばれると(珍しい状況下とはいえ)ハンドラがルートロガーに複数回加えられることがあり、ログ内のメッセージが重複するという予期しない結果をもたらすことがあります。
以下のキーワード引数がサポートされます。
フォーマット
説明
filename
StreamHandler ではなく指定された名前で FileHandler が作られます。
filemode
filename が指定された場合、この モード でファイルが開かれます。 デフォルトは 'a' です。
format
datefmt
指定された日時の書式で time.strftime() が受け付けるものを使います。
style
format が指定された場合、書式文字列にこのスタイルを仕様します。 '%', '{', '$' のうち1つで、それぞれ printf-style, str.format(), string.Template に対応します。 デフォルトは '%' です。
level
ルートロガーのレベルを指定された レベル に設定します。
stream
指定されたストリームを StreamHandler の初期化に使います。 この引数は filename と同時には使えないことに注意してください。 両方が指定されたときには ValueError が送出されます。
handlers
もし指定されれば、 これは root ロガーに追加される既に作られたハンドラのイテラブルになります。まだフォーマッタがセットされていないすべてのハンドラは、この関数で作られたデフォルトフォーマッタが割り当てられることになります。この引数は filename や stream と互換性がないことに注意してください。両方が存在する場合 ValueError が上げられます。
force
encoding
errors
バージョン 3.2 で変更: style 引数が追加されました。
バージョン 3.3 で変更: 互換性のない引数が指定された状況 (例えば handlers が stream や filename と一緒に指定されたり、stream が filename と一緒に指定された場合) を捕捉するために、追加のチェックが加えられました。
バージョン 3.8 で変更: The force argument was added.
バージョン 3.9 で変更: The encoding and errors arguments were added.
logging.shutdown()
ロギングシステムに対して、バッファのフラッシュを行い、すべてのハンドラを閉じることで順次シャットダウンを行うように告知します。この関数はアプリケーションの終了時に呼ばれるべきであり、また呼び出し以降はそれ以上ロギングシステムを使ってはなりません。
logging.setLoggerClass(klass)
ロギングシステムに対して、ロガーをインスタンス化する際にクラス klass を使うように指示します。 指定するクラスは引数として名前だけをとるようなメソッド __init__() を定義していなければならず、 __init__() では Logger.__init__() を呼び出さなければなりません。 この関数が呼び出されるのはたいてい、独自の振る舞いをするロガーを使う必要のあるアプリケーションでロガーがインスタンス化される前です。 呼び出された後は、いつでもそのサブクラスを使ってロガーのインスタンス化をしてはいけません: 引き続き logging.getLogger() API を使用してロガーを取得してください。
logging.setLogRecordFactory(factory)
LogRecord を生成するのに使われる callable をセットします。
パラメータ
factory -- ログレコードを生成するファクトリとして振舞う callable。
バージョン 3.2 で追加: この関数は、ログイベントを表現する LogRecord の構築方法に関して開発者により多くのコントロールを与えるため、 getLogRecordFactory() とともに提供されました。
ファクトリは以下のようなシグネチャを持っています:
factory(name, level, fn, lno, msg, args, exc_info, func=None, sinfo=None, **kwargs)
name
ロガーの名前。
level
ログレベル (数値)。
fn
ログ呼び出しが行われたファイルのフルパス名。
lno
ログ呼び出しが行われたファイルの行数。
msg
ログメッセージ。
args
ログメッセージに対する引数。
exc_info
例外タプルまたは None。
func
ログ呼び出しを起動した関数またはメソッドの名前。
sinfo
traceback.print_stack() で提供されるような、呼び出し階層を示すスタックトレースバック。
kwargs
追加のキーワード引数。
モジュールレベル属性
logging.lastResort
「最後の手段のハンドラ」が、この属性で利用可能です。これは StreamHandler が sys.stderr に WARNING レベルで書き出しているのがそうですし、ロギングの設定がなにか不在のロギングイベントを扱う場合に使われます。最終的な結果は、メッセージを単に sys.stderr に出力することです。これはかつて「logger XYZ についてのハンドラが見つかりません」と言っていたエラーメッセージを置き換えています。もしも何らかの理由でその昔の振る舞いが必要な場合は、 lastResort に None をセットすれば良いです。
バージョン 3.2 で追加.
warnings モジュールとの統合
captureWarnings() 関数を使って、 logging を warnings モジュールと統合できます。
logging.captureWarnings(capture)
この関数は、logging による警告の補足を、有効にまたは無効にします。
capture が True なら、 warnings モジュールに発せられた警告は、ロギングシステムにリダイレクトされるようになります。具体的には、警告が warnings.formatwarning() でフォーマット化され、結果の文字列が 'py.warnings' という名のロガーに、 WARNING の重大度でロギングされるようになります。
capture が False なら、警告のロギングシステムに対するリダイレクトは止められ、警告は元の (すなわち、captureWarnings(True) が呼び出される前に有効だった) 送信先にリダイレクトされるようになります。
参考
logging.config モジュール
logging モジュールの環境設定 API です。
logging.handlers モジュール
logging モジュールに含まれる、便利なハンドラです。
PEP 282 - ログシステム
この機能を Python 標準ライブラリに含めることを述べた提案です。
Original Python logging package
これは、 logging パッケージのオリジナルのソースです。このサイトから利用できるバージョンのパッケージは、 logging パッケージを標準ライブラリに含まない、 Python 1.5.2, 2.1.x および 2.2.x で使うのに適しています。
logging.config --- ロギングの環境設定
ソースコード: Lib/logging/config.py
Important
このページには、リファレンス情報だけが含まれています。チュートリアルは、以下のページを参照してください
基本チュートリアル
上級チュートリアル
ロギングクックブック
この節は、logging モジュールを設定するための API を解説します。
環境設定のための関数
以下の関数は logging モジュールの環境設定をします。これらの関数は、 logging.config にあります。これらの関数の使用はオプションです --- logging モジュールはこれらの関数を使うか、 (logging 自体で定義されている) 主要な API を呼び出し、 logging か logging.handlers で宣言されているハンドラを定義することで設定できます。
logging.config.dictConfig(config)
辞書からロギング環境設定を取得します。この辞書の内容は、以下の 環境設定辞書スキーマ で記述されています。
環境設定中にエラーに遭遇すると、この関数は適宜メッセージを記述しつつ ValueError, TypeError, AttributeError または ImportError を送出します。例外を送出する条件を (不完全かもしれませんが) 以下に列挙します:
文字列でなかったり、実際のロギングレベルと関係ない文字列であったりする level。
ブール値でない propagate の値。
対応する行き先を持たない id。
インクリメンタルな呼び出しの中で見つかった存在しないハンドラ id。
無効なロガー名。
内部や外部のオブジェクトに関わる不可能性。
解析は DictConfigurator クラスによって行われます。このクラスのコンストラクタは環境設定に使われる辞書に渡され、このクラスは configure() メソッドを持ちます。 logging.config モジュールは、呼び出し可能属性 dictConfigClass を持ち、これはまず DictConfigurator に設定されます。 dictConfigClass の値は適切な独自の実装で置き換えられます。
dictConfig() は dictConfigClass を、指定された辞書を渡して呼び出し、それから返されたオブジェクトの configure() メソッドを呼び出して、環境設定を作用させます:
def dictConfig(config):
    dictConfigClass(config).configure()
例えば、 DictConfigurator のサブクラスは、自身の __init__() で DictConfigurator.__init__() を呼び出し、それから続く configure() の呼び出しに使えるカスタムの接頭辞を設定できます。 dictConfigClass は、この新しいサブクラスに束縛され、そして dictConfig() はちょうどデフォルトの、カスタマイズされていない状態のように呼び出せます。
バージョン 3.2 で追加.
logging.config.fileConfig(fname, defaults=None, disable_existing_loggers=True)
ログ記録の環境設定を configparser 形式ファイルから読み出します。そのファイルの形式は 環境設定ファイルの書式 で記述されているとおりにしなければなりません。この関数はアプリケーションから何度も呼び出すことができ、これによって、 (設定を選択し、選択された設定を読み出す機構をデベロッパが提供していれば) 複数の準備済みの設定からエンドユーザが選択するようにできます。
パラメータ
fname -- ファイル名、あるいはファイルのようなオブジェクト、または RawConfigParser 派生のインスタンス。 RawConfigParser 派生のインスタンスが与えられれば、それはそのまま使われます。そうでない場合 Configparser がインスタンス化され、設定はそれを使って fname が指すオブジェクトから読み込まれます。それが readline() メソッドを持っていればそれはファイルのようなオブジェクトと仮定され、 read_file() で読み込まれます; そうでない場合、それはファイル名と仮定されて、 read() に渡されます。
defaults -- ConfigParser に渡されるデフォルト値をこの引数で指定することができます。
disable_existing_loggers -- If specified as False, loggers which exist when this call is made are left enabled. The default is True because this enables old behaviour in a backward-compatible way. This behaviour is to disable any existing non-root loggers unless they or their ancestors are explicitly named in the logging configuration.
バージョン 3.4 で変更: fname として RawConfigParser のサブクラスのインスタンスが渡せ得るようになっています。これによってこのようなことが容易になります:
ロギングの設定が、アプリケーション全体の設定における単なる一部であるような設定ファイルの使用。
ファイルから設定を読み込み、 fileConfig に通す前に(例えばコマンドラインパラメータやランタイム環境の他のなにかで)アプリケーションによって修正するようなこと。
logging.config.listen(port=DEFAULT_LOGGING_CONFIG_PORT, verify=None)
指定されたポートでソケットサーバを起動し、新しい設定を待ち受けます。ポートが指定されなかった場合は、モジュールのデフォルトの DEFAULT_LOGGING_CONFIG_PORT が使用されます。ロギング設定は dictConfig() あるいは fileConfig() で処理できるファイルとして送信されます。 Thread インスタンスを返し、このインスタンスの start() を呼び出してサーバを起動し、適切なところで join() を呼び出すことができます。サーバを停止するには、 stopListening() を呼び出します。
verify 引数を指定する場合は、これはソケットを通して受け取ったバイト文字列が妥当であるか、処理すべきであるかどうかを検査する callable である必要があります。ソケットを通じて、暗号化または署名あるいはその両方を受け取ることがあります。そのような場合に、 verify callable が署名の正当性検査または暗号化の復号あるいはその両方を実施することが出来ます。 verify callable は単一引数で呼び出されます - ソケットを通じて受け取ったバイト文字列です - そして処理すべきバイト文字列、または捨て去られるべきであることを示すための None を返す必要があります。返却されるバイト文字列は(たとえば正当性検査だけが行われて)渡されたものと同じかもしれませんし、あるいは(おそらく暗号化の復号が行われて)まったく異なるものかもしれません。
ソケットに設定を送るには、まず設定ファイルを読み、それを struct.pack('>L', n) を使って長さ 4 バイトのバイナリにパックしたものを前に付けたバイト列としてソケットに送ります。
注釈 設定の部分が eval() を通して渡されるので、この関数の使用はユーザに対してセキュリティリスクを公開してしまうかもしれません。この関数は単に localhost 上のソケットに接続してリモートマシンからは接続を受け付けませんが、 listen() を呼んだプロセスのアカウントで信頼されていないコードが実行されるシナリオが存在します。特に、 listen() を呼んだプロセスがユーザがお互いを信頼することができないマルチユーザのマシン上で実行される場合、悪意のあるユーザは、犠牲者のユーザのプロセスで本質的に任意のコードを実行するように細工することができます。単に犠牲者の listen() ソケットに接続して、犠牲者のプロセスで実行したいコードを実行するような設定を送るだけです。これは、特にデフォルトポートが使用されている場合に行うのがより簡単ですが、異なるポートが使用されていたとしてもそれほど難しくありません)。これが起こるリスクを避けるには、 listen() に verify 引数を使用して、認識されていない設定が適用されないようにしてください。
バージョン 3.4 で変更: verify 引数が追加されました。
注釈 If you want to send configurations to the listener which don't disable existing loggers, you will need to use a JSON format for the configuration, which will use dictConfig() for configuration. This method allows you to specify disable_existing_loggers as False in the configuration you send.
logging.config.stopListening()
listen() を呼び出して作成された、待ち受け中のサーバを停止します。通常 listen() の戻り値に対して join() が呼ばれる前に呼び出します。
環境設定辞書スキーマ
ロギング設定を記述するには、生成するさまざまなオブジェクトと、それらのつながりを列挙しなければなりません。例えば、 'console' という名前のハンドラを生成し、'startup' という名前のロガーがメッセージを 'console' ハンドラに送るというようなことを記述します。これらのオブジェクトは、 logging モジュールによって提供されるものに限らず、独自のフォーマッタやハンドラクラスを書くことも出来ます。このクラスへのパラメータは、 sys.stderr のような外部オブジェクトを必要とすることもあります。これらのオブジェクトとつながりを記述する構文は、以下の オブジェクトの接続 で定義されています。
辞書スキーマの詳細
dictConfig() に渡される辞書は、以下のキーを含んでいなければなりません:
version - スキーマのバージョンを表す整数値に設定されます。現在有効な値は 1 だけですが、このキーがあることで、このスキーマは後方互換性を保ちながら発展できます。
その他すべてのキーは省略可能ですが、与えられたなら以下に記述するように解釈されます。以下のすべての場合において、 '環境設定辞書' と記載されている所では、その辞書に特殊な '()' キーがあるかを調べることで、カスタムのインスタント化が必要であるか判断されます。その場合は、以下の ユーザ定義オブジェクト で記述されている機構がインスタンス生成に使われます。そうでなければ、インスタンス化するべきものを決定するのにコンテキストが使われます。
formatters - 対応する値は辞書で、そのそれぞれのキーがフォーマッタ id になり、それぞれの値が対応する Formatter インスタンスをどのように環境設定するかを記述する辞書になります。
環境設定辞書から、 (デフォルトが None の) キー format と datefmt を検索し、それらが Formatter インスタンスを構成するのに使われます。
バージョン 3.8 で変更: a validate key (with default of True) can be added into the formatters section of the configuring dict, this is to validate the format.
filters - 対応する値は辞書で、そのそれぞれのキーがフィルタ id になり、それぞれの値が対応する Filter インスタンスをどのように環境設定するかを記述する辞書になります。
環境設定辞書は、(デフォルトが空文字列の) キー name を検索され、それらが logging.Filter インスタンスを構成するのに使われます。
handlers - 対応する値は辞書で、そのそれぞれのキーがハンドラ id になり、それぞれの値が対応する Handler インスタンスをどのように環境設定するかを記述する辞書になります。
環境設定辞書は、以下のキーを検索されます:
class (必須)。これはハンドラクラスの完全に修飾された名前です。
level (任意)。ハンドラのレベルです。
formatter (任意)。このハンドラへのフォーマッタの id です。
filters (任意)。このハンドラへのフィルタの id のリストです。
その他の すべての キーは、ハンドラのコンストラクタにキーワード引数として渡されます。例えば、以下のコード片が与えられたとすると:
handlers:
  console:
    class : logging.StreamHandler
    formatter: brief
    level   : INFO
    filters: [allow_foo]
    stream  : ext://sys.stdout
  file:
    class : logging.handlers.RotatingFileHandler
    formatter: precise
    filename: logconfig.log
    maxBytes: 1024
    backupCount: 3
id が console であるハンドラが、 sys.stdout を根底のストリームにして、 logging.StreamHandler としてインスタンス化されます。id が file であるハンドラが、 filename='logconfig.log', maxBytes=1024, backupCount=3 をキーワード引数にして、 logging.handlers.RotatingFileHandler としてインスタンス化されます。
loggers - 対応する値は辞書で、そのそれぞれのキーがロガー名になり、それぞれの値が対応する Logger インスタンスをどのように環境設定するかを記述する辞書になります。
環境設定辞書は、以下のキーを検索されます:
level (任意)。ロガーのレベルです。
propagate (任意)。ロガーの伝播の設定です。
filters (任意)。このロガーへのフィルタの id のリストです。
handlers (任意)。このロガーへのハンドラの id のリストです。
指定されたロガーは、指定されたレベル、伝播、ハンドラに従って環境設定されます。
root - これは、ルートロガーへの設定になります。この環境設定の進行は、propagate 設定が適用されないことを除き、他のロガーと同じです。
incremental - この環境設定が既存の環境設定に対する増分として解釈されるかどうかです。この値のデフォルトは False で、指定された環境設定は、既存の fileConfig() API によって使われているのと同じ意味上で、既存の環境設定を置き換えます。
指定された値が True なら、環境設定は 増分設定 の節で記述されているように進行します。
disable_existing_loggers - whether any existing non-root loggers are to be disabled. This setting mirrors the parameter of the same name in fileConfig(). If absent, this parameter defaults to True. This value is ignored if incremental is True.
増分設定
増分設定に完全な柔軟性を提供するのは難しいです。例えば、フィルタやフォーマッタのようなオブジェクトは匿名なので、一旦環境設定がなされると、設定を拡張するときにそのような匿名オブジェクトを参照することができません。
さらに、一旦環境設定がなされた後、実行時にロガー、ハンドラ、フィルタ、フォーマッタのオブジェクトグラフを任意に変えなければならない例もありません。ロガーとハンドラの冗長性は、レベル (または、ロガーの場合には、伝播フラグ) を設定することによってのみ制御できます。安全な方法でオブジェクトグラフを任意に変えることは、マルチスレッド環境で問題となります。不可能ではないですが、その効用は実装に加えられる複雑さに見合いません。
従って、環境設定辞書の incremental キーが与えられ、これが True であるとき、システムは formatters と filters の項目を完全に無視し、handlers の項目の level 設定と、loggers と root の項目の level と propagate 設定のみを処理します。
環境設定辞書の値を使うことで、設定は pickle 化された辞書としてネットワークを通してソケットリスナに送ることができます。これにより、長時間起動するアプリケーションのロギングの冗長性を、アプリケーションを止めて再起動する必要なしに、いつでも変更することができます。
オブジェクトの接続
このスキーマは、ロギングオブジェクトの一揃い - ロガー、ハンドラ、フォーマッタ、フィルタ - について記述します。これらは、オブジェクトグラフ上でお互い接続されます。従って、このスキーマは、オブジェクト間の接続を表現しなければなりません。例えば、環境設定で、特定のロガーが特定のハンドラに取り付けられたとします。この議論では、ロガーとハンドラが、これら 2 つの接続のそれぞれ送信元と送信先であるといえます。もちろん、この設定オブジェクト中では、これはハンドラへの参照を保持しているロガーで表されます。設定辞書中で、これは次のようになされます。まず、送信先オブジェクトを曖昧さなく指定する id を与えます。そして、その id を送信元オブジェクトの環境設定で使い、送信元とその id をもつ送信先が接続されていることを示します。
ですから、例えば、以下の YAML のコード片を例にとると:
formatters:
  brief:
    # configuration for formatter with id 'brief' goes here
  precise:
    # configuration for formatter with id 'precise' goes here
handlers:
  h1: #This is an id
   # configuration of handler with id 'h1' goes here
   formatter: brief
  h2: #This is another id
   # configuration of handler with id 'h2' goes here
   formatter: precise
loggers:
  foo.bar.baz:
    # other configuration for logger 'foo.bar.baz'
    handlers: [h1, h2]
(注釈: YAML がここで使われているのは、辞書の等価な Python 形式よりもこちらのほうが少し読みやすいからです。)
ロガーの id は、プログラム上でロガーへの参照を得るために使われるロガー名で、たとえば foo.bar.baz です。フォーマッタとフィルタの id は、(上の brief, precise のような) 任意の文字列値にできます。これらは一時的なもので、環境設定辞書の処理にのみ意味があり、オブジェクト間の接続を決定するのに使われます。また、これらは設定の呼び出しが完了したとき、どこにも残りません。
上記のコード片は、foo.bar.baz というの名ロガーに、ハンドラ id h1 と h2 で表される 2 つのハンドラを接続することを示します。h1 のフォーマッタは id brief で記述されるもので、h2 のフォーマッタは id precise で記述されるものです。
ユーザ定義オブジェクト
このスキーマは、ハンドラ、フィルタ、フォーマッタのための、ユーザ定義オブジェクトをサポートします。(ロガーは、異なるインスタンスに対して異なる型を持つ必要はないので、この環境設定スキーマは、ユーザ定義ロガークラスをサポートしていません。)
設定されるオブジェクトは、それらの設定を詳述する辞書によって記述されます。場所によっては、あるオブジェクトがどのようにインスタンス化されるかというコンテキストを、ロギングシステムが推測できます。しかし、ユーザ定義オブジェクトがインスタンス化されるとき、システムはどのようにこれを行うかを知りません。ユーザ定義オブジェクトのインスタンス化を完全に柔軟なものにするため、ユーザは 'ファクトリ' - 設定辞書を引数として呼ばれ、インスタンス化されたオブジェクトを返す呼び出し可能オブジェクト - を提供する必要があります。これは特殊キー '()' で利用できる、ファクトリへの絶対インポートパスによって合図されます。ここに具体的な例を挙げます:
formatters:
  brief:
    format: '%(message)s'
  default:
    format: '%(asctime)s %(levelname)-8s %(name)-15s %(message)s'
    datefmt: '%Y-%m-%d %H:%M:%S'
  custom:
      (): my.package.customFormatterFactory
      bar: baz
      spam: 99.9
      answer: 42
上記の YAML コード片は 3 つのフォーマッタを定義します。 1 つ目は、id が brief で、指定されたフォーマット文字列をもつ、標準 logging.Formatter インスタンスです。 2 つ目は、id が default で、長いフォーマットを持ち、時間フォーマットも定義していて、結果はその 2 つのフォーマット文字列で初期化された logging.Formatter になります。Python ソース形式で見ると、 brief と default フォーマッタは、それぞれ設定の部分辞書:
{
  'format' : '%(message)s'
}
および:
{
  'format' : '%(asctime)s %(levelname)-8s %(name)-15s %(message)s',
  'datefmt' : '%Y-%m-%d %H:%M:%S'
}
を持ち、これらの辞書が特殊キー '()' を持たないので、インスタンス化はコンテキストから推測され、結果として標準の logging.Formatter インスタンスが生成されます。id が custom である、3 つ目のフォーマッタの設定をする部分辞書は:
{
  '()' : 'my.package.customFormatterFactory',
  'bar' : 'baz',
  'spam' : 99.9,
  'answer' : 42
}
で、ユーザ定義のインスタンス化が望まれることを示す特殊キー '()' を含みます。この場合、指定された呼び出し可能ファクトリオブジェクトが使われます。これが実際の呼び出し可能オブジェクトであれば、それが直接使われます - そうではなく、(この例でのように) 文字列を指定したなら、実際の呼び出し可能オブジェクトは、通常のインポート機構を使って検索されます。その呼び出し可能オブジェクトは、環境設定の部分辞書の、残りの 要素をキーワード引数として呼ばれます。上記の例では、id が custom のフォーマッタは、以下の呼び出しによって返されるものとみなされます:
my.package.customFormatterFactory(bar='baz', spam=99.9, answer=42)
キー '()' が特殊キーとして使われるのは、キーワードパラメータ名として不正で、呼び出しに使われるキーワード引数と衝突し得ないからです。'()' はまた、対応する値が呼び出し可能オブジェクトであると覚えやすくします。
外部オブジェクトへのアクセス
環境設定が、例えば sys.stderr のような、設定の外部のオブジェクトへの参照を必要とすることがあります。設定辞書が Python コードで構成されていれば話は簡単ですが、これがテキストファイル (JSON, YAML 等) を通して提供されていると問題となります。テキストファイルでは、sys.stderr をリテラル文字列 'sys.stderr' と区別する標準の方法がありません。この区別を容易にするため、環境設定システムは、文字列中の特定の特殊接頭辞を見つけ、それらを特殊に扱います。例えば、リテラル文字列 'ext://sys.stderr' が設定中の値として与えられたら、この ext:// は剥ぎ取られ、この値の残りが普通のインポート機構で処理されます。
このような接頭辞の処理は、プロトコルの処理と同じようになされます。どちらの機構も、正規表現 ^(?P<prefix>[a-z]+)://(?P<suffix>.*)$ にマッチする接頭辞を検索し、それによって prefix が認識されたなら、接頭辞に応じたやり方で suffix が処理され、その処理の結果によって文字列値が置き換えられます。接頭辞が認識されなければ、その文字列値はそのまま残されます。
内部オブジェクトへのアクセス
外部オブジェクトと同様、環境設定内部のオブジェクトへのアクセスを必要とすることもあります。これは、その各オブジェクトを司る環境設定システムによって暗黙に行われます。例えば、ロガーやハンドラの level に対する文字列値 'DEBUG' は、自動的に値 logging.DEBUG に変換されますし、handlers, filters および formatter の項目は、オブジェクト id を取って、適切な送信先オブジェクトを決定します。
However, a more generic mechanism is needed for user-defined objects which are not known to the logging module. For example, consider logging.handlers.MemoryHandler, which takes a target argument which is another handler to delegate to. Since the system already knows about this class, then in the configuration, the given target just needs to be the object id of the relevant target handler, and the system will resolve to the handler from the id. If, however, a user defines a my.package.MyHandler which has an alternate handler, the configuration system would not know that the alternate referred to a handler. To cater for this, a generic resolution system allows the user to specify:
handlers:
  file:
    # configuration of file handler goes here
  custom:
    (): my.package.MyHandler
    alternate: cfg://handlers.file
The literal string 'cfg://handlers.file' will be resolved in an analogous way to strings with the ext:// prefix, but looking in the configuration itself rather than the import namespace. The mechanism allows access by dot or by index, in a similar way to that provided by str.format. Thus, given the following snippet:
handlers:
  email:
    class: logging.handlers.SMTPHandler
    mailhost: localhost
    fromaddr: my_app@domain.tld
    toaddrs:
      - support_team@domain.tld
      - dev_team@domain.tld
    subject: Houston, we have a problem.
文字列 'cfg://handlers' は、キー handlers をもつ辞書であると分析され、文字列 'cfg://handlers.email' は、handlers 辞書内の、email キーをもつ辞書であると分析されます。文字列 'cfg://handlers.email.toaddrs[1] は、'dev_team@domain.tld' と分析され、'cfg://handlers.email.toaddrs[0]' は値 'support_team@domain.tld' と分析されます。subject の値には、'cfg://handlers.email.subject' または等価な 'cfg://handlers.email[subject]' でアクセスできます。後者が必要なのは、キーがスペースや非アルファベット文字を含むときのみです。インデックス値が十進数字のみで構成されているなら、まず対応する整数値を使ってアクセスが試みられ、必要なら文字列値で代替します。
文字列 cfg://handlers.myhandler.mykey.123 が与えられると、これは config_dict['handlers']['myhandler']['mykey']['123'] と分析されます。文字列が cfg://handlers.myhandler.mykey[123] と指定されたら、システムは config_dict['handlers']['myhandler']['mykey'][123] から値を引き出そうとし、失敗したら config_dict['handlers']['myhandler']['mykey']['123'] で代替します。
インポート解決とカスタムインポーター
インポート解決は、デフォルトではインポートを行うために __import__() 組み込み関数を使用します。これを独自のインポートメカニズムに置き換えたいと思うかもしれません: もしそうなら、 DictConfigurator あるいはその上位クラスである BaseConfigurator クラスの importer 属性を置換することができます。ただし、この関数はクラスからディスクリプタ経由でアクセスされる点に注意する必要があります。インポートを行うために Python callable を使用していて、それをインスタンスレベルではなくクラスレベルで定義したければ、 staticmethod() でそれをラップする必要があります。例えば:
from importlib import import_module
from logging.config import BaseConfigurator
BaseConfigurator.importer = staticmethod(import_module)
configurator インスタンス に対してインポート callable をセットする場合は、 staticmethod() でラップする必要はありません。
環境設定ファイルの書式
fileConfig() が解釈できる環境設定ファイルの形式は、 configparser の機能に基づいています。ファイルには、 [loggers], [handlers], [formatters] といったセクションが入っていなければならず、各セクションではファイル中で定義されている各タイプのエンティティを名前で指定しています。こうしたエンティティの各々について、そのエンティティをどう設定するかを示した個別のセクションがあります。すなわち、 log01 という名前の [loggers] セクションにあるロガーに対しては、対応する詳細設定がセクション [logger_log01] に収められています。同様に、 hand01 という名前の [handlers] セクションにあるハンドラは [handler_hand01] と呼ばれるセクションに設定をもつことになり、 [formatters] セクションにある form01 は [formatter_form01] というセクションで設定が指定されています。ルートロガーの設定は [logger_root] と呼ばれるセクションで指定されていなければなりません。
注釈 fileConfig() API は dictConfig() API よりも古く、ロギングのある種の側面についてカバーする機能に欠けています。たとえば fileConfig() では数値レベルを超えたメッセージを単に拾うフィルタリングを行う Filter オブジェクトを構成出来ません。 Filter のインスタンスをロギングの設定において持つ必要があるならば、 dictConfig() を使う必要があるでしょう。設定の機能における将来の拡張は dictConfig() に対して行われることに注意してください。ですから、そうするのが便利であるときに新しい API に乗り換えるのは良い考えです。
ファイルにおけるこれらのセクションの例を以下に示します。
[loggers]
keys=root,log02,log03,log04,log05,log06,log07
[handlers]
keys=hand01,hand02,hand03,hand04,hand05,hand06,hand07,hand08,hand09
[formatters]
keys=form01,form02,form03,form04,form05,form06,form07,form08,form09
ルートロガーでは、レベルとハンドラのリストを指定しなければなりません。ルートロガーのセクションの例を以下に示します。
[logger_root]
level=NOTSET
handlers=hand01
level エントリは DEBUG, INFO, WARNING, ERROR, CRITICAL のうちの一つか、 NOTSET になります。ルートロガーの場合にのみ、 NOTSET はすべてのメッセージがログ記録されることを意味します。レベル値は logging パッケージの名前空間のコンテキストにおいて eval() されます。
handlers エントリはコンマで区切られたハンドラ名からなるリストで、[handlers] セクションになくてはなりません。また、これらの各ハンドラの名前に対応するセクションが設定ファイルに存在しなければなりません。
ルートロガー以外のロガーでは、いくつか追加の情報が必要になります。これは以下の例のように表されます。
[logger_parser]
level=DEBUG
handlers=hand01
propagate=1
qualname=compiler.parser
level および handlers エントリはルートロガーのエントリと同様に解釈されますが、非ルートロガーのレベルが NOTSET に指定された場合、ロギングシステムはロガー階層のより上位のロガーにロガーの実効レベルを問い合わせるところが違います。propagate エントリは、メッセージをロガー階層におけるこのロガーの上位のハンドラに伝播させることを示す 1 に設定されるか、メッセージを階層の上位に伝播 しない ことを示す 0 に設定されます。qualname エントリはロガーのチャネル名を階層的に表したもの、すなわちアプリケーションがこのロガーを取得する際に使う名前になります。
ハンドラの環境設定を指定しているセクションは以下の例のようになります。
[handler_hand01]
class=StreamHandler
level=NOTSET
formatter=form01
args=(sys.stdout,)
class エントリはハンドラのクラス (logging パッケージの名前空間において eval() で決定されます) を示します。 level はロガーの場合と同じように解釈され、 NOTSET は "すべてを記録する (log everything)" と解釈されます。
formatter エントリはこのハンドラのフォーマッタに対するキー名を表します。空文字列の場合、デフォルトのフォーマッタ (logging._defaultFormatter) が使われます。名前が指定されている場合、その名前は [formatters] セクションになくてはならず、対応するセクションが設定ファイル中になければなりません。
[handler_hand02]
class=FileHandler
level=DEBUG
formatter=form02
args=('python.log', 'w')
[handler_hand03]
class=handlers.SocketHandler
level=INFO
formatter=form03
args=('localhost', handlers.DEFAULT_TCP_LOGGING_PORT)
[handler_hand04]
class=handlers.DatagramHandler
level=WARN
formatter=form04
args=('localhost', handlers.DEFAULT_UDP_LOGGING_PORT)
[handler_hand05]
class=handlers.SysLogHandler
level=ERROR
formatter=form05
args=(('localhost', handlers.SYSLOG_UDP_PORT), handlers.SysLogHandler.LOG_USER)
[handler_hand06]
class=handlers.NTEventLogHandler
level=CRITICAL
formatter=form06
args=('Python Application', '', 'Application')
[handler_hand07]
class=handlers.SMTPHandler
level=WARN
formatter=form07
args=('localhost', 'from@abc', ['user1@abc', 'user2@xyz'], 'Logger Subject')
kwargs={'timeout': 10.0}
[handler_hand08]
class=handlers.MemoryHandler
level=NOTSET
formatter=form08
target=
args=(10, ERROR)
[handler_hand09]
class=handlers.HTTPHandler
level=NOTSET
formatter=form09
args=('localhost:9022', '/log', 'GET')
kwargs={'secure': True}
フォーマッタの環境設定を指定しているセクションは以下のような形式です。
[formatter_form01]
format=F1 %(asctime)s %(levelname)s %(message)s
datefmt=
class=logging.Formatter
class エントリはオプションです。これはフォーマッタクラスの名前を (モジュール名とクラス名をドットでつないだもので) 指し示すものです。このオプションは Formatter の子クラスをインスタンス化するのに便利です。 Formatter の子クラスが、展開もしくは要約された形式の例外トレースバックを表示することができます。
注釈 eval() を使用していることで、上述のようにソケット経由で設定を送受信するために listen() を使用していることに起因する潜在的なセキュリティリスクがあります。そのリスクは、相互に信頼できない多数のユーザが同じマシン上でコードを実行する場合に制限されています; 詳細は listen() ドキュメンテーションを参照してください。
参考
logging モジュール
logging モジュールの API リファレンス。
logging.handlers モジュール
logging モジュールに含まれる、便利なハンドラです。
logging.handlers --- ロギングハンドラ
ソースコード: Lib/logging/handlers.py
Important
このページには、リファレンス情報だけが含まれています。チュートリアルは、以下のページを参照してください
基本チュートリアル
上級チュートリアル
ロギングクックブック
このパッケージでは、以下の便利なハンドラが提供されています。なお、これらのハンドラのうち、3 つ (StreamHandler, FileHandler および NullHandler) は、実際には logging モジュール自身で定義されていますが、他のハンドラと一緒にここでドキュメント化します。
StreamHandler
logging コアパッケージに含まれる StreamHandler クラスは、ログ出力を sys.stdout, sys.stderr あるいは何らかのファイル風 (file-like) オブジェクト (あるいは、より正確に言えば write() および flush() メソッドをサポートする何らかのオブジェクト) といったストリームに送信します。
class logging.StreamHandler(stream=None)
StreamHandler クラスの新たなインスタンスを返します。 stream が指定された場合、インスタンスはログ出力先として指定されたストリームを使います; そうでない場合、 sys.stderr が使われます。
emit(record)
flush()
ストリームの flush() メソッドを呼び出してバッファをフラッシュします。 close() メソッドは Handler から継承しているため何も出力を行わないので、 flush() 呼び出しを明示的に行う必要があるかもしれません。
setStream(stream)
このインスタンスの stream と指定された値が異なる場合、指定された値に設定します。 新しい stream を設定する前に、古い stream はフラッシュされます。
パラメータ
stream -- ハンドラがこれから使う stream 。
戻り値
stream が変更された場合は古い stream 、そうでない場合は None 。
バージョン 3.7 で追加.
terminator
バージョン 3.2 で追加.
FileHandler
logging コアパッケージに含まれる FileHandler クラスは、ログ出力をディスク上のファイルに送信します。このクラスは出力機能を StreamHandler から継承しています。
class logging.FileHandler(filename, mode='a', encoding=None, delay=False, errors=None)
バージョン 3.6 で変更: 文字列値に加え、 Path オブジェクトも filename 引数が受け取るようになりました。
バージョン 3.9 で変更: The errors parameter was added.
close()
ファイルを閉じます。
emit(record)
record をファイルに出力します。
NullHandler
バージョン 3.1 で追加.
logging コアパッケージに含まれる NullHandler クラスは、いかなる書式化も出力も行いません。これは本質的には、ライブラリ開発者に使われる 'no-op' ハンドラです。
class logging.NullHandler
NullHandler クラスの新しいインスタンスを返します。
emit(record)
このメソッドは何もしません。
handle(record)
このメソッドは何もしません。
createLock()
アクセスが特殊化される必要がある I/O が下にないので、このメソッドはロックに対して None を返します。
NullHandler の使い方の詳しい情報は、 ライブラリのためのロギングの設定 を参照してください。
WatchedFileHandler
logging.handlers モジュールに含まれる WatchedFileHandler クラスは、ログ記録先のファイルを監視する FileHandler の一種です。ファイルが変更された場合、ファイルを閉じてからファイル名を使って開き直します。
ファイルはログファイルをローテーションさせる newsyslog や logrotate のようなプログラムを使うことで変更されることがあります。このハンドラは、 Unix/Linux で使われることを意図していますが、ファイルが最後にログを出力してから変わったかどうかを監視します。 (ファイルはデバイスや inode が変わることで変わったと判断します。) ファイルが変わったら古いファイルのストリームは閉じて、現在のファイルを新しいストリームを取得するために開きます。
このハンドラを Windows で使うことは適切ではありません。というのも Windows では開いているログファイルを移動したり削除したりできないからです - logging はファイルを排他的ロックを掛けて開きます - そのためこうしたハンドラは必要ないのです。さらに、 Windows では ST_INO がサポートされていません; stat() はこの値として常に 0 を返します。
class logging.handlers.WatchedFileHandler(filename, mode='a', encoding=None, delay=False, errors=None)
バージョン 3.6 で変更: 文字列値に加え、 Path オブジェクトも filename 引数が受け取るようになりました。
バージョン 3.9 で変更: The errors parameter was added.
reopenIfNeeded()
ファイルが変更されていないかチェックします。 もし変更されていれば、手始めにレコードをファイルに出力し、既存のストリームはフラッシュして閉じられ、ファイルが再度開かれます。
バージョン 3.6 で追加.
emit(record)
レコードをファイルに出力しますが、最初に reopenIfNeeded() を呼び出して、変更があった場合はファイルを再度開きます。
BaseRotatingHandler
logging.handlers モジュールに存在する BaseRotatingHandler クラスは、ローテートを行うファイルハンドラ RotatingFileHandler と TimedRotatingFileHandler のベースクラスです。このクラスをインスタンス化する必要はありませんが、オーバーライドすることになるかもしれない属性とメソッドを持っています。
class logging.handlers.BaseRotatingHandler(filename, mode, encoding=None, delay=False, errors=None)
パラメータは FileHandler と同じです。属性は次の通りです:
namer
この属性に callable がセットされた場合、 rotation_filename() メソッドはこの callable に委譲されます。 callable に渡されるパラメータは rotation_filename() に渡されたものです。
注釈 namer 関数はロールオーバー中にかなりの回数呼ばれます。そのため、できるだけ単純で、速くあるべきです。さらに、それは与えられた入力に対しては常に同じ出力を返すべきです。そうでなければ、ロールオーバーの振る舞いは期待通りに動かないかもしれません。
バージョン 3.3 で追加.
rotator
この属性に callable がセットされた場合、 rotate() メソッドはこの callable に委譲されます。 callable に渡されるパラメータは rotate() に渡されたものです。
バージョン 3.3 で追加.
rotation_filename(default_name)
ローテートを行う際にログファイルのファイル名を変更します。
このメソッドは、ファイル名をカスタマイズするために提供されます。
デフォルト実装は、ハンドラの 'namer' 属性が callable だった場合、その callable を呼んでデフォルト名を渡します。属性が callable でない場合 (デフォルトは None です)、名前は変更せずに返されます。
パラメータ
default_name -- ログファイルのデフォルトのファイル名。
バージョン 3.3 で追加.
rotate(source, dest)
ローテートが行われる時、現在のログをローテートします。
デフォルト実装は、 ハンドラの 'rotator' 属性が callable だった場合、その callable を呼んで source と dest 引数を渡します。属性が callable でない場合 (デフォルトは None です)、単に source が destination に改名されます。
パラメータ
source -- ソースファイル名。これは通常ベースファイル名 、例えば 'test.log' となります。
dest -- 変更先ファイル名。これは通常ソースファイルをローテートしたもの (例えば 'test.log.1') です。
バージョン 3.3 で追加.
これらの属性が存在する理由は、サブクラス化を省略できるようにするためです。 RotatingFileHandler と TimedRotatingFileHandler のインスタンスに対して同じ callable が使えます。もし namer や rotator callable が例外を上げれば、 emit() 呼び出しで発生した他の例外と同じ方法で、つまりハンドラの handleError() メソッドによって扱われます。
ローテート処理に大幅な変更を加える必要があれば、メソッドをオーバーライドすることができます。
例えば、 rotator と namer を使ってログローテートをカスタマイズする を参照してください。
RotatingFileHandler
logging.handlers モジュールに含まれる RotatingFileHandler クラスは、ディスク上のログファイルに対するローテーション処理をサポートします。
class logging.handlers.RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False, errors=None)
maxBytes および backupCount 値を指定することで、あらかじめ決められたサイズでファイルをロールオーバ (rollover) させることができます。 指定サイズを超えそうになると、ファイルは閉じられ、暗黙のうちに新たなファイルが開かれます。 ロールオーバは現在のログファイルの長さが maxBytes に近くなると常に起きますが、 maxBytes または backupCount がゼロならロールオーバは起きなくなってしまうので、一般的には backupCount を少なくとも 1 に設定し maxBytes を非ゼロにするのが良いでしょう。 backupCount が非ゼロのとき、システムは古いログファイルをファイル名に ".1", ".2" といった拡張子を追加して保存します。 例えば、 backupCount が 5 で、基本のファイル名が app.log なら、 app.log, app.log.1, app.log.2 ... と続き、 app.log.5 までを得ることになります。 ログの書き込み対象になるファイルは常に app.log です。このファイルが満杯になると、ファイルは閉じられ、 app.log.1 に名前が変更されます。 app.log.1, app.log.2 などが存在する場合、それらのファイルはそれぞれ app.log.2, app.log.3 といった具合に名前が変更されます。
バージョン 3.6 で変更: 文字列値に加え、 Path オブジェクトも filename 引数が受け取るようになりました。
バージョン 3.9 で変更: The errors parameter was added.
doRollover()
上述のような方法でロールオーバを行います。
emit(record)
上述のようなロールオーバを行いながら、レコードをファイルに出力します。
TimedRotatingFileHandler
logging.handlers モジュールに含まれる TimedRotatingFileHandler クラスは、特定の時間間隔でのログローテーションをサポートしています。
class logging.handlers.TimedRotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None, errors=None)
TimedRotatingFileHandler クラスの新たなインスタンスを返します。 filename に指定したファイルを開き、ログ出力先のストリームとして使います。ログファイルのローテーション時には、ファイル名に拡張子 (suffix) をつけます。ログファイルのローテーションは when および interval の積に基づいて行います。
when は interval の単位を指定するために使います。使える値は下表の通りです。大小文字の区別は行いません。
値
interval の単位
atTime の使用有無/使用方法
'S'
秒
無視
'M'
分
無視
'H'
時間
無視
'D'
日
無視
'W0'-'W6'
曜日 (0=月曜)
初期のロールオーバー時刻の算出に使用
'midnight'
atTime が指定されなかった場合は深夜に、そうでない場合は atTime の時刻にロールオーバーされます
初期のロールオーバー時刻の算出に使用
曜日ベースのローテーションを使う場合は、月曜として 'W0' を、火曜として 'W1' を、…、日曜として 'W6' を指定します。このケースの場合は、 interval は使われません。
古いログファイルの保存時、ロギングシステムによりファイル名に拡張子が付けられます。 ロールオーバ間隔によって、strftime の %Y-%m-%d_%H-%M-%S 形式またはその前方の一部を使って、日付と時間に基づいた拡張子が付けられます。
最初に次のロールオーバー時間を計算するとき (ハンドラが生成されるとき)、次のローテーションがいつ起こるかを計算するために、既存のログファイルの最終変更時刻または現在の時間が使用されます。
utc 引数が true の場合時刻は UTC になり、それ以外では現地時間が使われます。
backupCount がゼロでない場合、保存されるファイル数は高々 backupCount 個で、それ以上のファイルがロールオーバされる時に作られるならば、一番古いものが削除されます。削除のロジックは interval で決まるファイルを削除するので、 interval を変えると古いファイルが残ったままになることもあります。
delay が true なら、ファイルを開くのは emit() の最初の呼び出しまで延期されます。
注釈 Calculation of the initial rollover time is done when the handler is initialised. Calculation of subsequent rollover times is done only when rollover occurs, and rollover occurs only when emitting output. If this is not kept in mind, it might lead to some confusion. For example, if an interval of "every minute" is set, that does not mean you will always see log files with times (in the filename) separated by a minute; if, during application execution, logging output is generated more frequently than once a minute, then you can expect to see log files with times separated by a minute. If, on the other hand, logging messages are only output once every five minutes (say), then there will be gaps in the file times corresponding to the minutes where no output (and hence no rollover) occurred.
バージョン 3.4 で変更: atTime パラメータが追加されました。
バージョン 3.6 で変更: 文字列値に加え、 Path オブジェクトも filename 引数が受け取るようになりました。
バージョン 3.9 で変更: The errors parameter was added.
doRollover()
上述のような方法でロールオーバを行います。
emit(record)
上で説明した方法でロールオーバを行いながら、レコードをファイルに出力します。
SocketHandler
logging.handlers モジュールに含まれる SocketHandler クラスは、ログ出力をネットワークソケットに送信します。基底クラスでは TCP ソケットを用います。
class logging.handlers.SocketHandler(host, port)
アドレスが host および port で与えられた遠隔のマシンと通信するようにした SocketHandler クラスのインスタンスを生成して返します。
バージョン 3.4 で変更: port に None を指定すると、Unix ドメインソケットが host 値を用いて作られます - そうでない場合は TCP ソケットが作られます。
close()
ソケットを閉じます。
emit()
レコードの属性辞書を pickle して、バイナリ形式でソケットに書き込みます。ソケット操作でエラーが生じた場合、暗黙のうちにパケットは捨てられます。事前に接続が失われていた場合、接続を再度確立します。受信端でレコードを unpickle して LogRecord にするには、 makeLogRecord() 関数を使ってください。
handleError()
emit() の処理中に発生したエラーを処理します。よくある原因は接続の消失です。次のイベント発生時に再試行できるようにソケットを閉じます。
makeSocket()
サブクラスで必要なソケット形式を詳細に定義できるようにするためのファクトリメソッドです。デフォルトの実装では、 TCP ソケット (socket.SOCK_STREAM) を生成します。
makePickle(record)
レコードの属性辞書をバイナリ形式に pickle したものの先頭に長さ情報を付け、ソケットを介して送信できるようにして返します。 この操作の詳細は次のコードと同等です:
data = pickle.dumps(record_attr_dict, 1)
datalen = struct.pack('>L', len(data))
return datalen + data
pickle が完全に安全というわけではないことに注意してください。セキュリティに関して心配なら、より安全なメカニズムを実装するためにこのメソッドをオーバーライドすると良いでしょう。例えば、 HMAC を使って pickle に署名して、受け取る側ではそれを検証することができます。あるいはまた、受け取る側でグローバルなオブジェクトの unpickle を無効にすることができます。
send(packet)
pickle したバイト文字列 packet をソケットに送信します。 送信するバイト文字列のフォーマットは、 makePickle() のドキュメントで解説されています。
この関数はネットワークがビジーの時に発生する部分的送信に対応しています。
createSocket()
ソケットの生成を試みます。失敗時には、指数的な減速アルゴリズムを使います。最初の失敗時には、ハンドラは送ろうとしていたメッセージを落とします。続くメッセージが同じインスタンスで扱われたとき、幾らかの時間が経過するまで接続を試みません。デフォルトのパラメタは、最初の遅延時間が 1 秒で、その遅延時間の後でそれでも接続が確保できないなら、遅延時間は 2 倍づつになり、最大で 30 秒になります。
この働きは、以下のハンドラ属性で制御されます:
retryStart (最初の遅延時間、デフォルトは 1.0 秒)。
retryFactor (乗数、デフォルトは 2.0)。
retryMax (最大遅延時間、デフォルトは 30.0 秒)。
つまり、ハンドラが使われた 後に リモートリスナが起動した場合、メッセージが失われてしまうことがあります (ハンドラは、遅延時間が経過するまで接続を試みようとさえせず、その遅延時間中に通知なくメッセージを捨てるので)。
DatagramHandler
logging.handlers モジュールに含まれる DatagramHandler クラスは、 SocketHandler を継承しており、 UDP ソケットを介したログ記録メッセージの送信をサポートしています。
class logging.handlers.DatagramHandler(host, port)
アドレスが host および port で与えられた遠隔のマシンと通信するようにした DatagramHandler クラスのインスタンスを生成して返します。
バージョン 3.4 で変更: port に None を指定すると、Unix ドメインソケットが host 値を用いて作られます - そうでない場合は UDP ソケットが作られます。
emit()
レコードの属性辞書を pickle して、バイナリ形式でソケットに書き込みます。ソケット操作でエラーが生じた場合、暗黙のうちにパケットは捨てられます。事前に接続が失われていた場合、接続を再度確立します。受信端でレコードを unpickle して LogRecord にするには、 makeLogRecord() 関数を使ってください。
makeSocket()
ここで SocketHandler のファクトリメソッドをオーバライドして、 UDP ソケット (socket.SOCK_DGRAM) を生成しています。
send(s)
pickle したバイト文字列をソケットに送信します。 送信するバイト文字列のフォーマットは、 SocketHandler.makePickle() のドキュメントで解説されています。
SysLogHandler
logging.handlers モジュールに含まれる SysLogHandler クラスは、ログ記録メッセージを遠隔またはローカルの Unix syslog に送信する機能をサポートしています。
class logging.handlers.SysLogHandler(address=('localhost', SYSLOG_UDP_PORT), facility=LOG_USER, socktype=socket.SOCK_DGRAM)
遠隔の Unix マシンと通信するための、 SysLogHandler クラスの新たなインスタンスを返します。マシンのアドレスは (host, port) のタプル形式をとる address で与えられます。 address が指定されない場合、 ('localhost', 514) が使われます。アドレスは UDP ソケットを使って開かれます。 (host, port) のタプル形式の代わりに文字列で "/dev/log" のように与えることもできます。この場合、 Unix ドメインソケットが syslog にメッセージを送るのに使われます。 facility が指定されない場合、 LOG_USER が使われます。開かれるソケットの型は、 socktype 引数に依り、デフォルトは socket.SOCK_DGRAM で、UDP ソケットを開きます。 (rsyslog のような新しい syslog デーモンと使うために) TCP ソケットを開くには、 socket.SOCK_STREAM の値を指定してください。
使用中のサーバが UDP ポート 514 を待機していない場合、 SysLogHandler が正常に動作していないように見える場合があります。その場合、ドメインソケットに使うべきアドレスを調べてください。そのアドレスはシステムによって異なります。例えば、Linux システムでは通常 '/dev/log' ですが、 OS X では '/var/run/syslog' です。プラットフォームを確認し、適切なアドレスを使う必要があります (アプリケーションを複数のプラットフォーム上で動作させる必要がある場合、実行時に確認する必要があるかもしれません)。Windows では、多くの場合、UDP オプションを使用する必要があります。
バージョン 3.2 で変更: socktype が追加されました。
close()
遠隔ホストへのソケットを閉じます。
emit(record)
レコードは書式化された後、 syslog サーバに送信されます。例外情報が存在しても、サーバには 送信されません 。
バージョン 3.2.1 で変更: (参照: bpo-12168) 初期のバージョンでは、 syslog デーモンに送られるメッセージは常に NUL バイトで終端していました。初期のバージョンの syslog デーモンが NUL 終端されたメッセージを期待していたからです - たとえ、それが適切な仕様 (RFC 5424) にはなかったとしても。 syslog デーモンの新しいバージョンは NUL バイトを期待せず、代わりにもしそれがある場合は削除します。さらに、より最近のデーモン (RFC 5424 により忠実なバージョン) は、メッセージの一部として NUL バイトを通します。
このような異なるデーモンの振る舞いすべてに対して syslog メッセージの取り扱いをより容易にするため、 NUL バイトの追加はクラスレベル属性 append_nul を使用して設定できるようになりました。これはデフォルトで True (既存の振る舞いを保持) ですが、 SysLogHandler インスタンスが NUL 終端文字を追加 しない ように False にセットすることができます。
バージョン 3.3 で変更: (参照: bpo-12419) 以前のバージョンでは、メッセージソースを識別するための "ident" あるいは "tag" プリフィックス機能はありませんでした。これは、今ではクラスレベル属性を使用して指定することができるようになりました。デフォルトでは既存の振る舞いを保持するために "" ですが、特定の SysLogHandler インスタンスが扱うすべてのメッセージに識別子を前置するようにそれをオーバーライドすることができます。識別子はバイトではなくテキストでなければならず、正確にそのままメッセージに前置されることに注意してください。
encodePriority(facility, priority)
ファシリティおよび優先度を整数に符号化します。値は文字列でも整数でも渡すことができます。文字列が渡された場合、内部の対応付け辞書が使われ、整数に変換されます。
シンボリックな LOG_ 値は SysLogHandler で定義されています。これは sys/syslog.h ヘッダーファイルで定義された値を反映しています。
優先度
名前 (文字列)
シンボル値
alert
LOG_ALERT
crit or critical
LOG_CRIT
debug
LOG_DEBUG
emerg or panic
LOG_EMERG
err or error
LOG_ERR
info
LOG_INFO
notice
LOG_NOTICE
warn or warning
LOG_WARNING
ファシリティ
名前 (文字列)
シンボル値
auth
LOG_AUTH
authpriv
LOG_AUTHPRIV
cron
LOG_CRON
daemon
LOG_DAEMON
ftp
LOG_FTP
kern
LOG_KERN
lpr
LOG_LPR
mail
LOG_MAIL
news
LOG_NEWS
syslog
LOG_SYSLOG
user
LOG_USER
uucp
LOG_UUCP
local0
LOG_LOCAL0
local1
LOG_LOCAL1
local2
LOG_LOCAL2
local3
LOG_LOCAL3
local4
LOG_LOCAL4
local5
LOG_LOCAL5
local6
LOG_LOCAL6
local7
LOG_LOCAL7
mapPriority(levelname)
ログレベル名を syslog 優先度名に対応付けます。カスタムレベルを使用している場合や、デフォルトアルゴリズムがニーズに適していない場合には、このメソッドをオーバーライドする必要があるかもしれません。デフォルトアルゴリズムは、 DEBUG, INFO, WARNING, ERROR, CRITICAL を等価な syslog 名に、他のすべてのレベル名を "warning" に対応付けます。
NTEventLogHandler
logging.handlers モジュールに含まれる NTEventLogHandler クラスは、ログ記録メッセージをローカルな Windows NT, Windows 2000, または Windows XP のイベントログに送信する機能をサポートします。この機能を使えるようにするには、 Mark Hammond による Python 用 Win32 拡張パッケージをインストールする必要があります。
class logging.handlers.NTEventLogHandler(appname, dllname=None, logtype='Application')
NTEventLogHandler クラスの新たなインスタンスを返します。 appname はイベントログに表示する際のアプリケーション名を定義するために使われます。この名前を使って適切なレジストリエントリが生成されます。 dllname はログに保存するメッセージ定義の入った .dll または .exe ファイルへの完全修飾パス名を与えなければなりません (指定されない場合、 'win32service.pyd' が使われます - このライブラリは Win32 拡張とともにインストールされ、いくつかのプレースホルダとなるメッセージ定義を含んでいます)。これらのプレースホルダを利用すると、メッセージの発信源全体がログに記録されるため、イベントログは巨大になるので注意してください。 logtype は 'Application', 'System', 'Security' のいずれかで、デフォルトは 'Application' です。
close()
現時点では、イベントログエントリの発信源としてのアプリケーション名をレジストリから除去することはできます。しかしこれを行うと、イベントログビューアで意図した通りにログが見えなくなるでしょう - これはイベントログが .dll 名を取得するためにレジストリにアクセスできなければならないからです。現在のバージョンではこの操作を行いません。
emit(record)
メッセージ ID、イベントカテゴリ、イベント型を決定し、メッセージを NT イベントログに記録します。
getEventCategory(record)
レコードに対するイベントカテゴリを返します。自作のカテゴリを指定したい場合、このメソッドをオーバライドしてください。このクラスのバージョンのメソッドは 0 を返します。
getEventType(record)
レコードのイベント型を返します。自作の型を指定したい場合、このメソッドをオーバライドしてください。このクラスのバージョンのメソッドは、ハンドラの typemap 属性を使って対応付けを行います。この属性は __init__() で初期化され、 DEBUG, INFO, WARNING, ERROR, CRITICAL が入っています。自作のレベルを使っているのなら、このメソッドをオーバライドするか、ハンドラの typemap 属性に適切な辞書を配置する必要があるでしょう。
getMessageID(record)
レコードのメッセージ ID を返します。自作のメッセージを使っているのなら、ロガーに渡される msg を書式化文字列ではなく ID にします。その上で、辞書参照を行ってメッセージ ID を得ます。このクラスのバージョンでは 1 を返します。この値は win32service.pyd における基本メッセージ ID です。
SMTPHandler
logging.handlers モジュールに含まれる SMTPHandler クラスは、 SMTP を介したログ記録メッセージの送信機能をサポートします。
class logging.handlers.SMTPHandler(mailhost, fromaddr, toaddrs, subject, credentials=None, secure=None, timeout=1.0)
新たな SMTPHandler クラスのインスタンスを返します。インスタンスは email の from および to アドレス行、および subject 行とともに初期化されます。 toaddrs は文字列からなるリストでなければなりません。非標準の SMTP ポートを指定するには、 mailhost 引数に (host, port) のタプル形式を指定します。文字列を使った場合、標準の SMTP ポートが使われます。もし SMTP サーバが認証を必要とするならば、 (username, password) のタプル形式を credentials 引数に指定することができます。
セキュアプロトコル (TLS) の使用を指定するには secure 引数にタプルを渡してください。これは認証情報が渡された場合のみ使用されます。タプルは、空のタプルか、キーファイルの名前を持つ1要素のタプルか、またはキーファイルと証明書ファイルの名前を持つ2要素のタプルのいずれかでなければなりません。 (このタプルは smtplib.SMTP.starttls() メソッドに渡されます。)
SMTP サーバとのコミュニケーションのために、 timeout 引数を使用してタイムアウトを指定することができます。
バージョン 3.3 で追加: timeout 引数が追加されました。
emit(record)
レコードを書式化し、指定されたアドレスに送信します。
getSubject(record)
レコードに応じたサブジェクト行を指定したいなら、このメソッドをオーバライドしてください。
MemoryHandler
logging.handlers モジュールに含まれる MemoryHandler は、ログ記録するレコードをメモリ上にバッファリングし、定期的にその内容をターゲット (target) となるハンドラにフラッシュする機能をサポートしています。フラッシュ処理はバッファが一杯になるか、ある深刻度かそれ以上のレベルを持つイベントが観測された際に行われます。
MemoryHandler はより一般的な抽象クラス、 BufferingHandler のサブクラスです。この抽象クラスでは、ログ記録するレコードをメモリ上にバッファリングします。各レコードがバッファに追加される毎に、 shouldFlush() を呼び出してバッファをフラッシュすべきかどうか調べます。フラッシュする必要がある場合、 flush() がフラッシュ処理を行うものと想定されます。
class logging.handlers.BufferingHandler(capacity)
emit(record)
flush()
このメソッドをオーバライドして、自作のフラッシュ動作を実装することができます。このクラスのバージョンのメソッドでは、単にバッファの内容を削除して空にします。
shouldFlush(record)
class logging.handlers.MemoryHandler(capacity, flushLevel=ERROR, target=None, flushOnClose=True)
バージョン 3.6 で変更: flushOnClose パラメータが追加されました。
close()
flush() を呼び出し、ターゲットを None に設定してバッファを消去します。
flush()
MemoryHandler の場合、フラッシュ処理は単に、バッファされたレコードをターゲットがあれば送信することを意味します。これと異なる動作を行いたい場合、オーバライドしてください。
setTarget(target)
ターゲットハンドラをこのハンドラに設定します。
shouldFlush(record)
バッファが一杯になっているか、 flushLevel またはそれ以上のレコードでないかを調べます。
HTTPHandler
logging.handlers モジュールに含まれる HTTPHandler クラスは、ログ記録メッセージを GET または POST セマンティクスを使って Web サーバに送信する機能をサポートしています。
class logging.handlers.HTTPHandler(host, url, method='GET', secure=False, credentials=None, context=None)
HTTPHandler クラスの新たなインスタンスを返します。特別なポートを使う必要がある場合、host は host:port の形式で使うことができます。 method が指定されない場合、 GET が使われます。 secure が真の場合、HTTPS 接続が使われます。 HTTPS 接続で使用する SSL 設定のために context 引数を ssl.SSLContext のインスタンスに設定することができます。 credentials を指定する場合、BASIC 認証の際の HTTP 'Authorization' ヘッダに使われるユーザIDとパスワードからなる 2要素タプルを渡してください。 credentials を指定する場合、ユーザIDとパスワードが通信中に平文として剥き出しにならないよう、secure=True も指定すべきです。
バージョン 3.5 で変更: context パラメータが追加されました。
mapLogRecord(record)
URL エンコードされて Web サーバに送信することになる、 record に基づく辞書を供給します。デフォルトの実装では単に record.__dict__ を返します。例えば LogRecord のサブセットのみを Web サーバに送信する場合や、 サーバーに送信する内容を特別にカスタマイズする必要がある場合には、このメソッドをオーバライドできます。
emit(record)
レコードを URL エンコードされた辞書形式で Web サーバに送信します。レコードを送信のために辞書に変換するために mapLogRecord() が呼び出されます。
注釈 Web server に送信するためのレコードを準備することは一般的な書式化操作とは同じではありませんので、 setFormatter() を使って Formatter を指定することは、 HTTPHandler には効果はありません。 format() を呼び出す代わりに、このハンドラは mapLogRecord() を呼び出し、その後その返却辞書を Web server に送信するのに適した様式にエンコードするために urllib.parse.urlencode() を呼び出します。
QueueHandler
バージョン 3.2 で追加.
logging.handlers モジュールに含まれる QueueHandler クラスは、 queue モジュールや multiprocessing のモジュールで実装されるようなキューにログメッセージを送信する機能をサポートしています。
QueueListener クラスとともに QueueHandler を使うと、ロギングを行うスレッドから分離されたスレッド上でハンドラを動かすことができます。これは、クライアントに対してサービスするスレッドができるだけ速く応答する必要がある一方、別のスレッド上で (SMTPHandler によって電子メールを送信するような) 潜在的に遅い操作が行われるような、ウェブアプリケーションおよびその他のサービスアプリケーションにおいて重要です。
class logging.handlers.QueueHandler(queue)
emit(record)
prepare(record)
キューに追加するためレコードを準備します。このメソッドが返したオブジェクトがキューに追加されます。
メッセージと、引数と、もしあれば例外の情報を合成するためにレコードを書式化して、レコードから pickle 不可能なアイテムを in-place で取り除くベース実装です。
レコードを dict や JSON 文字列に変換したい場合や、オリジナルのレコードを変更せずに修正済のコピーを送りたい場合は、このメソッドをオーバーライドすると良いでしょう。
enqueue(record)
キューにレコードを put_nowait() を使ってエンキューします; ブロッキングやタイムアウト、あるいはなにか特別なキューの実装を使いたければ、これをオーバライドしてみてください。
QueueListener
バージョン 3.2 で追加.
logging.handlers モジュールに含まれる QueueListener クラスは、 queue モジュールや multiprocessing のモジュールで実装されるようなキューからログメッセージを受信する機能をサポートしています。メッセージは内部スレッドのキューから受信され、同じスレッド上の複数のハンドラに渡されて処理されます。 QueueListener それ自体はハンドラではありませんが、 QueueHandler と連携して動作するのでここで文書化されています。
QueueHandler クラスとともに QueueListener を使うと、ロギングを行うスレッドから分離されたスレッド上でハンドラを動かすことができます。これは、クライアントに対してサービスするスレッドができるだけ速く応答する必要がある一方、別のスレッド上で (SMTPHandler によって電子メールを送信するような) 潜在的に遅い操作が行われるような、ウェブアプリケーションおよびその他のサービスアプリケーションにおいて重要です。
class logging.handlers.QueueListener(queue, *handlers, respect_handler_level=False)
バージョン 3.5 で変更: The respect_handler_level argument was added.
dequeue(block)
キューからレコードを取り除き、それを返します。ブロッキングすることがあります。
ベース実装は get() を使用します。タイムアウトを有効にしたい場合や、カスタムのキュー実装を使いたい場合は、このメソッドをオーバーライドすると良いでしょう。
prepare(record)
レコードを扱うための準備をします。
この実装は渡されたレコードをそのまま返します。その値をハンドラに渡す前に何らかのカスタムな整列化 (marshalling) あるいはレコードに対する操作を行う必要があれば、このメソッドをオーバーライドすると良いでしょう。
handle(record)
レコードを処理します。
これは、ハンドラをループしてそれらに処理すべきレコードを渡します。ハンドラに渡される実際のオブジェクトは、 prepare() から返されたものです。
start()
リスナーを開始します。
これは、 LogRecord を処理するキューを監視するために、バックグラウンドスレッドを開始します。
stop()
リスナーを停止します。
スレッドに終了するように依頼し、終了するまで待ちます。アプリケーションの終了前にこのメソッドを呼ばないと、いくつかのレコードがキューに残り、処理されなくなるかもしれないことに注意してください。
enqueue_sentinel()
リスナーに停止するように指示するためキューに番兵を書き込みます。この実装は put_nowait() を使用します。タイムアウトを有効にしたい場合や、カスタムのキュー実装を使いたい場合は、このメソッドをオーバーライドすると良いでしょう。
バージョン 3.3 で追加.
参考
logging モジュール
logging モジュールの API リファレンス。
logging.config モジュール
logging モジュールの環境設定 API です。
getpass --- 可搬性のあるパスワード入力機構
ソースコード: Lib/getpass.py
getpass モジュールは二つの関数を提供します:
getpass.getpass(prompt='Password: ', stream=None)
エコーなしでユーザーにパスワードを入力させるプロンプト。ユーザーは prompt の文字列をプロンプトに使え、デフォルトは 'Password: ' です。 Unixではプロンプトはファイルに似たオブジェクト stream へ、必要なら置き換えられたエラーハンドラを使って出力されます。 stream のデフォルトは、制御端末(/dev/tty)か、それが利用できない場合は sys.stderr です (この引数は Windowsでは無視されます)。
もしエコーなしで入力が利用できない場合は、 getpass() は stream に警告メッセージを出力し、 sys.stdin から読み込み、 GetPassWarning 警告を発生させます。
注釈 IDLE から getpass を呼び出した場合、入力はIDLEのウィンドウではなく、IDLE を起動したターミナルから行われます。
exception getpass.GetPassWarning
UserWarning のサブクラスで、入力がエコーされてしまった場合に発生します。
getpass.getuser()
ユーザーの "ログイン名"を返します。
この関数は環境変数 LOGNAME USER LNAME USERNAME の順序でチェックして、最初の空ではない文字列が設定された値を返します。もし、なにも設定されていない場合は pwd モジュールが提供するシステム上のパスワードデータベースから返します。それ以外は、例外が上がります。
一般的に、この関数は os.getlogin() よりも優先されるべきです。
curses --- 文字セル表示を扱うための端末操作
curses モジュールは、可搬性のある高度な端末操作のデファクトスタンダードである、curses ライブラリへのインタフェースを提供します。
curses が最も広く用いられているのは Unix 環境ですが、Windows、DOS で利用できるバージョンもあり、おそらく他のシステムで利用できるバージョンもあります。この拡張モジュールは Linux および BSD 系の Unixで動作するオープンソースの curses ライブラリである ncurses の API に合致するように設計されています。
注釈 Whenever the documentation mentions a character it can be specified as an integer, a one-character Unicode string or a one-byte byte string.
注釈 version 5.4 から、ncurses ライブラリは nl_langinfo 関数を利用して非 ASCII データをどう解釈するかを決定するようになりました。これは、アプリケーションは locale.setlocale() 関数を呼び出して、Unicode 文字列をシステムの利用可能なエンコーディングのどれかでエンコードする必要があることを意味します。この例では、システムのデフォルトエンコーディングを利用しています:
import locale
locale.setlocale(locale.LC_ALL, '')
code = locale.getpreferredencoding()
この後、str.encode() を呼び出すときに code を利用します。
参考
curses.ascii モジュール
ロケール設定に関わらず ASCII 文字を扱うためのユーティリティ。
curses.panel モジュール
curses ウィンドウにデプス機能を追加するパネルスタック拡張。
curses.textpad モジュール
Emacs ライクなキーバインディングをサポートする編集可能な curses 用テキストウィジェット。
Python で Curses プログラミング
Andrew Kuchling および Eric Raymond によって書かれた、curses を Python で使うためのチュートリアルです。
Python ソースコードの Tools/demo/ ディレクトリには、このモジュールで提供されている curses バインディングを使ったプログラム例がいくつか収められています。
関数
curses モジュールでは以下の例外を定義しています:
exception curses.error
curses ライブラリ関数がエラーを返した際に送出される例外です。
注釈 関数やメソッドにおけるオプションの引数 x および y がある場合、デフォルト値は常に現在のカーソルになります。オプションの attr がある場合、デフォルト値は A_NORMAL です。
curses では以下の関数を定義しています:
curses.baudrate()
端末の出力速度をビット/秒で返します。ソフトウェア端末エミュレータの場合、これは固定の高い値を持つことになります。この関数は歴史的な理由で入れられています; かつては、この関数は時間遅延を生成するための出力ループを書くために用いられたり、行速度に応じてインタフェースを切り替えたりするために用いられたりしていました。
curses.beep()
注意を促す短い音を鳴らします。
curses.can_change_color()
端末に表示される色をプログラマが変更できるか否かによって、True または False を返します。
curses.cbreak()
cbreak モードに入ります。cbreak モード ("rare" モードと呼ばれることもあります) では、通常の tty 行バッファリングはオフにされ、文字を一文字一文字読むことができます。ただし、raw モードとは異なり、特殊文字 (割り込み:interrupt、終了:quit、一時停止:suspend、およびフロー制御) については、tty ドライバおよび呼び出し側のプログラムに対する通常の効果をもっています。まず raw() を呼び出し、次いで cbreak() を呼び出すと、端末を cbreak モードにします。
curses.color_content(color_number)
curses.color_pair(pair_number)
curses.curs_set(visibility)
curses.def_prog_mode()
現在の端末属性を、稼動中のプログラムが curses を使う際のモードである "プログラム" モードとして保存します。(このモードの反対は、プログラムが curses を使わない "シェル" モードです。) その後 reset_prog_mode() を呼ぶとこのモードを復旧します。
curses.def_shell_mode()
現在の端末属性を、稼動中のプログラムが curses を使っていないときのモードである "シェル" モードとして保存します。(このモードの反対は、プログラムが curses 機能を利用している "プログラム" モードです。) その後 reset_shell_mode() を呼ぶとこのモードを復旧します。
curses.delay_output(ms)
出力に ms ミリ秒の一時停止を入れます。
curses.doupdate()
物理スクリーンを更新します。curses ライブラリは、現在の物理スクリーンの内容と、次の状態として要求されている仮想スクリーンをそれぞれ表す、2 つのデータ構造を保持しています。doupdate() は更新を適用し、物理スクリーンを仮想スクリーンに一致させます。
curses.echo()
echo モードに入ります。echo モードでは、各文字入力はスクリーン上に入力された通りにエコーバックされます。
curses.endwin()
ライブラリの非初期化を行い、端末を通常の状態に戻します。
curses.erasechar()
curses.filter()
curses.flash()
スクリーンを点滅します。すなわち、画面を色反転して、短時間でもとにもどします。人によっては、beep() で生成される注意音よりも、このような "目に見えるベル" を好みます。
curses.flushinp()
すべての入力バッファをフラッシュします。この関数は、ユーザによってすでに入力されているが、まだプログラムによって処理されていないすべての先行入力文字を破棄します。
curses.getmouse()
curses.getsyx()
curses.getwin(file)
以前の putwin() 呼び出しでファイルに保存されている、ウィンドウ関連データを読み出します。次に、このルーチンはそのデータを使って新たなウィンドウを生成し初期化して、その新規ウィンドウオブジェクトを返します。
curses.has_colors()
端末が色表示を行える場合には True を返します。そうでない場合には False を返します。
curses.has_ic()
端末が文字の挿入/削除機能を持つ場合に True を返します。最近の端末エミュレータはどれもこの機能を持っており、この関数は歴史的な理由のためだけに存在しています。
curses.has_il()
端末が行の挿入/削除機能を持つ場合に True を返します。最近の端末エミュレータはどれもこの機能を持っていて、この関数は歴史的な理由のためだけに存在しています。
curses.has_key(ch)
キー値 ch をとり、現在の端末タイプがその値のキーを認識できる場合に True を返します。
curses.halfdelay(tenths)
curses.init_color(color_number, r, g, b)
curses.init_pair(pair_number, fg, bg)
curses.initscr()
注釈 端末のオープン時にエラーが発生した場合、curses ライブラリによってインタープリタが終了される場合があります。
curses.is_term_resized(nlines, ncols)
resize_term() によってウィンドウ構造が変更されている場合に True を、そうでない場合は False を返します。
curses.isendwin()
endwin() がすでに呼び出されている (すなわち、curses ライブラリが非初期化されてしまっている) 場合に True を返します。
curses.keyname(k)
curses.killchar()
curses.longname()
curses.meta(flag)
curses.mouseinterval(interval)
ボタンが押されてから離されるまでの時間をマウスクリック一回として認識する最大の時間間隔をミリ秒で設定します。返り値は以前の内部設定値になります。デフォルトは 200 ミリ秒 (5 分の 1 秒) です。
curses.mousemask(mousemask)
curses.napms(ms)
ms ミリ秒間スリープします。
curses.newpad(nlines, ncols)
curses.newwin(nlines, ncols)
curses.newwin(nlines, ncols, begin_y, begin_x)
デフォルトでは、ウィンドウは指定された位置からスクリーンの右下まで広がります。
curses.nl()
newlime モードに入ります。このモードはリターンキーを入力中の改行として変換し、出力時に改行文字を復帰 (return) と改行 (line-feed) に変換します。newline モードは初期化時にはオンになっています。
curses.nocbreak()
cbreak モードを終了します。行バッファリングを行う通常の "cooked" モードに戻ります。
curses.noecho()
echo モードを終了します。入力のエコーバックはオフにされます。
curses.nonl()
newline モードを終了します。入力時のリターンキーから改行への変換、および出力時の改行から復帰/改行への低レベル変換を無効化します (ただし、addch('\n') の振る舞いは変更せず、仮想スクリーン上では常に復帰と改行に等しくなります)。変換をオフにすることで、curses は水平方向の動きを少しだけ高速化できることがあります; また、入力中のリターンキーの検出ができるようになります。
curses.noqiflush()
curses.noraw()
raw モードから離れます。行バッファリングを行う通常の "cooked" モードに戻ります。
curses.pair_content(pair_number)
curses.pair_number(attr)
attr に対する色ペアセットの番号を返します。color_pair() はこの関数の逆に相当します。
curses.putp(str)
tputs(str, 1, putchar) と等価です; 現在の端末における、指定された terminfo 機能の値を出力します。putp() の出力は常に標準出力に送られるので注意して下さい。
curses.qiflush([flag])
flag が False なら、noqiflush() を呼ぶのとと同じ効果です。flag が True か、引数が与えられていない場合、制御文字が読み出された最にキューはフラッシュされます。
curses.raw()
raw モードに入ります。raw モードでは、通常の行バッファリングと割り込み (interrupt)、終了 (quit)、一時停止 (suspend)、およびフロー制御キーはオフになります; 文字は curses 入力関数に一文字づつ渡されます。
curses.reset_prog_mode()
端末を "program" モードに復旧し、あらかじめ def_prog_mode() で保存した内容に戻します。
curses.reset_shell_mode()
端末を "shell" モードに復旧し、あらかじめ def_shell_mode() で保存した内容に戻します。
curses.resetty()
端末モードの状態を最後に savetty() を呼び出した時の状態に戻します。
curses.resize_term(nlines, ncols)
curses.resizeterm(nlines, ncols)
現在の標準ウィンドウのサイズを指定された寸法に変更し、curses ライブラリが使用する、その他のウィンドウサイズを記憶しているデータ (特に SIGWINCH ハンドラ) を調整します。
curses.savetty()
resetty() で使用される、バッファ内の端末モードの現在の状態を保存します。
curses.get_escdelay()
バージョン 3.9 で追加.
curses.set_escdelay(ms)
バージョン 3.9 で追加.
curses.get_tabsize()
バージョン 3.9 で追加.
curses.set_tabsize(size)
バージョン 3.9 で追加.
curses.setsyx(y, x)
curses.setupterm(term=None, fd=-1)
curses.start_color()
プログラマがカラーを利用したい場合で、かつ他の何らかのカラー操作ルーチンを呼び出す前に呼び出さなくてはなりません。この関数は initscr() を呼んだ直後に呼ぶようにしておくとよいでしょう。
start_color() は 8 つの基本色 (黒、赤、緑、黄、青、マゼンタ、シアン、および白) と、色数の最大値と端末がサポートする色ペアの最大数が入っている、curses モジュールにおける二つのグローバル変数、COLORS および COLOR_PAIRS を初期化します。この関数はまた、色設定を端末のスイッチが入れられたときの状態に戻します。
curses.termattrs()
端末がサポートするすべてのビデオ属性を論理和した値を返します。この情報は、curses プログラムがスクリーンの見え方を完全に制御する必要がある場合に便利です。
curses.termname()
curses.tigetflag(capname)
curses.tigetnum(capname)
curses.tigetstr(capname)
curses.tparm(str[, ...])
curses.typeahead(fd)
先読みチェックに使うためのファイル記述子 fd を指定します。fd が -1 の場合、先読みチェックは行われません。
curses ライブラリはスクリーンを更新する間、先読み文字列を定期的に検索することで "行はみ出し最適化 (line-breakout optimization)" を行います。入力が得られ、かつ入力は端末からのものである場合、現在行おうとしている更新は refresh や doupdate を再度呼び出すまで先送りにします。この関数は異なるファイル記述子で先読みチェックを行うように指定することができます。
curses.unctrl(ch)
curses.ungetch(ch)
注釈 Only one ch can be pushed before getch() is called.
curses.update_lines_cols()
LINES と COLS についての更新。マニュアルでスクリーンのサイズを変更したことを検知するために有用です。
バージョン 3.5 で追加.
curses.unget_wch(ch)
注釈 Only one ch can be pushed before get_wch() is called.
バージョン 3.3 で追加.
curses.ungetmouse(id, x, y, z, bstate)
与えられた状態データが関連付けられた KEY_MOUSE イベントを入力キューにプッシュします。
curses.use_env(flag)
この関数を使う場合、initscr() または newterm を呼ぶ前に呼び出さなくてはなりません。flag が False の場合、環境変数 LINES および COLUMNS の値 (デフォルトで使用されます) の値が設定されていたり、curses がウィンドウ内で動作して (この場合 LINES や COLUMNS が設定されていないとウィンドウのサイズを使います) いても、terminfo データベースに指定された lines および columns の値を使います。
curses.use_default_colors()
curses.wrapper(func, /, *args, **kwargs)
Window オブジェクト
上記の initscr() や newwin() が返すウィンドウは、以下のメソッドと属性を持ちます:
window.addch(ch[, attr])
window.addch(y, x, ch[, attr])
注釈 Writing outside the window, subwindow, or pad raises a curses.error. Attempting to write to the lower right corner of a window, subwindow, or pad will cause an exception to be raised after the character is printed.
window.addnstr(str, n[, attr])
window.addnstr(y, x, str, n[, attr])
window.addstr(str[, attr])
window.addstr(y, x, str[, attr])
注釈
window.attroff(attr)
現在のウィンドウに書き込まれたすべての内容に対し "バックグラウンド" に設定された属性 attr を除去します。
window.attron(attr)
現在のウィンドウに書き込まれたすべての内容に対し "バックグラウンド" に属性 attr を追加します。
window.attrset(attr)
window.bkgd(ch[, attr])
ウィンドウ上の背景プロパティを、attr を属性とする文字 ch に設定します。変更はそのウィンドウ中のすべての文字に以下のようにして適用されます:
ウィンドウ中のすべての文字の属性が新たな背景属性に変更されます。
以前の背景文字が出現すると、常に新たな背景文字に変更されます。
window.bkgdset(ch[, attr])
ウィンドウの背景を設定します。ウィンドウの背景は、文字と何らかの属性の組み合わせから成り立ちます。背景情報の属性の部分は、ウィンドウ上に描画されている空白でないすべての文字と組み合わされ (OR され) ます。空白文字には文字部分と属性部分の両方が組み合わされます。背景は文字のプロパティとなり、スクロールや行/文字の挿入/削除操作の際には文字と一緒に移動します。
window.border([ls[, rs[, ts[, bs[, tl[, tr[, bl[, br]]]]]]]])
注釈 どの引数も、0 を指定した場合デフォルトの文字が使われるようになります。キーワード引数は使うことが できません。デフォルトはテーブル内で示しています:
引数
説明
デフォルト値
ls
左側
ACS_VLINE
rs
右側
ACS_VLINE
ts
上側
ACS_HLINE
bs
下側
ACS_HLINE
tl
左上の角
ACS_ULCORNER
tr
右上の角
ACS_URCORNER
bl
左下の角
ACS_LLCORNER
br
右下の角
ACS_LRCORNER
window.box([vertch, horch])
border() と同様ですが、ls および rs は共に vertch で、ts および bs は共に horch です。この関数では、角に使われるデフォルト文字が常に使用されます。
window.chgat(attr)
window.chgat(num, attr)
window.chgat(y, x, attr)
window.chgat(y, x, num, attr)
window.clear()
erase() に似ていますが、次に refresh() が呼び出された際にすべてのウィンドウを再描画するようにします。
window.clearok(flag)
window.clrtobot()
カーソルの位置からウィンドウの端までを消去します: カーソル以降のすべての行が削除されるため、clrtoeol() と等価です。
window.clrtoeol()
カーソル位置から行末までを消去します。
window.cursyncup()
ウィンドウのすべての親ウィンドウについて、現在のカーソル位置を反映するよう更新します。
window.delch([y, x])
(y, x) にある文字を削除します。
window.deleteln()
カーソルの下にある行を削除します。後続の行はすべて 1 行上に移動します。
window.derwin(begin_y, begin_x)
window.derwin(nlines, ncols, begin_y, begin_x)
"derive window (ウィンドウを派生する)" の短縮形です。derwin() は subwin() と同じですが、begin_y および begin_x はスクリーン全体の原点ではなく、ウィンドウの原点からの相対位置です。派生したウィンドウオブジェクトが返されます。
window.echochar(ch[, attr])
文字 ch に属性 attr を付与し、即座に refresh() をウィンドウに対して呼び出します。
window.enclose(y, x)
与えられた文字セル座標をスクリーン原点から相対的なものとし、ウィンドウの中に含まれるかを調べて、True または False を返します。スクリーン上のウィンドウの一部がマウスイベントの発生場所を含むかどうかを調べる上で便利です。
window.encoding
encode メソッドの引数 (Unicode 文字列および文字) で使用されるエンコーディングです。例えば window.subwin() などでサブウィンドウを生成した時、エンコーディング属性は親ウィンドウから継承します。デフォルトでは、そのロケールのエンコーディングが使用されます (locale.getpreferredencoding() 参照)。
バージョン 3.3 で追加.
window.erase()
ウィンドウをクリアします。
window.getbegyx()
左上の角の座標をあらわすタプル (y, x) を返します。
window.getbkgd()
与えられたウィンドウの現在の背景文字と属性のペアを返します。
window.getch([y, x])
window.get_wch([y, x])
バージョン 3.3 で追加.
window.getkey([y, x])
window.getmaxyx()
ウィンドウの高さおよび幅を表すタプル (y, x) を返します。
window.getparyx()
window.getstr()
window.getstr(n)
window.getstr(y, x)
window.getstr(y, x, n)
window.getyx()
ウィンドウの左上角からの相対で表した現在のカーソル位置をタプル (y, x) で返します。
window.hline(ch, n)
window.hline(y, x, ch, n)
(y, x) から始まり、n の長さを持つ、文字 ch で作られる水平線を表示します。
window.idcok(flag)
flag が False の場合、curses は端末のハードウェアによる文字挿入/削除機能を使おうとしなくなります; flag が True ならば、文字挿入/削除は有効にされます。curses が最初に初期化された際には文字挿入/削除はデフォルトで有効になっています。
window.idlok(flag)
window.immedok(flag)
flag が True ならば、ウィンドウイメージ内における何らかの変更があるとウィンドウを更新するようになります; すなわち、refresh() を自分で呼ばなくても良くなります。とはいえ、wrefresh を繰り返し呼び出すことになるため、この操作はかなりパフォーマンスを低下させます。デフォルトでは無効になっています。
window.inch([y, x])
ウィンドウの指定の位置の文字を返します。下位 8 ビットが本来の文字で、それより上のビットは属性です。
window.insch(ch[, attr])
window.insch(y, x, ch[, attr])
(y, x) に文字 ch を属性 attr で描画し、行の x からの内容を 1 文字分右にずらします。
window.insdelln(nlines)
nlines 行を指定されたウィンドウの現在の行の上に挿入します。その下にある nlines 行は失われます。負の nlines を指定すると、カーソルのある行以降の nlines を削除し、削除された行の後ろに続く内容が上に来ます。その下にある nlines は消去されます。現在のカーソル位置はそのままです。
window.insertln()
カーソルの下に空行を 1 行入れます。それ以降の行は 1 行づつ下に移動します。
window.insnstr(str, n[, attr])
window.insnstr(y, x, str, n[, attr])
文字列をカーソルの下にある文字の前に (一行に収まるだけ) 最大 n 文字挿入します。n がゼロまたは負の値の場合、文字列全体が挿入されます。カーソルの右にあるすべての文字は右に移動し、行の左端にある文字は失われます。カーソル位置は (y, x が指定されていた場合はそこに移動しますが、その後は) 変化しません。
window.insstr(str[, attr])
window.insstr(y, x, str[, attr])
キャラクタ文字列を (行に収まるだけ) カーソルより前に挿入します。カーソルの右側にある文字はすべて右にシフトし、行の右端の文字は失われます。カーソル位置は (y, x が指定されていた場合はそこに移動しますが、その後は) 変化しません。
window.instr([n])
window.instr(y, x[, n])
window.is_linetouched(line)
指定した行が、最後に refresh() を呼んだ時から変更されている場合に True を返します; そうでない場合には False を返します。line が現在のウィンドウ上の有効な行でない場合、curses.error 例外を送出します。
window.is_wintouched()
指定したウィンドウが、最後に refresh() を呼んだ時から変更されている場合に True を返します; そうでない場合には False を返します。
window.keypad(flag)
window.leaveok(flag)
window.move(new_y, new_x)
カーソルを (new_y, new_x) に移動します。
window.mvderwin(y, x)
ウィンドウを親ウィンドウの中で移動します。ウィンドウのスクリーン相対となるパラメタ群は変化しません。このルーチンは親ウィンドウの一部をスクリーン上の同じ物理位置に表示する際に用いられます。
window.mvwin(new_y, new_x)
ウィンドウの左上角が (new_y, new_x) になるように移動します。
window.nodelay(flag)
window.notimeout(flag)
window.noutrefresh()
更新をマークはしますが待機します。この関数はウィンドウのデータ構造を表現したい内容を反映するように更新しますが、物理スクリーン上に反映させるための強制更新を行いません。更新を行うためには doupdate() を呼び出します。
window.overlay(destwin[, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol])
ウィンドウを destwin の上に重ね書き (overlay) します。ウィンドウは同じサイズである必要はなく、重なっている領域だけが複写されます。この複写は非破壊的です。これは現在の背景文字が destwin の内容を上書きしないことを意味します。
複写領域をきめ細かく制御するために、overlay() の第二形式を使うことができます。sminrow および smincol は元のウィンドウの左上の座標で、他の変数は destwin 内の矩形を表します。
window.overwrite(destwin[, sminrow, smincol, dminrow, dmincol, dmaxrow, dmaxcol])
destwin の上にウィンドウの内容を上書き (overwrite) します。ウィンドウは同じサイズである必要はなく、重なっている領域だけが複写されます。この複写は破壊的です。これは現在の背景文字が destwin の内容を上書きすることを意味します。
複写領域をきめ細かく制御するために、overwrite() の第二形式を使うことができます。sminrow および smincol は元のウィンドウの左上の座標で、他の変数は destwin 内の矩形を表します。
window.putwin(file)
ウィンドウに関連付けられているすべてのデータを与えられたファイルオブジェクトに書き込みます。この情報は後に getwin() 関数を使って取得することができます。
window.redrawln(beg, num)
beg 行から始まる num スクリーン行の表示内容が壊れており、次の refresh() 呼び出しで完全に再描画されなければならないことを通知します。
window.redrawwin()
ウィンドウ全体を更新 (touch) し、次の refresh() 呼び出しで完全に再描画されるようにします。
window.refresh([pminrow, pmincol, sminrow, smincol, smaxrow, smaxcol])
ディスプレイを即時更新し (実際のウィンドウとこれまでの描画/削除メソッドの内容とを同期し) ます。
6 つのオプション引数はウィンドウが newpad() で生成された場合にのみ指定することができます。追加の引数はパッドやスクリーンのどの部分が含まれるのかを示すために必要です。pminrow および pmincol にはパッドが表示されている矩形の左上角を指定します。sminrow, smincol, smaxrow, および smaxcol には、スクリーン上に表示される矩形の縁を指定します。パッド内に表示される矩形の右下角はスクリーン座標から計算されるので、矩形は同じサイズでなければなりません。矩形は両方とも、それぞれのウィンドウ構造内に完全に含まれていなければなりません。pminrow, pmincol, sminrow, または smincol に負の値を指定すると、ゼロを指定したものとして扱われます。
window.resize(nlines, ncols)
curses ウィンドウの記憶域を、指定値のサイズに調整するため再割当てします。サイズが現在の値より大きい場合、ウィンドウのデータは現在の背景設定 (bkgdset() で設定) で埋められマージされます。
window.scroll([lines=1])
スクリーンまたはスクロール領域を上に lines 行スクロールします。
window.scrollok(flag)
window.setscrreg(top, bottom)
スクロール領域を top から bottom に設定します。スクロール動作はすべてこの領域で行われます。
window.standend()
A_STANDOUT 属性をオフにします。端末によっては、この操作ですべての属性をオフにする副作用が発生します。
window.standout()
A_STANDOUT 属性をオンにします。
window.subpad(begin_y, begin_x)
window.subpad(nlines, ncols, begin_y, begin_x)
左上の角が (begin_y, begin_x) にあり、幅/高さがそれぞれ ncols / nlines であるようなサブウィンドウを返します。
window.subwin(begin_y, begin_x)
window.subwin(nlines, ncols, begin_y, begin_x)
左上の角が (begin_y, begin_x) にあり、幅/高さがそれぞれ ncols / nlines であるようなサブウィンドウを返します。
デフォルトでは、サブウィンドウは指定された場所からウィンドウの右下角まで広がります。
window.syncdown()
このウィンドウの上位のウィンドウのいずれかで更新(touch)された各場所をこのウィンドウ内でも更新します。このルーチンは refresh() から呼び出されるので、手動で呼び出す必要はほとんどないはずです。
window.syncok(flag)
window.syncup()
ウィンドウ内で更新 (touch) した場所を、上位のすべてのウィンドウ内でも更新します。
window.timeout(delay)
window.touchline(start, count[, changed])
window.touchwin()
描画を最適化するために、すべてのウィンドウが変更されたかのように振舞わせます。
window.untouchwin()
ウィンドウ内のすべての行を、最後に refresh() を呼んだ際から変更されていないものとしてマークします。
window.vline(ch, n)
window.vline(y, x, ch, n)
(y, x) から始まり、n の長さを持つ、文字 ch で作られる垂直線を表示します。
定数
curses モジュールでは以下のデータメンバを定義しています:
curses.ERR
curses.OK
napms() のような整数を返す curses ルーチンのいくつかは、成功した際に OK を返します。
curses.version
curses.ncurses_version
バージョン 3.8 で追加.
属性
意味
A_ALTCHARSET
Alternate character set mode
A_BLINK
Blink mode
A_BOLD
Bold mode
A_DIM
Dim mode
A_INVIS
Invisible or blank mode
A_ITALIC
Italic mode
A_NORMAL
Normal attribute
A_PROTECT
Protected mode
A_REVERSE
Reverse background and foreground colors
A_STANDOUT
Standout mode
A_UNDERLINE
Underline mode
A_HORIZONTAL
Horizontal highlight
A_LEFT
Left highlight
A_LOW
Low highlight
A_RIGHT
Right highlight
A_TOP
Top highlight
A_VERTICAL
Vertical highlight
A_CHARTEXT
Bit-mask to extract a character
バージョン 3.7 で追加: A_ITALIC was added.
Bit-mask
意味
A_ATTRIBUTES
Bit-mask to extract attributes
A_CHARTEXT
Bit-mask to extract a character
A_COLOR
Bit-mask to extract color-pair field information
キーは KEY_ で始まる名前をもつ整数定数です。利用可能なキーキャップはシステムに依存します。
キー定数
キー
KEY_MIN
最小のキー値
KEY_BREAK
ブレークキー (Break, 信頼できません)
KEY_DOWN
下矢印
KEY_UP
上矢印
KEY_LEFT
左矢印
KEY_RIGHT
右矢印
KEY_HOME
ホームキー (Home, または上左矢印)
KEY_BACKSPACE
バックスペース (Backspace, 信頼できません)
KEY_F0
ファンクションキー。64 個までサポートされています。
KEY_Fn
ファンクションキー n の値
KEY_DL
行削除 (Delete line)
KEY_IL
行挿入 (Insert line)
KEY_DC
文字削除 (Delete char)
KEY_IC
文字挿入、または文字挿入モードへ入る
KEY_EIC
文字挿入モードから抜ける
KEY_CLEAR
画面消去
KEY_EOS
画面の末端まで消去
KEY_EOL
行末端まで消去
KEY_SF
前に 1 行スクロール
KEY_SR
後ろ (逆方向) に 1 行スクロール
KEY_NPAGE
次のページ (Page Next)
KEY_PPAGE
前のページ (Page Prev)
KEY_STAB
タブ設定
KEY_CTAB
タブリセット
KEY_CATAB
すべてのタブをリセット
KEY_ENTER
入力または送信 (信頼できません)
KEY_SRESET
ソフトウェア (部分的) リセット (信頼できません)
KEY_RESET
リセットまたはハードリセット (信頼できません)
KEY_PRINT
印刷 (Print)
KEY_LL
下ホーム (Home down) または最下行 (左下)
KEY_A1
キーパッドの左上キー
KEY_A3
キーパッドの右上キー
KEY_B2
キーパッドの中央キー
KEY_C1
キーパッドの左下キー
KEY_C3
キーパッドの右下キー
KEY_BTAB
Back tab
KEY_BEG
開始 (Beg)
KEY_CANCEL
キャンセル (Cancel)
KEY_CLOSE
Close [閉じる]
KEY_COMMAND
コマンド (Cmd)
KEY_COPY
Copy [コピー]
KEY_CREATE
生成 (Create)
KEY_END
終了 (End)
KEY_EXIT
Exit [終了]
KEY_FIND
検索 (Find)
KEY_HELP
ヘルプ (Help)
KEY_MARK
マーク (Mark)
KEY_MESSAGE
メッセージ (Message)
KEY_MOVE
移動 (Move)
KEY_NEXT
次へ (Next)
KEY_OPEN
開く (Open)
KEY_OPTIONS
オプション
KEY_PREVIOUS
前へ (Prev)
KEY_REDO
Redo [やり直し]
KEY_REFERENCE
参照 (Ref)
KEY_REFRESH
更新 (Refresh)
KEY_REPLACE
置換 (Replace)
KEY_RESTART
再起動 (Restart)
KEY_RESUME
再開 (Resume)
KEY_SAVE
Save [保存]
KEY_SBEG
シフト付き Beg
KEY_SCANCEL
シフト付き Cancel
KEY_SCOMMAND
シフト付き Command
KEY_SCOPY
シフト付き Copy
KEY_SCREATE
シフト付き Create
KEY_SDC
シフト付き Delete char
KEY_SDL
シフト付き Delete line
KEY_SELECT
選択 (Select)
KEY_SEND
シフト付き End
KEY_SEOL
シフト付き Clear line
KEY_SEXIT
シフト付き Exit
KEY_SFIND
シフト付き Find
KEY_SHELP
シフト付き Help
KEY_SHOME
シフト付き Home
KEY_SIC
シフト付き Input
KEY_SLEFT
シフト付き Left arrow
KEY_SMESSAGE
シフト付き Message
KEY_SMOVE
シフト付き Move
KEY_SNEXT
シフト付き Next
KEY_SOPTIONS
シフト付き Options
KEY_SPREVIOUS
シフト付き Prev
KEY_SPRINT
シフト付き Print
KEY_SREDO
シフト付き Redo
KEY_SREPLACE
シフト付き Replace
KEY_SRIGHT
シフト付き Right arrow
KEY_SRSUME
シフト付き Resume
KEY_SSAVE
シフト付き Save
KEY_SSUSPEND
シフト付き Suspend
KEY_SUNDO
シフト付き Undo
KEY_SUSPEND
一時停止 (Suspend)
KEY_UNDO
Undo [元に戻す]
KEY_MOUSE
マウスイベント通知
KEY_RESIZE
端末リサイズイベント
KEY_MAX
最大キー値
VT100 や、X 端末エミュレータのようなソフトウェアエミュレーションでは、通常少なくとも 4 つのファンクションキー (KEY_F1, KEY_F2, KEY_F3, KEY_F4) が利用可能で、矢印キーは KEY_UP, KEY_DOWN, KEY_LEFT および KEY_RIGHT が対応付けられています。計算機に PC キーボードが付属している場合、矢印キーと 12 個のファンクションキー (古い PC キーボードには 10 個しかファンクションキーがないかもしれません) が利用できると考えてよいでしょう; また、以下のキーパッド対応付けは標準的なものです:
キーキャップ
定数
Insert
KEY_IC
Delete
KEY_DC
Home
KEY_HOME
End
KEY_END
Page Up
KEY_PPAGE
Page Down
KEY_NPAGE
代替文字セットを以下の表に列挙します。これらは VT100 端末から継承したものであり、X 端末のようなソフトウェアエミュレーション上で一般に利用可能なものです。グラフィックが利用できない場合、curses は印字可能 ASCII文字による粗雑な近似出力を行います。
注釈 これらは initscr() が呼び出された後でしか利用できません。
ACS コード
意味
ACS_BBSS
右上角の別名
ACS_BLOCK
黒四角ブロック
ACS_BOARD
白四角ブロック
ACS_BSBS
水平線の別名
ACS_BSSB
左上角の別名
ACS_BSSS
上向き T 字罫線の別名
ACS_BTEE
下向き T 字罫線
ACS_BULLET
黒丸(bullet)
ACS_CKBOARD
チェッカーボードパタン (点描)
ACS_DARROW
下向き矢印
ACS_DEGREE
度記号
ACS_DIAMOND
ダイアモンド
ACS_GEQUAL
大なりイコール
ACS_HLINE
水平線
ACS_LANTERN
ランタン(lantern) シンボル
ACS_LARROW
左向き矢印
ACS_LEQUAL
小なりイコール
ACS_LLCORNER
左下角
ACS_LRCORNER
右下角
ACS_LTEE
左向き T 字罫線
ACS_NEQUAL
不等号
ACS_PI
パイ記号
ACS_PLMINUS
プラスマイナス記号
ACS_PLUS
大プラス記号
ACS_RARROW
右向き矢印
ACS_RTEE
右向き T 字罫線
ACS_S1
スキャンライン 1
ACS_S3
スキャンライン 3
ACS_S7
スキャンライン 7
ACS_S9
スキャンライン 9
ACS_SBBS
右下角の別名
ACS_SBSB
垂直線の別名
ACS_SBSS
右向き T 字罫線の別名
ACS_SSBB
左下角の別名
ACS_SSBS
下向き T 字罫線の別名
ACS_SSSB
左向き T 字罫線の別名
ACS_SSSS
交差罫線または大プラス記号の別名
ACS_STERLING
ポンドスターリング記号
ACS_TTEE
上向き T 字罫線
ACS_UARROW
上向き矢印
ACS_ULCORNER
左上角
ACS_URCORNER
右上角
ACS_VLINE
垂直線
以下のテーブルは定義済みの色を列挙したものです:
定数
色
COLOR_BLACK
黒
COLOR_BLUE
青
COLOR_CYAN
シアン (薄く緑がかった青)
COLOR_GREEN
緑
COLOR_MAGENTA
マゼンタ (紫がかった赤)
COLOR_RED
赤
COLOR_WHITE
白
COLOR_YELLOW
黄色
curses.textpad --- curses プログラムのためのテキスト入力ウィジェット
curses.textpad モジュールでは、curses ウィンドウ内での基本的なテキスト編集を処理し、Emacs に似た (すなわち Netscape Navigator, BBedit 6.x, FrameMaker, その他諸々のプログラムとも似た) キーバインドをサポートしている Textbox クラスを提供します。このモジュールではまた、テキストボックスを枠で囲むなどの目的のために有用な、矩形描画関数を提供しています。
curses.textpad モジュールでは以下の関数を定義しています:
curses.textpad.rectangle(win, uly, ulx, lry, lrx)
矩形を描画します。最初の引数はウィンドウオブジェクトでなければなりません; 残りの引数はそのウィンドウからの相対座標になります。2 番目および 3 番目の引数は描画すべき矩形の左上角の y および x 座標です; 4 番目および 5 番目の引数は右下角の y および x 座標です。矩形は、VT100/IBM PC におけるフォーム文字を利用できる端末 (xterm やその他のほとんどのソフトウェア端末エミュレータを含む) ではそれを使って描画されます。そうでなければ ASCII 文字のダッシュ、垂直バー、およびプラス記号で描画されます。
Textbox オブジェクト
以下のような Textbox オブジェクトをインスタンス生成することができます:
class curses.textpad.Textbox(win)
Textbox オブジェクトは以下のメソッドを持ちます:
edit([validator])
普段使うことになるエントリポイントです。終了キーストロークの一つが入力されるまで編集キーストロークを受け付けます。validator を与える場合、関数でなければなりません。validator はキーストロークが入力されるたびにそのキーストロークが引数となって呼び出されます; 返された値に対して、コマンドキーストロークとして解釈が行われます。このメソッドはウィンドウの内容を文字列として返します; ウィンドウ内の空白が含められるかどうかは stripspaces 属性で決められます。
do_command(ch)
単一のコマンドキーストロークを処理します。以下にサポートされている特殊キーストロークを示します:
キーストローク
動作
Control-A
ウィンドウの左端に移動します。
Control-B
カーソルを左へ移動し、必要なら前の行に折り返します。
Control-D
カーソル下の文字を削除します。
Control-E
右端 (stripspaces がオフのとき) または行末 (stripspaces がオンのとき) に移動します。
Control-F
カーソルを右に移動し、必要なら次の行に折り返します。
Control-G
ウィンドウを終了し、その内容を返します。
Control-H
逆方向に文字を削除します。
Control-J
ウィンドウが 1 行であれば終了し、そうでなければ新しい行を挿入します。
Control-K
行が空白行ならその行全体を削除し、そうでなければカーソル以降行末までを消去します。
Control-L
スクリーンを更新します。
Control-N
カーソルを下に移動します; 1 行下に移動します。
Control-O
カーソルの場所に空行を 1 行挿入します。
Control-P
カーソルを上に移動します; 1 行上に移動します。
移動操作は、カーソルがウィンドウの縁にあって移動ができない場合には何も行いません。場合によっては、以下のような同義のキーストロークがサポートされています:
定数
キーストローク
KEY_LEFT
Control-B
KEY_RIGHT
Control-F
KEY_UP
Control-P
KEY_DOWN
Control-N
KEY_BACKSPACE
Control-h
他のキーストロークは、与えられた文字を挿入し、(行折り返し付きで) 右に移動するコマンドとして扱われます。
gather()
ウィンドウの内容を文字列として返します; ウィンドウ内の空白が含められるかどうかは stripspaces メンバ変数で決められます。
stripspaces
この属性はウィンドウ内の空白領域の解釈方法を制御するためのフラグです。フラグがオンに設定されている場合、各行の末端にある空白領域は無視されます; すなわち、末端空白領域にカーソルが入ると、その場所の代わりに行の末尾にカーソルが移動します。また、末端の空白領域はウィンドウの内容を取得する際に剥ぎ取られます。
curses.ascii --- ASCII 文字に関するユーティリティ
curses.ascii モジュールでは、 ASCII 文字を指す名前定数と、様々な ASCII 文字区分についてある文字が帰属するかどうかを調べる関数を提供します。このモジュールで提供されている定数は以下の制御文字の名前です:
名前
意味
NUL
SOH
ヘディング開始、コンソール割り込み
STX
テキスト開始
ETX
テキスト終了
EOT
テキスト伝送終了
ENQ
問い合わせ、 ACK フロー制御時に使用
ACK
肯定応答
BEL
ベル
BS
一文字後退
TAB
タブ
HT
TAB の別名: "水平タブ"
LF
改行
NL
LF の別名: "改行"
VT
垂直タブ
FF
改頁
CR
復帰
SO
シフトアウト、他の文字セットの開始
SI
シフトイン、標準の文字セットに復帰
DLE
データリンクでのエスケープ
DC1
装置制御 1、フロー制御のための XON
DC2
装置制御 2、ブロックモードフロー制御
DC3
装置制御 3、フロー制御のための XOFF
DC4
装置制御 4
NAK
否定応答
SYN
同期信号
ETB
ブロック転送終了
CAN
キャンセル (Cancel)
EM
媒体終端
SUB
代入文字
ESC
エスケープ文字
FS
ファイル区切り文字
GS
グループ区切り文字
RS
レコード区切り文字、ブロックモード終了子
US
単位区切り文字
SP
空白文字
DEL
削除
これらの大部分は、最近は実際に定数の意味通りに使われることがほとんどないので注意してください。これらのニーモニック符号はデジタル計算機より前のテレプリンタにおける慣習から付けられたものです。
このモジュールでは、標準 C ライブラリの関数を雛型とする以下の関数をサポートしています:
curses.ascii.isalnum(c)
ASCII 英数文字かどうかを調べます; isalpha(c) or isdigit(c) と等価です。
curses.ascii.isalpha(c)
ASCII アルファベット文字かどうかを調べます; isupper(c) or islower(c) と等価です。
curses.ascii.isascii(c)
文字が 7 ビット ASCII 文字に合致するかどうかを調べます。
curses.ascii.isblank(c)
ASCII 余白文字、すなわち空白または水平タブかどうかを調べます。
curses.ascii.iscntrl(c)
ASCII 制御文字 (0x00 から 0x1f の範囲または 0x7f) かどうかを調べます。
curses.ascii.isdigit(c)
ASCII 10 進数字、すなわち '0' から '9' までの文字かどうかを調べます。c in string.digits と等価です。
curses.ascii.isgraph(c)
空白以外の ASCII 印字可能文字かどうかを調べます。
curses.ascii.islower(c)
ASCII 小文字かどうかを調べます。
curses.ascii.isprint(c)
空白文字を含め、ASCII 印字可能文字かどうかを調べます。
curses.ascii.ispunct(c)
空白または英数字以外の ASCII 印字可能文字かどうかを調べます。
curses.ascii.isspace(c)
ASCII 余白文字、すなわち空白、改行、復帰、改頁、水平タブ、垂直タブかどうかを調べます。
curses.ascii.isupper(c)
ASCII 大文字かどうかを調べます。
curses.ascii.isxdigit(c)
ASCII 16 進数字かどうかを調べます。c in string.hexdigits と等価です。
curses.ascii.isctrl(c)
ASCII 制御文字 (0 から 31 までの値) かどうかを調べます。
curses.ascii.ismeta(c)
非 ASCII 文字 (0x80 またはそれ以上の値) かどうかを調べます。
これらの関数は数字も 1 文字の文字列も使えます; 引数を文字列にした場合、組み込み関数 ord() を使って変換されます。
これらの関数は全て、関数に渡した文字列の文字から得られたビット値を調べるので注意してください; 関数はホスト計算機で使われている文字列エンコーディングについて何ら関知しません。
以下の 2 つの関数は、引数として 1 文字の文字列または整数で表したバイト値のどちらでもとり得ます; これらの関数は引数と同じ型で値を返します。
curses.ascii.ascii(c)
ASCII 値を返します。c の下位 7 ビットに対応します。
curses.ascii.ctrl(c)
与えた文字に対応する制御文字を返します (0x1f とビット単位で論理積を取ります)。
curses.ascii.alt(c)
与えた文字に対応する 8 ビット文字を返します (0x80 とビット単位で論理和を取ります)。
以下の関数は 1 文字からなる文字列値または整数値を引数に取り、文字列を返します。
curses.ascii.unctrl(c)
ASCII 文字 c の文字列表現を返します。 もし c が印字可能文字であれば、返される文字列は c そのものになります。 もし c が制御文字 (0x00--0x1f) であれば、キャレット ('^') と、その後ろに続く c に対応した大文字からなる文字列になります。 c が ASCII 削除文字 (0x7f) であれば、文字列は '^?' になります。 c のメタビット (0x80) がセットされていれば、メタビットは取り去られ、前述のルールが適用され、'!' が前につけられます。
curses.ascii.controlnames
0 (NUL) から 0x1f (US) までの 32 の ASCII 制御文字と、空白文字 SP のニーモニック符号名からなる 33 要素の文字列によるシーケンスです。
curses.panel --- curses のためのパネルスタック拡張
パネルは深さ (depth) の機能が追加されたウィンドウです。これにより、ウィンドウをお互いに重ね合わせることができ、各ウィンドウの可視部分だけが表示されます。パネルはスタック中に追加したり、スタック内で上下移動させたり、スタックから除去することができます。
関数
curses.panel では以下の関数を定義しています:
curses.panel.bottom_panel()
パネルスタックの最下層のパネルを返します。
curses.panel.new_panel(win)
与えられたウィンドウ win に関連付けられたパネルオブジェクトを返します。返されたパネルオブジェクトを参照しておく必要があることに注意してください。もし参照しなければ、パネルオブジェクトはガベージコレクションされてパネルスタックから削除されます。
curses.panel.top_panel()
パネルスタックの最上層のパネルを返します。
curses.panel.update_panels()
仮想スクリーンをパネルスタック変更後の状態に更新します。この関数では curses.doupdate() を呼ばないので、ユーザは自分で呼び出す必要があります。
Panel オブジェクト
上記の new_panel() が返す Panel オブジェクトはスタック順の概念を持つウィンドウです。ウィンドウはパネルに関連付けられており、表示する内容を決定している一方、パネルのメソッドはパネルスタック中のウィンドウの深さ管理を担います。
Panel オブジェクトは以下のメソッドを持っています:
Panel.above()
現在のパネルの上にあるパネルを返します。
Panel.below()
現在のパネルの下にあるパネルを返します。
Panel.bottom()
パネルをスタックの最下層にプッシュします。
Panel.hidden()
パネルが隠れている (不可視である) 場合に True を返し、そうでない場合 False を返します。
Panel.hide()
パネルを隠します。この操作ではオブジェクトは消去されず、スクリーン上のウィンドウを不可視にするだけです。
Panel.move(y, x)
パネルをスクリーン座標 (y, x) に移動します。
Panel.replace(win)
パネルに関連付けられたウィンドウを win に変更します。
Panel.set_userptr(obj)
パネルのユーザポインタを obj に設定します。このメソッドは任意のデータをパネルに関連付けるために使われ、任意の Python オブジェクトにすることができます。
Panel.show()
(隠れているはずの) パネルを表示します。
Panel.top()
パネルをスタックの最上層にプッシュします。
Panel.userptr()
パネルのユーザポインタを返します。任意の Python オブジェクトです。
Panel.window()
パネルに関連付けられているウィンドウオブジェクトを返します。
platform --- 実行中プラットフォームの固有情報を参照する
ソースコード: Lib/platform.py
注釈 プラットフォーム毎にアルファベット順に並べています。Linuxについては Unixセクションを参照してください。
クロスプラットフォーム
platform.architecture(executable=sys.executable, bits='', linkage='')
executable で指定した実行可能ファイル（省略時はPythonインタープリタのバイナリ）の各種アーキテクチャ情報を調べます。
戻り値はタプル (bits, linkage) で、アーキテクチャのビット数と実行可能ファイルのリンク形式を示します。どちらの値も文字列で返ります。
値を決定できない場合はパラメータプリセットから与えられる値を返します。bits に '' を与えた場合、サポートされているポインタサイズを知るために sizeof(pointer) (Python バージョン < 1.5.2 では sizeof(long)) が使用されます。
この関数は、システムの file コマンドを使用します。 file はほとんどのUnixプラットフォームと一部の非Unixプラットフォームで利用可能ですが、 file コマンドが利用できず、かつ executable が Pythonインタープリタでない場合には適切なデフォルト値が返ります。
注釈 Mac OS X (とひょっとすると他のプラットフォーム) では、実行可能ファイルは複数のアーキテクチャを含んだユニバーサル形式かもしれません。
現在のインタプリタが "64-bit" であるかどうかを調べるには、 sys.maxsize の方が信頼できます:
is_64bits = sys.maxsize > 2**32
platform.machine()
'i386' のような、機種を返します。不明な場合は空文字列を返します。
platform.node()
コンピュータのネットワーク名を返します。ネットワーク名は完全修飾名とは限りません。不明な場合は空文字列を返します。
platform.platform(aliased=0, terse=0)
実行中プラットフォームを識別する文字列を返します。この文字列には、有益な情報をできるだけ多く付加しています。
戻り値は機械で処理しやすい形式ではなく、人間にとって読みやすい 形式となっています。異なったプラットフォームでは異なった戻り値となるようになっています。
aliased が真なら、システムの名称として一般的な名称ではなく、別名を使用して結果を返します。たとえば、SunOS は Solaris となります。この機能は system_alias() で実装されています。
terse が真なら、プラットフォームを特定するために最低限必要な情報だけを返します。
バージョン 3.8 で変更: macOSでは、 mac_ver() が空でないリリース文字列を返すとき、darwin のバージョンではなく macOS のバージョンを取得するために、この関数は mac_ver() を使うようになりました。
platform.processor()
'amdk6' のような、（現実の）プロセッサ名を返します。
不明な場合は空文字列を返します。NetBSDのようにこの情報を提供しない、または machine() と同じ値しか返さないプラットフォームも多く存在しますので、注意してください。
platform.python_build()
Pythonのビルド番号と日付を、(buildno, builddate) のタプルで返します。
platform.python_compiler()
Pythonをコンパイルする際に使用したコンパイラを示す文字列を返します。
platform.python_branch()
Python実装のバージョン管理システム上のブランチを特定する文字列を返します。
platform.python_implementation()
Python実装を指定する文字列を返します。戻り値は: 'CPython', 'IronPython', 'Jython', 'PyPy' のいずれかです。
platform.python_revision()
Python実装のバージョン管理システム上のリビジョンを特定する文字列を返します。
platform.python_version()
Python のバージョンを、'major.minor.patchlevel' 形式の文字列で返します。
sys.version と異なり、patchlevel（デフォルトでは0)も必ず含まれています。
platform.python_version_tuple()
Pythonのバージョンを、文字列のタプル (major, minor, patchlevel) で返します。
sys.version と異なり、patchlevel（デフォルトでは '0')も必ず含まれています。
platform.release()
'2.2.0' や 'NT' のような、システムのリリース情報を返します。不明な場合は空文字列を返します。
platform.system()
'Linux' 、 'Darwin' 、 'Java' 、 'Windows' のような、システム/OS 名を返します。不明な場合は空文字列を返します。
platform.system_alias(system, release, version)
マーケティング目的で使われる一般的な別名に変換して (system, release, version) を返します。混乱を避けるために、情報を並べなおす場合があります。
platform.version()
'#3 on degas' のような、システムのリリース情報を返します。不明な場合は空文字列を返します。
platform.uname()
極めて可搬性の高い uname インタフェースです。 system, node, release, version, machine, processor の6つの属性を持った namedtuple() を返します。
この関数が os.uname() の結果には含まれない 6番目の属性 (processor) を追加することに注意してください。さらに、最初の2つの属性については属性名が異なります; os.uname() はそれらを sysname と nodename と命名します。
不明な項目は '' となります。
バージョン 3.3 で変更: 結果が tuple から namedtuple に変更されました。
Java プラットフォーム
platform.java_ver(release='', vendor='', vminfo=('', '', ''), osinfo=('', '', ''))
Jython用のバージョンインターフェースです。
タプル (release, vendor, vminfo, osinfo) を返します。vminfo はタプル (vm_name, vm_release, vm_vendor)、osinfo はタプル (os_name, os_version, os_arch) です。不明な項目は引数で指定した値(デフォルトは '') となります。
Windows プラットフォーム
platform.win32_ver(release='', version='', csd='', ptype='')
Windows レジストリから追加のバージョン情報を取得して、タプル (release, version, csd, ptype) を返します。それぞれ、OS リリース、バージョン番号、CSD レベル (サービスパック)、OS タイプ (マルチ/シングルプロセッサー) を指しています。
参考: ptype はシングルプロセッサのNT上では 'Uniprocessor Free'、マルチプロセッサでは 'Multiprocessor Free' となります。'Free' がついている場合はデバッグ用のコードが含まれていないことを示し、'Checked' がついていれば引数や範囲のチェックなどのデバッグ用コードが含まれていることを示します。
platform.win32_edition()
現在の Windows のエディションの文字列表現を返します。取りうる返り値には 'Enterprise' 、 'IoTUAP' 、 'ServerStandard' 、 'nanoserver' がありますが、これらに限定されません。
バージョン 3.8 で追加.
platform.win32_is_iot()
win32_edition() によって返された Windows のエディションが IoT エディションの時 True を返します。
バージョン 3.8 で追加.
Mac OS プラットフォーム
platform.mac_ver(release='', versioninfo=('', '', ''), machine='')
Mac OSのバージョン情報を、タプル (release, versioninfo, machine) で返します。versioninfo は、タプル (version, dev_stage, non_release_version) です。
不明な項目は '' となります。タプルの要素は全て文字列です。
Unix プラットフォーム
platform.libc_ver(executable=sys.executable, lib='', version='', chunksize=16384)
executableで指定したファイル（省略時はPythonインタープリタ）がリンクしているlibcバージョンの取得を試みます。戻り値は文字列のタプル (lib, version) で、不明な項目は引数で指定した値となります。
この関数は、実行形式に追加されるシンボルの細かな違いによって、libcのバージョンを特定します。この違いは gcc でコンパイルされた実行可能ファイルでのみ有効だと思われます。
chunksize にはファイルから情報を取得するために読み込むバイト数を指定します。
errno --- 標準の errno システムシンボル
このモジュールから標準の errno システムシンボルを取得することができます。個々のシンボルの値は errno に対応する整数値です。これらのシンボルの名前は、 linux/include/errno.h から借用されており、かなり網羅的なはずです。
errno.errorcode
errno 値を背後のシステムにおける文字列表現に対応付ける辞書です。例えば、errno.errorcode[errno.EPERM] は 'EPERM' に対応付けられます。
数値のエラーコードをエラーメッセージに変換するには、 os.strerror() を使ってください。
以下のリストの内、現在のプラットフォームで使われていないシンボルはモジュール上で定義されていません。定義されているシンボルだけを挙げたリストは errno.errorcode.keys() として取得することができます。取得できるシンボルには以下のようなものがあります:
errno.EPERM
許可されていない操作です (Operation not permitted)
errno.ENOENT
そのようなファイルまたはディレクトリは存在しません (No such file or directory)
errno.ESRCH
指定したプロセスは存在しません (No such process)
errno.EINTR
システムコールが中断されました (Interrupted system call)
参考 このエラーは例外 InterruptedError にマップされます。
errno.EIO
I/O エラーです (I/O error)
errno.ENXIO
そのようなデバイスまたはアドレスは存在しません (No such device or address)
errno.E2BIG
引数リストが長すぎます (Arg list too long)
errno.ENOEXEC
実行形式にエラーがあります (Exec format error)
errno.EBADF
ファイル番号が間違っています (Bad file number)
errno.ECHILD
子プロセスがありません (No child processes)
errno.EAGAIN
再試行してください (Try again)
errno.ENOMEM
空きメモリがありません (Out of memory)
errno.EACCES
許可がありません (Permission denied)
errno.EFAULT
不正なアドレスです (Bad address)
errno.ENOTBLK
ブロックデバイスが必要です (Block device required)
errno.EBUSY
そのデバイスまたはリソースは使用中です (Device or resource busy)
errno.EEXIST
ファイルがすでに存在します (File exists)
errno.EXDEV
デバイスをまたいだリンクです (Cross-device link)
errno.ENODEV
そのようなデバイスはありません (No such device)
errno.ENOTDIR
ディレクトリではありません (Not a directory)
errno.EISDIR
ディレクトリです (Is a directory)
errno.EINVAL
無効な引数です (Invalid argument)
errno.ENFILE
ファイルテーブルがオーバフローしています (File table overflow)
errno.EMFILE
開かれたファイルが多すぎます (Too many open files)
errno.ENOTTY
タイプライタではありません (Not a typewriter)
errno.ETXTBSY
テキストファイルが使用中です (Text file busy)
errno.EFBIG
ファイルが大きすぎます (File too large)
errno.ENOSPC
デバイス上に空きがありません (No space left on device)
errno.ESPIPE
不正なシークです (Illegal seek)
errno.EROFS
リードオンリーのファイルシステムです (Read-only file system)
errno.EMLINK
リンクが多すぎます (Too many links)
errno.EPIPE
壊れたパイプです (Broken pipe)
errno.EDOM
数学引数が関数の定義域を越えています (Math argument out of domain of func)
errno.ERANGE
表現できない数学演算結果になりました (Math result not representable)
errno.EDEADLK
リソースのデッドロックが起きます (Resource deadlock would occur)
errno.ENAMETOOLONG
ファイル名が長すぎます (File name too long)
errno.ENOLCK
レコードロッキングが利用できません (No record locks available)
errno.ENOSYS
実装されていない機能です (Function not implemented)
errno.ENOTEMPTY
ディレクトリが空ではありません (Directory not empty)
errno.ELOOP
これ以上シンボリックリンクを追跡できません (Too many symbolic links encountered)
errno.EWOULDBLOCK
操作がブロックします (Operation would block)
errno.ENOMSG
指定された型のメッセージはありません (No message of desired type)
errno.EIDRM
識別子が除去されました (Identifier removed)
errno.ECHRNG
チャネル番号が範囲を超えました (Channel number out of range)
errno.EL2NSYNC
レベル 2 で同期がとれていません (Level 2 not synchronized)
errno.EL3HLT
レベル 3 で終了しました (Level 3 halted)
errno.EL3RST
レベル 3 でリセットしました (Level 3 reset)
errno.ELNRNG
リンク番号が範囲を超えています (Link number out of range)
errno.EUNATCH
プロトコルドライバが接続されていません (Protocol driver not attached)
errno.ENOCSI
CSI 構造体がありません (No CSI structure available)
errno.EL2HLT
レベル 2 で終了しました (Level 2 halted)
errno.EBADE
無効な変換です (Invalid exchange)
errno.EBADR
無効な要求記述子です (Invalid request descriptor)
errno.EXFULL
変換テーブルが一杯です (Exchange full)
errno.ENOANO
陰極がありません (No anode)
errno.EBADRQC
無効なリクエストコードです (Invalid request code)
errno.EBADSLT
無効なスロットです (Invalid slot)
errno.EDEADLOCK
ファイルロックにおけるデッドロックエラーです (File locking deadlock error)
errno.EBFONT
フォントファイル形式が間違っています (Bad font file format)
errno.ENOSTR
ストリーム型でないデバイスです (Device not a stream)
errno.ENODATA
利用可能なデータがありません (No data available)
errno.ETIME
時間切れです (Timer expired)
errno.ENOSR
ストリームリソースを使い切りました (Out of streams resources)
errno.ENONET
計算機はネットワーク上にありません (Machine is not on the network)
errno.ENOPKG
パッケージがインストールされていません (Package not installed)
errno.EREMOTE
対象物は遠隔にあります (Object is remote)
errno.ENOLINK
リンクが切られました (Link has been severed)
errno.EADV
Advertise エラーです (Advertise error)
errno.ESRMNT
Srmount エラーです (Srmount error)
errno.ECOMM
送信時の通信エラーです (Communication error on send)
errno.EPROTO
プロトコルエラーです (Protocol error)
errno.EMULTIHOP
多重ホップを試みました (Multihop attempted)
errno.EDOTDOT
RFS 特有のエラーです (RFS specific error)
errno.EBADMSG
データメッセージではありません (Not a data message)
errno.EOVERFLOW
定義されたデータ型にとって大きすぎる値です (Value too large for defined data type)
errno.ENOTUNIQ
名前がネットワーク上で一意でありません (Name not unique on network)
errno.EBADFD
ファイル記述子の状態が不正です (File descriptor in bad state)
errno.EREMCHG
遠隔のアドレスが変更されました (Remote address changed)
errno.ELIBACC
必要な共有ライブラリにアクセスできません (Can not access a needed shared library)
errno.ELIBBAD
壊れた共有ライブラリにアクセスしています (Accessing a corrupted shared library)
errno.ELIBSCN
a.out の .lib セクションが壊れています (.lib section in a.out corrupted)
errno.ELIBMAX
リンクを試みる共有ライブラリが多すぎます (Attempting to link in too many shared libraries)
errno.ELIBEXEC
共有ライブラリを直接実行することができません (Cannot exec a shared library directly)
errno.EILSEQ
不正なバイト列です (Illegal byte sequence)
errno.ERESTART
割り込みシステムコールを復帰しなければなりません (Interrupted system call should be restarted)
errno.ESTRPIPE
ストリームパイプのエラーです (Streams pipe error)
errno.EUSERS
ユーザが多すぎます (Too many users)
errno.ENOTSOCK
非ソケットに対するソケット操作です (Socket operation on non-socket)
errno.EDESTADDRREQ
目的アドレスが必要です (Destination address required)
errno.EMSGSIZE
メッセージが長すぎます (Message too long)
errno.EPROTOTYPE
ソケットに対して不正なプロトコル型です (Protocol wrong type for socket)
errno.ENOPROTOOPT
利用できないプロトコルです (Protocol not available)
errno.EPROTONOSUPPORT
サポートされていないプロトコルです (Protocol not supported)
errno.ESOCKTNOSUPPORT
サポートされていないソケット型です (Socket type not supported)
errno.EOPNOTSUPP
通信端点に対してサポートされていない操作です (Operation not supported on transport endpoint)
errno.EPFNOSUPPORT
サポートされていないプロトコルファミリです (Protocol family not supported)
errno.EAFNOSUPPORT
プロトコルでサポートされていないアドレスファミリです (Address family not supported by protocol)
errno.EADDRINUSE
アドレスは使用中です (Address already in use)
errno.EADDRNOTAVAIL
要求されたアドレスを割り当てできません (Cannot assign requested address)
errno.ENETDOWN
ネットワークがダウンしています (Network is down)
errno.ENETUNREACH
ネットワークに到達できません (Network is unreachable)
errno.ENETRESET
リセットによってネットワーク接続が切られました (Network dropped connection because of reset)
errno.ECONNABORTED
ソフトウェアによって接続が終了されました (Software caused connection abort)
errno.ECONNRESET
接続がピアによってリセットされました (Connection reset by peer)
errno.ENOBUFS
バッファに空きがありません (No buffer space available)
errno.EISCONN
通信端点がすでに接続されています (Transport endpoint is already connected)
errno.ENOTCONN
通信端点が接続されていません (Transport endpoint is not connected)
errno.ESHUTDOWN
通信端点のシャットダウン後は送信できません (Cannot send after transport endpoint shutdown)
errno.ETOOMANYREFS
参照が多すぎます: 接続できません (Too many references: cannot splice)
errno.ETIMEDOUT
接続がタイムアウトしました (Connection timed out)
errno.ECONNREFUSED
接続を拒否されました (Connection refused)
errno.EHOSTDOWN
ホストはシステムダウンしています (Host is down)
errno.EHOSTUNREACH
ホストへの経路がありません (No route to host)
errno.EALREADY
すでに処理中です (Operation already in progress)
errno.EINPROGRESS
現在処理中です (Operation now in progress)
errno.ESTALE
無効な NFS ファイルハンドルです (Stale NFS file handle)
errno.EUCLEAN
構造のクリーニングが必要です (Structure needs cleaning)
errno.ENOTNAM
XENIX 名前付きファイルではありません (Not a XENIX named type file)
errno.ENAVAIL
XENIX セマフォは利用できません (No XENIX semaphores available)
errno.EISNAM
名前付きファイルです (Is a named type file)
errno.EREMOTEIO
遠隔側の I/O エラーです (Remote I/O error)
errno.EDQUOT
ディスククオータを超えました (Quota exceeded)
ctypes --- Pythonのための外部関数ライブラリ
ctypes は Python のための外部関数ライブラリです。このライブラリは C と互換性のあるデータ型を提供し、動的リンク/共有ライブラリ内の関数呼び出しを可能にします。動的リンク/共有ライブラリを純粋な Python でラップするために使うことができます。
ctypesチュートリアル
注意: このチュートリアルのコードサンプルは動作確認のために doctest を使います。コードサンプルの中には Linux、 Windows、あるいは Mac OS X 上で異なる動作をするものがあるため、サンプルのコメントに doctest 命令を入れてあります。
注意: いくつかのコードサンプルで ctypes の c_int 型を参照しています。 sizeof(long) == sizeof(int) であるようなプラットフォームでは、この型は c_long のエイリアスです。そのため、 c_int 型を想定しているときに c_long が表示されたとしても、混乱しないようにしてください --- 実際には同じ型なのです。
動的リンクライブラリをロードする
動的リンクライブラリをロードするために、 ctypes は cdll をエクスポートします。 Windows では windll と oledll オブジェクトをエクスポートします。
これらのオブジェクトの属性としてライブラリにアクセスすることでライブラリをロードします。 cdll は、標準 cdecl 呼び出し規約を用いて関数をエクスポートしているライブラリをロードします。それに対して、 windll ライブラリは stdcall 呼び出し規約を用いる関数を呼び出します。 oledll も stdcall 呼び出し規約を使いますが、関数が Windows HRESULT エラーコードを返すことを想定しています。このエラーコードは関数呼び出しが失敗したとき、 OSError 例外を自動的に送出させるために使われます。
バージョン 3.3 で変更: Windows エラーは以前は WindowsError を送出していましたが、これは現在では OSError の別名になっています。
Windows用の例ですが、 msvcrt はほとんどの標準 C 関数が含まれている MS 標準 C ライブラリであり、 cdecl 呼び出し規約を使うことに注意してください:
>>>
>>> from ctypes import *
>>> print(windll.kernel32)  
<WinDLL 'kernel32', handle ... at ...>
>>> print(cdll.msvcrt)      
<CDLL 'msvcrt', handle ... at ...>
>>> libc = cdll.msvcrt      
>>>
Windows では通常の .dll ファイル拡張子を自動的に追加します。
注釈 cdll.msvcrt 経由で標準 C ライブラリにアクセスすると、Python が使用しているライブラリとは互換性のない可能性のある、古いバージョンのライブラリが使用されます。可能な場合には、ネイティブ Python の機能を使用するか、msvcrt モジュールをインポートして使用してください。
Linux ではライブラリをロードするために拡張子を 含む ファイル名を指定する必要があるので、ロードしたライブラリに対する属性アクセスはできません。 dll ローダーの LoadLibrary() メソッドを使うか、コンストラクタを呼び出して CDLL のインスタンスを作ることでライブラリをロードするかのどちらかを行わなければなりません:
>>>
>>> cdll.LoadLibrary("libc.so.6")  
<CDLL 'libc.so.6', handle ... at ...>
>>> libc = CDLL("libc.so.6")       
>>> libc                           
<CDLL 'libc.so.6', handle ... at ...>
>>>
ロードしたdllから関数にアクセスする
dll オブジェクトの属性として関数にアクセスします:
>>>
>>> from ctypes import *
>>> libc.printf
<_FuncPtr object at 0x...>
>>> print(windll.kernel32.GetModuleHandleA)  
<_FuncPtr object at 0x...>
>>> print(windll.kernel32.MyOwnFunction)     
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "ctypes.py", line 239, in __getattr__
    func = _StdcallFuncPtr(name, self)
AttributeError: function 'MyOwnFunction' not found
>>>
kernel32 や user32 のような win32 システム dll は、多くの場合関数の UNICODE バージョンに加えて ANSI バージョンもエクスポートすることに注意してください。 UNICODE バージョンは後ろに W が付いた名前でエクスポートされ、 ANSI バージョンは A が付いた名前でエクスポートされます。与えられたモジュールの モジュールハンドル を返す win32 GetModuleHandle 関数は次のような C プロトタイプを持ちます。 UNICODE バージョンが定義されているかどうかにより GetModuleHandle としてどちらか一つを公開するためにマクロが使われます:
/* ANSI version */
HMODULE GetModuleHandleA(LPCSTR lpModuleName);
/* UNICODE version */
HMODULE GetModuleHandleW(LPCWSTR lpModuleName);
windll は魔法を使ってどちらか一つを選ぶようなことはしません。GetModuleHandleA もしくは GetModuleHandleW を明示的に指定して必要とするバージョンにアクセスし、バイト列か文字列を使ってそれぞれ呼び出さなければなりません。
時には、 dll が関数を "??2@YAPAXI@Z" のような Python 識別子として有効でない名前でエクスポートすることがあります。このような場合に関数を取り出すには、 getattr() を使わなければなりません。:
>>>
>>> getattr(cdll.msvcrt, "??2@YAPAXI@Z")  
<_FuncPtr object at 0x...>
>>>
Windows では、名前ではなく序数によって関数をエクスポートする dll もあります。こうした関数には序数を使って dll オブジェクトにインデックス指定することでアクセスします:
>>>
>>> cdll.kernel32[1]  
<_FuncPtr object at 0x...>
>>> cdll.kernel32[0]  
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "ctypes.py", line 310, in __getitem__
    func = _StdcallFuncPtr(name, self)
AttributeError: function ordinal 0 not found
>>>
関数を呼び出す
これらの関数は他の Python 呼び出し可能オブジェクトと同じように呼び出すことができます。この例では time() 関数 (Unixエポックからのシステム時間を秒単位で返す) と、 GetModuleHandleA() 関数 (win32モジュールハンドルを返す) を使います。
この例は両方の関数を NULL ポインタとともに呼び出します (None を NULL ポインタとして使う必要があります):
>>>
>>> print(libc.time(None))  
1150640792
>>> print(hex(windll.kernel32.GetModuleHandleA(None)))  
0x1d000000
>>>
cdecl 呼び出し規約を使って stdcall 関数を呼び出したときには、 ValueError が送出されます。逆の場合も同様です:
>>>
>>> cdll.kernel32.GetModuleHandleA(None)  
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: Procedure probably called with not enough arguments (4 bytes missing)
>>>
>>> windll.msvcrt.printf(b"spam")  
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: Procedure probably called with too many arguments (4 bytes in excess)
>>>
正しい呼び出し規約を知るためには、呼び出したい関数についての C ヘッダファイルもしくはドキュメントを見なければなりません。
Windows では、関数が無効な引数とともに呼び出された場合の一般保護例外によるクラッシュを防ぐために、 ctypes は win32 構造化例外処理を使います:
>>>
>>> windll.kernel32.GetModuleHandleA(32)  
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
OSError: exception: access violation reading 0x00000020
>>>
しかしそれでも他に ctypes で Python がクラッシュする状況はあるので、どちらにせよ気を配るべきです。クラッシュのデバッグには、 faulthandler モジュールが役に立つ場合があります (例えば、誤った C ライブラリ呼び出しによって引き起こされたセグメンテーション違反) 。
None 、整数、バイト列オブジェクトおよび (Unicode) 文字列だけが、こうした関数呼び出しにおいてパラメータとして直接使えるネイティブの Python オブジェクトです。 None は C の NULL ポインタとして渡され、バイト文字列とユニコード文字列はそのデータを含むメモリブロックへのポインタ (char * または wchar_t *) として渡されます。 Python 整数はプラットホームのデフォルトの C int 型として渡され、その値は C int 型に合うようにマスクされます。
他のパラメータ型をもつ関数呼び出しに移る前に、 ctypes データ型についてさらに学ぶ必要があります。
基本データ型
ctypes ではいくつもの C 互換のプリミティブなデータ型を定義しています:
ctypes の型
C の型
Python の型
c_bool
_Bool
bool (1)
c_char
char
1文字のバイト列オブジェクト
c_wchar
wchar_t
1文字の文字列
c_byte
char
int
c_ubyte
unsigned char
int
c_short
short
int
c_ushort
unsigned short
int
c_int
int
int
c_uint
unsigned int
int
c_long
long
int
c_ulong
unsigned long
int
c_longlong
__int64 または long long
int
c_ulonglong
unsigned __int64 または unsigned long long
int
c_size_t
size_t
int
c_ssize_t
ssize_t または Py_ssize_t
int
c_float
float
浮動小数点数
c_double
double
浮動小数点数
c_longdouble
long double
浮動小数点数
c_char_p
char * (NUL 終端)
バイト列オブジェクトまたは None
c_wchar_p
wchar_t * (NUL 終端)
文字列または None
c_void_p
void *
整数または None
コンストラクタは任意のオブジェクトをその真偽値として受け取ります。
これら全ての型はその型を呼び出すことによって作成でき、オプションとして型と値が合っている初期化子を指定することができます:
>>>
>>> c_int()
c_long(0)
>>> c_wchar_p("Hello, World")
c_wchar_p(140018365411392)
>>> c_ushort(-3)
c_ushort(65533)
>>>
これらの型は変更可能であり、値を後で変更することもできます:
>>>
>>> i = c_int(42)
>>> print(i)
c_long(42)
>>> print(i.value)
42
>>> i.value = -99
>>> print(i.value)
-99
>>>
新しい値をポインタ型 c_char_p, c_wchar_p および c_void_p のインスタンスへ代入すると、変わるのは指している メモリ位置 であって、メモリブロックの 内容ではありません (これは当然で、なぜなら、 Python バイト列オブジェクトは変更不可能だからです):
>>>
>>> s = "Hello, World"
>>> c_s = c_wchar_p(s)
>>> print(c_s)
c_wchar_p(139966785747344)
>>> print(c_s.value)
Hello World
>>> c_s.value = "Hi, there"
>>> print(c_s)              # the memory location has changed
c_wchar_p(139966783348904)
>>> print(c_s.value)
Hi, there
>>> print(s)                # first object is unchanged
Hello, World
>>>
しかし、変更可能なメモリを指すポインタであることを想定している関数へそれらを渡さないように注意すべきです。もし変更可能なメモリブロックが必要なら、 ctypes には create_string_buffer() 関数があり、いろいろな方法で作成することできます。現在のメモリブロックの内容は raw プロパティを使ってアクセス (あるいは変更) することができます。もし現在のメモリブロックに NUL 終端文字列としてアクセスしたいなら、 value プロパティを使ってください:
>>>
>>> from ctypes import *
>>> p = create_string_buffer(3)            # create a 3 byte buffer, initialized to NUL bytes
>>> print(sizeof(p), repr(p.raw))
3 b'\x00\x00\x00'
>>> p = create_string_buffer(b"Hello")     # create a buffer containing a NUL terminated string
>>> print(sizeof(p), repr(p.raw))
6 b'Hello\x00'
>>> print(repr(p.value))
b'Hello'
>>> p = create_string_buffer(b"Hello", 10) # create a 10 byte buffer
>>> print(sizeof(p), repr(p.raw))
10 b'Hello\x00\x00\x00\x00\x00'
>>> p.value = b"Hi"
>>> print(sizeof(p), repr(p.raw))
10 b'Hi\x00lo\x00\x00\x00\x00\x00'
>>>
create_string_buffer() 関数は初期の ctypes リリースにあった c_string() 関数だけでなく、 (エイリアスとしてはまだ利用できる) c_buffer() 関数をも置き換えるものです。 C の型 wchar_t の Unicode 文字を含む変更可能なメモリブロックを作成するには、 create_unicode_buffer() 関数を使ってください。
続・関数を呼び出す
printf は sys.stdout では なく 、本物の標準出力チャンネルへプリントすることに注意してください。したがって、これらの例はコンソールプロンプトでのみ動作し、 IDLE や PythonWin では動作しません。:
>>>
>>> printf = libc.printf
>>> printf(b"Hello, %s\n", b"World!")
Hello, World!
14
>>> printf(b"Hello, %S\n", "World!")
Hello, World!
14
>>> printf(b"%d bottles of beer\n", 42)
42 bottles of beer
19
>>> printf(b"%f bottles of beer\n", 42.5)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ArgumentError: argument 2: exceptions.TypeError: Don't know how to convert parameter 2
>>>
前に述べたように、必要な C のデータ型へ変換できるようにするためには、整数、文字列およびバイト列オブジェクトを除くすべての Python 型を対応する ctypes 型でラップしなければなりません:
>>>
>>> printf(b"An int %d, a double %f\n", 1234, c_double(3.14))
An int 1234, a double 3.140000
31
>>>
自作のデータ型とともに関数を呼び出す
自作のクラスのインスタンスを関数引数として使えるように、 ctypes 引数変換をカスタマイズすることもできます。 ctypes は _as_parameter_ 属性を探し出し、関数引数として使います。もちろん、整数、文字列もしくはバイト列オブジェクトの中の一つでなければなりません:
>>>
>>> class Bottles:
...     def __init__(self, number):
...         self._as_parameter_ = number
...
>>> bottles = Bottles(42)
>>> printf(b"%d bottles of beer\n", bottles)
42 bottles of beer
19
>>>
_as_parameter_ インスタンス変数にインスタンスのデータを保持したくない場合は、必要に応じて利用できる属性を作る property を定義しても構いません。
要求される引数の型を指定する (関数プロトタイプ)
argtypes 属性を設定することによって、 DLL からエクスポートされている関数に要求される引数の型を指定することができます。
argtypes は C データ型のシーケンスでなければなりません (この場合 printf 関数はおそらく良い例ではありません。なぜなら、引数の数が可変であり、フォーマット文字列に依存した異なる型のパラメータを取るからです。一方では、この機能の実験にはとても便利です)。:
>>>
>>> printf.argtypes = [c_char_p, c_char_p, c_int, c_double]
>>> printf(b"String '%s', Int %d, Double %f\n", b"Hi", 10, 2.2)
String 'Hi', Int 10, Double 2.200000
37
>>>
(C の関数のプロトタイプのように) 書式を指定すると互換性のない引数型になるのを防ぎ、引数を有効な型へ変換しようとします。:
>>>
>>> printf(b"%d %d %d", 1, 2, 3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ArgumentError: argument 2: exceptions.TypeError: wrong type
>>> printf(b"%s %d %f\n", b"X", 2, 3)
X 2 3.000000
13
>>>
関数呼び出しへ渡す自作のクラスを定義した場合には、 argtypes シーケンスの中で使えるようにするために、そのクラスに from_param() クラスメソッドを実装しなければなりません。 from_param() クラスメソッドは関数呼び出しへ渡された Python オブジェクトを受け取り、型チェックもしくはこのオブジェクトが受け入れ可能であると確かめるために必要なことはすべて行ってから、オブジェクト自身、 _as_parameter_ 属性、あるいは、この場合に C 関数引数として渡したい何かの値を返さなければなりません。繰り返しになりますが、その返される結果は整数、文字列、バイト列、 ctypes インスタンス、あるいは _as_parameter_ 属性をもつオブジェクトであるべきです。
戻り値の型
デフォルトでは、関数は C int を返すと仮定されます。他の戻り値の型を指定するには、関数オブジェクトの restype 属性に設定します。
さらに高度な例として、 strchr 関数を使います。この関数は文字列ポインタと char を受け取り、文字列へのポインタを返します。:
>>>
>>> strchr = libc.strchr
>>> strchr(b"abcdef", ord("d"))  
8059983
>>> strchr.restype = c_char_p    # c_char_p is a pointer to a string
>>> strchr(b"abcdef", ord("d"))
b'def'
>>> print(strchr(b"abcdef", ord("x")))
None
>>>
上の ord("x") 呼び出しを避けたいなら、 argtypes 属性を設定することができます。二番目の引数が一文字の Python バイト列オブジェクトから C の char へ変換されます:
>>>
>>> strchr.restype = c_char_p
>>> strchr.argtypes = [c_char_p, c_char]
>>> strchr(b"abcdef", b"d")
'def'
>>> strchr(b"abcdef", b"def")
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ArgumentError: argument 2: exceptions.TypeError: one character string expected
>>> print(strchr(b"abcdef", b"x"))
None
>>> strchr(b"abcdef", b"d")
'def'
>>>
外部関数が整数を返す場合は、 restype 属性として呼び出し可能な Python オブジェクト (例えば、関数またはクラス) を使うこともできます。呼び出し可能オブジェクトは C 関数が返す 整数 とともに呼び出され、この呼び出しの結果は関数呼び出しの結果として使われるでしょう。これはエラーの戻り値をチェックして自動的に例外を送出させるために役に立ちます。:
>>>
>>> GetModuleHandle = windll.kernel32.GetModuleHandleA  
>>> def ValidHandle(value):
...     if value == 0:
...         raise WinError()
...     return value
...
>>>
>>> GetModuleHandle.restype = ValidHandle  
>>> GetModuleHandle(None)  
486539264
>>> GetModuleHandle("something silly")  
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in ValidHandle
>>>
WinError はエラーコードの文字列表現を得るために Windows の FormatMessage() api を呼び出し、例外を 返す 関数です。 WinError はオプションでエラーコードパラメータを取ります。このパラメータが使われない場合は、エラーコードを取り出すために GetLastError() を呼び出します。
errcheck 属性によってもっと強力なエラーチェック機構を利用できることに注意してください。詳細はリファレンスマニュアルを参照してください。
ポインタを渡す(または、パラメータの参照渡し)
時には、 C api 関数がパラメータのデータ型として ポインタ を想定していることがあります。おそらくパラメータと同一の場所に書き込むためか、もしくはそのデータが大きすぎて値渡しできない場合です。これは パラメータの参照渡し としても知られています。
ctypes は byref() 関数をエクスポートしており、パラメータを参照渡しするために使用します。 pointer() 関数を使っても同じ効果が得られます。しかし、 pointer() は本当のポインタオブジェクトを構築するためより多くの処理を行うことから、 Python 側でポインタオブジェクト自体を必要としないならば byref() を使う方がより高速です。:
>>>
>>> i = c_int()
>>> f = c_float()
>>> s = create_string_buffer(b'\000' * 32)
>>> print(i.value, f.value, repr(s.value))
0 0.0 b''
>>> libc.sscanf(b"1 3.14 Hello", b"%d %f %s",
...             byref(i), byref(f), s)
3
>>> print(i.value, f.value, repr(s.value))
1 3.1400001049 b'Hello'
>>>
構造体と共用体
構造体と共用体は ctypes モジュールに定義されている Structure および Union ベースクラスからの派生クラスでなければなりません。それぞれのサブクラスは _fields_ 属性を定義する必要があります。 _fields_ は フィールド名 と フィールド型 を持つ 2要素タプル のリストでなければなりません。
フィールド型は c_int か他の ctypes 型 (構造体、共用体、配列、ポインタ) から派生した ctypes 型である必要があります。
以下は、 x と y という名前の二つの整数からなる簡単な POINT 構造体の例です。コンストラクタで構造体を初期化する方法も説明しています:
>>>
>>> from ctypes import *
>>> class POINT(Structure):
...     _fields_ = [("x", c_int),
...                 ("y", c_int)]
...
>>> point = POINT(10, 20)
>>> print(point.x, point.y)
10 20
>>> point = POINT(y=5)
>>> print(point.x, point.y)
0 5
>>> POINT(1, 2, 3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: too many initializers
>>>
しかし、もっと複雑な構造体を構築することもできます。ある構造体は、他の構造体をフィールド型として使うことで、他の構造体を含むことができます。
upperleft と lowerright という名前の二つの POINT を持つ RECT 構造体です。:
>>>
>>> class RECT(Structure):
...     _fields_ = [("upperleft", POINT),
...                 ("lowerright", POINT)]
...
>>> rc = RECT(point)
>>> print(rc.upperleft.x, rc.upperleft.y)
0 5
>>> print(rc.lowerright.x, rc.lowerright.y)
0 0
>>>
入れ子になった構造体はいくつかの方法を用いてコンストラクタで初期化することができます。:
>>>
>>> r = RECT(POINT(1, 2), POINT(3, 4))
>>> r = RECT((1, 2), (3, 4))
フィールド descriptor (記述子)は クラス から取り出せます。デバッグするときに役に立つ情報を得ることができます:
>>>
>>> print(POINT.x)
<Field type=c_long, ofs=0, size=4>
>>> print(POINT.y)
<Field type=c_long, ofs=4, size=4>
>>>
警告 ctypes では、ビットフィールドのある共用体や構造体の関数への値渡しはサポートしていません。これは 32-bit の x86 環境では動くかもしれませんが、このライブラリでは一般の場合に動作することは保証していません。
構造体/共用体アライメントとバイトオーダー
デフォルトでは、構造体 (Structure) と共用体(Union) のフィールドは C コンパイラが行うのと同じ方法でアライメントされています。サブクラスを定義するときに _pack_ クラス属性を指定することでこの動作を変えることは可能です。このクラス属性には正の整数を設定する必要があり、フィールドの最大アライメントを指定します。これは MSVC で #pragma pack(n) が行っていること同じです。
ctypes は Structure と Union に対してネイティブのバイトオーダーを使います。ネイティブではないバイトオーダーの構造体を作成するには、 BigEndianStructure, LittleEndianStructure, BigEndianUnion および LittleEndianUnion ベースクラスの中の一つを使います。これらのクラスにポインタフィールドを持たせることはできません。
構造体と共用体におけるビットフィールド
ビットフィールドを含む構造体と共用体を作ることができます。ビットフィールドは整数フィールドに対してのみ作ることができ、ビット幅は _fields_ タプルの第三要素で指定します。:
>>>
>>> class Int(Structure):
...     _fields_ = [("first_16", c_int, 16),
...                 ("second_16", c_int, 16)]
...
>>> print(Int.first_16)
<Field type=c_long, ofs=0:0, bits=16>
>>> print(Int.second_16)
<Field type=c_long, ofs=0:16, bits=16>
>>>
配列
配列 (Array) はシーケンスであり、決まった数の同じ型のインスタンスを持ちます。
推奨されている配列の作成方法はデータ型に正の整数を掛けることです。:
TenPointsArrayType = POINT * 10
ややわざとらしいデータ型の例になりますが、他のものに混ざって 4 個の POINT がある構造体です:
>>>
>>> from ctypes import *
>>> class POINT(Structure):
...     _fields_ = ("x", c_int), ("y", c_int)
...
>>> class MyStruct(Structure):
...     _fields_ = [("a", c_int),
...                 ("b", c_float),
...                 ("point_array", POINT * 4)]
>>>
>>> print(len(MyStruct().point_array))
4
>>>
インスタンスはクラスを呼び出す通常の方法で作成します。:
arr = TenPointsArrayType()
for pt in arr:
    print(pt.x, pt.y)
上記のコードは 0 0 という行が並んだものを表示します。配列の要素がゼロで初期化されているためです。
正しい型の初期化子を指定することもできます。:
>>>
>>> from ctypes import *
>>> TenIntegers = c_int * 10
>>> ii = TenIntegers(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
>>> print(ii)
<c_long_Array_10 object at 0x...>
>>> for i in ii: print(i, end=" ")
...
1 2 3 4 5 6 7 8 9 10
>>>
ポインタ
ポインタのインスタンスは ctypes 型に対して pointer() 関数を呼び出して作成します。:
>>>
>>> from ctypes import *
>>> i = c_int(42)
>>> pi = pointer(i)
>>>
次のように、ポインタインスタンスは、ポインタが指すオブジェクト (上の例では i) を返す contents 属性を持ちます:
>>>
>>> pi.contents
c_long(42)
>>>
ctypes は OOR (original object return 、元のオブジェクトを返すこと) ではないことに注意してください。属性を取り出す度に、新しい同等のオブジェクトを作成しているのです。:
>>>
>>> pi.contents is i
False
>>> pi.contents is pi.contents
False
>>>
別の c_int インスタンスがポインタの contents 属性に代入されると、これが記憶されているメモリ位置を指すポインタに変化します。:
>>>
>>> i = c_int(99)
>>> pi.contents = i
>>> pi.contents
c_long(99)
>>>
ポインタインスタンスは整数でインデックス指定することもできます。:
>>>
>>> pi[0]
99
>>>
整数インデックスへ代入するとポインタが指す値が変更されます。:
>>>
>>> print(i)
c_long(99)
>>> pi[0] = 22
>>> print(i)
c_long(22)
>>>
0 ではないインデックスを使うこともできますが、 C の場合と同じように自分が何をしているかを理解している必要があります。任意のメモリ位置にアクセスもしくは変更できるのです。一般的にこの機能を使うのは、 C 関数からポインタを受け取り、そのポインタが単一の要素ではなく実際に配列を指していると 分かっている 場合だけです。
舞台裏では、 pointer() 関数は単にポインタインスタンスを作成するという以上のことを行っています。はじめにポインタ 型 を作成する必要があります。これは任意の ctypes 型を受け取る POINTER() 関数を使って行われ、新しい型を返します:
>>>
>>> PI = POINTER(c_int)
>>> PI
<class 'ctypes.LP_c_long'>
>>> PI(42)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: expected c_long instead of int
>>> PI(c_int(42))
<ctypes.LP_c_long object at 0x...>
>>>
ポインタ型を引数なしで呼び出すと NULL ポインタを作成します。 NULL ポインタは False ブール値を持っています。:
>>>
>>> null_ptr = POINTER(c_int)()
>>> print(bool(null_ptr))
False
>>>
ctypes はポインタの指す値を取り出すときに NULL かどうかを調べます(しかし、 NULL でない不正なポインタの指す値の取り出す行為は Python をクラッシュさせるでしょう)。:
>>>
>>> null_ptr[0]
Traceback (most recent call last):
    ....
ValueError: NULL pointer access
>>>
>>> null_ptr[0] = 1234
Traceback (most recent call last):
    ....
ValueError: NULL pointer access
>>>
型変換
たいていの場合、 ctypes は厳密な型チェックを行います。これが意味するのは、関数の argtypes リスト内に、もしくは、構造体定義におけるメンバーフィールドの型として POINTER(c_int) がある場合、厳密に同じ型のインスタンスだけを受け取るということです。このルールには ctypes が他のオブジェクトを受け取る場合に例外がいくつかあります。例えば、ポインタ型の代わりに互換性のある配列インスタンスを渡すことができます。このように、 POINTER(c_int) に対して、 ctypes は c_int の配列を受け取ります。:
>>>
>>> class Bar(Structure):
...     _fields_ = [("count", c_int), ("values", POINTER(c_int))]
...
>>> bar = Bar()
>>> bar.values = (c_int * 3)(1, 2, 3)
>>> bar.count = 3
>>> for i in range(bar.count):
...     print(bar.values[i])
...
1
2
3
>>>
それに加えて、 argtypes で関数の引数が明示的に (POINTER(c_int) などの) ポインタ型であると宣言されていた場合、ポインタ型が指し示している型のオブジェクト (この場合では c_int) を関数に渡すことができます。この場合 ctypes は、必要となる byref() での変換を自動的に適用します。
POINTER型フィールドを NULL に設定するために、 None を代入してもかまいません。:
>>>
>>> bar.values = None
>>>
時には、非互換な型のインスタンスであることもあります。 C では、ある型を他の型へキャストすることができます。 ctypes は同じやり方で使える cast() 関数を提供しています。上で定義した Bar 構造体は POINTER(c_int) ポインタまたは c_int 配列を values フィールドに対して受け取り、他の型のインスタンスは受け取りません:
>>>
>>> bar.values = (c_byte * 4)()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: incompatible types, c_byte_Array_4 instance instead of LP_c_long instance
>>>
このような場合には、 cast() 関数が便利です。
cast() 関数は ctypes インスタンスを異なる ctypes データ型を指すポインタへキャストするために使えます。 cast() は二つのパラメータ、ある種のポインタかそのポインタへ変換できる ctypes オブジェクトと、 ctypes ポインタ型を取ります。そして、第二引数のインスタンスを返します。このインスタンスは第一引数と同じメモリブロックを参照しています:
>>>
>>> a = (c_byte * 4)()
>>> cast(a, POINTER(c_int))
<ctypes.LP_c_long object at ...>
>>>
したがって、 cast() を Bar 構造体の values フィールドへ代入するために使うことができます:
>>>
>>> bar = Bar()
>>> bar.values = cast((c_byte * 4)(), POINTER(c_int))
>>> print(bar.values[0])
0
>>>
不完全型
不完全型 はメンバーがまだ指定されていない構造体、共用体もしくは配列です。 C では、前方宣言により指定され、後で定義されます。:
struct cell; /* forward declaration */
struct cell {
    char *name;
    struct cell *next;
};
ctypes コードへの直接的な変換ではこうなるでしょう。しかし、動作しません:
>>>
>>> class cell(Structure):
...     _fields_ = [("name", c_char_p),
...                 ("next", POINTER(cell))]
...
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 2, in cell
NameError: name 'cell' is not defined
>>>
なぜなら、新しい class cell はクラス文自体の中では利用できないからです。 ctypes では、 cell クラスを定義して、 _fields_ 属性をクラス文の後で設定することができます。:
>>>
>>> from ctypes import *
>>> class cell(Structure):
...     pass
...
>>> cell._fields_ = [("name", c_char_p),
...                  ("next", POINTER(cell))]
>>>
試してみましょう。 cell のインスタンスを二つ作り、互いに参照し合うようにします。最後に、つながったポインタを何度かたどります。:
>>>
>>> c1 = cell()
>>> c1.name = "foo"
>>> c2 = cell()
>>> c2.name = "bar"
>>> c1.next = pointer(c2)
>>> c2.next = pointer(c1)
>>> p = c1
>>> for i in range(8):
...     print(p.name, end=" ")
...     p = p.next[0]
...
foo bar foo bar foo bar foo bar
>>>
コールバック関数
ctypes は C の呼び出し可能な関数ポインタを Python 呼び出し可能オブジェクトから作成できるようにします。これらは コールバック関数 と呼ばれることがあります。
最初に、コールバック関数のためのクラスを作る必要があります。そのクラスには呼び出し規約、戻り値の型およびこの関数が受け取る引数の数と型についての情報があります。
CFUNCTYPE() ファクトリ関数は通常の cdecl 呼び出し規約を用いてコールバック関数のための型を作成します。 Windows では、 WINFUNCTYPE() ファクトリ関数が stdcall 呼び出し規約を用いてコールバック関数の型を作成します。
これらのファクトリ関数はともに最初の引数に戻り値の型、残りの引数としてコールバック関数が想定する引数の型を渡して呼び出されます。
標準 C ライブラリの qsort() 関数を使う例を示します。これはコールバック関数の助けをかりて要素をソートするために使われます。 qsort() は整数の配列をソートするために使われます:
>>>
>>> IntArray5 = c_int * 5
>>> ia = IntArray5(5, 1, 7, 33, 99)
>>> qsort = libc.qsort
>>> qsort.restype = None
>>>
qsort() はソートするデータを指すポインタ、データ配列の要素の数、要素の一つの大きさ、およびコールバック関数である比較関数へのポインタを引数に渡して呼び出さなければなりません。そして、コールバック関数は要素を指す二つのポインタを渡されて呼び出され、一番目が二番目より小さいなら負の数を、等しいならゼロを、それ以外なら正の数を返さなければなりません。
コールバック関数は整数へのポインタを受け取り、整数を返す必要があります。まず、コールバック関数のための type を作成します。:
>>>
>>> CMPFUNC = CFUNCTYPE(c_int, POINTER(c_int), POINTER(c_int))
>>>
まず初めに、これが受け取った変数を表示するだけのシンプルなコールバックです:
>>>
>>> def py_cmp_func(a, b):
...     print("py_cmp_func", a[0], b[0])
...     return 0
...
>>> cmp_func = CMPFUNC(py_cmp_func)
>>>
結果は以下の通りです:
>>>
>>> qsort(ia, len(ia), sizeof(c_int), cmp_func)  
py_cmp_func 5 1
py_cmp_func 33 99
py_cmp_func 7 33
py_cmp_func 5 7
py_cmp_func 1 7
>>>
ここで 2 つの要素を実際に比較し、役に立つ結果を返します:
>>>
>>> def py_cmp_func(a, b):
...     print("py_cmp_func", a[0], b[0])
...     return a[0] - b[0]
...
>>>
>>> qsort(ia, len(ia), sizeof(c_int), CMPFUNC(py_cmp_func)) 
py_cmp_func 5 1
py_cmp_func 33 99
py_cmp_func 7 33
py_cmp_func 1 7
py_cmp_func 5 7
>>>
簡単に確認できるように、配列を次のようにソートしました:
>>>
>>> for i in ia: print(i, end=" ")
...
1 5 7 33 99
>>>
関数ファクトリはデコレータファクトリとしても使えるので、次のようにも書けます:
>>>
>>> @CFUNCTYPE(c_int, POINTER(c_int), POINTER(c_int))
... def py_cmp_func(a, b):
...     print("py_cmp_func", a[0], b[0])
...     return a[0] - b[0]
...
>>> qsort(ia, len(ia), sizeof(c_int), py_cmp_func)
py_cmp_func 5 1
py_cmp_func 33 99
py_cmp_func 7 33
py_cmp_func 1 7
py_cmp_func 5 7
>>>
注釈 C コードから CFUNCTYPE() オブジェクトが使用される限り、そのオブジェクトへの参照を確実に保持してください。 ctypes は参照を保持しないため、あなたが参照を保持しないと、オブジェクトはガベージコレクションの対象となり、コールバックが行われたときにプログラムをクラッシュさせる場合があります。
同様に、コールバック関数が Python の管理外 (例えば、コールバックを呼び出す外部のコード) で作られたスレッドで呼び出された場合、 ctypes は全ての呼び出しごとに新しいダミーの Python スレッドを作成することに注意してください。 この動作はほとんどの目的に対して正しいものですが、同じ C スレッドからの呼び出しだったとしても、 threading.local で格納された値は異なるコールバックをまたいで生存は しません 。
dllからエクスポートされた値へアクセスする
共有ライブラリの一部は関数だけでなく変数もエクスポートしています。 Python ライブラリにある例としては Py_OptimizeFlag 、起動時の -O または -OO フラグに依存して、 0 , 1 または 2 が設定される整数があります。
ctypes は型の in_dll() クラスメソッドを使ってこのように値にアクセスできます。 pythonapi はPython C api へアクセスできるようにするための予め定義されたシンボルです。:
>>>
>>> opt_flag = c_int.in_dll(pythonapi, "Py_OptimizeFlag")
>>> print(opt_flag)
c_long(0)
>>>
インタープリタが -O を指定されて動き始めた場合、サンプルは c_long(1) を表示するでしょうし、 -OO が指定されたならば c_long(2) を表示するでしょう。
ポインタの使い方を説明する拡張例では、 Python がエクスポートする PyImport_FrozenModules ポインタにアクセスします。
この値のドキュメントから引用すると:
このポインタは struct _frozen のレコードからなり、終端の要素のメンバが NULL かゼロになっているような配列を指すよう初期化されます。 フリーズされたモジュールをインポートするとき、このテーブルを検索します。 サードパーティ製のコードからこのポインタに仕掛けを講じて、動的に生成されたフリーズ化モジュールの集合を提供するようにできます。
これで、このポインタを操作することが役に立つことを証明できるでしょう。例の大きさを制限するために、このテーブルを ctypes を使って読む方法だけを示します。:
>>>
>>> from ctypes import *
>>>
>>> class struct_frozen(Structure):
...     _fields_ = [("name", c_char_p),
...                 ("code", POINTER(c_ubyte)),
...                 ("size", c_int)]
...
>>>
私たちは struct _frozen データ型を定義済みなので、このテーブルを指すポインタを得ることができます:
>>>
>>> FrozenTable = POINTER(struct_frozen)
>>> table = FrozenTable.in_dll(pythonapi, "PyImport_FrozenModules")
>>>
table が struct_frozen レコードの配列への pointer なので、その配列に対して反復処理を行えます。しかし、ループが確実に終了するようにする必要があります。なぜなら、ポインタに大きさの情報がないからです。遅かれ早かれ、アクセス違反か何かでクラッシュすることになるでしょう。 NULL エントリに達したときはループを抜ける方が良いです:
>>>
>>> for item in table:
...     if item.name is None:
...         break
...     print(item.name.decode("ascii"), item.size)
...
_frozen_importlib 31764
_frozen_importlib_external 41499
__hello__ 161
__phello__ -161
__phello__.spam 161
>>>
標準 Python はフローズンモジュールとフローズンパッケージ (負の size メンバーで表されています) を持っているという事実はあまり知られておらず、テストにだけ使われています。例えば、 import __hello__ を試してみてください。
びっくり仰天
次に示す例について考えてみてください。:
>>>
>>> from ctypes import *
>>> class POINT(Structure):
...     _fields_ = ("x", c_int), ("y", c_int)
...
>>> class RECT(Structure):
...     _fields_ = ("a", POINT), ("b", POINT)
...
>>> p1 = POINT(1, 2)
>>> p2 = POINT(3, 4)
>>> rc = RECT(p1, p2)
>>> print(rc.a.x, rc.a.y, rc.b.x, rc.b.y)
1 2 3 4
>>> # now swap the two points
>>> rc.a, rc.b = rc.b, rc.a
>>> print(rc.a.x, rc.a.y, rc.b.x, rc.b.y)
3 4 3 4
>>>
うーん、最後の文に 3 4 1 2 と表示されることを期待していたはずです。何が起きたのでしょうか? 上の行の rc.a, rc.b = rc.b, rc.a の各段階はこのようになります。:
>>>
>>> temp0, temp1 = rc.b, rc.a
>>> rc.a = temp0
>>> rc.b = temp1
>>>
temp0 と temp1 は前記の rc オブジェクトの内部バッファでまだ使われているオブジェクトです。したがって、 rc.a = temp0 を実行すると temp0 のバッファ内容が rc のバッファへコピーされます。さらに、これは temp1 の内容を変更します。そのため、最後の代入 rc.b = temp1 は、期待する結果にはならないのです。
Structure 、 Union および Array のサブオブジェクトを取り出しても、そのサブオブジェクトが コピー されるわけではなく、ルートオブジェクトの内部バッファにアクセスするラッパーオブジェクトを取り出すことを覚えておいてください。
期待とは違う振る舞いをする別の例はこれです:
>>>
>>> s = c_char_p()
>>> s.value = b"abc def ghi"
>>> s.value
b'abc def ghi'
>>> s.value is s.value
False
>>>
注釈 c_char_p からインスタンス化されたオブジェクトは、bytes または整数に設定された値しか持てません。
なぜ False と表示されるのでしょうか? ctypes インスタンスはメモリと、メモリの内容にアクセスするいくつかの descriptor (記述子)を含むオブジェクトです。メモリブロックに Python オブジェクトを保存してもオブジェクト自身が保存される訳ではなく、オブジェクトの contents が保存されます。その contents に再アクセスすると新しい Python オブジェクトがその度に作られます。
可変サイズのデータ型
ctypes は可変サイズの配列と構造体をサポートしています。
resize() 関数は既存の ctypes オブジェクトのメモリバッファのサイズを変更したい場合に使えます。この関数は第一引数にオブジェクト、第二引数に要求されたサイズをバイト単位で指定します。メモリブロックはオブジェクト型で指定される通常のメモリブロックより小さくすることはできません。これをやろうとすると、 ValueError が送出されます。:
>>>
>>> short_array = (c_short * 4)()
>>> print(sizeof(short_array))
8
>>> resize(short_array, 4)
Traceback (most recent call last):
    ...
ValueError: minimum size is 8
>>> resize(short_array, 32)
>>> sizeof(short_array)
32
>>> sizeof(type(short_array))
8
>>>
これはこれで上手くいっていますが、この配列の追加した要素へどうやってアクセスするのでしょうか? この型は要素の数が 4 個であるとまだ認識しているので、他の要素にアクセスするとエラーになります。:
>>>
>>> short_array[:]
[0, 0, 0, 0]
>>> short_array[7]
Traceback (most recent call last):
    ...
IndexError: invalid index
>>>
ctypes で可変サイズのデータ型を使うもう一つの方法は、必要なサイズが分かった後に Python の動的性質を使って一つ一つデータ型を(再)定義することです。
ctypesリファレンス
共有ライブラリを見つける
コンパイルされる言語でプログラミングしている場合、共有ライブラリはプログラムをコンパイル/リンクしているときと、そのプログラムが動作しているときにアクセスされます。
ctypes ライブラリローダーはプログラムが動作しているときのように振る舞い、ランタイムローダーを直接呼び出すのに対し、 find_library() 関数の目的はコンパイラまたはランタイムローダーが行うのと似た方法でライブラリを探し出すことです。 (複数のバージョンの共有ライブラリがあるプラットホームでは、一番最近に見つかったものがロードされます)。
ctypes.util モジュールはロードするライブラリを決めるのに役立つ関数を提供します。
ctypes.util.find_library(name)
ライブラリを見つけてパス名を返そうと試みます。 name は lib のような接頭辞、 .so, .dylib のような接尾辞、あるいは、バージョン番号が何も付いていないライブラリの名前です (これは posix リンカのオプション -l に使われている形式です)。 ライブラリが見つからないときは None を返します。
厳密な機能はシステムに依存します。
Linux では、 find_library() はライブラリファイルを見つけるために外部プログラム (/sbin/ldconfig, gcc, objdump と ld) を実行しようとします。ライブラリファイルのファイル名を返します。
バージョン 3.6 で変更: Linux では、ライブラリを検索する際に、他の方法でライブラリが見つけられない場合は、 LD_LIBRARY_PATH 環境変数の値が使われます
ここに例があります:
>>>
>>> from ctypes.util import find_library
>>> find_library("m")
'libm.so.6'
>>> find_library("c")
'libc.so.6'
>>> find_library("bz2")
'libbz2.so.1.0'
>>>
OS X では、 find_library() はライブラリの位置を探すために、予め定義された複数の命名方法とパスを試し、成功すればフルパスを返します。:
>>>
>>> from ctypes.util import find_library
>>> find_library("c")
'/usr/lib/libc.dylib'
>>> find_library("m")
'/usr/lib/libm.dylib'
>>> find_library("bz2")
'/usr/lib/libbz2.dylib'
>>> find_library("AGL")
'/System/Library/Frameworks/AGL.framework/AGL'
>>>
Windows では、 find_library() はシステムの探索パスに沿って探し、フルパスを返します。しかし、予め定義された命名方法がないため、 find_library("c") のような呼び出しは失敗し、 None を返します。
ctypes で共有ライブラリをラップする場合、 find_library() を使って実行時にライブラリの場所を特定するのではなく、共有ライブラリの名前を開発時に決めておいて、ラッパーモジュールにハードコードする方が良い かもしれません 。
共有ライブラリをロードする
共有ライブラリを Python プロセスへロードする方法はいくつかあります。一つの方法は下記のクラスの一つをインスタンス化することです:
class ctypes.CDLL(name, mode=DEFAULT_MODE, handle=None, use_errno=False, use_last_error=False, winmode=0)
このクラスのインスタンスはロードされた共有ライブラリをあらわします。これらのライブラリの関数は標準 C 呼び出し規約を使用し、 int を返すと仮定されます。
参考 Microsoft DUMPBIN tool -- A tool to find DLL dependents.
class ctypes.OleDLL(name, mode=DEFAULT_MODE, handle=None, use_errno=False, use_last_error=False, winmode=0)
Windows 用: このクラスのインスタンスはロードされた共有ライブラリをあらわします。これらのライブラリの関数は stdcall 呼び出し規約を使用し、 windows 固有の HRESULT コードを返すと仮定されます。 HRESULT 値には関数呼び出しが失敗したのか成功したのかを特定する情報とともに、補足のエラーコードが含まれます。戻り値が失敗を知らせたならば、 OSError が自動的に送出されます。
バージョン 3.3 で変更: 以前は WindowsError を送出していました。
class ctypes.WinDLL(name, mode=DEFAULT_MODE, handle=None, use_errno=False, use_last_error=False, winmode=0)
Windows 用: このクラスのインスタンスはロードされた共有ライブラリをあらわします。これらのライブラリの関数は stdcall 呼び出し規約を使用し、デフォルトでは int を返すと仮定されます。
Windows CE では標準呼び出し規約だけが使われます。便宜上、このプラットフォームでは、 WinDLL と OleDLL が標準呼び出し規約を使用します。
これらのライブラリがエクスポートするどの関数でも呼び出す前に Python global interpreter lock は解放され、後でまた獲得されます。
class ctypes.PyDLL(name, mode=DEFAULT_MODE, handle=None)
Python GIL が関数呼び出しの間解放 されず 、関数実行の後に Python エラーフラグがチェックされるということを除けば、このクラスのインスタンスは CDLL インスタンスのように振る舞います。エラーフラグがセットされた場合、 Python 例外が送出されます。
要するに、これは Python C api 関数を直接呼び出すのに便利だというだけです。
これらすべてのクラスは少なくとも一つの引数、すなわちロードする共有ライブラリのパスを渡して呼び出すことでインスタンス化されます。すでにロード済みの共有ライブラリへのハンドルがあるなら、 handle 名前付き引数として渡すことができます。土台となっているプラットフォームの dlopen または LoadLibrary 関数がプロセスへライブラリをロードするために使われ、そのライブラリに対するハンドルを得ます。
mode パラメータを使うと、ライブラリがどうやってロードされたかを特定できます。 詳細は dlopen(3) マニュアルページを参考にしてください。 Windows では mode は無視されます。 POSIX システムでは RTLD_NOW が常に追加され、設定変更はできません。
use_errno 変数が真に設定されたとき、システムの errno エラーナンバーに安全にアクセスする ctypes の仕組みが有効化されます。 ctypes はシステムの errno 変数のスレッド限定のコピーを管理します。もし、 use_errno=True の状態で作られた外部関数を呼び出したなら、関数呼び出し前の errno 変数は ctypes のプライベートコピーと置き換えられ、同じことが関数呼び出しの直後にも発生します。
ctypes.get_errno() 関数は ctypes のプライベートコピーの値を返します。そして、 ctypes.set_errno() 関数は ctypes のプライベートコピーを置き換え、以前の値を返します。
use_last_error パラメータは、真に設定されたとき、 GetLastError() と SetLastError() Windows API によって管理される Windows エラーコードに対するのと同じ仕組みが有効化されます。 ctypes.get_last_error() と ctypes.set_last_error() は Windows エラーコードの ctypes プライベートコピーを変更したり要求したりするのに使われます。
バージョン 3.8 で変更: Added winmode parameter.
ctypes.RTLD_GLOBAL
mode パラメータとして使うフラグ。このフラグが利用できないプラットフォームでは、整数のゼロと定義されています。
ctypes.RTLD_LOCAL
mode パラメータとして使うフラグ。これが利用できないプラットフォームでは、 RTLD_GLOBAL と同様です。
ctypes.DEFAULT_MODE
共有ライブラリをロードするために使われるデフォルトモード。 OSX 10.3 では RTLD_GLOBAL であり、そうでなければ RTLD_LOCAL と同じです。
これらのクラスのインスタンスには公開メソッドはありません。 共有ライブラリからエクスポートされた関数は、属性として、もしくは添字でアクセスできます。 属性を通した関数へのアクセスは結果がキャッシュされ、従って繰り返しアクセスされると毎回同じオブジェクトを返すことに注意してください。 それとは反対に、添字を通したアクセスは毎回新しいオブジェクトを返します:
>>>
>>> from ctypes import CDLL
>>> libc = CDLL("libc.so.6")  # On Linux
>>> libc.time == libc.time
True
>>> libc['time'] == libc['time']
False
次に述べる公開属性が利用できます。それらの名前はエクスポートされた関数名に衝突しないように下線で始まります。:
PyDLL._handle
ライブラリへのアクセスに用いられるシステムハンドル。
PyDLL._name
コンストラクタに渡されたライブラリの名前。
共有ライブラリは (LibraryLoader クラスのインスタンスである) 前もって作られたオブジェクトの一つを使うことによってロードすることもできます。それらの LoadLibrary() メソッドを呼び出すか、ローダーインスタンスの属性としてライブラリを取り出すかのどちらかによりロードします。
class ctypes.LibraryLoader(dlltype)
共有ライブラリをロードするクラス。 dlltype は CDLL 、 PyDLL 、 WinDLL もしくは OleDLL 型の一つであるべきです。
__getattr__() は次のような特別なはたらきをします。ライブラリローダーインスタンスの属性として共有ライブラリにアクセスするとそれがロードされるということを可能にします。結果はキャッシュされます。そのため、繰り返し属性アクセスを行うといつも同じライブラリが返されます。
LoadLibrary(name)
共有ライブラリをプロセスへロードし、それを返します。このメソッドはライブラリの新しいインスタンスを常に返します。
これらの前もって作られたライブラリローダーを利用することができます。:
ctypes.cdll
CDLL インスタンスを作ります。
ctypes.windll
Windows 用: WinDLL インスタンスを作ります。
ctypes.oledll
Windows 用: OleDLL インスタンスを作ります。
ctypes.pydll
PyDLL インスタンスを作ります。
C Python api に直接アクセスするために、すぐに使用できる Python 共有ライブラリオブジェクトが次のように用意されています。
ctypes.pythonapi
属性として Python C api 関数を公開する PyDLL のインスタンス。これらすべての関数は C int を返すと仮定されますが、もちろん常に正しいとは限りません。そのため、これらの関数を使うためには正しい restype 属性を代入しなければなりません。
外部関数
前節で説明した通り、外部関数はロードされた共有ライブラリの属性としてアクセスできます。デフォルトではこの方法で作成された関数オブジェクトはどんな数の引数でも受け取り、引数としてどんな ctypes データのインスタンスをも受け取り、そして、ライブラリローダーが指定したデフォルトの結果の値の型を返します。関数オブジェクトはプライベートクラスのインスタンスです。:
class ctypes._FuncPtr
C の呼び出し可能外部関数のためのベースクラス。
外部関数のインスタンスも C 互換データ型です。それらは C の関数ポインタを表しています。
この振る舞いは外部関数オブジェクトの特別な属性に代入することによって、カスタマイズすることができます。
restype
外部関数の結果の型を指定するために ctypes 型を代入する。何も返さない関数を表す void に対しては None を使います。
ctypes 型ではない呼び出し可能な Python オブジェクトを代入することは可能です。このような場合、関数が C int を返すと仮定され、呼び出し可能オブジェクトはこの整数を引数に呼び出されます。さらに処理を行ったり、エラーチェックをしたりできるようにするためです。これの使用は推奨されません。より柔軟な後処理やエラーチェックのためには restype として ctypes 型を使い、 errcheck 属性へ呼び出し可能オブジェクトを代入してください。
argtypes
関数が受け取る引数の型を指定するために ctypes 型のタプルを代入します。stdcall 呼び出し規約を使う関数はこのタプルの長さと同じ数の引数で呼び出されます。C 呼び出し規約を使う関数は、追加の不特定の引数も取ります。
外部関数が呼ばれたとき、それぞれの実引数は argtypes タプルの要素の from_param() クラスメソッドへ渡されます。このメソッドは実引数を外部関数が受け取るオブジェクトに合わせて変えられるようにします。例えば、 argtypes タプルの c_char_p 要素は、 ctypes 変換規則にしたがって引数として渡された文字列をバイト列オブジェクトへ変換するでしょう。
新: ctypes 型でない要素を argtypes に入れることができますが、個々の要素は引数として使える値 (整数、文字列、 ctypes インスタンス) を返す from_param() メソッドを持っていなければなりません。これにより関数パラメータとしてカスタムオブジェクトを適合するように変更できるアダプタが定義可能となります。
errcheck
Python 関数または他の呼び出し可能オブジェクトをこの属性に代入します。呼び出し可能オブジェクトは三つ以上の引数とともに呼び出されます。
callable(result, func, arguments)
result は外部関数が返すもので、 restype 属性で指定されます。
func は外部関数オブジェクト自身で、これにより複数の関数の処理結果をチェックまたは後処理するために、同じ呼び出し可能オブジェクトを再利用できるようになります。
arguments は関数呼び出しに最初に渡されたパラメータが入ったタプルです。これにより使われた引数に基づいた特別な振る舞いをさせることができるようになります。
この関数が返すオブジェクトは外部関数呼び出しから返された値でしょう。しかし、戻り値をチェックして、外部関数呼び出しが失敗しているなら例外を送出させることもできます。
exception ctypes.ArgumentError
この例外は外部関数呼び出しが渡された引数を変換できなかったときに送出されます。
関数プロトタイプ
外部関数は関数プロトタイプをインスタンス化することによって作成されます。 関数プロトタイプは C の関数プロトタイプと似ています。実装は定義せずに、関数 (返り値の型、引数の型、呼び出し規約) を記述します。 ファクトリ関数は、その関数に要求される返り値の型と引数の型とともに呼び出されます。そしてこの関数はデコレータファクトリとしても使え、 @wrapper 構文で他の関数に適用できます。 例については コールバック関数 を参照してください。
ctypes.CFUNCTYPE(restype, *argtypes, use_errno=False, use_last_error=False)
返された関数プロトタイプは標準 C 呼び出し規約をつかう関数を作成します。関数は呼び出されている間 GIL を解放します。 use_errno が真に設定されれば、呼び出しの前後で System 変数 errno の ctypesプライベートコピーは本当の errno の値と交換されます。 use_last_error も Windows エラーコードに対するのと同様です。
ctypes.WINFUNCTYPE(restype, *argtypes, use_errno=False, use_last_error=False)
Windows のみ: 返された関数プロトタイプは stdcall 呼び出し規約を使う関数を作成します。ただし、 WINFUNCTYPE() が CFUNCTYPE() と同じである Windows CE を除きます。関数は呼び出されている間 GIL を解放します。 use_errno と use_last_error は前述と同じ意味を持ちます。
ctypes.PYFUNCTYPE(restype, *argtypes)
返された関数プロトタイプは Python 呼び出し規約を使う関数を作成します。関数は呼び出されている間 GIL を解放 しません。
ファクトリ関数によって作られた関数プロトタイプは呼び出しのパラメータの型と数に依存した別の方法でインスタンス化することができます。 :
prototype(address)
指定されたアドレス(整数でなくてはなりません)の外部関数を返します。
prototype(callable)
Python の callable から C の呼び出し可能関数(コールバック関数) を作成します。
prototype(func_spec[, paramflags])
共有ライブラリがエクスポートしている外部関数を返します。 func_spec は 2 要素タプル (name_or_ordinal, library) でなければなりません。第一要素はエクスポートされた関数の名前である文字列、またはエクスポートされた関数の序数である小さい整数です。第二要素は共有ライブラリインスタンスです。
prototype(vtbl_index, name[, paramflags[, iid]])
COM メソッドを呼び出す外部関数を返します。 vtbl_index は仮想関数テーブルのインデックスで、非負の小さい整数です。 name は COM メソッドの名前です。 iid はオプションのインターフェイス識別子へのポインタで、拡張されたエラー情報の提供のために使われます。
COM メソッドは特殊な呼び出し規約を用います。このメソッドは argtypes タプルに指定されたパラメータに加えて、第一引数として COM インターフェイスへのポインタを必要とします。
オプションの paramflags パラメータは上述した機能より多機能な外部関数ラッパーを作成します。
paramflags は argtypes と同じ長さのタプルでなければなりません。
このタプルの個々の要素はパラメータについてのより詳細な情報を持ち、 1 、 2 もしくは 3 要素を含むタプルでなければなりません。
第一要素はパラメータについてのフラグの組み合わせを含んだ整数です。
1
入力パラメータを関数に指定します。
2
出力パラメータ。外部関数が値を書き込みます。
4
デフォルトで整数ゼロになる入力パラメータ。
オプションの第二要素はパラメータ名の文字列です。これが指定された場合は、外部関数を名前付きパラメータで呼び出すことができます。
オプションの第三要素はこのパラメータのデフォルト値です。
この例では、デフォルトパラメータと名前付き引数をサポートするために Windows の MessageBoxW 関数をラップする方法を示します。 windows のヘッダファイルの C の宣言は次の通りです:
WINUSERAPI int WINAPI
MessageBoxW(
    HWND hWnd,
    LPCWSTR lpText,
    LPCWSTR lpCaption,
    UINT uType);
ctypes を使ってラップします。:
>>>
>>> from ctypes import c_int, WINFUNCTYPE, windll
>>> from ctypes.wintypes import HWND, LPCWSTR, UINT
>>> prototype = WINFUNCTYPE(c_int, HWND, LPCWSTR, LPCWSTR, UINT)
>>> paramflags = (1, "hwnd", 0), (1, "text", "Hi"), (1, "caption", "Hello from ctypes"), (1, "flags", 0)
>>> MessageBox = prototype(("MessageBoxW", windll.user32), paramflags)
これで外部関数の MessageBox を次のような方法で呼び出すことができるようになりました:
>>>
>>> MessageBox()
>>> MessageBox(text="Spam, spam, spam")
>>> MessageBox(flags=2, text="foo bar")
二番目の例は出力パラメータについて説明します。 win32 の GetWindowRect 関数は、指定されたウィンドウの大きさを呼び出し側が与える RECT 構造体へコピーすることで取り出します。 C の宣言はこうです。:
WINUSERAPI BOOL WINAPI
GetWindowRect(
     HWND hWnd,
     LPRECT lpRect);
ctypes を使ってラップします。:
>>>
>>> from ctypes import POINTER, WINFUNCTYPE, windll, WinError
>>> from ctypes.wintypes import BOOL, HWND, RECT
>>> prototype = WINFUNCTYPE(BOOL, HWND, POINTER(RECT))
>>> paramflags = (1, "hwnd"), (2, "lprect")
>>> GetWindowRect = prototype(("GetWindowRect", windll.user32), paramflags)
>>>
出力パラメータを持つ関数は、単一のパラメータがある場合にはその出力パラメータ値を、複数のパラメータがある場合には出力パラメータ値が入ったタプルを、それぞれ自動的に返します。そのため、GetWindowRect 関数は呼び出されると RECT インスタンスを返します。
さらに出力処理やエラーチェックを行うために、出力パラメータを errcheck プロトコルと組み合わせることができます。 win32 GetWindowRect api 関数は成功したか失敗したかを知らせるために BOOL を返します。そのため、この関数はエラーチェックを行って、 api 呼び出しが失敗した場合に例外を送出させることができます。:
>>>
>>> def errcheck(result, func, args):
...     if not result:
...         raise WinError()
...     return args
...
>>> GetWindowRect.errcheck = errcheck
>>>
errcheck 関数が受け取った引数タプルを変更なしに返した場合、 ctypes は出力パラメータに対する通常の処理を続けます。 RECT インスタンスの代わりに window 座標のタプルを返すには、関数のフィールドを取り出し、代わりにそれらを返すことができます。この場合、通常処理は行われなくなります:
>>>
>>> def errcheck(result, func, args):
...     if not result:
...         raise WinError()
...     rc = args[1]
...     return rc.left, rc.top, rc.bottom, rc.right
...
>>> GetWindowRect.errcheck = errcheck
>>>
ユーティリティー関数
ctypes.addressof(obj)
メモリバッファのアドレスを示す整数を返します。 obj は ctypes 型のインスタンスでなければなりません。
ctypes.alignment(obj_or_type)
ctypes 型のアライメントの必要条件を返します。 obj_or_type は ctypes 型またはインスタンスでなければなりません。
ctypes.byref(obj[, offset])
obj (ctypes 型のインスタンスでなければならない) への軽量ポインタを返します。 offset はデフォルトでは 0 で、内部ポインターへ加算される整数です。
byref(obj, offset) は、 C コードとしては、以下のようにみなされます。:
(((char *)&obj) + offset)
返されるオブジェクトは外部関数呼び出しのパラメータとしてのみ使用できます。pointer(obj) と似たふるまいをしますが、作成が非常に速く行えます。
ctypes.cast(obj, type)
この関数は C のキャスト演算子に似ています。obj と同じメモリブロックを指している type の新しいインスタンスを返します。type はポインタ型でなければならず、obj はポインタとして解釈できるオブジェクトでなければなりません。
ctypes.create_string_buffer(init_or_size, size=None)
この関数は変更可能な文字バッファを作成します。返されるオブジェクトは c_char の ctypes 配列です。
init_or_size は配列のサイズを指定する整数もしくは配列要素を初期化するために使われるバイト列オブジェクトである必要があります。
バイト列オブジェクトが第一引数として指定されていた場合、配列の最後の要素が NUL 終端文字となるように、バイト列オブジェクトの長さより 1 つ長いバッファを作成します。バイト列の長さを使うべきではない場合は、第二引数として整数を渡して、配列の長さを指定することができます。
ctypes.create_unicode_buffer(init_or_size, size=None)
この関数は変更可能な Unicode 文字バッファを作成します。返されるオブジェクトは c_wchar の ctypes 配列です。
init_or_size は配列のサイズを指定する整数もしくは配列要素を初期化するために使われる文字列である必要があります。
第一引数として文字列が指定された場合は、バッファが文字列の長さより一要素分大きく作られます。配列の最後の要素が NUL 終端文字であるためです。文字列の長さを使うべきでない場合は、配列のサイズを指定するために整数を第二引数として渡すことができます。
ctypes.DllCanUnloadNow()
Windows 用: この関数は ctypes をつかってインプロセス COM サーバーを実装できるようにするためのフックです。_ctypes 拡張 dll がエクスポートしている DllCanUnloadNow 関数から呼び出されます。
ctypes.DllGetClassObject()
Windows 用: この関数は ctypes をつかってインプロセス COM サーバーを実装できるようにするためのフックです。_ctypes 拡張 dll がエクスポートしている DllGetClassObject 関数から呼び出されます。
ctypes.util.find_library(name)
ライブラリを検索し、パス名を返します。 name は lib のような接頭辞、 .so や .dylib のような接尾辞、そして、バージョンナンバーを除くライブラリ名です (これは posix のリンカーオプション -l で使われる書式です) 。もしライブラリが見つからなければ、 None を返します。
厳密な機能はシステムに依存します。
ctypes.util.find_msvcrt()
Windows 用: Python と拡張モジュールで使われる VC ランタイムライブラリのファイル名を返します。もしライブラリ名が同定できなければ、 None を返します。
もし、例えば拡張モジュールにより割り付けられたメモリを free(void *) で解放する必要があるなら、メモリ割り付けを行ったのと同じライブラリの関数を使うことが重要です。
ctypes.FormatError([code])
Windows 用: エラーコード code の説明文を返します。エラーコードが指定されない場合は、 Windows api 関数 GetLastError を呼び出して、もっとも新しいエラーコードが使われます。
ctypes.GetLastError()
Windows 用: 呼び出し側のスレッド内で Windows によって設定された最新のエラーコードを返します。この関数は Windows の GetLastError() 関数を直接実行します。 ctypes のプライベートなエラーコードのコピーを返したりはしません。
ctypes.get_errno()
システムの errno 変数の、スレッドローカルなプライベートコピーを返します。
ctypes.get_last_error()
Windows 用: システムの LastError 変数の、スレッドローカルなプライベートコピーを返します。
ctypes.memmove(dst, src, count)
標準 C の memmove ライブラリ関数と同じものです。: count バイトを src から dst へコピーします。 dst と src はポインタへ変換可能な整数または ctypes インスタンスでなければなりません。
ctypes.memset(dst, c, count)
標準 C の memset ライブラリ関数と同じものです。: アドレス dst のメモリブロックを値 c を count バイト分書き込みます。 dst はアドレスを指定する整数または ctypes インスタンスである必要があります。
ctypes.POINTER(type)
このファクトリ関数は新しい ctypes ポインタ型を作成して返します。ポインタ型はキャッシュされ、内部で再利用されます。したがって、この関数を繰り返し呼び出してもコストは小さいです。type は ctypes 型でなければなりません。
ctypes.pointer(obj)
この関数は obj を指す新しいポインタインスタンスを作成します。戻り値は POINTER(type(obj)) 型のオブジェクトです。
注意: 外部関数呼び出しへオブジェクトへのポインタを渡したいだけなら、はるかに高速な byref(obj) を使うべきです。
ctypes.resize(obj, size)
この関数は obj の内部メモリバッファのサイズを変更します。 obj は ctypes 型のインスタンスでなければなりません。バッファを sizeof(type(obj)) で与えられるオブジェクト型の本来のサイズより小さくすることはできませんが、バッファを拡大することはできます。
ctypes.set_errno(value)
システム変数 errno の、呼び出し元スレッドでの ctypes のプライベートコピーの現在値を value に設定し、前の値を返します。
ctypes.set_last_error(value)
Windows 用: システム変数 LastError の、呼び出し元スレッドでの ctypes のプライベートコピーの現在値を value に設定し、前の値を返します。
ctypes.sizeof(obj_or_type)
ctypes の型やインスタンスのメモリバッファのサイズをバイト数で返します。C の sizeof 演算子と同様の動きをします。
ctypes.string_at(address, size=-1)
この関数はメモリアドレス address から始まる C 文字列を返します。size が指定された場合はサイズとして使われます。指定されなければ、文字列がゼロ終端されていると仮定します。
ctypes.WinError(code=None, descr=None)
Windows 用: この関数はおそらく ctypes の中で最悪の名前でしょう。これは OSError のインスタンスを作成します。 code が指定されていなかった場合、エラーコードを判別するために GetLastError が呼び出されます。 descr が指定されていなかった場合、エラーの説明文を得るために FormatError() が呼び出されます。
バージョン 3.3 で変更: 以前は WindowsError インスタンスが作成されていました。
ctypes.wstring_at(address, size=-1)
この関数は文字列としてメモリアドレス address から始まるワイドキャラクタ文字列を返します。size が指定されたならば、文字列の文字数として使われます。指定されなければ、文字列がゼロ終端されていると仮定します。
データ型
class ctypes._CData
この非公開クラスはすべての ctypes データ型の共通のベースクラスです。他のことはさておき、すべての ctypes 型インスタンスは C 互換データを保持するメモリブロックを内部に持ちます。このメモリブロックのアドレスは addressof() ヘルパー関数が返します。別のインスタンス変数が _objects として公開されます。これはメモリブロックがポインタを含む場合に存続し続ける必要のある他の Python オブジェクトを含んでいます。
ctypes データ型の共通メソッド、すべてのクラスメソッドが存在します (正確には、 メタクラス のメソッドです):
from_buffer(source[, offset])
このメソッドは source オブジェクトのバッファを共有する ctypes のインスタンスを返します。 source オブジェクトは書き込み可能バッファインターフェースをサポートしている必要があります。オプションの offset 引数では source バッファのオフセットをバイト単位で指定します。デフォルトではゼロです。もし source バッファが十分に大きくなければ、 ValueError が送出されます。
from_buffer_copy(source[, offset])
このメソッドは source オブジェクトの読み出し可能バッファをコピーすることで、ctypes のインスタンスを生成します。オプションの offset 引数では source バッファのオフセットをバイト単位で指定します。デフォルトではゼロです。もし source バッファが十分に大きくなければ、 ValueError が送出されます。
from_address(address)
このメソッドは address で指定されたメモリを使って ctypes 型のインスタンスを返します。 address は整数でなければなりません。
from_param(obj)
このメソッドは obj を ctypes 型に適合させます。外部関数の argtypes タプルに、その型があるとき、外部関数呼び出しで実際に使われるオブジェクトと共に呼び出されます。
すべての ctypes のデータ型は、それが型のインスタンスであれば、 obj を返すこのクラスメソッドのデフォルトの実装を持ちます。いくつかの型は、別のオブジェクトも受け付けます。
in_dll(library, name)
このメソッドは、共有ライブラリによってエクスポートされた ctypes 型のインスタンスを返します。 name はエクスポートされたデータの名前で、 library はロードされた共有ライブラリです。
ctypes データ型共通のインスタンス変数:
_b_base_
ctypes 型データのインスタンスは、それ自身のメモリブロックを持たず、基底オブジェクトのメモリブロックの一部を共有することがあります。 _b_base_ 読み出し専用属性は、メモリブロックを保持する ctypes の基底オブジェクトです。
_b_needsfree_
この読み出し専用の変数は、 ctypes データインスタンスが、それ自身に割り当てられたメモリブロックを持つとき true になります。それ以外の場合は false になります。
_objects
このメンバは None 、または、メモリブロックの内容が正しく保つために、生存させておかなくてはならない Python オブジェクトを持つディクショナリです。このオブジェクトはデバッグでのみ使われます。決してディクショナリの内容を変更しないで下さい。
基本データ型
class ctypes._SimpleCData
この非公開クラスは、全ての基本的な ctypes データ型の基底クラスです。これは基本的な ctypes データ型に共通の属性を持っているので、ここで触れておきます。 _SimpleCData は _CData の子クラスなので、そのメソッドと属性を継承しています。ポインタでないかポインタを含まない ctypes データ型は、現在は pickle 化できます。
インスタンスは一つだけ属性を持ちます:
value
この属性は、インスタンスの実際の値を持ちます。整数型とポインタ型に対しては整数型、文字型に対しては一文字のバイト列オブジェクト、文字へのポインタに対しては Python のバイト列オブジェクトもしくは文字列となります。
value 属性が ctypes インスタンスより参照されたとき、大抵の場合はそれぞれに対し新しいオブジェクトを返します。 ctypes はオリジナルのオブジェクトを返す実装にはなって おらず 新しいオブジェクトを構築します。同じことが他の ctypes オブジェクトインスタンスに対しても言えます。
基本データ型は、外部関数呼び出しの結果として返されたときや、例えば構造体のフィールドメンバーや配列要素を取り出すときに、ネイティブの Python 型へ透過的に変換されます。言い換えると、外部関数が c_char_p の restype を持つ場合は、 c_char_p インスタンスでは なく 常に Python バイト列オブジェクトを受け取ることでしょう。
基本データ型のサブクラスはこの振る舞いを継承 しません 。したがって、外部関数の restype が c_void_p のサブクラスならば、関数呼び出しからこのサブクラスのインスタンスを受け取ります。もちろん、 value 属性にアクセスしてポインタの値を得ることができます。
これらが基本 ctypes データ型です:
class ctypes.c_byte
C の signed char データ型を表し、小整数として値を解釈します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_char
C char データ型を表し、単一の文字として値を解釈します。コンストラクタはオプションの文字列初期化子を受け取り、その文字列の長さちょうど一文字である必要があります。
class ctypes.c_char_p
C char * データ型を表し、ゼロ終端文字列へのポインタでなければなりません。バイナリデータを指す可能性のある一般的なポインタに対しては POINTER(c_char) を使わなければなりません。コンストラクタは整数のアドレスもしくはバイト列オブジェクトを受け取ります。
class ctypes.c_double
C double データ型を表します。コンストラクタはオプションの浮動小数点数初期化子を受け取ります。
class ctypes.c_longdouble
C long double データ型を表します。コンストラクタはオプションで浮動小数点数初期化子を受け取ります。 sizeof(long double) == sizeof(double) であるプラットフォームでは c_double の別名です。
class ctypes.c_float
C float データ型を表します。コンストラクタはオプションの浮動小数点数初期化子を受け取ります。
class ctypes.c_int
C signed int データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。 sizeof(int) == sizeof(long) であるプラットフォームでは、 c_long の別名です。
class ctypes.c_int8
C 8-bit signed int データ型を表します。たいていは、 c_byte の別名です。
class ctypes.c_int16
C 16-bit signed int データ型を表します。たいていは、 c_short の別名です。
class ctypes.c_int32
C 32-bit signed int データ型を表します。たいていは、 c_int の別名です。
class ctypes.c_int64
C 64-bit signed int データ型を表します。たいていは、 c_longlong の別名です。
class ctypes.c_long
C signed long データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_longlong
C signed long long データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_short
C signed short データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_size_t
C size_t データ型を表します。
class ctypes.c_ssize_t
C ssize_t データ型を表します。
バージョン 3.2 で追加.
class ctypes.c_ubyte
C の unsigned char データ型を表し、小さな整数として値を解釈します。コンストラクタはオプションの整数初期化子を受け取ります; オーバーフローのチェックは行われません。
class ctypes.c_uint
C の unsigned int データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります; オーバーフローのチェックは行われません。これは、 sizeof(int) == sizeof(long) であるプラットフォームでは c_ulong の別名です。
class ctypes.c_uint8
C 8-bit unsigned int データ型を表します。たいていは、 c_ubyte の別名です。
class ctypes.c_uint16
C 16-bit unsigned int データ型を表します。たいていは、 c_ushort の別名です。
class ctypes.c_uint32
C 32-bit unsigned int データ型を表します。たいていは、 c_uint の別名です。
class ctypes.c_uint64
C 64-bit unsigned int データ型を表します。たいていは、 c_ulonglong の別名です。
class ctypes.c_ulong
C unsigned long データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_ulonglong
C unsigned long long データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_ushort
C unsigned short データ型を表します。コンストラクタはオプションの整数初期化子を受け取ります。オーバーフローのチェックは行われません。
class ctypes.c_void_p
C void * データ型を表します。値は整数として表されます。コンストラクタはオプションの整数初期化子を受け取ります。
class ctypes.c_wchar
C wchar_t データ型を表し、値は Unicode 文字列の単一の文字として解釈されます。コンストラクタはオプションの文字列初期化子を受け取り、その文字列の長さはちょうど一文字である必要があります。
class ctypes.c_wchar_p
C wchar_t * データ型を表し、ゼロ終端ワイド文字列へのポインタでなければなりません。コンストラクタは整数のアドレスもしくは文字列を受け取ります。
class ctypes.c_bool
C の bool データ型 (より正確には、 C99 以降の _Bool) を表します。 True または False の値を持ち、コンストラクタは真偽値と解釈できるオブジェクトを受け取ります。
class ctypes.HRESULT
Windows用: HRESULT 値を表し、関数またはメソッド呼び出しに対する成功またはエラーの情報を含んでいます。
class ctypes.py_object
C PyObject * データ型を表します。引数なしでこれを呼び出すと NULL PyObject * ポインタを作成します。
ctypes.wintypes モジュールは他の Windows 固有のデータ型を提供します。例えば、 HWND, WPARAM, DWORD です。 MSG や RECT のような有用な構造体も定義されています。
構造化データ型
class ctypes.Union(*args, **kw)
ネイティブのバイトオーダーでの共用体のための抽象ベースクラス。
class ctypes.BigEndianStructure(*args, **kw)
ビックエンディアン バイトオーダーでの構造体のための抽象ベースクラス。
class ctypes.LittleEndianStructure(*args, **kw)
リトルエンディアン バイトオーダーでの構造体のための抽象ベースクラス。
ネイティブではないバイトオーダーを持つ構造体にポインタ型フィールドあるいはポインタ型フィールドを含む他のどんなデータ型をも入れることはできません。
class ctypes.Structure(*args, **kw)
ネイティブ のバイトオーダーでの構造体のための抽象ベースクラス。
具象構造体型と具象共用体型はこれらの型の一つをサブクラス化することで作らなければなりません。少なくとも、 _fields_ クラス変数を定義する必要があります。 ctypes は、属性に直接アクセスしてフィールドを読み書きできるようにする デスクリプタ を作成するでしょう。これらは、
_fields_
構造体のフィールドを定義するシーケンス。要素は2要素タプルか3要素タプルでなければなりません。第一要素はフィールドの名前です。第二要素はフィールドの型を指定します。それはどんな ctypes データ型でも構いません。
c_int のような整数型のために、オプションの第三要素を与えることができます。フィールドのビット幅を定義する正の小整数である必要があります。
一つの構造体と共用体の中で、フィールド名はただ一つである必要があります。これはチェックされません。名前が繰り返しでてきたときにアクセスできるのは一つのフィールドだけです。
Structure サブクラスを定義するクラス文の 後で 、 _fields_ クラス変数を定義することができます。これにより、次のように自身を直接または間接的に参照するデータ型を作成できるようになります:
class List(Structure):
    pass
List._fields_ = [("pnext", POINTER(List)),
                 ...
                ]
しかし、 _fields_ クラス変数はその型が最初に使われる (インスタンスが作成される、それに対して sizeof() が呼び出されるなど) より前に定義されていなければなりません。その後 _fields_ クラス変数へ代入すると AttributeError が送出されます。
構造体型のサブクラスのサブクラスを定義することもでき、もしあるならサブクラスのサブクラス内で定義された _fields_ に加えて、基底クラスのフィールドも継承します。
_pack_
インスタンスの構造体フィールドのアライメントを上書きできるようにするオブションの小整数。 _pack_ は _fields_ が代入されたときすでに定義されていなければなりません。そうでなければ、何の効果もありません。
_anonymous_
無名 (匿名) フィールドの名前が並べあげられたオプションのシーケンス。 _fields_ が代入されたとき、 _anonymous_ がすでに定義されていなければなりません。そうでなければ、何ら影響はありません。
この変数に並べあげられたフィールドは構造体型もしくは共用体型フィールドである必要があります。構造体フィールドまたは共用体フィールドを作る必要なく、入れ子になったフィールドに直接アクセスできるようにするために、 ctypes は構造体型の中に記述子を作成します。
型の例です (Windows):
class _U(Union):
    _fields_ = [("lptdesc", POINTER(TYPEDESC)),
                ("lpadesc", POINTER(ARRAYDESC)),
                ("hreftype", HREFTYPE)]
class TYPEDESC(Structure):
    _anonymous_ = ("u",)
    _fields_ = [("u", _U),
                ("vt", VARTYPE)]
TYPEDESC 構造体はCOMデータ型を表現しており、 vt フィールドは共用体フィールドのどれが有効であるかを指定します。 u フィールドは匿名フィールドとして定義されているため、 TYPEDESC インスタンスから取り除かれてそのメンバーへ直接アクセスできます。 td.lptdesc と td.u.lptdesc は同等ですが、前者がより高速です。なぜなら一時的な共用体インスタンスを作る必要がないためです。:
td = TYPEDESC()
td.vt = VT_PTR
td.lptdesc = POINTER(some_type)
td.u.lptdesc = POINTER(some_type)
構造体のサブクラスのサブクラスを定義することができ、基底クラスのフィールドを継承します。 サブクラス定義に別の _fields_ 変数がある場合は、この中で指定されたフィールドは基底クラスのフィールドへ追加されます。
構造体と共用体のコンストラクタは位置引数とキーワード引数の両方を受け取ります。位置引数は _fields_ の中に現れたのと同じ順番でメンバーフィールドを初期化するために使われます。コンストラクタのキーワード引数は属性代入として解釈され、そのため、同じ名前をもつ _fields_ を初期化するか、 _fields_ に存在しない名前に対しては新しい属性を作ります。
配列とポインタ
class ctypes.Array(*args)
配列のための抽象基底クラスです。
具象配列型を作成するための推奨される方法は、任意の ctypes データ型に正の整数を乗算することです。代わりに、この型のサブクラスを作成し、 _length_ と _type_ のクラス変数を定義することもできます。配列の要素は、標準の添え字とスライスによるアクセスを使用して読み書きを行うことができます。スライスの読み込みでは、結果のオブジェクト自体は Array ではありません。
_length_
配列の要素数を指定する正の整数。範囲外の添え字を指定すると、 IndexError が送出されます。len() がこの整数を返します。
_type_
配列内の各要素の型を指定します。
配列のサブクラスのコンストラクタは、位置引数を受け付けて、配列を順番に初期化するために使用します。
class ctypes._Pointer
ポインタのためのプライベートな抽象基底クラスです。
具象ポインタ型は、ポイント先の型を持つ POINTER() を呼び出すことで、作成できます。これは、 pointer() により自動的に行われます。
ポインタが配列を指す場合、その配列の要素は、標準の添え字とスライスによるアクセスを使用して読み書きが行えます。ポインタオブジェクトには、サイズがないため、 len() 関数は TypeError を送出します。負の添え字は、(C と同様に) ポインタの 前 のメモリから読み込み、範囲外の添え字はおそらく (幸運な場合でも) アクセス違反によりクラッシュを起こします。
_type_
ポイント先の型を指定します。
contents
ポインタが指すオブジェクトを返します。この属性に割り当てると、ポインタが割り当てられたオブジェクトを指すようになります。
threading --- スレッドベースの並列処理
ソースコード: Lib/threading.py
このモジュールでは、高水準のスレッドインタフェースをより低水準 な _thread モジュールの上に構築しています。 queue モジュールのドキュメントも参照してください。
バージョン 3.7 で変更: このモジュールは以前はオプションでしたが、常に利用可能なモジュールとなりました。
注釈 ここには載っていませんが、Python 2.x シリーズでこのモジュールの一部のメソッドや関数に使われていた camelCase 名は、まだこのモジュールでサポートされます。
このモジュールは以下の関数を定義しています:
threading.active_count()
生存中の Thread オブジェクトの数を返します。この数は enumerate() の返すリストの長さと同じです。
threading.current_thread()
関数を呼び出している処理のスレッドに対応する Thread オブジェクトを返します。関数を呼び出している処理のスレッドが threading モジュールで生成したものでない場合、限定的な機能しかもたないダミースレッドオブジェクトを返します。
threading.excepthook(args, /)
The args argument has the following attributes:
exc_type: Exception type.
exc_value: Exception value, can be None.
exc_traceback: Exception traceback, can be None.
thread: Thread which raised the exception, can be None.
threading.excepthook() can be overridden to control how uncaught exceptions raised by Thread.run() are handled.
参考 sys.excepthook() handles uncaught exceptions.
バージョン 3.8 で追加.
threading.get_ident()
現在のスレッドの 'スレッドID' を返します。非ゼロの整数です。この値は直接の意味を持っていません; 例えばスレッド特有のデータの辞書に索引をつけるためのような、マジッククッキーとして意図されています。スレッドが終了し、他のスレッドが作られたとき、スレッド ID は再利用されるかもしれません。
バージョン 3.3 で追加.
threading.get_native_id()
バージョン 3.8 で追加.
threading.enumerate()
現在、生存中の Thread オブジェクト全てのリストを返します。リストには、デーモンスレッド (daemonic thread)、 current_thread() の生成するダミースレッドオブジェクト、そして主スレッドが入ります。終了したスレッドとまだ開始していないスレッドは入りません。
threading.main_thread()
main Thread オブジェクトを返します。通常の条件では、メインスレッドはPythonインタプリタが起動したスレッドを指します。
バージョン 3.4 で追加.
threading.settrace(func)
threading モジュールを使って開始した全てのスレッドにトレース関数を設定します。 func は各スレッドの run() を呼び出す前にスレッドの sys.settrace() に渡されます。
threading.setprofile(func)
threading モジュールを使って開始した全てのスレッドにプロファイル関数を設定します。 func は各スレッドの run() を呼び出す前にスレッドの sys.setprofile() に渡されます。
threading.stack_size([size])
新しいスレッドを作るときのスレッドスタックサイズを返します。オプションの size 引数にはこれ以降に作成するスレッドのスタックサイズを指定し、0 (プラットフォームのデフォルト値または設定されたデフォルト値) か、 32,768 (32 KiB) 以上の正の整数でなければなりません。size が指定されない場合 0 が使われます。スレッドのスタックサイズの変更がサポートされていない場合、 RuntimeError を送出します。不正なスタックサイズが指定された場合、 ValueError を送出して、スタックサイズは変更されません。32 KiB は現在のインタープリタ自身のために十分であると保証された最小のスタックサイズです。いくつかのプラットフォームではスタックサイズに対して制限があることに注意してください。例えば最小のスタックサイズが 32 KiB より大きかったり、システムのメモリページサイズ の整数倍の必要があるなどです。この制限についてはプラットフォームのドキュメントを参照してください (一般的なページサイズは 4 KiB なので、プラットフォームに関する情報がない場合は 4096 の整数倍のスタックサイズを選ぶといいかもしれません)。
このモジュールでは以下の定数も定義しています:
threading.TIMEOUT_MAX
ブロックする関数 (Lock.acquire(), RLock.acquire(), Condition.wait() など) の timeout 引数に許される最大値。これ以上の値を timeout に指定すると OverflowError が発生します。
バージョン 3.2 で追加.
このモジュールは多くのクラスを定義しています。それらは下記のセクションで詳しく説明されます。
このモジュールのおおまかな設計は Java のスレッドモデルに基づいています。とはいえ、 Java がロックと条件変数を全てのオブジェクトの基本的な挙動にしているのに対し、 Python ではこれらを別個のオブジェクトに分けています。 Python の Thread クラスがサポートしているのは Java の Thread クラスの挙動のサブセットにすぎません; 現状では、優先度 (priority)やスレッドグループがなく、スレッドの破壊 (destroy)、中断 (stop)、一時停止 (suspend)、復帰 (resume)、割り込み (interrupt) は行えません。 Java の Thread クラスにおける静的メソッドに対応する機能が実装されている場合にはモジュールレベルの関数になっています。
以下に説明するメソッドは全て原子的 (atomic) に実行されます。
スレッドローカルデータ
スレッドローカルデータは、その値がスレッド固有のデータです。スレッドローカルデータを管理するには、単に local (あるいはそのサブクラス) のインスタンスを作成して、その属性に値を設定してください:
mydata = threading.local()
mydata.x = 1
インスタンスの値はスレッドごとに違った値になります。
class threading.local
スレッドローカルデータを表現するクラス。
詳細と例題については、 _threading_local モジュールのドキュメンテーション文字列を参照してください。
Thread オブジェクト
Thread クラスは個別のスレッド中で実行される活動 (activity) を表現します。活動を決める方法は 2 つあり、一つは呼び出し可能オブジェクトをコンストラクタへ渡す方法、もう一つはサブクラスで run() メソッドをオーバライドする方法です。 (コンストラクタを除く) その他のメソッドは一切サブクラスでオーバライドしてはなりません。言い換えるならば、このクラスの __init__() と run() メソッド だけ をオーバライドしてくださいということです。
ひとたびスレッドオブジェクトを生成すると、スレッドの start() メソッドを呼び出して活動を開始しなければなりません。 start() メソッド はそれぞれのスレッドの run() メソッドを起動します。
スレッドの活動が始まると、スレッドは '生存中 (alive)' とみなされます。 スレッドは、通常 run() メソッドが終了するまで、もしくは捕捉されない例外が送出されるまで生存中となります。 is_alive() メソッドは、スレッドが生存中であるかどうか調べます。
スレッドは他のスレッドの join() メソッドを呼び出すことができます。このメソッドは、 join() メソッドを呼ばれたスレッドが終了するまでメソッドの呼び出し元のスレッドをブロックします。
スレッドは名前を持っています。名前はコンストラクタに渡すことができ、 name 属性を通して読み出したり変更したりできます。
スレッドには "デーモンスレッド (daemon thread)" であるというフラグを立てられます。 このフラグには、残っているスレッドがデーモンスレッドだけになった時に Python プログラム全体を終了させるという意味があります。フラグの初期値はスレッドを生成したスレッドから継承します。フラグの値は daemon プロパティまたは daemon コンストラクタ引数を通して設定できます。
注釈 デーモンスレッドは終了時にいきなり停止されます。デーモンスレッドで使われたリソース (開いているファイル、データベースのトランザクションなど) は適切に解放されないかもしれません。きちんと (gracefully) スレッドを停止したい場合は、スレッドを非デーモンスレッドにして、Event のような適切なシグナル送信機構を使用してください。
スレッドには "主スレッド (main thread)" オブジェクトがあります。主スレッドは Python プログラムを最初に制御していたスレッドです。主スレッドはデーモンスレッドではありません。
"ダミースレッド (dummy thread)" オブジェクトを作成することができます。 ダミースレッドは、 "外来スレッド (alien thread)" に対応するスレッドオブジェクトです。ダミースレッドは、 C コードから直接生成されたスレッドのような、 threading モジュールの外で開始された処理スレッドです。 ダミースレッドオブジェクトには限られた機能しかなく、常に生存中、かつデーモンスレッドであるとみなされ、 join() できません。また、外来スレッドの終了を検出するのは不可能なので、ダミースレッドは削除できません。
class threading.Thread(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
コンストラクタは常にキーワード引数を使って呼び出さなければなりません。各引数は以下の通りです:
group は None でなければなりません。将来 ThreadGroup クラスが実装されたときの拡張用に予約されている引数です。
target は run() メソッドによって起動される呼び出し可能オブジェクトです。デフォルトでは何も呼び出さないことを示す None になっています。
name はスレッドの名前です。デフォルトでは、 N を小さな 10 進数として、 "Thread- N" という形式の一意な名前を生成します。
args は target を呼び出すときの引数タプルです。デフォルトは () です。
kwargs は target を呼び出すときのキーワード引数の辞書です。デフォルトは {} です。
None でない場合、daemon はスレッドがデーモンかどうかを明示的に設定します。None の場合 (デフォルト)、デーモン属性は現在のスレッドから継承されます。
サブクラスでコンストラクタをオーバライドした場合、必ずスレッドが何かを始める前に基底クラスのコンストラクタ (Thread.__init__()) を呼び出しておかなくてはなりません。
バージョン 3.3 で変更: daemon 引数が追加されました。
start()
スレッドの活動を開始します。
このメソッドは、スレッドオブジェクトあたり一度しか呼び出してはなりません。 start() は、オブジェクトの run() メソッドが個別の処理スレッド中で呼び出されるように調整します。
同じスレッドオブジェクトに対し、このメソッドを2回以上呼び出した場合、 RuntimeError を送出します。
run()
スレッドの活動をもたらすメソッドです。
join(timeout=None)
スレッドが終了するまで待機します。 このメソッドは、 join() を呼ばれたスレッドが正常終了あるいは処理されない例外によって終了するか、オプションのタイムアウトが発生するまで、メソッドの呼び出し元のスレッドをブロックします。
timeout 引数が存在して None 以外の場合、それは操作に対するタイムアウト秒 (あるいは秒未満の端数) を表す浮動小数点数でなければなりません。 join() は常に None を返すので、 join() の後に is_alive() を呼び出してタイムアウトしたかどうかを確認しなければなりません。もしスレッドがまだ生存中であれば、 join() はタイムアウトしています。
timeout が指定されないかまたは None であるときは、この操作はスレッドが終了するまでブロックします。
一つのスレッドに対して何度でも join() できます。
現在のスレッドに対して join() を呼び出そうとすると、デッドロックを引き起こすため RuntimeError が送出されます。 スレッドが開始される前に join() を呼び出すことも同様のエラーのため、同じ例外が送出されます。
name
識別のためにのみ用いられる文字列です。名前には機能上の意味づけ (semantics) はありません。複数のスレッドに同じ名前をつけてもかまいません。名前の初期値はコンストラクタで設定されます。
getName()
setName()
name に対する古い getter/setter API; 代わりにプロパティを直接使用してください。
ident
native_id
注釈 Similar to Process IDs, Thread IDs are only valid (guaranteed unique system-wide) from the time the thread is created until the thread has been terminated.
バージョン 3.8 で追加.
is_alive()
スレッドが生存中かどうかを返します。
このメソッドは、 run() メソッドが起動する直前から run() メソッドが終了する直後までの間 True を返します。モジュール関数 enumerate() は、全ての生存中のスレッドのリストを返します。
daemon
このスレッドがデーモンスレッドか (True) か否か (False) を示すブール値。この値は start() の呼び出し前に設定されなければなりません。さもなければ RuntimeError が送出されます。初期値は生成側のスレッドから継承されます; メインスレッドはデーモンスレッドではないので、メインスレッドで作成されたすべてのスレッドは、デフォルトで daemon = False になります。
デーモンでない生存中のスレッドが全てなくなると、 Python プログラム全体が終了します。
isDaemon()
setDaemon()
daemon に対する古い getter/setter API; 代わりにプロパティを直接使用してください。
Lock オブジェクト
プリミティブロックとは、ロックが生じた際に特定のスレッドによって所有されない同期プリミティブです。 Python では現在のところ拡張モジュール _thread で直接実装されている最も低水準の同期プリミティブを使えます。
プリミティブロックは2つの状態、 "ロック" または "アンロック" があります。ロックはアンロック状態で作成されます。ロックには基本となる二つのメソッド、 acquire() と release() があります。ロックの状態がアンロックである場合、 acquire() は状態をロックに変更して即座に処理を戻します。 状態がロックの場合、 acquire() は他のスレッドが release() を呼び出してロックの状態をアンロックに変更するまでブロックします。その後、 acquire() 呼び出しは状態を再度ロックに設定してから処理を戻します。 release() メソッドを呼び出すのはロック状態のときでなければなりません; このメソッドはロックの状態をアンロックに変更して、即座に処理を戻します。 アンロックの状態のロックを解放しようとすると RuntimeError が送出されます。
ロックは コンテキストマネージメントプロトコル もサポートします。
複数のスレッドにおいて acquire() がアンロック状態への遷移を待っているためにブロックが起きている時に release() を呼び出してロックの状態をアンロックにすると、一つのスレッドだけが処理を進行できます。 どのスレッドが処理を進行できるのかは定義されておらず、実装によって異なるかもしれません。
全てのメソッドはアトミックに実行されます。
class threading.Lock
プリミティブロック (primitive lock) オブジェクトを実装しているクラスです。スレッドが一度ロックを獲得すると、それ以後のロック獲得の試みはロックが解放されるまでブロックします。どのスレッドでもロックを解放できます。
acquire(blocking=True, timeout=-1)
ブロックあり、またはブロックなしでロックを獲得します。
引数 blocking を True (デフォルト) に設定して呼び出した場合、ロックがアンロック状態になるまでブロックします。そしてそれをロック状態にしてから True を返します。
引数 blocking の値を False にして呼び出すとブロックしません。blocking を True にして呼び出した場合にブロックするような状況では、直ちに False を返します。それ以外の場合には、ロックをロック状態にして True を返します。
正の値に設定された浮動小数点の timeout 引数とともに起動された場合、ロックを得られなければ最大で timeout によって指定された秒数だけブロックします。timeout 引数の -1 は無制限の待機を指定します。blocking が false の場合に timeout を指定することは禁止されています。
ロックを獲得すると True を、ロックを獲得できなかったとき (例えば timeout が過ぎた場合) には False を返します。
バージョン 3.2 で変更: 新しい timeout 引数。
バージョン 3.2 で変更: Lock acquisition can now be interrupted by signals on POSIX if the underlying threading implementation supports it.
release()
ロックを解放します。これはロックを獲得したスレッドだけでなく、任意のスレッドから呼ぶことができます。
ロックの状態がロックのとき、状態をアンロックにリセットして処理を戻します。他のスレッドがロックがアンロック状態になるのを待ってブロックしている場合、ただ一つのスレッドだけが処理を継続できるようにします。
アンロック状態のロックに対して呼び出された場合、RuntimeError が送出されます。
戻り値はありません。
locked()
RLock オブジェクト
再入可能ロック (reentrant lock) とは、同じスレッドが複数回獲得できるような同期プリミティブです。再入可能ロックの内部では、プリミティブロックの使うロック／アンロック状態に加え、 "所有スレッド (owning thread)" と "再帰レベル (recursion level)" という概念を用いています。ロック状態では何らかのスレッドがロックを所有しており、アンロック状態ではいかなるスレッドもロックを所有していません。
このロックの状態をロックにするには、スレッドがロックの acquire() メソッドを呼び出します。このメソッドはスレッドがロックを所有すると処理を戻します。ロックの状態をアンロックにするには release() メソッドを呼び出します。 acquire() / release() からなるペアの呼び出しはネストできます; 最後に呼び出した release() (最も外側の呼び出しペアの release()) だけがロックの状態をアンロックにリセットして、 acquire() でブロック中の別のスレッドの処理を進行させることができます。
再入可能ロックは コンテキストマネージメントプロトコル もサポートします。
class threading.RLock
このクラスは再入可能ロックオブジェクトを実装します。再入可能ロックはそれを獲得したスレッドによって解放されなければなりません。いったんスレッドが再入可能ロックを獲得すると、同じスレッドはブロックされずにもう一度それを獲得できます ; そのスレッドは獲得した回数だけ解放しなければいけません。
RLock は実際にはファクトリ関数で、プラットフォームでサポートされる最も効率的なバージョンの具体的な RLock クラスのインスタンスを返すことに注意してください。
acquire(blocking=True, timeout=-1)
ブロックあり、またはブロックなしでロックを獲得します。
引数なしで呼び出した場合: スレッドが既にロックを所有している場合、再帰レベルをインクリメントして即座に処理を戻します。それ以外の場合、他のスレッドがロックを所有していれば、そのロックの状態がアンロックになるまでブロックします。その後、ロックの状態がアンロックになる (いかなるスレッドもロックを所有しない状態になる) と、ロックの所有権を獲得し、再帰レベルを 1 にセットして処理を戻します。ロックの状態がアンロックになるのを待っているスレッドが複数ある場合、その中の一つだけがロックの所有権を獲得できます。この場合、戻り値はありません。
バージョン 3.2 で変更: 新しい timeout 引数。
release()
再帰レベルをデクリメントしてロックを解放します。デクリメント後に再帰レベルがゼロになった場合、ロックの状態をアンロック (いかなるスレッドにも所有されていない状態) にリセットし、ロックの状態がアンロックになるのを待ってブロックしているスレッドがある場合にはその中のただ一つだけが処理を進行できるようにします。デクリメント後も再帰レベルがゼロでない場合、ロックの状態はロックのままで、呼び出し側のスレッドに所有されたままになります。
呼び出し側のスレッドがロックを所有しているときにのみこのメソッドを呼び出してください。ロックの状態がアンロックの時にこのメソッドを呼び出すと、 RuntimeError が送出されます。
戻り値はありません。
Condition オブジェクト
条件変数 (condition variable) は、常にある種のロックに関連付けられています; このロックは明示的に渡すことも、デフォルトで生成させることもできます。複数の条件変数で同じロックを共有しなければならない場合には、引渡しによる関連付けが便利です。ロックは条件オブジェクトの一部です: それを別々に扱う必要はありません。
条件変数は コンテキスト管理プロトコル に従います: with 文を使って囲まれたブロックの間だけ関連付けられたロックを獲得することができます。 acquire() メソッドと release() メソッドは、さらに関連付けられたロックの対応するメソッドを呼び出します。
他のメソッドは、関連付けられたロックを保持した状態で呼び出さなければなりません。 wait() メソッドはロックを解放します。そして別のスレッドが notify() または notify_all() を呼ぶことによってスレッドを起こすまでブロックします。一旦起こされたなら、 wait() は再びロックを得て戻ります。タイムアウトを指定することも可能です。
notify() メソッドは条件変数待ちのスレッドを1つ起こします。 notify_all() メソッドは条件変数待ちの全てのスレッドを起こします。
注意: notify() と notify_all() はロックを解放しません; 従って、スレッドが起こされたとき、 wait() の呼び出しは即座に処理を戻すわけではなく、 notify() または notify_all() を呼び出したスレッドが最終的にロックの所有権を放棄したときに初めて処理を返すのです。
条件変数を使う典型的なプログラミングスタイルでは、何らかの共有された状態変数へのアクセスを同期させるためにロックを使います; 状態変数が特定の状態に変化したことを知りたいスレッドは、自分の望む状態になるまで繰り返し wait() を呼び出します。その一方で、状態変更を行うスレッドは、前者のスレッドが待ち望んでいる状態であるかもしれないような状態へ変更を行ったときに notify() や notify_all() を呼び出します。例えば、以下のコードは無制限のバッファ容量のときの一般的な生産者-消費者問題です:
# Consume one item
with cv:
    while not an_item_is_available():
        cv.wait()
    get_an_available_item()
# Produce one item
with cv:
    make_an_item_available()
    cv.notify()
アプリケーションの条件をチェックする while ループは必須です。なぜなら、 wait() が任意の長時間の後で返り、 notify() 呼び出しを促した条件がもはや真でないことがありえるからです。これはマルチスレッドプログラミングに固有です。条件チェックを自動化するために wait_for() メソッドを使うことができ、それはタイムアウトの計算を簡略化します:
# Consume an item
with cv:
    cv.wait_for(an_item_is_available)
    get_an_available_item()
notify() と notify_all() のどちらを使うかは、その状態の変化に興味を持っている待ちスレッドが一つだけなのか、あるいは複数なのかで考えます。例えば、典型的な生産者-消費者問題では、バッファに1つの要素を加えた場合には消費者スレッドを 1 つしか起こさなくてかまいません。
class threading.Condition(lock=None)
このクラスは条件変数 (condition variable) オブジェクトを実装します。条件変数を使うと、1つ以上のスレッドを別のスレッドの通知があるまで待機させておけます。
lock に None でない値を指定した場合、その値は Lock または RLock オブジェクトでなければなりません。 この場合、 lock は根底にあるロックオブジェクトとして使われます。 それ以外の場合には、 RLock オブジェクトを新しく作成して使います。
バージョン 3.3 で変更: ファクトリ関数からクラスに変更されました。
acquire(*args)
根底にあるロックを獲得します。このメソッドは根底にあるロックの対応するメソッドを呼び出します。そのメソッドの戻り値を返します。
release()
根底にあるロックを解放します。このメソッドは根底にあるロックの対応するメソッドを呼び出します。戻り値はありません。
wait(timeout=None)
通知 (notify) を受けるか、タイムアウトするまで待機します。呼び出し側のスレッドがロックを獲得していないときにこのメソッドを呼び出すと RuntimeError が送出されます。
このメソッドは根底にあるロックを解放し、他のスレッドが同じ条件変数に対して notify() または notify_all() を呼び出して現在のスレッドを起こすか、オプションのタイムアウトが発生するまでブロックします。一度スレッドが起こされると、再度ロックを獲得して処理を戻します。
timeout 引数を指定して、 None 以外の値にする場合、タイムアウトを秒 (または端数秒) を表す浮動小数点数でなければなりません。
根底にあるロックが RLock である場合、 release() メソッドではロックは解放されません。というのも、ロックが再帰的に複数回獲得されている場合には、 release() によって実際にアンロックが行われないかもしれないからです。その代わり、ロックが再帰的に複数回獲得されていても確実にアンロックを行える RLock クラスの内部インタフェースを使います。その後ロックを再獲得する時に、もう一つの内部インタフェースを使ってロックの再帰レベルを復帰します。
与えられた timeout が過ぎていなければ返り値は True です。タイムアウトした場合には False が返ります。
バージョン 3.2 で変更: 以前は、このメソッドは常に None を返していました。
wait_for(predicate, timeout=None)
条件が真と判定されるまで待ちます。 predicate は呼び出し可能オブジェクトでなければならず、その結果はブール値として解釈されます。 最大の待ち時間を指定する timeout を与えることができます。
このユーティリティメソッドは、述語が満たされるかタイムアウトが発生するまで wait() を繰り返し呼び出す場合があります。戻り値は述語の最後の戻り値で、もしメソッドがタイムアウトすれば、 False と評価されます。
タイムアウト機能を無視すれば、このメソッドの呼び出しは以下のように書くのとほぼ等価です:
while not predicate():
    cv.wait()
したがって、 wait() と同じルールが適用されます: 呼び出された時にロックを保持していなければならず、戻るときにロックが再度獲得されます。述語はロックを保持した状態で評価されます。
バージョン 3.2 で追加.
notify(n=1)
デフォルトで、この条件変数を待っている1つのスレッドを起こします。 呼び出し側のスレッドがロックを獲得していないときにこのメソッドを呼び出すと RuntimeError が送出されます。
何らかの待機中スレッドがある場合、そのうち n スレッドを起こします。待機中のスレッドがなければ何もしません。
現在の実装では、少なくとも n スレッドが待機中であれば、ちょうど n スレッドを起こします。とはいえ、この挙動に依存するのは安全ではありません。将来、実装の最適化によって、複数のスレッドを起こすようになるかもしれないからです。
注意: 起こされたスレッドは実際にロックを再獲得できるまで wait() 呼び出しから戻りません。 notify() はロックを解放しないので、 notify() 呼び出し側は明示的にロックを解放しなければなりません。
notify_all()
この条件を待っているすべてのスレッドを起こします。このメソッドは notify() のように動作しますが、 1 つではなくすべての待ちスレッドを起こします。呼び出し側のスレッドがロックを獲得していない場合、 RuntimeError が送出されます。
Semaphore オブジェクト
セマフォ (semaphore) は、計算機科学史上最も古い同期プリミティブの一つ で、草創期のオランダ計算機科学者 Edsger W. Dijkstra によって発明されました (彼は acquire() と release() の代わりに P() と V() を使いました)。
セマフォは acquire() でデクリメントされ release() でインクリメントされるような内部カウンタを管理します。 カウンタは決してゼロより小さくはなりません; acquire() は、カウンタがゼロになっている場合、他のスレッドが release() を呼び出すまでブロックします。
セマフォは コンテキストマネージメントプロトコル もサポートします。
class threading.Semaphore(value=1)
オプションの引数には、内部カウンタの初期値を指定します。デフォルトは 1 です。与えられた value が 0 より小さい場合、 ValueError が送出されます。
バージョン 3.3 で変更: ファクトリ関数からクラスに変更されました。
acquire(blocking=True, timeout=None)
セマフォを獲得します。
When invoked without arguments:
バージョン 3.2 で変更: 新しい timeout 引数。
release(n=1)
バージョン 3.9 で変更: Added the n parameter to release multiple waiting threads at once.
class threading.BoundedSemaphore(value=1)
有限セマフォ (bounded semaphore) オブジェクトを実装しているクラスです。有限セマフォは、現在の値が初期値を超過しないようチェックを行います。超過を起こした場合、 ValueError を送出します。たいていの場合、セマフォは限られた容量のリソースを保護するために使われるものです。従って、あまりにも頻繁なセマフォの解放はバグが生じているしるしです。 value を指定しない場合、デフォルトの値は 1 になります。
バージョン 3.3 で変更: ファクトリ関数からクラスに変更されました。
Semaphore の例
セマフォはしばしば、容量に限りのある資源、例えばデータベースサーバなどを保護するために使われます。リソースが固定の状況では、常に有限セマフォを使わなければなりません。主スレッドは、作業スレッドを立ち上げる前にセマフォを初期化します:
maxconnections = 5
# ...
pool_sema = BoundedSemaphore(value=maxconnections)
作業スレッドは、ひとたび立ち上がると、サーバへ接続する必要が生じたときにセマフォの acquire() および release() メソッドを呼び出します:
with pool_sema:
    conn = connectdb()
    try:
        # ... use connection ...
    finally:
        conn.close()
有限セマフォを使うと、セマフォを獲得回数以上に解放してしまうというプログラム上の間違いを見逃しにくくします。
Event オブジェクト
イベントは、あるスレッドがイベントを発信し、他のスレッドはそれを待つという、スレッド間で通信を行うための最も単純なメカニズムの一つです。
イベントオブジェクトは内部フラグを管理します。このフラグは set() メソッドで値を true に、 clear() メソッドで値を false にリセットします。 wait() メソッドはフラグが true になるまでブロックします。
class threading.Event
イベントオブジェクトを実装しているクラスです。イベントは set() メソッドを使うと True に、 clear() メソッドを使うと False にセットされるようなフラグを管理します。 wait() メソッドは、全てのフラグが true になるまでブロックするようになっています。フラグの初期値は false です。
バージョン 3.3 で変更: ファクトリ関数からクラスに変更されました。
is_set()
内部フラグが真のとき True を返します。
set()
内部フラグの値を true にセットします。フラグの値が true になるのを待っている全てのスレッドを起こします。一旦フラグが true になると、スレッドが wait() を呼び出しても全くブロックしなくなります。
clear()
内部フラグの値を false にリセットします。以降は、 set() を呼び出して再び内部フラグの値を true にセットするまで、 wait() を呼び出したスレッドはブロックするようになります。
wait(timeout=None)
内部フラグの値が true になるまでブロックします。 wait() 処理に入った時点で内部フラグの値が true であれば、直ちに処理を戻します。そうでない場合、他のスレッドが set() を呼び出してフラグの値を true にセットするか、オプションのタイムアウトが発生するまでブロックします。
timeout 引数を指定して、 None 以外の値にする場合、タイムアウトを秒 (または端数秒) を表す浮動小数点数でなければなりません。
バージョン 3.1 で変更: 以前は、このメソッドは常に None を返していました。
Timer オブジェクト
このクラスは、一定時間経過後に実行される活動、すなわちタイマ活動を表現します。 Timer は Thread のサブクラスであり、自作のスレッドを構築した一例でもあります。
タイマは start() メソッドを呼び出すとスレッドとして作動し始めします。 (活動を開始する前に) cancel() メソッドを呼び出すと、タイマを停止できます。タイマが活動を実行するまでの待ち時間は、ユーザが指定した待ち時間と必ずしも厳密には一致しません。
例えば:
def hello():
    print("hello, world")
t = Timer(30.0, hello)
t.start()  # after 30 seconds, "hello, world" will be printed
class threading.Timer(interval, function, args=None, kwargs=None)
interval 秒後に引数 args キーワード引数 kwargs で function を実行するようなタイマを生成します。args*が ``None`` (デフォルト) なら空のリストが使用されます。*kwargs が None (デフォルト) なら空の辞書が使用されます。
バージョン 3.3 で変更: ファクトリ関数からクラスに変更されました。
cancel()
タイマをストップして、その動作の実行をキャンセルします。このメソッドはタイマがまだ活動待ち状態にある場合にのみ動作します。
バリアオブジェクト
バージョン 3.2 で追加.
バリアは同じ数のスレッドに対して何度でも再利用することができます。
例として、クライアントとサーバの間でスレッドを同期させる単純な方法を紹介します:
b = Barrier(2, timeout=5)
def server():
    start_server()
    b.wait()
    while True:
        connection = accept_connection()
        process_server_connection(connection)
def client():
    b.wait()
    while True:
        connection = make_connection()
        process_client_connection(connection)
class threading.Barrier(parties, action=None, timeout=None)
parties 個のスレッドのためのバリアオブジェクトを作成します。 action は、もし提供されるなら呼び出し可能オブジェクトで、スレッドが解放される時にそのうちの1つによって呼ばれます。 timeout は、 wait() メソッドに対して none が指定された場合のデフォルトのタイムアウト値です。
wait(timeout=None)
バリアを通ります。バリアに対するすべてのスレッドがこの関数を呼んだ時に、それらは同時にすべて解放されます。timeout が提供される場合、それはクラスコンストラクタに渡された値に優先して使用されます。
返り値は 0 から parties -- 1 の範囲の整数で、それぞれのスレッドに対して異なります。これは、特別な後始末 (housekeeping) を行うスレッドを選択するために使用することができます。例えば:
i = barrier.wait()
if i == 0:
    # Only one thread needs to print this
    print("passed the barrier")
action がコンストラクタに渡されていれば、スレッドのうちの1つが解放される前にそれを呼び出します。万一この呼び出しでエラーが発生した場合、バリアは broken な状態に陥ります。
この呼び出しがタイムアウトする場合、バリアは broken な状態に陥ります。
スレッドが待っている間にバリアが broken になるかリセットされた場合、このメソッドは BrokenBarrierError 例外を送出するかもしれません。
reset()
バリアをデフォルトの空の状態に戻します。そのバリアの上で待っているすべてのスレッドは BrokenBarrierError 例外を受け取ります。
abort()
スレッドのうちの1つが返ってこないことに対して自動的に保護するように、単純に常識的な timeout 値でバリアを作成することは望ましいかもしれません。
parties
バリアを通るために要求されるスレッドの数。
n_waiting
現在バリアの中で待っているスレッドの数。
broken
バリアが broken な状態である場合に True となるブール値。
exception threading.BrokenBarrierError
Barrier オブジェクトがリセットされるか broken な場合に、この例外 (RuntimeError のサブクラス) が送出されます。
Using locks, conditions, and semaphores in the with statement
このモジュールのオブジェクトのうち acquire() メソッドと release() メソッドを備えているものは全て with 文のコンテキストマネージャ として使うことができます。 with 文のブロックに入るときに acquire() メソッドが 呼び出され、ブロック脱出時には release() メソッドが呼ばれます。したがって、次のコード:
with some_lock:
    # do something...
は、以下と同じです
some_lock.acquire()
try:
    # do something...
finally:
    some_lock.release()
現在のところ、 Lock 、 RLock 、 Condition 、 Semaphore 、 BoundedSemaphore を with 文のコンテキストマネージャとして使うことができます。
multiprocessing --- プロセスベースの並列処理
ソースコード: Lib/multiprocessing/
はじめに
multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.
multiprocessing モジュールでは、threading モジュールには似たものが存在しない API も導入されています。その最たるものが Pool オブジェクトです。これは複数の入力データに対して、サブプロセス群に入力データを分配 (データ並列) して関数を並列実行するのに便利な手段を提供します。以下の例では、モジュール内で関数を定義して、子プロセスがそのモジュールを正常にインポートできるようにする一般的な方法を示します。 Pool を用いたデータ並列の基礎的な例は次の通りです:
from multiprocessing import Pool
def f(x):
    return x*x
if __name__ == '__main__':
    with Pool(5) as p:
        print(p.map(f, [1, 2, 3]))
標準出力に以下が出力されます:
[1, 4, 9]
Process クラス
multiprocessing モジュールでは、プロセスは以下の手順によって生成されます。はじめに Process のオブジェクトを作成し、続いて start() メソッドを呼び出します。この Process クラスは threading.Thread クラスと同様の API を持っています。まずは、簡単な例をもとにマルチプロセスを使用したプログラムについてみていきましょう
from multiprocessing import Process
def f(name):
    print('hello', name)
if __name__ == '__main__':
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()
実行された個々のプロセス ID を表示するために拡張したサンプルコードを以下に示します:
from multiprocessing import Process
import os
def info(title):
    print(title)
    print('module name:', __name__)
    print('parent process:', os.getppid())
    print('process id:', os.getpid())
def f(name):
    info('function f')
    print('hello', name)
if __name__ == '__main__':
    info('main line')
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()
なぜ if __name__ == '__main__' という記述が必要かは プログラミングガイドライン を参照してください。
コンテキストと開始方式
プラットフォームにもよりますが、multiprocessing はプロセスを開始するために 3 つの方法をサポートしています。それら 開始方式 は以下のとおりです
spawn
Unix と Windows で利用可能。Windows と macOS でのデフォルト。
fork
親プロセスは os.fork() を使用して Python インタープリターをフォークします。子プロセスはそれが開始されるとき、事実上親プロセスと同一になります。親プロセスのリソースはすべて子プロセスに継承されます。マルチスレッドプロセスのフォークは安全性に問題があることに注意してください。
Unix でのみ利用可能。Unix でのデフォルト。
forkserver
プログラムを開始するとき forkserver 方式を選択した場合、サーバープロセスが開始されます。それ以降、新しいプロセスが必要になったときはいつでも、親プロセスはサーバーに接続し、新しいプロセスのフォークを要求します。フォークサーバープロセスはシングルスレッドなので os.fork() の使用に関しても安全です。不要なリソースは継承されません。
Unix パイプを経由したファイル記述子の受け渡しをサポートする Unix で利用可能。
バージョン 3.8 で変更: macOS では、 spawn 開始方式がデフォルトになりました。 fork 開始方法は、サブプロセスのクラッシュを引き起こす可能性があるため、安全ではありません。 bpo-33725 を参照。
バージョン 3.4 で変更: すべての Unix プラットフォームで spawn が、一部のプラットフォームで forkserver が追加されました。Windows では親プロセスの継承可能な全ハンドルが子プロセスに継承されることがなくなりました。
Unix で開始方式に spawn あるいは forkserver を使用した場合は、プログラムのプロセスによって作成されたリンクされていない名前付きシステムリソース (名前付きセマフォや、SharedMemory オブジェクト) を追跡する リソーストラッカー プロセスも開始されます。全プロセスが終了したときに、リソーストラッカーは残っているすべての追跡していたオブジェクトのリンクを解除します。通常そういったことはないのですが、プロセスがシグナルによって kill されたときに "漏れた" リソースが発生する場合があります。(この場合、名前付きセマフォと共有メモリセグメントは、システムが再起動されるまでリンク解除されません。名前付きセマフォの個数はシステムによって制限されており、共有メモリセグメントはメインメモリを占有するため、これらは問題になる可能性があります。)
開始方式はメインモジュールの if __name__ == '__main__' 節内で、関数 set_start_method() によって指定します。以下に例を示します:
import multiprocessing as mp
def foo(q):
    q.put('hello')
if __name__ == '__main__':
    mp.set_start_method('spawn')
    q = mp.Queue()
    p = mp.Process(target=foo, args=(q,))
    p.start()
    print(q.get())
    p.join()
関数 set_start_method() はプログラム内で複数回使用してはいけません。
もうひとつの方法として、get_context() を使用してコンテキストオブジェクトを取得することができます。コンテキストオブジェクトは multiprocessing モジュールと同じ API を持ち、同じプログラム内で複数の開始方式を使用できます。
import multiprocessing as mp
def foo(q):
    q.put('hello')
if __name__ == '__main__':
    ctx = mp.get_context('spawn')
    q = ctx.Queue()
    p = ctx.Process(target=foo, args=(q,))
    p.start()
    print(q.get())
    p.join()
あるコンテキストに関連したオブジェクトは、異なるコンテキストのプロセスとは互換性がない場合があることに注意してください。特に、fork コンテキストを使用して作成されたロックは、spawn あるいは forkserver を使用して開始されたプロセスに渡すことはできません。
特定の開始方式の使用を要求するライブラリは get_context() を使用してライブラリ利用者の選択を阻害しないようにするべきです。
警告 Unix において、'spawn' あるいは 'forkserver' で開始された場合、 "frozen" な実行可能形式 (PyInstaller や cx_Freeze で作成されたバイナリなど) は使用できません。'fork' で開始した場合は動作します。
プロセス間でのオブジェクト交換
multiprocessing モジュールでは、プロセス間通信の手段が2つ用意されています。それぞれ以下に詳細を示します:
キュー (Queue)
Queue クラスは queue.Queue クラスとほとんど同じように使うことができます。以下に例を示します:
from multiprocessing import Process, Queue
def f(q):
    q.put([42, None, 'hello'])
if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print(q.get())    # prints "[42, None, 'hello']"
    p.join()
キューはスレッドセーフであり、プロセスセーフです。
パイプ (Pipe)
Pipe() 関数はパイプで繋がれたコネクションオブジェクトのペアを返します。デフォルトでは双方向性パイプを返します。以下に例を示します:
from multiprocessing import Process, Pipe
def f(conn):
    conn.send([42, None, 'hello'])
    conn.close()
if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    p = Process(target=f, args=(child_conn,))
    p.start()
    print(parent_conn.recv())   # prints "[42, None, 'hello']"
    p.join()
パイプのそれぞれの端を表す2つのコネクションオブジェクトが Pipe() 関数から返されます。各コネクションオブジェクトには、 send()、 recv()、その他のメソッドがあります。2つのプロセス (またはスレッド) がパイプの 同じ 端で同時に読み込みや書き込みを行うと、パイプ内のデータが破損してしまうかもしれないことに注意してください。もちろん、各プロセスがパイプの別々の端を同時に使用するならば、データが破壊される危険性はありません。
プロセス間の同期
multiprocessing は threading モジュールと等価な同期プリミティブを備えています。以下の例では、ロックを使用して、一度に1つのプロセスしか標準出力に書き込まないようにしています:
from multiprocessing import Process, Lock
def f(l, i):
    l.acquire()
    try:
        print('hello world', i)
    finally:
        l.release()
if __name__ == '__main__':
    lock = Lock()
    for num in range(10):
        Process(target=f, args=(lock, num)).start()
ロックを使用しないで標準出力に書き込んだ場合は、各プロセスからの出力がごちゃまぜになってしまいます。
プロセス間での状態の共有
これまでの話の流れで触れたとおり、並行プログラミングを行うときには、できるかぎり状態を共有しないのが定石です。複数のプロセスを使用するときは特にそうでしょう。
しかし、どうしてもプロセス間のデータ共有が必要な場合のために multiprocessing モジュールには2つの方法が用意されています。
共有メモリ (Shared memory)
データを共有メモリ上に保持するために Value クラス、もしくは Array クラスを使用することができます。以下のサンプルコードを使って、この機能についてみていきましょう
from multiprocessing import Process, Value, Array
def f(n, a):
    n.value = 3.1415927
    for i in range(len(a)):
        a[i] = -a[i]
if __name__ == '__main__':
    num = Value('d', 0.0)
    arr = Array('i', range(10))
    p = Process(target=f, args=(num, arr))
    p.start()
    p.join()
    print(num.value)
    print(arr[:])
このサンプルコードを実行すると以下のように表示されます
3.1415927
[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
num と arr を生成するときに使用されている、引数 'd' と 'i' は array モジュールにより使用される種別の型コードです。ここで使用されている 'd' は倍精度浮動小数、 'i' は符号付整数を表します。これらの共有オブジェクトは、プロセスセーフでありスレッドセーフです。
共有メモリを使用して、さらに柔軟なプログラミングを行うには multiprocessing.sharedctypes モジュールを使用します。このモジュールは共有メモリから割り当てられた任意の ctypes オブジェクトの生成をサポートします。
サーバープロセス (Server process)
Manager() 関数により生成されたマネージャーオブジェクトはサーバープロセスを管理します。マネージャーオブジェクトは Python のオブジェクトを保持して、他のプロセスがプロキシ経由でその Python オブジェクトを操作することができます。
Manager() 関数が返すマネージャは list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value, Array をサポートします。 以下にサンプルコードを示します。
from multiprocessing import Process, Manager
def f(d, l):
    d[1] = '1'
    d['2'] = 2
    d[0.25] = None
    l.reverse()
if __name__ == '__main__':
    with Manager() as manager:
        d = manager.dict()
        l = manager.list(range(10))
        p = Process(target=f, args=(d, l))
        p.start()
        p.join()
        print(d)
        print(l)
このサンプルコードを実行すると以下のように表示されます
{0.25: None, 1: '1', '2': 2}
[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
サーバープロセスのマネージャーオブジェクトは共有メモリのオブジェクトよりも柔軟であるといえます。それは、どのような型のオブジェクトでも使えるからです。また、1つのマネージャーオブジェクトはネットワーク経由で他のコンピューター上のプロセスによって共有することもできます。しかし、共有メモリより動作が遅いという欠点があります。
ワーカープロセスのプールを使用
Pool クラスは、ワーカープロセスをプールする機能を備えています。このクラスには、異なる方法でワーカープロセスへタスクを割り当てるいくつかのメソッドがあります。
例えば:
from multiprocessing import Pool, TimeoutError
import time
import os
def f(x):
    return x*x
if __name__ == '__main__':
    # start 4 worker processes
    with Pool(processes=4) as pool:
        # print "[0, 1, 4,..., 81]"
        print(pool.map(f, range(10)))
        # print same numbers in arbitrary order
        for i in pool.imap_unordered(f, range(10)):
            print(i)
        # evaluate "f(20)" asynchronously
        res = pool.apply_async(f, (20,))      # runs in *only* one process
        print(res.get(timeout=1))             # prints "400"
        # evaluate "os.getpid()" asynchronously
        res = pool.apply_async(os.getpid, ()) # runs in *only* one process
        print(res.get(timeout=1))             # prints the PID of that process
        # launching multiple evaluations asynchronously *may* use more processes
        multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)]
        print([res.get(timeout=1) for res in multiple_results])
        # make a single worker sleep for 10 secs
        res = pool.apply_async(time.sleep, (10,))
        try:
            print(res.get(timeout=1))
        except TimeoutError:
            print("We lacked patience and got a multiprocessing.TimeoutError")
        print("For the moment, the pool remains available for more work")
    # exiting the 'with'-block has stopped the pool
    print("Now the pool is closed and no longer available")
プールオブジェクトのメソッドは、そのプールを作成したプロセスのみが呼び出すべきです。
注釈 このパッケージに含まれる機能を使用するためには、子プロセスから __main__ モジュールをインポートできる必要があります。このことについては プログラミングガイドライン で触れていますが、ここであらためて強調しておきます。なぜかというと、いくつかのサンプルコード、例えば multiprocessing.pool.Pool のサンプルはインタラクティブシェル上では動作しないからです。以下に例を示します:
>>>
>>> from multiprocessing import Pool
>>> p = Pool(5)
>>> def f(x):
...     return x*x
...
>>> with p:
...   p.map(f, [1,2,3])
Process PoolWorker-1:
Process PoolWorker-2:
Process PoolWorker-3:
Traceback (most recent call last):
AttributeError: 'module' object has no attribute 'f'
AttributeError: 'module' object has no attribute 'f'
AttributeError: 'module' object has no attribute 'f'
(もしこのコードを試すなら、実際には3つの完全なトレースバックがばらばらの順番で出力されますし、親プロセスを何らかの方法で止める必要があります。)
リファレンス
multiprocessing パッケージは threading モジュールの API とほとんど同じです。
Process クラスと例外
class multiprocessing.Process(group=None, target=None, name=None, args=(), kwargs={}, *, daemon=None)
Process オブジェクトは各プロセスの処理を表します。 Process クラスは threading.Thread クラスのすべてのメソッドと同じインタフェースを提供します。
コンストラクターは必ずキーワード引数で呼び出すべきです。引数 group には必ず None を渡してください。 この引数は threading.Thread クラスとの互換性のためだけに残されています。引数 target には、 run() メソッドから呼び出される callable オブジェクトを渡します。この引数はデフォルトで None となっており、何も呼び出されません。引数 name にはプロセス名を渡します (詳細は name を見てください)。 args は対象の呼び出しに対する引数のタプルを渡します。 kwargs は対象の呼び出しに対するキーワード引数の辞書を渡します。もし提供されれば、キーワード専用の daemon 引数はプロセスの daemon フラグを True または False にセットします。 None の場合 (デフォルト)、このフラグは作成するプロセスから継承されます。
デフォルトでは、target には引数が渡されないようになっています。
サブクラスがコンストラクターをオーバーライドする場合は、そのプロセスに対する処理を行う前に基底クラスのコンストラクター (Process.__init__()) を実行しなければなりません。
バージョン 3.3 で変更: daemon 引数が追加されました。
run()
プロセスが実行する処理を表すメソッドです。
このメソッドはサブクラスでオーバーライドすることができます。標準の run() メソッドは、コンストラクターの target 引数として渡された呼び出し可能オブジェクトを呼び出します。もしコンストラクターに args もしくは kwargs 引数が渡されていれば、呼び出すオブジェクトにこれらの引数を渡します。
start()
プロセスの処理を開始するためのメソッドです。
各 Process オブジェクトに対し、このメソッドが2回以上呼び出されてはいけません。各プロセスでオブジェクトの run() メソッドを呼び出す準備を行います。
join([timeout])
オプションの引数 timeout が None (デフォルト) の場合、 join() メソッドが呼ばれたプロセスは処理が終了するまでブロックします。 timeout が正の数である場合、最大 timeout 秒ブロックします。 プロセスが終了あるいはタイムアウトした場合、メソッドは None を返すことに注意してください。 プロセスの exitcode を確認し終了したかどうかを判断してください。
1つのプロセスは何回も join されることができます。
プロセスは自分自身を join することはできません。それはデッドロックを引き起こすことがあるからです。プロセスが start される前に join しようとするとエラーが発生します。
name
プロセスの名前。名前は識別のためだけに使用される文字列です。それ自体には特別な意味はありません。複数のプロセスに同じ名前が与えられても構いません。
最初の名前はコンストラクターによってセットされます。コンストラクターに明示的な名前が渡されない場合、 'Process-N1:N2:...:Nk' 形式の名前が構築されます。ここでそれぞれの Nk はその親のN番目の子供です。
is_alive()
プロセスが実行中かを判別します。
おおまかに言って、プロセスオブジェクトは start() メソッドを呼び出してから子プロセス終了までの期間が実行中となります。
daemon
デーモンプロセスであるかのフラグであり、ブール値です。この属性は start() が呼び出される前に設定されている必要があります。
初期値は作成するプロセスから継承します。
あるプロセスが終了するとき、そのプロセスはその子プロセスであるデーモンプロセスすべてを終了させようとします。
デーモンプロセスは子プロセスを作成できないことに注意してください。もし作成できてしまうと、そのデーモンプロセスの親プロセスが終了したときにデーモンプロセスの子プロセスが孤児になってしまう場合があるからです。さらに言えば、デーモンプロセスはUnix デーモンやサービスでは なく 通常のプロセスであり、非デーモンプロセスが終了すると終了されます (そして join されません)。
threading.Thread クラスの API に加えて Process クラスのオブジェクトには以下の属性およびメソッドがあります:
pid
プロセスIDを返します。プロセスの生成前は None が設定されています。
exitcode
子プロセスの終了コードです。子プロセスがまだ終了していない場合は None が返されます。負の値 -N は子プロセスがシグナル N で終了したことを表します。
authkey
プロセスの認証キーです (バイト文字列です)。
multiprocessing モジュールがメインプロセスにより初期化される場合には、 os.urandom() 関数を使用してランダムな値が設定されます。
Process クラスのオブジェクトの作成時にその親プロセスから認証キーを継承します。もしくは authkey に別のバイト文字列を設定することもできます。
詳細は 認証キー を参照してください。
sentinel
プロセスが終了するときに "ready" となるシステムオブジェクトの数値ハンドル。
multiprocessing.connection.wait() を使用していくつかのイベントを同時に wait したい場合はこの値を使うことができます。それ以外の場合は join() を呼ぶ方がより単純です。
Windows においては、これは WaitForSingleObject および WaitForMultipleObjects ファミリーの API 呼び出しで使用可能な OS ハンドルです。 Unix においては、これは select モジュールのプリミティブで使用可能なファイル記述子です。
バージョン 3.3 で追加.
terminate()
プロセスを終了します。Unix 環境では SIGTERM シグナルを、 Windows 環境では TerminateProcess() を使用して終了させます。終了ハンドラーや finally 節などは、実行されないことに注意してください。
このメソッドにより終了するプロセスの子孫プロセスは、終了 しません 。そういった子孫プロセスは単純に孤児になります。
警告 このメソッドの使用時に、関連付けられたプロセスがパイプやキューを使用している場合には、使用中のパイプやキューが破損して他のプロセスから使用できなくなる可能性があります。同様に、プロセスがロックやセマフォなどを取得している場合には、このプロセスが終了してしまうと他のプロセスのデッドロックの原因になるでしょう。
kill()
meth:terminate() と同様の動作をしますが、Unix では``SIGKILL`` シグナルを使用します。
バージョン 3.7 で追加.
close()
Process オブジェクトを閉じ、関連付けられていたすべてのリソースを開放します。中のプロセスが実行中であった場合、ValueError を送出します。close() が成功した場合、class:Process オブジェクトの他のメソッドや属性は、ほとんどが ValueError を送出します。
バージョン 3.7 で追加.
プロセスオブジェクトが作成したプロセスのみが start(), join(), is_alive(), terminate() と exitcode のメソッドを呼び出すべきです。
以下の例では Process のメソッドの使い方を示しています:
 >>> import multiprocessing, time, signal
 >>> p = multiprocessing.Process(target=time.sleep, args=(1000,))
 >>> print(p, p.is_alive())
 <Process ... initial> False
 >>> p.start()
 >>> print(p, p.is_alive())
 <Process ... started> True
 >>> p.terminate()
 >>> time.sleep(0.1)
 >>> print(p, p.is_alive())
 <Process ... stopped exitcode=-SIGTERM> False
 >>> p.exitcode == -signal.SIGTERM
 True
exception multiprocessing.ProcessError
すべての multiprocessing 例外の基底クラスです。
exception multiprocessing.BufferTooShort
この例外は Connection.recv_bytes_into() によって発生し、バッファーオブジェクトが小さすぎてメッセージが読み込めないことを示します。
e が BufferTooShort のインスタンスであるとすると、 e.args[0] はそのメッセージをバイト文字列で与えるものです。
exception multiprocessing.AuthenticationError
認証エラーがあった場合に送出されます。
exception multiprocessing.TimeoutError
タイムアウトをサポートするメソッドでタイムアウトが過ぎたときに送出されます。
パイプ (Pipe) とキュー (Queue)
複数のプロセスを使う場合、一般的にはメッセージパッシングをプロセス間通信に使用し、ロックのような同期プリミティブを使用しないようにします。
メッセージのやりとりのために Pipe() (2つのプロセス間の通信用)、もしくはキュー (複数のメッセージ生成プロセス (producer)、消費プロセス (consumer) の実現用) を使うことができます。
Queue, SimpleQueue と JoinableQueue 型は複数プロセスから生成/消費を行う FIFO キューです。これらのキューは標準ライブラリの queue.Queue を模倣しています。 Queue には Python 2.5 の queue.Queue クラスで導入された task_done() と join() メソッドがないことが違う点です。
もし JoinableQueue を使用するなら、キューから削除される各タスクのために JoinableQueue.task_done() を呼び出さなければ なりません 。さもないと、いつか完了していないタスクを数えるためのセマフォがオーバーフローし、例外を発生させるでしょう。
管理オブジェクトを使用することで共有キューを作成できることも覚えておいてください。詳細は マネージャー を参照してください。
注釈 multiprocessing は、タイムアウトを伝えるために、通常の queue.Empty と queue.Full 例外を使用します。それらは multiprocessing の名前空間では利用できないため、queue からインポートする必要があります。
注釈 オブジェクトがキューに追加される際、そのオブジェクトは pickle 化されています。そのため、バックグラウンドのスレッドが後になって下位層のパイプに pickle 化されたデータをフラッシュすることがあります。これにより、少し驚くような結果になりますが、実際に問題になることはないはずです。これが問題になるような状況では、かわりに manager を使ってキューを作成することができるからです。
空のキューの中にオブジェクトを追加した後、キューの empty() メソッドが False を返すまでの間にごくわずかな遅延が起きることがあり、get_nowait() が queue.Empty を発生させることなく制御が呼び出し元に返ってしまうことがあります。
複数のプロセスがオブジェクトをキューに詰めている場合、キューの反対側ではオブジェクトが詰められたのとは違う順序で取得される可能性があります。ただし、同一のプロセスから詰め込まれたオブジェクトは、それらのオブジェクト間では、必ず期待どおりの順序になります。
警告 Queue を利用しようとしている最中にプロセスを Process.terminate() や os.kill() で終了させる場合、キューにあるデータは破損し易くなります。終了した後で他のプロセスがキューを利用しようとすると、例外を発生させる可能性があります。
警告 上述したように、もし子プロセスがキューへ要素を追加するなら (かつ JoinableQueue.cancel_join_thread を使用しないなら) そのプロセスはバッファーされたすべての要素がパイプへフラッシュされるまで終了しません。
これは、そのプロセスを join しようとする場合、キューに追加されたすべての要素が消費されたことが確実でないかぎり、デッドロックを発生させる可能性があることを意味します。似たような現象で、子プロセスが非デーモンプロセスの場合、親プロセスは終了時に非デーモンのすべての子プロセスを join しようとしてハングアップする可能性があります。
マネージャーを使用して作成されたキューではこの問題はありません。詳細は プログラミングガイドライン を参照してください。
プロセス間通信におけるキューの使用例を知りたいなら 使用例 を参照してください。
multiprocessing.Pipe([duplex])
duplex が True (デフォルト) ならパイプは双方向性です。duplex が False ならパイプは一方向性で、conn1 はメッセージの受信専用、conn2 はメッセージの送信専用になります。
class multiprocessing.Queue([maxsize])
パイプや2～3個のロック/セマフォを使用して実装されたプロセス共有キューを返します。あるプロセスが最初に要素をキューへ追加するとき、バッファーからパイプの中へオブジェクトを転送する供給スレッドが開始されます。
標準ライブラリの queue モジュールの通常の queue.Empty や queue.Full 例外がタイムアウトを伝えるために送出されます。
Queue は task_done() や join() を除く queue.Queue のすべてのメソッドを実装します。
qsize()
おおよそのキューのサイズを返します。マルチスレッディング/マルチプロセスの特性上、この数値は信用できません。
これは sem_getvalue() が実装されていない Mac OS X のような Unix プラットホーム上で NotImplementedError を発生させる可能性があることを覚えておいてください。
empty()
キューが空っぽなら True を、そうでなければ False を返します。マルチスレッディング/マルチプロセシングの特性上、これは信用できません。
full()
キューがいっぱいなら True を、そうでなければ False を返します。マルチスレッディング/マルチプロセシングの特性上、これは信用できません。
put(obj[, block[, timeout]])
キューの中へ obj を追加します。オプションの引数 block が True (デフォルト) 且つ timeout が None (デフォルト) なら、空きスロットが利用可能になるまで必要であればブロックします。 timeout が正の数なら、最大 timeout 秒ブロックして、その時間内に空きスロットが利用できなかったら queue.Full 例外を発生させます。それ以外 (block が False) で、空きスロットがすぐに利用可能な場合はキューに要素を追加します。そうでなければ queue.Full 例外が発生します(その場合 timeout は無視されます)。
バージョン 3.8 で変更: If the queue is closed, ValueError is raised instead of AssertionError.
put_nowait(obj)
put(obj, False) と等価です。
get([block[, timeout]])
キューから要素を取り出して削除します。オプションの引数 block が True (デフォルト) 且つ timeout が None (デフォルト) なら、要素が取り出せるまで必要であればブロックします。 timeout が正の数なら、最大 timeout 秒ブロックして、その時間内に要素が取り出せなかったら queue.Empty 例外を発生させます。それ以外 (block が False) で、要素がすぐに取り出せる場合は要素を返します。そうでなければ queue.Empty 例外が発生します(その場合 timeout は無視されます)。
バージョン 3.8 で変更: If the queue is closed, ValueError is raised instead of OSError.
get_nowait()
get(False) と等価です。
multiprocessing.Queue は queue.Queue にはない追加メソッドがあります。 これらのメソッドは通常、ほとんどのコードに必要ありません:
close()
カレントプロセスからこのキューへそれ以上データが追加されないことを表します。バックグラウンドスレッドはパイプへバッファーされたすべてのデータをフラッシュするとすぐに終了します。これはキューがガベージコレクトされるときに自動的に呼び出されます。
join_thread()
バックグラウンドスレッドを join します。このメソッドは close() が呼び出された後でのみ使用されます。バッファーされたすべてのデータがパイプへフラッシュされるのを保証するため、バックグラウンドスレッドが終了するまでブロックします。
デフォルトでは、あるプロセスがキューを作成していない場合、終了時にキューのバックグラウンドスレッドを join しようとします。そのプロセスは join_thread() が何もしないように cancel_join_thread() を呼び出すことができます。
cancel_join_thread()
join_thread() がブロッキングするのを防ぎます。特にこれはバックグラウンドスレッドがそのプロセスの終了時に自動的に join されるのを防ぎます。詳細は join_thread() を参照してください。
このメソッドは allow_exit_without_flush() という名前のほうがよかったかもしれません。キューに追加されたデータが失われてしまいがちなため、このメソッドを使う必要はほぼ確実にないでしょう。本当にこれが必要になるのは、キューに追加されたデータを下位層のパイプにフラッシュすることなくカレントプロセスを直ちに終了する必要があり、かつ失われるデータに関心がない場合です。
注釈 このクラスに含まれる機能には、ホストとなるオペレーティングシステム上で動作している共有セマフォ (shared semaphore) を使用しているものがあります。これが使用できない場合には、このクラスが無効になり、 Queue をインスタンス化する時に ImportError が発生します。詳細は bpo-3770 を参照してください。同様のことが、以下に列挙されている特殊なキューでも成り立ちます。
class multiprocessing.SimpleQueue
単純化された Queue 型です。ロックされた Pipe と非常に似ています。
close()
バージョン 3.9 で追加.
empty()
キューが空ならば True を、そうでなければ False を返します。
get()
キューから要素を削除して返します。
put(item)
item をキューに追加します。
class multiprocessing.JoinableQueue([maxsize])
JoinableQueue は Queue のサブクラスであり、 task_done() や join() メソッドが追加されているキューです。
task_done()
以前にキューへ追加されたタスクが完了したことを表します。キューのコンシューマによって使用されます。 タスクをフェッチするために使用されるそれぞれの get() に対して、 後続の task_done() 呼び出しはタスクの処理が完了したことをキューへ伝えます。
もし join() がブロッキング状態なら、 すべての要素が処理されたときに復帰します( task_done() 呼び出しが すべての要素からキュー内へ put() されたと受け取ったことを意味します)。
キューにある要素より多く呼び出された場合 ValueError が発生します。
join()
キューにあるすべてのアイテムが取り出されて処理されるまでブロックします。
キューに要素が追加されると未完了タスク数が増えます。コンシューマがキューの要素が取り出されてすべての処理が完了したことを表す task_done() を呼び出すと数が減ります。 未完了タスク数がゼロになると join() はブロッキングを解除します。
その他
multiprocessing.active_children()
カレントプロセスのすべてのアクティブな子プロセスのリストを返します。
これを呼び出すと "join" してすでに終了しているプロセスには副作用があります。
multiprocessing.cpu_count()
システムの CPU 数を返します。
この数は現在のプロセスが使える CPU 数と同じものではありません。 使用可能な CPU 数は len(os.sched_getaffinity(0)) で取得できます。
NotImplementedError を送出するかもしれません。
参考 os.cpu_count()
multiprocessing.current_process()
カレントプロセスに対応する Process オブジェクトを返します。
threading.current_thread() とよく似た関数です。
multiprocessing.parent_process()
バージョン 3.8 で追加.
multiprocessing.freeze_support()
multiprocessing を使用しているプログラムをフリーズして Windows の実行可能形式を生成するためのサポートを追加します。(py2exe , PyInstaller や cx_Freeze でテストされています。)
メインモジュールの if __name__ == '__main__' の直後にこの関数を呼び出す必要があります。以下に例を示します:
from multiprocessing import Process, freeze_support
def f():
    print('hello world!')
if __name__ == '__main__':
    freeze_support()
    Process(target=f).start()
もし freeze_support() の行がない場合、フリーズされた実行可能形式を実行しようとすると RuntimeError を発生させます。
freeze_support() の呼び出しは Windows 以外の OS では効果がありません。さらに、もしモジュールが Windows の通常の Python インタプリタによって実行されているならば（プログラムがフリーズされていなければ） freeze_support() は効果がありません。
multiprocessing.get_all_start_methods()
サポートしている開始方式のリストを返します。先頭の要素がデフォルトを意味します。利用可能な開始方式には 'fork'、'spawn' および 'forkserver' があります。Windows では 'spawn' のみが利用可能です。Unix では 'fork' および 'spawn' は常にサポートされており、'fork' がデフォルトになります。
バージョン 3.4 で追加.
multiprocessing.get_context(method=None)
multiprocessing モジュールと同じ属性を持つコンテキストオブジェクトを返します。
method が None の場合、デフォルトのコンテキストが返されます。その他の場合 method は 'fork'、'spawn' あるいは 'forkserver' でなければなりません。指定された開始方式が利用できない場合は ValueError が送出されます。
バージョン 3.4 で追加.
multiprocessing.get_start_method(allow_none=False)
開始するプロセスで使用する開始方式名を返します。
開始方式がまだ確定しておらず、allow_none の値が偽の場合、開始方式はデフォルトに確定され、その名前が返されます。開始方式が確定しておらず、allow_none の値が真の場合、 None が返されます。
返り値は 'fork'、'spawn'、'forkserver' あるいは None になります。Unix では 'fork' が、Windows では 'spawn' がデフォルトになります。
バージョン 3.4 で追加.
multiprocessing.set_executable()
子プロセスを開始するときに、使用する Python インタープリターのパスを設定します。(デフォルトでは sys.executable が使用されます)。コードに組み込むときは、おそらく次のようにする必要があります
set_executable(os.path.join(sys.exec_prefix, 'pythonw.exe'))
子プロセスを作成する前に行ってください。
バージョン 3.4 で変更: Unix で開始方式に 'spawn' を使用している場合にサポートされました。
multiprocessing.set_start_method(method)
子プロセスの開始方式を指定します。method には 'fork'、'spawn' あるいは 'forkserver' を指定できます。
これは一度しか呼び出すことができず、その場所もメインモジュールの if __name__ == '__main__' 節内で保護された状態でなければなりません。
バージョン 3.4 で追加.
注釈 multiprocessing には threading.active_count(), threading.enumerate(), threading.settrace(), threading.setprofile(), threading.Timer や threading.local のような関数はありません。
Connection オブジェクト
Connection オブジェクトは pickle でシリアライズ可能なオブジェクトか文字列を送ったり、受け取ったりします。そういったオブジェクトはメッセージ指向の接続ソケットと考えられます。
class multiprocessing.connection.Connection
send(obj)
コネクションの相手側へ recv() を使用して読み込むオブジェクトを送ります。
recv()
コネクションの相手側から send() を使用して送られたオブジェクトを返します。 何か受け取るまでブロックします。何も受け取らずにコネクションの相手側でクローズされた場合 EOFError が発生します。
fileno()
コネクションが使用するハンドラーか、ファイル記述子を返します。
close()
コネクションをクローズします。
コネクションがガベージコレクトされるときに自動的に呼び出されます。
poll([timeout])
読み込み可能なデータがあるかどうかを返します。
timeout が指定されていなければすぐに返します。 timeout に数値を指定すると、最大指定した秒数をブロッキングします。 timeout に None を指定するとタイムアウトせずにずっとブロッキングします。
multiprocessing.connection.wait() を使って複数のコネクションオブジェクトを同時にポーリングできることに注意してください。
send_bytes(buffer[, offset[, size]])
bytes-like object から完全なメッセージとしてバイトデータを送ります。
If offset is given then data is read from that position in buffer. If size is given then that many bytes will be read from buffer. Very large buffers (approximately 32 MiB+, though it depends on the OS) may raise a ValueError exception
recv_bytes([maxlength])
コネクションの相手側から送られたバイトデータの完全なメッセージを文字列として返します。何か受け取るまでブロックします。受け取るデータが何も残っておらず、相手側がコネクションを閉じていた場合、 EOFError が送出されます。
maxlength を指定していて、かつメッセージが maxlength より長い場合、 OSError が発生してコネクションからそれ以上読めなくなります。
バージョン 3.3 で変更: この関数は以前は IOError を送出していました。今では OSError の別名です。
recv_bytes_into(buffer[, offset])
コネクションの相手側から送られたバイトデータを buffer に読み込み、メッセージのバイト数を返します。 何か受け取るまでブロックします。何も受け取らずにコネクションの相手側でクローズされた場合 EOFError が発生します。
buffer は書き込み可能な bytes-like object でなければなりません。 offset が与えられたら、その位置からバッファーへメッセージが書き込まれます。 オフセットは buffer バイトよりも小さい正の数でなければなりません。
バッファーがあまりに小さいと BufferTooShort 例外が発生します。 e が例外インスタンスとすると完全なメッセージは e.args[0] で確認できます。
バージョン 3.3 で変更: Connection.send() と Connection.recv() を使用して Connection オブジェクト自体をプロセス間で転送できるようになりました。
バージョン 3.3 で追加: Connection オブジェクトがコンテキストマネージメント・プロトコルをサポートするようになりました。 -- コンテキストマネージャ型 を参照してください。 __enter__() は Connection オブジェクトを返します。また __exit__() は close() を呼び出します。
例えば:
>>> from multiprocessing import Pipe
>>> a, b = Pipe()
>>> a.send([1, 'hello', None])
>>> b.recv()
[1, 'hello', None]
>>> b.send_bytes(b'thank you')
>>> a.recv_bytes()
b'thank you'
>>> import array
>>> arr1 = array.array('i', range(5))
>>> arr2 = array.array('i', [0] * 10)
>>> a.send_bytes(arr1)
>>> count = b.recv_bytes_into(arr2)
>>> assert count == len(arr1) * arr1.itemsize
>>> arr2
array('i', [0, 1, 2, 3, 4, 0, 0, 0, 0, 0])
警告 Connection.recv() メソッドは受信したデータを自動的に unpickle 化します。それはメッセージを送ったプロセスが信頼できる場合を除いてセキュリティリスクになります。
そのため Pipe() を使用してコネクションオブジェクトを生成する場合を除いて、何らかの認証処理を実行した後で recv() や send() メソッドのみを使用すべきです。詳細は 認証キー を参照してください。
警告 もしプロセスがパイプの読み込みまたは書き込み中に kill されると、メッセージの境界がどこなのか分からなくなってしまうので、そのパイプ内のデータは破損してしまいがちです。
同期プリミティブ
一般的にマルチプロセスプログラムは、マルチスレッドプログラムほどは同期プリミティブを必要としません。詳細は threading モジュールのドキュメントを参照してください。
マネージャーオブジェクトを使用して同期プリミティブを作成できることも覚えておいてください。詳細は マネージャー を参照してください。
class multiprocessing.Barrier(parties[, action[, timeout]])
バリアーオブジェクト: threading.Barrier のクローンです。
バージョン 3.3 で追加.
class multiprocessing.BoundedSemaphore([value])
有限セマフォオブジェクト: threading.BoundedSemaphore の類似物です。
よく似た threading.BoundedSemaphore とは、次の一点だけ異なります。 acquire メソッドの第一引数名は block で、Lock.acquire() と一致しています。
注釈 Mac OS X では sem_getvalue() が実装されていないので Semaphore と区別がつきません。
class multiprocessing.Condition([lock])
状態変数: threading.Condition の別名です。
lock を指定するなら multiprocessing の Lock か RLock オブジェクトにすべきです。
バージョン 3.3 で変更: wait_for() メソッドが追加されました。
class multiprocessing.Event
threading.Event のクローンです。
class multiprocessing.Lock
再帰しないロックオブジェクトで、 threading.Lock 相当のものです。プロセスやスレッドがロックをいったん獲得 (acquire) すると、それに続くほかのプロセスやスレッドが獲得しようとする際、それが解放 (release) されるまではブロックされます。解放はどのプロセス、スレッドからも行えます。スレッドに対して適用される threading.Lock のコンセプトと振る舞いは、特筆すべきものがない限り、プロセスとスレッドに適用される multiprocessing.Lock に引き継がれています。
Lock は実際にはファクトリ関数で、デフォルトコンテキストで初期化された multiprocessing.synchronize.Lock のインスタンスを返すことに注意してください。
Lock は context manager プロトコルをサポートしています。つまり with 文で使うことができます。
acquire(block=True, timeout=None)
ブロックあり、またはブロックなしでロックを獲得します。
引数 block を True (デフォルト) に設定して呼び出した場合、ロックがアンロック状態になるまでブロックします。ブロックから抜けるとそれをロック状態にしてから True を返します。 threading.Lock.acquire() の最初の引数とは名前が違っているので注意してください。
引数 block の値を False にして呼び出すとブロックしません。 現在ロック状態であれば、直ちに False を返します。それ以外の場合には、ロックをロック状態にして True を返します。
timeout として正の浮動小数点数を与えて呼び出すと、ロックが獲得できない限り、指定された秒数だけブロックします。 timeout 値に負数を与えると、ゼロを与えた場合と同じになります。 timeout 値の None (デフォルト) を与えると、無限にブロックします。 timeout 引数の負数と None の扱いは、 threading.Lock.acquire() に実装された動作と異なるので注意してください。 block が False の場合、 timeout は実際的な意味を持たなくなるので無視されます。ロックを獲得した場合は True 、タイムアウトした場合は False で戻ります。
release()
ロックを解放します。これはロックを獲得したプロセスやスレッドだけでなく、任意のプロセスやスレッドから呼ぶことができます。
threading.Lock.release() と同じように振舞いますが、ロックされていない場合に呼び出すと ValueError となる点だけが違います。
class multiprocessing.RLock
再帰ロックオブジェクトで、 threading.RLock 相当のものです。再帰ロックオブジェクトはそれを獲得 (acquire) したプロセスやスレッドが解放 (release) しなければなりません。プロセスやスレッドがロックをいったん獲得すると、同じプロセスやスレッドはブロックされずに再度獲得出来ます。そのプロセスやスレッドは獲得した回数ぶん解放しなければなりません。
RLock は実際にはファクトリ関数で、デフォルトコンテキストで初期化された multiprocessing.synchronize.Lock のインスタンスを返すことに注意してください。
RLock は context manager プロトコルをサポートしています。つまり with 文で使うことができます。
acquire(block=True, timeout=None)
ブロックあり、またはブロックなしでロックを獲得します。
block 引数を True にして呼び出した場合、ロックが既にカレントプロセスもしくはカレントスレッドが既に所有していない限りは、アンロック状態 (どのプロセス、スレッドも所有していない状態) になるまでブロックします。ブロックから抜けるとカレントプロセスもしくはカレントスレッドが (既に持っていなければ) 所有権を得て、再帰レベルをインクリメントし、 True で戻ります。 threading.RLock.acquire() の実装とはこの最初の引数の振る舞いが、その名前自身を始めとしていくつか違うので注意してください。
block 引数を False にして呼び出した場合、ブロックしません。ロックが他のプロセスもしくはスレッドにより獲得済み (つまり所有されている) であれば、カレントプロセスまたはカレントスレッドは所有権を得ず、再帰レベルも変更せずに、 False で戻ります。ロックがアンロック状態の場合、カレントプロセスもしくはカレントスレッドは所有権を得て再帰レベルがインクリメントされ、 True で戻ります。(---訳注: block の True/False 関係なくここでの説明では「所有権を持っている場合の2度目以降の aquire」の説明が欠けています。2度目以降の acquire では再帰レベルがインクリメントされて即座に返ります。全体読めばわかるとは思いますが一応。---)
timeout 引数の使い方と振る舞いは Lock.acquire() と同じです。 timeout 引数の振る舞いがいくつかの点で threading.RLock.acquire() と異なるので注意してください。
release()
再帰レベルをデクリメントしてロックを解放します。デクリメント後に再帰レベルがゼロになった場合、ロックの状態をアンロック (いかなるプロセス、いかなるスレッドにも所有されていない状態) にリセットし、ロックの状態がアンロックになるのを待ってブロックしているプロセスもしくはスレッドがある場合にはその中のただ一つだけが処理を進行できるようにします。デクリメント後も再帰レベルがゼロでない場合、ロックの状態はロックのままで、呼び出し側のプロセスもしくはスレッドに所有されたままになります。
このメソッドは呼び出しプロセスあるいはスレッドがロックを所有している場合に限り呼び出してください。所有者でないプロセスもしくはスレッドによって呼ばれるか、あるいはアンロック (未所有) 状態で呼ばれた場合、 AssertionError が送出されます。同じ状況での threading.RLock.release() 実装とは例外の型が異なるので注意してください。
class multiprocessing.Semaphore([value])
セマフォオブジェクト: threading.Semaphore のクローンです。
よく似た threading.BoundedSemaphore とは、次の一点だけ異なります。 acquire メソッドの第一引数名は block で、Lock.acquire() と一致しています。
注釈 Mac OS X では sem_timedwait がサポートされていないので、acquire() にタイムアウトを与えて呼ぶと、ループ内でスリープすることでこの関数がエミュレートされます。
注釈 メインスレッドが BoundedSemaphore.acquire(), Lock.acquire(), RLock.acquire(), Semaphore.acquire(), Condition.acquire() 又は Condition.wait() を呼び出してブロッキング状態のときに Ctrl-C で生成される SIGINT シグナルを受け取ると、その呼び出しはすぐに中断されて KeyboardInterrupt が発生します。
これは同等のブロッキング呼び出しが実行中のときに SIGINT が無視される threading の振る舞いとは違っています。
注釈 このパッケージに含まれる機能には、ホストとなるオペレーティングシステム上で動作している共有セマフォを使用しているものがあります。これが使用できない場合には、multiprocessing.synchronize モジュールが無効になり、このモジュールのインポート時に ImportError が発生します。詳細は bpo-3770 を参照してください。
共有 ctypes オブジェクト
子プロセスにより継承される共有メモリを使用する共有オブジェクトを作成することができます。
multiprocessing.Value(typecode_or_type, *args, lock=True)
共有メモリから割り当てられた ctypes オブジェクトを返します。 デフォルトでは、返り値は実際のオブジェクトの同期ラッパーです。オブジェクトそれ自身は、 Value の value 属性によってアクセスできます。
typecode_or_type は返されるオブジェクトの型を決めます。それは ctypes の型か array モジュールで使用されるような1文字の型コードかのどちらか一方です。 *args は型のコンストラクターへ渡されます。
lock が True (デフォルト) なら、値へ同期アクセスするために新たに再帰的なロックオブジェクトが作成されます。 lock が Lock か RLock なら値への同期アクセスに使用されます。 lock が False なら、返されたオブジェクトへのアクセスはロックにより自動的に保護されません。そのため、必ずしも "プロセスセーフ" ではありません。
+= のような演算は、読み込みと書き込みを含むためアトミックでありません。このため、たとえば自動的に共有の値を増加させたい場合、以下のようにするのでは不十分です
counter.value += 1
関連するロックが再帰的 (それがデフォルトです) なら、かわりに次のようにします
with counter.get_lock():
    counter.value += 1
lock はキーワード専用引数であることに注意してください。
multiprocessing.Array(typecode_or_type, size_or_initializer, *, lock=True)
共有メモリから割り当てられた ctypes 配列を返します。デフォルトでは、返り値は実際の配列の同期ラッパーです。
typecode_or_type は返される配列の要素の型を決めます。それは ctypes の型か array モジュールで使用されるような1文字の型コードかのどちらか一方です。 size_or_initializer が整数なら、配列の長さを決定し、その配列はゼロで初期化されます。別の使用方法として size_or_initializer は配列の初期化に使用されるシーケンスになり、そのシーケンス長が配列の長さを決定します。
lock が True (デフォルト) なら、値へ同期アクセスするために新たなロックオブジェクトが作成されます。 lock が Lock か RLock なら値への同期アクセスに使用されます。 lock が False なら、返されたオブジェクトへのアクセスはロックにより自動的に保護されません。そのため、必ずしも "プロセスセーフ" ではありません。
lock はキーワード引数としてのみ利用可能なことに注意してください。
ctypes.c_char の配列は文字列を格納して取り出せる value と raw 属性を持っていることを覚えておいてください。
multiprocessing.sharedctypes モジュール
multiprocessing.sharedctypes モジュールは子プロセスに継承される共有メモリの ctypes オブジェクトを割り当てる関数を提供します。
注釈 共有メモリのポインターを格納することは可能ではありますが、特定プロセスのアドレス空間の位置を参照するということを覚えておいてください。しかし、そのポインターは別のプロセスのコンテキストにおいて無効になる確率が高いです。そして、別のプロセスからそのポインターを逆参照しようとするとクラッシュを引き起こす可能性があります。
multiprocessing.sharedctypes.RawArray(typecode_or_type, size_or_initializer)
共有メモリから割り当てられた ctypes 配列を返します。
typecode_or_type は返される配列の要素の型を決めます。それは ctypes の型か array モジュールで使用されるような1文字の型コードのどちらか一方です。 size_or_initializer が整数なら、それが配列の長さになり、その配列はゼロで初期化されます。別の使用方法として size_or_initializer には配列の初期化に使用されるシーケンスを設定することもでき、その場合はシーケンスの長さが配列の長さになります。
要素を取得したり設定したりすることは潜在的に非アトミックであることに注意してください。ロックを使用して自動的に同期化されたアクセスを保証するには Array() を使用してください。
multiprocessing.sharedctypes.RawValue(typecode_or_type, *args)
共有メモリから割り当てられた ctypes オブジェクトを返します。
typecode_or_type は返されるオブジェクトの型を決めます。それは ctypes の型か array モジュールで使用されるような1文字の型コードかのどちらか一方です。 *args は型のコンストラクターへ渡されます。
値を取得したり設定したりすることは潜在的に非アトミックであることに注意してください。ロックを使用して自動的に同期化されたアクセスを保証するには Value() を使用してください。
ctypes.c_char の配列は文字列を格納して取り出せる value と raw 属性を持っていることを覚えておいてください。詳細は ctypes を参照してください。
multiprocessing.sharedctypes.Array(typecode_or_type, size_or_initializer, *, lock=True)
RawArray() と同様ですが、 lock の値によっては ctypes 配列をそのまま返す代わりに、プロセスセーフな同期ラッパーが返されます。
lock が True (デフォルト) なら、値へ同期アクセスするために新たな ロックオブジェクトが作成されます。 lock が Lock か RLock なら値への同期アクセスに使用されます。 lock が False なら、返された オブジェクトへのアクセスはロックにより自動的に保護されません。 そのため、必ずしも "プロセスセーフ" ではありません。
lock はキーワード専用引数であることに注意してください。
multiprocessing.sharedctypes.Value(typecode_or_type, *args, lock=True)
RawValue() と同様ですが、 lock の値によっては ctypes オブジェクトをそのまま返す代わりに、プロセスセーフな同期ラッパーが返されます。
lock が True (デフォルト) なら、値へ同期アクセスするために新たな ロックオブジェクトが作成されます。 lock が Lock か RLock なら値への同期アクセスに使用されます。 lock が False なら、返された オブジェクトへのアクセスはロックにより自動的に保護されません。 そのため、必ずしも "プロセスセーフ" ではありません。
lock はキーワード専用引数であることに注意してください。
multiprocessing.sharedctypes.copy(obj)
共有メモリから割り当てられた ctypes オブジェクト obj をコピーしたオブジェクトを返します。
multiprocessing.sharedctypes.synchronized(obj[, lock])
同期アクセスに lock を使用する ctypes オブジェクトのためにプロセスセーフなラッパーオブジェクトを返します。 lock が None (デフォルト) なら、 multiprocessing.RLock オブジェクトが自動的に作成されます。
同期ラッパーがラップするオブジェクトに加えて2つのメソッドがあります。 get_obj() はラップされたオブジェクトを返します。 get_lock() は同期のために使用されるロックオブジェクトを返します。
ラッパー経由で ctypes オブジェクトにアクセスすることは raw ctypes オブジェクトへアクセスするよりずっと遅くなることに注意してください。
バージョン 3.5 で変更: synchronized オブジェクトは コンテキストマネージャ プロトコルをサポートしています。
次の表は通常の ctypes 構文で共有メモリから共有 ctypes オブジェクトを作成するための構文を比較します。 (MyStruct テーブル内には ctypes.Structure のサブクラスがあります。)
ctypes
type を使用する sharedctypes
typecode を使用する sharedctypes
c_double(2.4)
RawValue(c_double, 2.4)
RawValue('d', 2.4)
MyStruct(4, 6)
RawValue(MyStruct, 4, 6)
(c_short * 7)()
RawArray(c_short, 7)
RawArray('h', 7)
(c_int * 3)(9, 2, 8)
RawArray(c_int, (9, 2, 8))
RawArray('i', (9, 2, 8))
以下に子プロセスが多くの ctypes オブジェクトを変更する例を紹介します:
from multiprocessing import Process, Lock
from multiprocessing.sharedctypes import Value, Array
from ctypes import Structure, c_double
class Point(Structure):
    _fields_ = [('x', c_double), ('y', c_double)]
def modify(n, x, s, A):
    n.value **= 2
    x.value **= 2
    s.value = s.value.upper()
    for a in A:
        a.x **= 2
        a.y **= 2
if __name__ == '__main__':
    lock = Lock()
    n = Value('i', 7)
    x = Value(c_double, 1.0/3.0, lock=False)
    s = Array('c', b'hello world', lock=lock)
    A = Array(Point, [(1.875,-6.25), (-5.75,2.0), (2.375,9.5)], lock=lock)
    p = Process(target=modify, args=(n, x, s, A))
    p.start()
    p.join()
    print(n.value)
    print(x.value)
    print(s.value)
    print([(a.x, a.y) for a in A])
結果は以下のように表示されます
49
0.1111111111111111
HELLO WORLD
[(3.515625, 39.0625), (33.0625, 4.0), (5.640625, 90.25)]
マネージャー
マネージャーは異なるプロセス間で共有されるデータの作成方法を提供します。これには別のマシン上で走るプロセス間のネットワーク越しの共有も含まれます。マネージャーオブジェクトは 共有オブジェクト を管理するサーバープロセスを制御します。他のプロセスはプロキシ経由で共有オブジェクトへアクセスすることができます。
multiprocessing.Manager()
プロセス間でオブジェクトを共有するために使用される SyncManager オブジェクトを返します。返されたマネージャーオブジェクトは生成される子プロセスに対応付けられ、共有オブジェクトを作成するメソッドや、共有オブジェクトに対応するプロキシを返すメソッドを持ちます。
マネージャープロセスは親プロセスが終了するか、ガベージコレクトされると停止します。マネージャークラスは multiprocessing.managers モジュールで定義されています:
class multiprocessing.managers.BaseManager([address[, authkey]])
BaseManager オブジェクトを作成します。
作成後、start() または get_server().serve_forever() を呼び出して、マネージャーオブジェクトが、開始されたマネージャープロセスを確実に参照するようにしてください。
address はマネージャープロセスが新たなコネクションを待ち受けるアドレスです。address が None の場合、任意のアドレスが設定されます。
authkey はサーバープロセスへ接続しようとするコネクションの正当性を検証するために 使用される認証キーです。authkey が None の場合 current_process().authkey が使用されます。authkey を使用する場合はバイト文字列でなければなりません。
start([initializer[, initargs]])
マネージャーを開始するためにサブプロセスを開始します。initializer が None でなければ、サブプロセスは開始時に initializer(*initargs) を呼び出します。
get_server()
マネージャーの制御下にある実際のサーバーを表す Server オブジェクトを返します。 Server オブジェクトは serve_forever() メソッドをサポートします:
>>>
>>> from multiprocessing.managers import BaseManager
>>> manager = BaseManager(address=('', 50000), authkey=b'abc')
>>> server = manager.get_server()
>>> server.serve_forever()
Server はさらに address 属性も持っています。
connect()
ローカルからリモートのマネージャーオブジェクトへ接続します:
>>>
>>> from multiprocessing.managers import BaseManager
>>> m = BaseManager(address=('127.0.0.1', 50000), authkey=b'abc')
>>> m.connect()
shutdown()
マネージャーが使用するプロセスを停止します。これはサーバープロセスを開始するために start() が使用された場合のみ有効です。
これは複数回呼び出すことができます。
register(typeid[, callable[, proxytype[, exposed[, method_to_typeid[, create_method]]]]])
マネージャークラスで呼び出し可能オブジェクト(callable)や型を登録するために使用されるクラスメソッドです。
typeid は特に共有オブジェクトの型を識別するために使用される "型識別子" です。これは文字列でなければなりません。
callable はこの型識別子のオブジェクトを作成するために使用される呼び出し可能オブジェクトです。マネージャーインスタンスが connect() メソッドを使ってサーバーに接続されているか、 create_method 引数が False の場合は、 None でも構いません。
proxytype はこの typeid で共有オブジェクトのプロキシを作成するために使用される BaseProxy のサブクラスです。 None の場合、プロキシクラスは自動的に作成されます。
exposed は BaseProxy._callmethod() を使用したアクセスが許されるべき typeid をプロキシするメソッド名のシーケンスを指定するために使用されます (exposed が None の場合 proxytype._exposed_ が存在すればそれが代わりに使用されます)。exposed リストが指定されない場合、共有オブジェクトのすべての "パブリックメソッド" がアクセス可能になります。 (ここでいう "パブリックメソッド" とは __call__() メソッドを持つものと名前が '_' で始まらないあらゆる属性を意味します。)
method_to_typeid はプロキシが返す exposed メソッドの返り値の型を指定するために使用されるマッピングで、メソッド名を typeid 文字列にマップします。 (method_to_typeid が None の場合 proxytype._method_to_typeid_ が存在すれば、それが代わりに使用されます。) メソッド名がこのマッピングのキーではないか、マッピングが None の場合、そのメソッドによって返されるオブジェクトが値として (by value) コピーされます。
create_method は、共有オブジェクトを作成し、それに対するプロキシを返すようサーバープロセスに伝える、名前 typeid のメソッドを作成するかを決定します。デフォルトでは True です。
BaseManager インスタンスも読み出し専用属性を1つ持っています:
address
マネージャーが使用するアドレスです。
バージョン 3.3 で変更: マネージャーオブジェクトはコンテキストマネージメント・プロトコルをサポートします -- コンテキストマネージャ型 を参照してください。 __enter__() は (まだ開始していない場合) サーバープロセスを開始してから、マネージャーオブジェクトを返します。 __exit__() は shutdown() を呼び出します。
旧バージョンでは、 __enter__() はマネージャーのサーバープロセスがまだ開始していなかった場合でもプロセスを開始しませんでした。
class multiprocessing.managers.SyncManager
プロセス間の同期のために使用される BaseManager のサブクラスです。 multiprocessing.Manager() はこの型のオブジェクトを返します。
Barrier(parties[, action[, timeout]])
共有 threading.Barrier オブジェクトを作成して、そのプロキシを返します。
バージョン 3.3 で追加.
BoundedSemaphore([value])
共有 threading.BoundedSemaphore オブジェクトを作成して、そのプロキシを返します。
Condition([lock])
共有 threading.Condition オブジェクトを作成して、そのプロキシを返します。
lock が提供される場合 threading.Lock か threading.RLock オブジェクトのためのプロキシになります。
バージョン 3.3 で変更: wait_for() メソッドが追加されました。
Event()
共有 threading.Event オブジェクトを作成して、そのプロキシを返します。
Lock()
共有 threading.Lock オブジェクトを作成して、そのプロキシを返します。
Namespace()
共有 Namespace オブジェクトを作成して、そのプロキシを返します。
Queue([maxsize])
共有 queue.Queue オブジェクトを作成して、そのプロキシを返します。
RLock()
共有 threading.RLock オブジェクトを作成して、そのプロキシを返します。
Semaphore([value])
共有 threading.Semaphore オブジェクトを作成して、そのプロキシを返します。
Array(typecode, sequence)
配列を作成して、そのプロキシを返します。
Value(typecode, value)
書き込み可能な value 属性を作成して、そのプロキシを返します。
dict()
dict(mapping)
dict(sequence)
共有 dict オブジェクトを作成して、そのプロキシを返します。
list()
list(sequence)
共有 list オブジェクトを作成して、そのプロキシを返します。
バージョン 3.6 で変更: 共有オブジェクトは入れ子もできます。 例えば、共有リストのような共有コンテナオブジェクトは、 SyncManager がまとめて管理し同期を取っている他の共有オブジェクトを保持できます。
class multiprocessing.managers.Namespace
SyncManager に登録することのできる型です。
Namespace オブジェクトにはパブリックなメソッドはありませんが、書き込み可能な属性を持ちます。そのオブジェクト表現はその属性の値を表示します。
しかし、Namespace オブジェクトのためにプロキシを使用するとき '_' が先頭に付く属性はプロキシの属性になり、参照対象の属性にはなりません:
>>> manager = multiprocessing.Manager()
>>> Global = manager.Namespace()
>>> Global.x = 10
>>> Global.y = 'hello'
>>> Global._z = 12.3    # this is an attribute of the proxy
>>> print(Global)
Namespace(x=10, y='hello')
カスタマイズされたマネージャー
独自のマネージャーを作成するには、BaseManager のサブクラスを作成して、 マネージャークラスで呼び出し可能なオブジェクトか新たな型を登録するために register() クラスメソッドを使用します。例えば:
from multiprocessing.managers import BaseManager
class MathsClass:
    def add(self, x, y):
        return x + y
    def mul(self, x, y):
        return x * y
class MyManager(BaseManager):
    pass
MyManager.register('Maths', MathsClass)
if __name__ == '__main__':
    with MyManager() as manager:
        maths = manager.Maths()
        print(maths.add(4, 3))         # prints 7
        print(maths.mul(7, 8))         # prints 56
リモートマネージャーを使用する
あるマシン上でマネージャーサーバーを実行して、他のマシンからそのサーバーを使用するクライアントを持つことができます(ファイアウォールを通過できることが前提)。
次のコマンドを実行することでリモートクライアントからアクセスを受け付ける1つの共有キューのためにサーバーを作成します:
>>>
>>> from multiprocessing.managers import BaseManager
>>> from queue import Queue
>>> queue = Queue()
>>> class QueueManager(BaseManager): pass
>>> QueueManager.register('get_queue', callable=lambda:queue)
>>> m = QueueManager(address=('', 50000), authkey=b'abracadabra')
>>> s = m.get_server()
>>> s.serve_forever()
あるクライアントからサーバーへのアクセスは次のようになります:
>>>
>>> from multiprocessing.managers import BaseManager
>>> class QueueManager(BaseManager): pass
>>> QueueManager.register('get_queue')
>>> m = QueueManager(address=('foo.bar.org', 50000), authkey=b'abracadabra')
>>> m.connect()
>>> queue = m.get_queue()
>>> queue.put('hello')
別のクライアントもそれを使用することができます:
>>>
>>> from multiprocessing.managers import BaseManager
>>> class QueueManager(BaseManager): pass
>>> QueueManager.register('get_queue')
>>> m = QueueManager(address=('foo.bar.org', 50000), authkey=b'abracadabra')
>>> m.connect()
>>> queue = m.get_queue()
>>> queue.get()
'hello'
ローカルプロセスもそのキューへアクセスすることができます。クライアント上で上述のコードを使用してアクセスします:
>>>
>>> from multiprocessing import Process, Queue
>>> from multiprocessing.managers import BaseManager
>>> class Worker(Process):
...     def __init__(self, q):
...         self.q = q
...         super(Worker, self).__init__()
...     def run(self):
...         self.q.put('local hello')
...
>>> queue = Queue()
>>> w = Worker(queue)
>>> w.start()
>>> class QueueManager(BaseManager): pass
...
>>> QueueManager.register('get_queue', callable=lambda: queue)
>>> m = QueueManager(address=('', 50000), authkey=b'abracadabra')
>>> s = m.get_server()
>>> s.serve_forever()
Proxy オブジェクト
プロキシは別のプロセスで(おそらく)有効な共有オブジェクトを 参照する オブジェクトです。共有オブジェクトはプロキシの 参照対象 になるということができます。複数のプロキシオブジェクトが同じ参照対象を持つ可能性もあります。
プロキシオブジェクトはその参照対象の対応するメソッドを呼び出すメソッドを持ちます (そうは言っても、参照対象のすべてのメソッドが必ずしもプロキシ経由で利用可能なわけではありません)。 この方法で、プロキシオブジェクトはまるでその参照先と同じように使えます:
>>> from multiprocessing import Manager
>>> manager = Manager()
>>> l = manager.list([i*i for i in range(10)])
>>> print(l)
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
>>> print(repr(l))
<ListProxy object, typeid 'list' at 0x...>
>>> l[4]
16
>>> l[2:5]
[4, 9, 16]
プロキシに str() を適用すると参照対象のオブジェクト表現を返すのに対して、 repr() を適用するとプロキシのオブジェクト表現を返すことに注意してください。
プロキシオブジェクトの重要な機能は pickle 化ができることで、これによりプロセス間での受け渡しができます。 そのため、参照対象が Proxy オブジェクト を持てます。 これによって管理されたリスト、辞書、その他 Proxy オブジェクト をネストできます:
>>> a = manager.list()
>>> b = manager.list()
>>> a.append(b)         # referent of a now contains referent of b
>>> print(a, b)
[<ListProxy object, typeid 'list' at ...>] []
>>> b.append('hello')
>>> print(a[0], b)
['hello'] ['hello']
同様に、辞書とリストのプロキシも他のプロキシの内部に入れてネストできます:
>>>
>>> l_outer = manager.list([ manager.dict() for i in range(2) ])
>>> d_first_inner = l_outer[0]
>>> d_first_inner['a'] = 1
>>> d_first_inner['b'] = 2
>>> l_outer[1]['c'] = 3
>>> l_outer[1]['z'] = 26
>>> print(l_outer[0])
{'a': 1, 'b': 2}
>>> print(l_outer[1])
{'c': 3, 'z': 26}
(プロキシでない) 標準の list オブジェクトや dict オブジェクトが参照対象に含まれていた場合、それらの可変な値の変更はマネージャーからは伝搬されません。 というのも、プロキシには参照対象の中に含まれる値がいつ変更されたかを知る術が無いのです。 しかし、コンテナプロキシに値を保存する (これはプロキシオブジェクトの __setitem__ を起動します) 場合はマネージャーを通して変更が伝搬され、その要素を実際に変更するために、コンテナプロキシに変更後の値が再代入されます:
# create a list proxy and append a mutable object (a dictionary)
lproxy = manager.list()
lproxy.append({})
# now mutate the dictionary
d = lproxy[0]
d['a'] = 1
d['b'] = 2
# at this point, the changes to d are not yet synced, but by
# updating the dictionary, the proxy is notified of the change
lproxy[0] = d
注釈 multiprocessing のプロキシ型は値による比較に対して何もサポートしません。そのため、例えば以下のようになります:
>>> manager.list([1,2,3]) == [1,2,3]
False
比較を行いたいときは参照対象のコピーを使用してください。
class multiprocessing.managers.BaseProxy
プロキシオブジェクトは BaseProxy のサブクラスのインスタンスです。
_callmethod(methodname[, args[, kwds]])
プロキシの参照対象のメソッドの実行結果を返します。
proxy がプロキシで、プロキシ内の参照対象が obj ならこの式
proxy._callmethod(methodname, args, kwds)
はこの式を評価します
getattr(obj, methodname)(*args, **kwds)
(マネージャープロセス内の)。
返される値はその呼び出し結果のコピーか、新たな共有オブジェクトに対するプロキシになります。詳細は BaseManager.register() の method_to_typeid 引数のドキュメントを参照してください。
その呼び出しによって例外が発生した場合、_callmethod() によってその例外は再送出されます。他の例外がマネージャープロセスで発生したなら、RemoteError 例外に変換されたものが _callmethod() によって送出されます。
特に methodname が 公開 されていない場合は例外が発生することに注意してください。
_callmethod() の使用例になります:
>>> l = manager.list(range(10))
>>> l._callmethod('__len__')
10
>>> l._callmethod('__getitem__', (slice(2, 7),)) # equivalent to l[2:7]
[2, 3, 4, 5, 6]
>>> l._callmethod('__getitem__', (20,))          # equivalent to l[20]
Traceback (most recent call last):
...
IndexError: list index out of range
_getvalue()
参照対象のコピーを返します。
参照対象が unpickle 化できるなら例外を発生します。
__repr__()
プロキシオブジェクトのオブジェクト表現を返します。
__str__()
参照対象のオブジェクト表現を返します。
クリーンアップ
プロキシオブジェクトは弱参照(weakref)コールバックを使用します。プロキシオブジェクトがガベージコレクトされるときにその参照対象が所有するマネージャーからその登録を取り消せるようにするためです。
共有オブジェクトはプロキシが参照しなくなったときにマネージャープロセスから削除されます。
プロセスプール
Pool クラスでタスクを実行するプロセスのプールを作成することができます。
class multiprocessing.pool.Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])
プロセスプールオブジェクトは、ジョブを送り込めるワーカープロセスのプールを制御します。タイムアウトやコールバックのある非同期の実行をサポートし、並列 map 実装を持ちます。
processes は使用するワーカープロセスの数です。processes が None の場合 os.cpu_count() が返す値を使用します。
initializer が None ではない場合、各ワーカープロセスは開始時に initializer(*initargs) を呼び出します。
maxtasksperchild は、ワーカープロセスが exit して新たなワーカープロセスと置き替えられるまでの間に、ワーカープロセスが完了することのできるタスクの数です。この設定により未利用のリソースが解放されるようなります。デフォルトの maxtasksperchild は None で、これはワーカープロセスがプールと同じ期間だけ生き続けるということを意味します。
context はワーカープロセスを開始するために使用されるコンテキストの指定に使用できます。通常プールは関数 multiprocessing.Pool() かコンテキストオブジェクトの Pool() メソッドを使用して作成されます。どちらの場合でも context は適切に設定されます。
プールオブジェクトのメソッドは、そのプールを作成したプロセスのみが呼び出すべきです。
警告 multiprocessing.pool objects have internal resources that need to be properly managed (like any other resource) by using the pool as a context manager or by calling close() and terminate() manually. Failure to do this can lead to the process hanging on finalization.
バージョン 3.2 で追加: maxtasksperchild
バージョン 3.4 で追加: context
注釈 Pool 中のワーカープロセスは、典型的にはプールのワークキューの存続期間とちょうど同じだけ生き続けます。ワーカーに確保されたリソースを解放するために (Apache, mod_wsgi, などのような) 他のシステムによく見られるパターンは、プール内のワーカーが設定された量だけの仕事を完了したら exit とクリーンアップを行い、古いプロセスを置き換えるために新しいプロセスを生成するというものです。 Pool の maxtasksperchild 引数は、この能力をエンドユーザーに提供します。
apply(func[, args[, kwds]])
引数 args とキーワード引数 kwds を伴って func を呼びます。結果が準備できるまでブロックします。このブロックがあるため、 apply_async() の方が並行作業により適しています。加えて、 func は、プール内の1つのワーカーだけで実行されます。
apply_async(func[, args[, kwds[, callback[, error_callback]]]])
callback が指定された場合、それは単一の引数を受け取る呼び出し可能オブジェクトでなければなりません。結果を返せるようになったときに callback が結果オブジェクトに対して適用されます。ただし呼び出しが失敗した場合は、代わりに error_callback が適用されます。
error_callback が指定された場合、それは単一の引数を受け取る呼び出し可能オブジェクトでなければなりません。対象の関数が失敗した場合、例外インスタンスを伴って error_callback が呼ばれます。
コールバックは直ちに完了すべきです。なぜなら、そうしなければ、結果を扱うスレッドがブロックするからです。
map(func, iterable[, chunksize])
このメソッドはイテラブルをいくつものチャンクに分割し、プロセスプールにそれぞれ独立したタスクとして送ります。(概算の) チャンクサイズは chunksize を正の整数に設定することで指定できます。
map_async(func, iterable[, chunksize[, callback[, error_callback]]])
callback が指定された場合、それは単一の引数を受け取る呼び出し可能オブジェクトでなければなりません。結果を返せるようになったときに callback が結果オブジェクトに対して適用されます。ただし呼び出しが失敗した場合は、代わりに error_callback が適用されます。
error_callback が指定された場合、それは単一の引数を受け取る呼び出し可能オブジェクトでなければなりません。対象の関数が失敗した場合、例外インスタンスを伴って error_callback が呼ばれます。
コールバックは直ちに完了すべきです。なぜなら、そうしなければ、結果を扱うスレッドがブロックするからです。
imap(func, iterable[, chunksize])
chunksize 引数は map() メソッドで使用されるものと同じです。 引数 iterable がとても長いなら chunksize に大きな値を指定して使用する方がデフォルト値の 1 を使用するよりもジョブの完了が かなり 速くなります。
また chunksize が 1 の場合 imap() メソッドが返すイテレーターの next() メソッドはオプションで timeout パラメーターを持ちます。 next(timeout) は、その結果が timeout 秒以内に返されないときに multiprocessing.TimeoutError を発生させます。
imap_unordered(func, iterable[, chunksize])
イテレーターが返す結果の順番が任意の順番で良いと見なされることを除けば imap() と同じです。 (ワーカープロセスが1つしかない場合のみ "正しい" 順番になることが保証されます。)
starmap(func, iterable[, chunksize])
iterable の要素が、引数として unpack されるイテレート可能オブジェクトであると期待される以外は、 map() と似ています。
そのため、iterable が [(1,2), (3, 4)] なら、結果は [func(1,2), func(3,4)] になります。
バージョン 3.3 で追加.
starmap_async(func, iterable[, chunksize[, callback[, error_callback]]])
starmap() と map_async() の組み合わせです。 イテレート可能オブジェクトの iterable をイテレートして、 unpack したイテレート可能オブジェクトを伴って func を呼び出します。結果オブジェクトを返します。
バージョン 3.3 で追加.
close()
これ以上プールでタスクが実行されないようにします。すべてのタスクが完了した後でワーカープロセスが終了します。
terminate()
実行中の処理を完了させずにワーカープロセスをすぐに停止します。プールオブジェクトがガベージコレクトされるときに terminate() が呼び出されます。
join()
ワーカープロセスが終了するのを待ちます。 join() を使用する前に close() か terminate() を呼び出さなければなりません。
バージョン 3.3 で追加: Pool オブジェクトがコンテキストマネージメント・プロトコルをサポートするようになりました。 -- コンテキストマネージャ型 を参照してください。 __enter__() は Pool オブジェクトを返します。また __exit__() は terminate() を呼び出します。
class multiprocessing.pool.AsyncResult
Pool.apply_async() や Pool.map_async() で返される結果のクラスです。
get([timeout])
結果を受け取ったときに返します。 timeout が None ではなくて、その結果が timeout 秒以内に受け取れない場合 multiprocessing.TimeoutError が発生します。リモートの呼び出しが例外を発生させる場合、その例外は get() が再発生させます。
wait([timeout])
その結果が有効になるか timeout 秒経つまで待ちます。
ready()
その呼び出しが完了しているかどうかを返します。
successful()
バージョン 3.7 で変更: If the result is not ready, ValueError is raised instead of AssertionError.
次の例はプールの使用例を紹介します:
from multiprocessing import Pool
import time
def f(x):
    return x*x
if __name__ == '__main__':
    with Pool(processes=4) as pool:         # start 4 worker processes
        result = pool.apply_async(f, (10,)) # evaluate "f(10)" asynchronously in a single process
        print(result.get(timeout=1))        # prints "100" unless your computer is *very* slow
        print(pool.map(f, range(10)))       # prints "[0, 1, 4,..., 81]"
        it = pool.imap(f, range(10))
        print(next(it))                     # prints "0"
        print(next(it))                     # prints "1"
        print(it.next(timeout=1))           # prints "4" unless your computer is *very* slow
        result = pool.apply_async(time.sleep, (10,))
        print(result.get(timeout=1))        # raises multiprocessing.TimeoutError
リスナーとクライアント
しかし multiprocessing.connection モジュールにはさらに柔軟な仕組みがあります。 このモジュールは、基本的にはソケットもしくは Windows の名前付きパイプを扱う高レベルのメッセージ指向 API を提供します。また、 hmac モジュールを使用した ダイジェスト認証 や同時の複数接続のポーリングもサポートします。
multiprocessing.connection.deliver_challenge(connection, authkey)
ランダム生成したメッセージをコネクションの相手側へ送信して応答を待ちます。
その応答がキーとして authkey を使用するメッセージのダイジェストと一致する場合、 コネクションの相手側へ歓迎メッセージを送信します。 そうでなければ AuthenticationError を発生させます。
multiprocessing.connection.answer_challenge(connection, authkey)
メッセージを受信して、そのキーとして authkey を使用するメッセージのダイジェストを計算し、ダイジェストを送り返します。
歓迎メッセージを受け取れない場合 AuthenticationError が発生します。
multiprocessing.connection.Client(address[, family[, authkey]])
コネクション種別は family 引数で決定しますが、一般的には address のフォーマットから推測できるので、これは指定されません。 (アドレスフォーマット を参照してください)
class multiprocessing.connection.Listener([address[, family[, backlog[, authkey]]]])
コネクションを '待ち受ける' 束縛されたソケットか Windows の名前付きパイプのラッパーです。
address はリスナーオブジェクトの束縛されたソケットか名前付きパイプが使用するアドレスです。
注釈 '0.0.0.0' のアドレスを使用する場合、Windows 上の終点へ接続することができません。終点へ接続したい場合は '127.0.0.1' を使用すべきです。
family は使用するソケット(名前付きパイプ)の種別です。これは 'AF_INET' (TCP ソケット), 'AF_UNIX' (Unix ドメインソケット) または 'AF_PIPE' (Windows 名前付きパイプ) という文字列のどれか1つになります。これらのうち 'AF_INET' のみが利用可能であることが保証されています。 family が None の場合 address のフォーマットから推測されたものが使用されます。 address も None の場合はデフォルトが選択されます。詳細は アドレスフォーマット を参照してください。 family が 'AF_UNIX' で address が None の場合 tempfile.mkstemp() を使用して作成されたプライベートな一時ディレクトリにソケットが作成されます。
リスナーオブジェクトがソケットを使用する場合、ソケットに束縛されるときに backlog (デフォルトでは1つ) がソケットの listen() メソッドに対して渡されます。
accept()
close()
リスナーオブジェクトの名前付きパイプか束縛されたソケットをクローズします。これはリスナーがガベージコレクトされるときに自動的に呼ばれます。そうは言っても、明示的に close() を呼び出す方が望ましいです。
リスナーオブジェクトは次の読み出し専用属性を持っています:
address
リスナーオブジェクトが使用中のアドレスです。
last_accepted
最後にコネクションを受け付けたアドレスです。有効なアドレスがない場合は None になります。
バージョン 3.3 で追加: Listener オブジェクトがコンテキストマネージメント・プロトコルをサポートするようになりました。 -- コンテキストマネージャ型 を参照してください。 __enter__() はリスナーオブジェクトを返します。また __exit__() は close() を呼び出します。
multiprocessing.connection.wait(object_list, timeout=None)
object_list 中のオブジェクトが準備ができるまで待機します。準備ができた object_list 中のオブジェクトのリストを返します。timeout が浮動小数点なら、最大でその秒数だけ呼び出しがブロックします。timeout が None の場合、無制限の期間ブロックします。負のタイムアウトは0と等価です。
Unix と Windows の両方で、 object_list には以下のオブジェクトを含めることが出来ます
a readable Connection object;
接続された読み取り可能な socket.socket オブジェクト; または
Process オブジェクトの sentinel 属性。
読み取ることのできるデータがある場合、あるいは相手側の端が閉じられている場合、コネクションまたはソケットオブジェクトは準備ができています。
Unix: wait(object_list, timeout) は select.select(object_list, [], [], timeout) とほとんど等価です。違いは、 select.select() がシグナルによって中断される場合、 EINTR のエラー番号付きで OSError を上げるということです。 wait() はそのようなことは行いません。
Windows: object_list の要素は、 (Win32 関数 WaitForMultipleObjects() のドキュメントで使われている定義から) wait 可能な整数ハンドルか、ソケットハンドルまたはパイプハンドルを返す fileno() メソッドを持つオブジェクトのどちらかでなければなりません。 (パイプハンドルとソケットハンドラーは wait 可能なハンドルでは ない ことに注意してください。)
バージョン 3.3 で追加.
例
次のサーバーコードは認証キーとして 'secret password' を使用するリスナーを作成します。このサーバーはコネクションを待ってクライアントへデータを送信します:
from multiprocessing.connection import Listener
from array import array
address = ('localhost', 6000)     # family is deduced to be 'AF_INET'
with Listener(address, authkey=b'secret password') as listener:
    with listener.accept() as conn:
        print('connection accepted from', listener.last_accepted)
        conn.send([2.25, None, 'junk', float])
        conn.send_bytes(b'hello')
        conn.send_bytes(array('i', [42, 1729]))
次のコードはサーバーへ接続して、サーバーからデータを受信します:
from multiprocessing.connection import Client
from array import array
address = ('localhost', 6000)
with Client(address, authkey=b'secret password') as conn:
    print(conn.recv())                  # => [2.25, None, 'junk', float]
    print(conn.recv_bytes())            # => 'hello'
    arr = array('i', [0, 0, 0, 0, 0])
    print(conn.recv_bytes_into(arr))    # => 8
    print(arr)                          # => array('i', [42, 1729, 0, 0, 0])
次のコードは wait() を使って複数のプロセスからのメッセージを同時に待ちます:
import time, random
from multiprocessing import Process, Pipe, current_process
from multiprocessing.connection import wait
def foo(w):
    for i in range(10):
        w.send((i, current_process().name))
    w.close()
if __name__ == '__main__':
    readers = []
    for i in range(4):
        r, w = Pipe(duplex=False)
        readers.append(r)
        p = Process(target=foo, args=(w,))
        p.start()
        # We close the writable end of the pipe now to be sure that
        # p is the only process which owns a handle for it.  This
        # ensures that when p closes its handle for the writable end,
        # wait() will promptly report the readable end as being ready.
        w.close()
    while readers:
        for r in wait(readers):
            try:
                msg = r.recv()
            except EOFError:
                readers.remove(r)
            else:
                print(msg)
アドレスフォーマット
'AF_INET' アドレスは (hostname, port) のタプルになります。 hostname は文字列で port は整数です。
'AF_UNIX' アドレスはファイルシステム上のファイル名の文字列です。
デフォルトでは、2つのバックスラッシュで始まる文字列は 'AF_UNIX' よりも 'AF_PIPE' として推測されることに注意してください。
認証キー
認証キーはパスワードとして見なされるバイト文字列です。コネクションが確立すると、双方の終点で正しい接続先であることを証明するために 知っているお互いの認証キーを要求します。(双方の終点が同じキーを使用して通信しようとしても、コネクション上でそのキーを送信することは できません。)
認証が要求されているにもかかわらず認証キーが指定されていない場合 current_process().authkey の返す値が使用されます。 (詳細は Process を参照してください。) この値はカレントプロセスを作成する Process オブジェクトによって自動的に継承されます。 これは(デフォルトでは)複数プロセスのプログラムの全プロセスが相互にコネクションを 確立するときに使用される1つの認証キーを共有することを意味します。
適当な認証キーを os.urandom() を使用して生成することもできます。
ログ記録
ロギングのためにいくつかの機能が利用可能です。しかし logging パッケージは、 (ハンドラー種別に依存して)違うプロセスからのメッセージがごちゃ混ぜになるので、プロセスの共有ロックを使用しないことに注意してください。
multiprocessing.get_logger()
multiprocessing が使用するロガーを返します。必要に応じて新たなロガーを作成します。
最初に作成するとき、ロガーはレベルに logging.NOTSET が設定されていてデフォルトハンドラーがありません。このロガーへ送られるメッセージはデフォルトではルートロガーへ伝播されません。
Windows 上では子プロセスが親プロセスのロガーレベルを継承しないことに注意してください。さらにその他のロガーのカスタマイズ内容もすべて継承されません。
multiprocessing.log_to_stderr()
この関数は get_logger() に対する呼び出しを実行しますが、 get_logger によって作成されるロガーを返すことに加えて、 '[%(levelname)s/%(processName)s] %(message)s' のフォーマットを使用して sys.stderr へ出力を送るハンドラーを追加します。
以下にロギングを有効にした例を紹介します:
>>>
>>> import multiprocessing, logging
>>> logger = multiprocessing.log_to_stderr()
>>> logger.setLevel(logging.INFO)
>>> logger.warning('doomed')
[WARNING/MainProcess] doomed
>>> m = multiprocessing.Manager()
[INFO/SyncManager-...] child process calling self.run()
[INFO/SyncManager-...] created temp directory /.../pymp-...
[INFO/SyncManager-...] manager serving at '/.../listener-...'
>>> del m
[INFO/MainProcess] sending shutdown message to manager
[INFO/SyncManager-...] manager exiting with exitcode 0
完全なロギングレベルの表については logging モジュールを参照してください。
multiprocessing.dummy モジュール
multiprocessing.dummy は multiprocessing の API を複製しますが threading モジュールのラッパーでしかありません。
class multiprocessing.pool.ThreadPool([processes[, initializer[, initargs]]])
processes is the number of worker threads to use. If processes is None then the number returned by os.cpu_count() is used.
initializer が None ではない場合、各ワーカープロセスは開始時に initializer(*initargs) を呼び出します。
注釈 A ThreadPool shares the same interface as Pool, which is designed around a pool of processes and predates the introduction of the concurrent.futures module. As such, it inherits some operations that don't make sense for a pool backed by threads, and it has its own type for representing the status of asynchronous jobs, AsyncResult, that is not understood by any other libraries.
プログラミングガイドライン
multiprocessing を使用するときに守るべき一定のガイドラインとイディオムを挙げます。
すべての開始方式について
以下はすべての開始方式に当てはまります。
共有状態を避ける
できるだけプロセス間で巨大なデータを移動することは避けるようにすべきです。
プロセス間の通信には、threading モジュールの低レベルな同期プリミティブを使うのではなく、キューやパイプを使うのが良いでしょう。
pickle 化の可能性
プロキシのメソッドへの引数は、 pickle 化できるものにしてください。
プロキシのスレッドセーフ性
1 つのプロキシオブジェクトは、ロックで保護しないかぎり、2 つ以上のスレッドから使用してはいけません。
(異なるプロセスで 同じ プロキシを使用することは問題ではありません。)
ゾンビプロセスを join する
Unix 上ではプロセスが終了したときに join しないと、そのプロセスはゾンビになります。新たなプロセスが開始する (または active_children() が呼ばれる) ときに、join されていないすべての完了プロセスが join されるので、あまり多くにはならないでしょう。また、終了したプロセスの Process.is_alive はそのプロセスを join します。そうは言っても、自分で開始したすべてのプロセスを明示的に join することはおそらく良いプラクティスです。
pickle/unpickle より継承する方が良い
開始方式に spawn あるいは forkserver を使用している場合、multiprocessing から多くの型を pickle 化する必要があるため子プロセスはそれらを使うことができます。しかし、一般にパイプやキューを使用して共有オブジェクトを他のプロセスに送信することは避けるべきです。代わりに、共有リソースにアクセスする必要のあるプロセスは上位プロセスからそれらを継承するようにすべきです。
プロセスの強制終了を避ける
あるプロセスを停止するために Process.terminate メソッドを使用すると、そのプロセスが現在使用されている (ロック、セマフォ、パイプやキューのような) 共有リソースを破壊したり他のプロセスから利用できない状態を引き起こし易いです。
そのため、共有リソースを使用しないプロセスでのみ Process.terminate を使用することを考慮することがおそらく最善の方法です。
キューを使用するプロセスを join する
キューに要素を追加するプロセスは、すべてのバッファーされた要素が "feeder" スレッドによって下位層のパイプに対してフィードされるまで終了を待つということを覚えておいてください。 (子プロセスはこの動作を避けるためにキューの Queue.cancel_join_thread メソッドを呼ぶことができます。)
これはキューを使用するときに、キューに追加されたすべての要素が最終的にそのプロセスが join される前に削除されていることを確認する必要があることを意味します。そうしないと、そのキューに要素が追加したプロセスの終了を保証できません。デーモンではないプロセスは自動的に join されることも覚えておいてください。
次の例はデッドロックを引き起こします:
from multiprocessing import Process, Queue
def f(q):
    q.put('X' * 1000000)
if __name__ == '__main__':
    queue = Queue()
    p = Process(target=f, args=(queue,))
    p.start()
    p.join()                    # this deadlocks
    obj = queue.get()
修正するには最後の2行を入れ替えます(または単純に p.join() の行を削除します)。
明示的に子プロセスへリソースを渡す
Unix で開始方式に fork を使用している場合、子プロセスはグローバルリソースを使用した親プロセス内で作成された共有リソースを使用できます。しかし、オブジェクトを子プロセスのコンストラクターに引数として渡すべきです。
Windows や他の開始方式と (将来的にでも) 互換性のあるコードを書く場合は別として、これは子プロセスが実行中である限りは親プロセス内でオブジェクトがガベージコレクトされないことも保証します。これは親プロセス内でオブジェクトがガベージコレクトされたときに一部のリソースが開放されてしまう場合に重要かもしれません。
そのため、例えば
from multiprocessing import Process, Lock
def f():
    ... do something using "lock" ...
if __name__ == '__main__':
    lock = Lock()
    for i in range(10):
        Process(target=f).start()
は、次のように書き直すべきです
from multiprocessing import Process, Lock
def f(l):
    ... do something using "l" ...
if __name__ == '__main__':
    lock = Lock()
    for i in range(10):
        Process(target=f, args=(lock,)).start()
sys.stdin を file-like オブジェクトに置き換えることに注意する
multiprocessing は元々無条件に:
os.close(sys.stdin.fileno())
を multiprocessing.Process._bootstrap() メソッドの中で呼び出していました --- これはプロセス内プロセス (processes-in-processes) で問題が起こしてしまいます。そこで、これは以下のように変更されました:
sys.stdin.close()
sys.stdin = open(os.open(os.devnull, os.O_RDONLY), closefd=False)
これによってプロセス同士が衝突して bad file descripter エラーを起こすという根本的な問題は解決しましたが、アプリケーションの出力バッファーを sys.stdin() から "file-like オブジェクト" に置き換えるという潜在的危険を持ち込んでしまいました。危険というのは、複数のプロセスが file-like オブジェクトの close() を呼び出すと、オブジェクトに同じデータが何度もフラッシュされ、破損してしまう可能性がある、というものです。
もし file-like オブジェクトを書いて独自のキャッシュを実装するなら、キャッシュするときに常に pid を記録しておき、pid が変わったらキュッシュを捨てることで、フォークセーフにできます。例:
@property
def cache(self):
    pid = os.getpid()
    if pid != self._pid:
        self._pid = pid
        self._cache = []
    return self._cache
より詳しい情報は bpo-5155 、 bpo-5313 、 bpo-5331 を見てください
開始方式が spawn および forkserver の場合
開始方式に fork を適用しない場合にいくつかの追加の制限事項があります。
さらなる pickle 化の可能性
Process.__init__() へのすべての引数は pickle 化できることを確認してください。また Process をサブクラス化する場合、そのインスタンスが Process.start メソッドが呼ばれたときに pickle 化できるようにしてください。
グローバル変数
子プロセスで実行されるコードがグローバル変数にアクセスしようとする場合、子プロセスが見るその値は Process.start が呼ばれたときの親プロセスの値と同じではない可能性があります。
しかし、単にモジュールレベルの定数であるグローバル変数なら問題にはなりません。
メインモジュールの安全なインポート
新たな Python インタプリタによるメインモジュールのインポートが、意図しない副作用 (新たなプロセスを開始する等) を起こさずできるようにしてください。
例えば、開始方式に spawn あるいは forkserver を使用した場合に以下のモジュールを実行すると RuntimeError で失敗します:
from multiprocessing import Process
def foo():
    print('hello')
p = Process(target=foo)
p.start()
代わりに、次のように if __name__ == '__main__': を使用してプログラムの "エントリポイント" を保護すべきです:
from multiprocessing import Process, freeze_support, set_start_method
def foo():
    print('hello')
if __name__ == '__main__':
    freeze_support()
    set_start_method('spawn')
    p = Process(target=foo)
    p.start()
(プログラムをフリーズせずに通常通り実行するなら freeze_support() 行は取り除けます。)
これは新たに生成された Python インタープリターがそのモジュールを安全にインポートして、モジュールの foo() 関数を実行します。
プールまたはマネージャーがメインモジュールで作成される場合に似たような制限が適用されます。
使用例
カスタマイズされたマネージャーやプロキシの作成方法と使用方法を紹介します:
from multiprocessing import freeze_support
from multiprocessing.managers import BaseManager, BaseProxy
import operator
##
class Foo:
    def f(self):
        print('you called Foo.f()')
    def g(self):
        print('you called Foo.g()')
    def _h(self):
        print('you called Foo._h()')
# A simple generator function
def baz():
    for i in range(10):
        yield i*i
# Proxy type for generator objects
class GeneratorProxy(BaseProxy):
    _exposed_ = ['__next__']
    def __iter__(self):
        return self
    def __next__(self):
        return self._callmethod('__next__')
# Function to return the operator module
def get_operator_module():
    return operator
##
class MyManager(BaseManager):
    pass
# register the Foo class; make `f()` and `g()` accessible via proxy
MyManager.register('Foo1', Foo)
# register the Foo class; make `g()` and `_h()` accessible via proxy
MyManager.register('Foo2', Foo, exposed=('g', '_h'))
# register the generator function baz; use `GeneratorProxy` to make proxies
MyManager.register('baz', baz, proxytype=GeneratorProxy)
# register get_operator_module(); make public functions accessible via proxy
MyManager.register('operator', get_operator_module)
##
def test():
    manager = MyManager()
    manager.start()
    print('-' * 20)
    f1 = manager.Foo1()
    f1.f()
    f1.g()
    assert not hasattr(f1, '_h')
    assert sorted(f1._exposed_) == sorted(['f', 'g'])
    print('-' * 20)
    f2 = manager.Foo2()
    f2.g()
    f2._h()
    assert not hasattr(f2, 'f')
    assert sorted(f2._exposed_) == sorted(['g', '_h'])
    print('-' * 20)
    it = manager.baz()
    for i in it:
        print('<%d>' % i, end=' ')
    print()
    print('-' * 20)
    op = manager.operator()
    print('op.add(23, 45) =', op.add(23, 45))
    print('op.pow(2, 94) =', op.pow(2, 94))
    print('op._exposed_ =', op._exposed_)
##
if __name__ == '__main__':
    freeze_support()
    test()
Pool を使用する例です:
import multiprocessing
import time
import random
import sys
#
# Functions used by test code
#
def calculate(func, args):
    result = func(*args)
    return '%s says that %s%s = %s' % (
        multiprocessing.current_process().name,
        func.__name__, args, result
        )
def calculatestar(args):
    return calculate(*args)
def mul(a, b):
    time.sleep(0.5 * random.random())
    return a * b
def plus(a, b):
    time.sleep(0.5 * random.random())
    return a + b
def f(x):
    return 1.0 / (x - 5.0)
def pow3(x):
    return x ** 3
def noop(x):
    pass
#
# Test code
#
def test():
    PROCESSES = 4
    print('Creating pool with %d processes\n' % PROCESSES)
    with multiprocessing.Pool(PROCESSES) as pool:
        #
        # Tests
        #
        TASKS = [(mul, (i, 7)) for i in range(10)] + \
                [(plus, (i, 8)) for i in range(10)]
        results = [pool.apply_async(calculate, t) for t in TASKS]
        imap_it = pool.imap(calculatestar, TASKS)
        imap_unordered_it = pool.imap_unordered(calculatestar, TASKS)
        print('Ordered results using pool.apply_async():')
        for r in results:
            print('\t', r.get())
        print()
        print('Ordered results using pool.imap():')
        for x in imap_it:
            print('\t', x)
        print()
        print('Unordered results using pool.imap_unordered():')
        for x in imap_unordered_it:
            print('\t', x)
        print()
        print('Ordered results using pool.map() --- will block till complete:')
        for x in pool.map(calculatestar, TASKS):
            print('\t', x)
        print()
        #
        # Test error handling
        #
        print('Testing error handling:')
        try:
            print(pool.apply(f, (5,)))
        except ZeroDivisionError:
            print('\tGot ZeroDivisionError as expected from pool.apply()')
        else:
            raise AssertionError('expected ZeroDivisionError')
        try:
            print(pool.map(f, list(range(10))))
        except ZeroDivisionError:
            print('\tGot ZeroDivisionError as expected from pool.map()')
        else:
            raise AssertionError('expected ZeroDivisionError')
        try:
            print(list(pool.imap(f, list(range(10)))))
        except ZeroDivisionError:
            print('\tGot ZeroDivisionError as expected from list(pool.imap())')
        else:
            raise AssertionError('expected ZeroDivisionError')
        it = pool.imap(f, list(range(10)))
        for i in range(10):
            try:
                x = next(it)
            except ZeroDivisionError:
                if i == 5:
                    pass
            except StopIteration:
                break
            else:
                if i == 5:
                    raise AssertionError('expected ZeroDivisionError')
        assert i == 9
        print('\tGot ZeroDivisionError as expected from IMapIterator.next()')
        print()
        #
        # Testing timeouts
        #
        print('Testing ApplyResult.get() with timeout:', end=' ')
        res = pool.apply_async(calculate, TASKS[0])
        while 1:
            sys.stdout.flush()
            try:
                sys.stdout.write('\n\t%s' % res.get(0.02))
                break
            except multiprocessing.TimeoutError:
                sys.stdout.write('.')
        print()
        print()
        print('Testing IMapIterator.next() with timeout:', end=' ')
        it = pool.imap(calculatestar, TASKS)
        while 1:
            sys.stdout.flush()
            try:
                sys.stdout.write('\n\t%s' % it.next(0.02))
            except StopIteration:
                break
            except multiprocessing.TimeoutError:
                sys.stdout.write('.')
        print()
        print()
if __name__ == '__main__':
    multiprocessing.freeze_support()
    test()
ワーカープロセスのコレクションに対してタスクをフィードしてその結果をまとめるキューの使い方の例を紹介します:
import time
import random
from multiprocessing import Process, Queue, current_process, freeze_support
#
# Function run by worker processes
#
def worker(input, output):
    for func, args in iter(input.get, 'STOP'):
        result = calculate(func, args)
        output.put(result)
#
# Function used to calculate result
#
def calculate(func, args):
    result = func(*args)
    return '%s says that %s%s = %s' % \
        (current_process().name, func.__name__, args, result)
#
# Functions referenced by tasks
#
def mul(a, b):
    time.sleep(0.5*random.random())
    return a * b
def plus(a, b):
    time.sleep(0.5*random.random())
    return a + b
#
#
#
def test():
    NUMBER_OF_PROCESSES = 4
    TASKS1 = [(mul, (i, 7)) for i in range(20)]
    TASKS2 = [(plus, (i, 8)) for i in range(10)]
    # Create queues
    task_queue = Queue()
    done_queue = Queue()
    # Submit tasks
    for task in TASKS1:
        task_queue.put(task)
    # Start worker processes
    for i in range(NUMBER_OF_PROCESSES):
        Process(target=worker, args=(task_queue, done_queue)).start()
    # Get and print results
    print('Unordered results:')
    for i in range(len(TASKS1)):
        print('\t', done_queue.get())
    # Add more tasks using `put()`
    for task in TASKS2:
        task_queue.put(task)
    # Get and print some more results
    for i in range(len(TASKS2)):
        print('\t', done_queue.get())
    # Tell child processes to stop
    for i in range(NUMBER_OF_PROCESSES):
        task_queue.put('STOP')
if __name__ == '__main__':
    freeze_support()
    test()
multiprocessing.shared_memory --- 異なるプロセスから参照可能な共有メモリ
ソースコード Lib/multiprocessing/shared_memory.py
バージョン 3.8 で追加.
このモジュールは、マルチコアもしくは対称型マルチプロセッサ(SMP) を持つマシン上で実行される、ひとつ以上のプロセスから参照される共有メモリの確保、管理を行うための:class:SharedMemory クラスを提供します。共有メモリのライフサイクル管理、とりわけ複数のプロセスにわたる場合のために、multiprocessing.managers モジュールで、BaseManager サブクラスと:class:SharedMemoryManager が提供されます。
class multiprocessing.shared_memory.SharedMemory(name=None, create=False, size=0)
name is the unique name for the requested shared memory, specified as a string. When creating a new shared memory block, if None (the default) is supplied for the name, a novel name will be generated.
create controls whether a new shared memory block is created (True) or an existing shared memory block is attached (False).
size specifies the requested number of bytes when creating a new shared memory block. Because some platforms choose to allocate chunks of memory based upon that platform's memory page size, the exact size of the shared memory block may be larger or equal to the size requested. When attaching to an existing shared memory block, the size parameter is ignored.
close()
unlink()
buf
name
size
The following example demonstrates low-level use of SharedMemory instances:
>>>
>>> from multiprocessing import shared_memory
>>> shm_a = shared_memory.SharedMemory(create=True, size=10)
>>> type(shm_a.buf)
<class 'memoryview'>
>>> buffer = shm_a.buf
>>> len(buffer)
10
>>> buffer[:4] = bytearray([22, 33, 44, 55])  # Modify multiple at once
>>> buffer[4] = 100                           # Modify single byte at a time
>>> # Attach to an existing shared memory block
>>> shm_b = shared_memory.SharedMemory(shm_a.name)
>>> import array
>>> array.array('b', shm_b.buf[:5])  # Copy the data into a new array.array
array('b', [22, 33, 44, 55, 100])
>>> shm_b.buf[:5] = b'howdy'  # Modify via shm_b using bytes
>>> bytes(shm_a.buf[:5])      # Access via shm_a
b'howdy'
>>> shm_b.close()   # Close each SharedMemory instance
>>> shm_a.close()
>>> shm_a.unlink()  # Call unlink only once to release the shared memory
The following example demonstrates a practical use of the SharedMemory class with NumPy arrays, accessing the same numpy.ndarray from two distinct Python shells:
>>> # In the first Python interactive shell
>>> import numpy as np
>>> a = np.array([1, 1, 2, 3, 5, 8])  # Start with an existing NumPy array
>>> from multiprocessing import shared_memory
>>> shm = shared_memory.SharedMemory(create=True, size=a.nbytes)
>>> # Now create a NumPy array backed by shared memory
>>> b = np.ndarray(a.shape, dtype=a.dtype, buffer=shm.buf)
>>> b[:] = a[:]  # Copy the original data into shared memory
>>> b
array([1, 1, 2, 3, 5, 8])
>>> type(b)
<class 'numpy.ndarray'>
>>> type(a)
<class 'numpy.ndarray'>
>>> shm.name  # We did not specify a name so one was chosen for us
'psm_21467_46075'
>>> # In either the same shell or a new Python shell on the same machine
>>> import numpy as np
>>> from multiprocessing import shared_memory
>>> # Attach to the existing shared memory block
>>> existing_shm = shared_memory.SharedMemory(name='psm_21467_46075')
>>> # Note that a.shape is (6,) and a.dtype is np.int64 in this example
>>> c = np.ndarray((6,), dtype=np.int64, buffer=existing_shm.buf)
>>> c
array([1, 1, 2, 3, 5, 8])
>>> c[-1] = 888
>>> c
array([  1,   1,   2,   3,   5, 888])
>>> # Back in the first Python interactive shell, b reflects this change
>>> b
array([  1,   1,   2,   3,   5, 888])
>>> # Clean up from within the second Python shell
>>> del c  # Unnecessary; merely emphasizing the array is no longer used
>>> existing_shm.close()
>>> # Clean up from within the first Python shell
>>> del b  # Unnecessary; merely emphasizing the array is no longer used
>>> shm.close()
>>> shm.unlink()  # Free and release the shared memory block at the very end
class multiprocessing.managers.SharedMemoryManager([address[, authkey]])
SharedMemory(size)
ShareableList(sequence)
The following example demonstrates the basic mechanisms of a SharedMemoryManager:
>>> from multiprocessing.managers import SharedMemoryManager
>>> smm = SharedMemoryManager()
>>> smm.start()  # Start the process that manages the shared memory blocks
>>> sl = smm.ShareableList(range(4))
>>> sl
ShareableList([0, 1, 2, 3], name='psm_6572_7512')
>>> raw_shm = smm.SharedMemory(size=128)
>>> another_sl = smm.ShareableList('alpha')
>>> another_sl
ShareableList(['a', 'l', 'p', 'h', 'a'], name='psm_6572_12221')
>>> smm.shutdown()  # Calls unlink() on sl, raw_shm, and another_sl
The following example depicts a potentially more convenient pattern for using SharedMemoryManager objects via the with statement to ensure that all shared memory blocks are released after they are no longer needed:
>>> with SharedMemoryManager() as smm:
...     sl = smm.ShareableList(range(2000))
...     # Divide the work among two processes, storing partial results in sl
...     p1 = Process(target=do_work, args=(sl, 0, 1000))
...     p2 = Process(target=do_work, args=(sl, 1000, 2000))
...     p1.start()
...     p2.start()  # A multiprocessing.Pool might be more efficient
...     p1.join()
...     p2.join()   # Wait for all work to complete in both processes
...     total_result = sum(sl)  # Consolidate the partial results now in sl
class multiprocessing.shared_memory.ShareableList(sequence=None, *, name=None)
sequence is used in populating a new ShareableList full of values. Set to None to instead attach to an already existing ShareableList by its unique shared memory name.
name is the unique name for the requested shared memory, as described in the definition for SharedMemory. When attaching to an existing ShareableList, specify its shared memory block's unique name while leaving sequence set to None.
count(value)
index(value)
format
shm
The following example demonstrates basic use of a ShareableList instance:
>>>
from multiprocessing import shared_memory
a = shared_memory.ShareableList(['howdy', b'HoWdY', -273.154, 100, None, True, 42])
[ type(entry) for entry in a ]
[<class 'str'>, <class 'bytes'>, <class 'float'>, <class 'int'>, <class 'NoneType'>, <class 'bool'>, <class 'int'>]
a[2]
-273.154
a[2] = -78.5
a[2]
-78.5
a[2] = 'dry ice'  # Changing data types is supported as well
a[2]
'dry ice'
a[2] = 'larger than previously allocated storage space'
Traceback (most recent call last):
  ...
ValueError: exceeds available storage for existing str
a[2]
'dry ice'
len(a)
7
a.index(42)
6
a.count(b'howdy')
0
a.count(b'HoWdY')
1
a.shm.close()
a.shm.unlink()
del a  # Use of a ShareableList after call to unlink() is unsupported
The following example depicts how one, two, or many processes may access the same ShareableList by supplying the name of the shared memory block behind it:
>>>
b = shared_memory.ShareableList(range(5))         # In a first process
c = shared_memory.ShareableList(name=b.shm.name)  # In a second process
c
ShareableList([0, 1, 2, 3, 4], name='...')
c[-1] = -999
b[-1]
-999
b.shm.close()
c.shm.close()
c.shm.unlink()
concurrent.futures -- 並列タスク実行
バージョン 3.2 で追加.
ソースコード: Lib/concurrent/futures/thread.py および Lib/concurrent/futures/process.py
concurrent.futures モジュールは、非同期に実行できる呼び出し可能オブジェクトの高水準のインターフェースを提供します。
非同期実行は ThreadPoolExecutor を用いてスレッドで実行することも、 ProcessPoolExecutor を用いて別々のプロセスで実行することもできます. どちらも Executor 抽象クラスで定義された同じインターフェースを実装します。
Executor オブジェクト
class concurrent.futures.Executor
非同期呼び出しを実行するためのメソッドを提供する抽象クラスです。このクラスを直接使ってはならず、具象サブクラスを介して使います。
submit(fn, /, *args, **kwargs)
呼び出し可能オブジェクト fn を、 fn(*args **kwargs) として実行するようにスケジュールし、呼び出し可能オブジェクトの実行を表現する Future オブジェクトを返します。
with ThreadPoolExecutor(max_workers=1) as executor:
    future = executor.submit(pow, 323, 1235)
    print(future.result())
map(func, *iterables, timeout=None, chunksize=1)
Similar to map(func, *iterables) except:
the iterables are collected immediately rather than lazily;
func is executed asynchronously and several calls to func may be made concurrently.
バージョン 3.5 で変更: chunksize 引数が追加されました。
shutdown(wait=True, *, cancel_futures=False)
executor に対して、現在保留中のフューチャーが実行された後で、使用中のすべての資源を解放するように伝えます。シャットダウンにより後に Executor.submit() と Executor.map() を呼び出すと RuntimeError が送出されます。
wait が True の場合、すべての未完了のフューチャの実行が完了して Executor に関連付けられたリソースが解放されるまで、このメソッドは返りません。 wait が False の場合、このメソッドはすぐに返り、すべての未完了のフューチャの実行が完了したときに、 Executor に関連付けられたリソースが解放されます。 wait の値に関係なく、すべての未完了のフューチャの実行が完了するまで Python プログラム全体は終了しません。
with 文を使用することで、このメソッドを明示的に呼ばないようにできます。 with 文は Executor をシャットダウンします (wait を True にセットして Executor.shutdown() が呼ばれたかのように待ちます)。
import shutil
with ThreadPoolExecutor(max_workers=4) as e:
    e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
    e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
    e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
    e.submit(shutil.copy, 'src4.txt', 'dest4.txt')
バージョン 3.9 で変更: Added cancel_futures.
ThreadPoolExecutor
ThreadPoolExecutor はスレッドのプールを使用して非同期に呼び出しを行う、 Executor のサブクラスです。
Future に関連づけられた呼び出し可能オブジェクトが、別の Future の結果を待つ時にデッドロックすることがあります。例:
import time
def wait_on_b():
    time.sleep(5)
    print(b.result())  # b will never complete because it is waiting on a.
    return 5
def wait_on_a():
    time.sleep(5)
    print(a.result())  # a will never complete because it is waiting on b.
    return 6
executor = ThreadPoolExecutor(max_workers=2)
a = executor.submit(wait_on_b)
b = executor.submit(wait_on_a)
以下でも同様です:
def wait_on_future():
    f = executor.submit(pow, 5, 2)
    # This will never complete because there is only one worker thread and
    # it is executing this function.
    print(f.result())
executor = ThreadPoolExecutor(max_workers=1)
executor.submit(wait_on_future)
class concurrent.futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=())
最大で max_workers 個のスレッドを非同期実行に使う Executor のサブクラスです。
initializer is an optional callable that is called at the start of each worker thread; initargs is a tuple of arguments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a BrokenThreadPool, as well as any attempt to submit more jobs to the pool.
バージョン 3.5 で変更: max_workers が None か指定されない場合のデフォルト値はマシンのプロセッサの数に 5 を掛けたものになります。これは、 ThreadPoolExecutor は CPU の処理ではなく I/O をオーバーラップするのによく使用されるため、 ProcessPoolExecutor のワーカーの数よりもこのワーカーの数を増やすべきであるという想定に基づいています。
バージョン 3.6 で追加: The thread_name_prefix argument was added to allow users to control the threading.Thread names for worker threads created by the pool for easier debugging.
バージョン 3.7 で変更: Added the initializer and initargs arguments.
バージョン 3.8 で変更: Default value of max_workers is changed to min(32, os.cpu_count() + 4). This default value preserves at least 5 workers for I/O bound tasks. It utilizes at most 32 CPU cores for CPU bound tasks which release the GIL. And it avoids using very large resources implicitly on many-core machines.
ThreadPoolExecutor の例
import concurrent.futures
import urllib.request
URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://europe.wsj.com/',
        'http://www.bbc.co.uk/',
        'http://some-made-up-domain.com/']
# Retrieve a single page and report the URL and contents
def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()
# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    # Start the load operations and mark each future with its URL
    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
    for future in concurrent.futures.as_completed(future_to_url):
        url = future_to_url[future]
        try:
            data = future.result()
        except Exception as exc:
            print('%r generated an exception: %s' % (url, exc))
        else:
            print('%r page is %d bytes' % (url, len(data)))
ProcessPoolExecutor
__main__ モジュールはワーカサブプロセスでインポート可能でなければなりません。 すなわち、 ProcessPoolExecutor は対話的インタープリタでは動きません。
ProcessPoolExecutor に渡された呼び出し可能オブジェクトから Executor や Future メソッドを呼ぶとデッドロックに陥ります。
class concurrent.futures.ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=())
initializer is an optional callable that is called at the start of each worker process; initargs is a tuple of arguments passed to the initializer. Should initializer raise an exception, all currently pending jobs will raise a BrokenProcessPool, as well as any attempt to submit more jobs to the pool.
バージョン 3.3 で変更: ワーカプロセスの1つが突然終了した場合、BrokenProcessPool エラーが送出されるようになりました。 以前は挙動は未定義でしたが、 executor や futures がフリーズしたりデッドロックを起こすことがしばしばでした。
バージョン 3.7 で変更: The mp_context argument was added to allow users to control the start_method for worker processes created by the pool.
ProcessPoolExecutor の例
import concurrent.futures
import math
PRIMES = [
    112272535095293,
    112582705942171,
    112272535095293,
    115280095190773,
    115797848077099,
    1099726899285419]
def is_prime(n):
    if n < 2:
        return False
    if n == 2:
        return True
    if n % 2 == 0:
        return False
    sqrt_n = int(math.floor(math.sqrt(n)))
    for i in range(3, sqrt_n + 1, 2):
        if n % i == 0:
            return False
    return True
def main():
    with concurrent.futures.ProcessPoolExecutor() as executor:
        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
            print('%d is prime: %s' % (number, prime))
if __name__ == '__main__':
    main()
Future オブジェクト
Future クラスは呼び出し可能オブジェクトの非同期実行をカプセル化します。 Future のインスタンスは Executor.submit() によって生成されます。
class concurrent.futures.Future
呼び出し可能オブジェクトの非同期実行をカプセル化します。 Future インスタンスは Executor.submit() で生成され、テストを除いて直接生成すべきではありません。
cancel()
cancelled()
呼び出しが正常にキャンセルされた場合 True を返します。
running()
現在呼び出しが実行中でキャンセルできない場合 True を返します。
done()
呼び出しが正常にキャンセルされたか終了した場合 True を返します。
result(timeout=None)
呼び出しによって返された値を返します。呼び出しがまだ完了していない場合、このメソッドは timeout 秒の間待機します。呼び出しが timeout 秒間の間に完了しない場合、 concurrent.futures.TimeoutError が送出されます。 timeout にはintかfloatを指定できます。timeout が指定されていないか、 None である場合、待機時間に制限はありません。
future が完了する前にキャンセルされた場合 CancelledError が送出されます。
呼び出しが例外を送出した場合、このメソッドは同じ例外を送出します。
exception(timeout=None)
呼び出しによって送出された例外を返します。呼び出しがまだ完了していない場合、このメソッドは timeout 秒だけ待機します。呼び出しが timeout 秒の間に完了しない場合、 concurrent.futures.TimeoutError が送出されます。 timeout にはintかfloatを指定できます。 timeout が指定されていないか、 None である場合、待機時間に制限はありません。
future が完了する前にキャンセルされた場合 CancelledError が送出されます。
呼び出しが例外を送出することなく完了した場合、None を返します。
add_done_callback(fn)
呼び出し可能な fn オブジェクトを future にアタッチします。futureがキャンセルされたか、実行を終了した際に、future をそのただ一つの引数として fn が呼び出されます。
追加された呼び出し可能オブジェクトは、追加された順番で呼びだされ、追加を行ったプロセスに属するスレッド中で呼び出されます。もし呼び出し可能オブジェクトが Exception のサブクラスを送出した場合、それはログに記録され無視されます。呼び出し可能オブジェクトが BaseException のサブクラスを送出した場合の動作は未定義です。
もしfutureがすでに完了しているか、キャンセル済みであれば、fn は即座に実行されます。
以下の Future メソッドは、ユニットテストでの使用と Executor を実装することを意図しています。
set_running_or_notify_cancel()
このメソッドは、Future に関連付けられたワークやユニットテストによるワークの実行前に、 Executor の実装によってのみ呼び出してください。
このメソッドが False を返す場合、 Future はキャンセルされています。つまり、 Future.cancel() が呼び出されて True が返っています。Future の完了を (as_completed() または wait() により) 待機するすべてのスレッドが起動します。
このメソッドが True を返す場合、 Future はキャンセルされて、実行状態に移行されています。つまり、 Future.running() を呼び出すと True が返ります。
このメソッドは、一度だけ呼び出すことができ、Future.set_result() または Future.set_exception() がキャンセルされた後には呼び出すことができません。
set_result(result)
Future に関連付けられたワークの結果を result に設定します。
このメソッドは、 Executor の実装またはユニットテストによってのみ使用してください。
バージョン 3.8 で変更: This method raises concurrent.futures.InvalidStateError if the Future is already done.
set_exception(exception)
Future に関連付けられたワークの結果を Exception exception に設定します。
このメソッドは、 Executor の実装またはユニットテストによってのみ使用してください。
バージョン 3.8 で変更: This method raises concurrent.futures.InvalidStateError if the Future is already done.
モジュール関数
concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)
timeout で結果を返すまで待機する最大秒数を指定できます。timeout は整数か浮動小数点数をとります。timeout が指定されないか None の場合、無期限に待機します。
return_when でこの関数がいつ結果を返すか指定します。指定できる値は以下の 定数のどれか一つです:
定数
説明
FIRST_COMPLETED
いずれかのフューチャが終了したかキャンセルされたときに返します。
FIRST_EXCEPTION
いずれかのフューチャが例外の送出で終了した場合に返します。例外を送出したフューチャがない場合は、ALL_COMPLETED と等価になります。
ALL_COMPLETED
すべてのフューチャが終了したかキャンセルされたときに返します。
concurrent.futures.as_completed(fs, timeout=None)
参考
PEP 3148 -- futures - execute computations asynchronously
この機能を Python 標準ライブラリに含めることを述べた提案です。
例外クラス
exception concurrent.futures.CancelledError
future がキャンセルされたときに送出されます。
exception concurrent.futures.TimeoutError
future の操作が与えられたタイムアウトを超過したときに送出されます。
exception concurrent.futures.BrokenExecutor
バージョン 3.7 で追加.
exception concurrent.futures.InvalidStateError
バージョン 3.8 で追加.
exception concurrent.futures.thread.BrokenThreadPool
バージョン 3.7 で追加.
exception concurrent.futures.process.BrokenProcessPool
バージョン 3.3 で追加.
subprocess --- サブプロセス管理
ソースコード: Lib/subprocess.py
subprocess モジュールは新しいプロセスの開始、入力/出力/エラーパイプの接続、リターンコードの取得を可能とします。このモジュールは以下の古いモジュールや関数を置き換えることを目的としています：
os.system
os.spawn*
これらのモジュールや関数の代わりに、subprocess モジュールをどのように使うかについてを以下の節で説明します。
参考 PEP 324 -- subprocess モジュールを提案している PEP
subprocess モジュールを使う
サブプロセスを起動するために推奨される方法は、すべての用法を扱える run() 関数を使用することです。より高度な用法では下層の Popen インターフェースを直接使用することもできます。
run() 関数は Python 3.5 で追加されました; 過去のバージョンとの互換性の維持が必要な場合は、古い高水準 API 節をご覧ください。
subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, capture_output=False, shell=False, cwd=None, timeout=None, check=False, encoding=None, errors=None, text=None, env=None, universal_newlines=None, **other_popen_kwargs)
args で指定されたコマンドを実行します。コマンドの完了を待って、CompletedProcess インスタンスを返します。
上記の引数は、もっともよく使われるものだけ示しており、後述の よく使われる引数 で説明されています (そのためここではキーワード専用引数の表記に省略されています)。関数の完全な使用法を説明しても大部分が Popen コンストラクターの内容と同じになります - この関数のほとんどの引数は Popen インターフェイスに渡されます。(timeout、input および check は除く。)
引数 timeout は Popen.communicate() に渡されます。タイムアウトが発生すると、子プロセスは kill され、待機されます。子プロセスが中断されたあと TimeoutExpired が再び送出されます。
check に真を指定した場合、プロセスが非ゼロの終了コードで終了すると CalledProcessError 例外が送出されます。 この例外の属性には、引数、終了コード、標準出力および標準エラー出力が捕捉できた場合に格納されます。
env が None 以外の場合、これは新しいプロセスでの環境変数を定義します。デフォルトでは、子プロセスは現在のプロセスの環境変数を引き継ぎます。 Popen に直接渡されます。
例:
>>>
>>> subprocess.run(["ls", "-l"])  # doesn't capture output
CompletedProcess(args=['ls', '-l'], returncode=0)
>>> subprocess.run("exit 1", shell=True, check=True)
Traceback (most recent call last):
  ...
subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1
>>> subprocess.run(["ls", "-l", "/dev/null"], capture_output=True)
CompletedProcess(args=['ls', '-l', '/dev/null'], returncode=0,
stdout=b'crw-rw-rw- 1 root root 1, 3 Jan 23 16:23 /dev/null\n', stderr=b'')
バージョン 3.5 で追加.
バージョン 3.6 で変更: encoding と error が引数に追加されました。
バージョン 3.7 で変更: Added the text parameter, as a more understandable alias of universal_newlines. Added the capture_output parameter.
class subprocess.CompletedProcess
run() の戻り値。プロセスが終了したことを表します。
args
プロセスを起動するときに使用された引数。1 個のリストか 1 個の文字列になります。
returncode
子プロセスの終了コード。一般に、終了ステータス 0 はプロセスが正常に終了したことを示します。
負の値 -N は子プロセスがシグナル N により中止させられたことを示します (POSIX のみ)。
stdout
子プロセスから補足された標準出力です。バイト列、もしくは run() でエンコーディングが指定された場合、エラーの場合、text=True が指定された場合は文字列です。標準出力が補足できなかったら None になります。
プロセスが stderr=subprocess.STDOUT で実行された場合、標準出力と標準エラー出力が混合されたものがこの属性に格納され、stderr は None になります。
stderr
子プロセスから補足された標準エラー出力です。バイト列、もしくは run() でエンコーディングが指定された場合、エラーの場合、text=True が指定された場合は文字列です。標準エラー出力が補足できなかったら None になります。
check_returncode()
returncode が非ゼロの場合、CalledProcessError が送出されます。
バージョン 3.5 で追加.
subprocess.DEVNULL
Popen の stdin, stdout, stderr 引数に渡して、標準入出力を os.devnull から入出力するように指定するための特殊値です。
バージョン 3.3 で追加.
subprocess.PIPE
Popen の stdin, stdout, stderr 引数に渡して、標準ストリームに対するパイプを開くことを指定するための特殊値です。Popen.communicate() に非常に有用です。
subprocess.STDOUT
Popen の stderr 引数に渡して、標準エラー出力が標準出力と同じハンドルに出力されるように指定するための特殊値です。
exception subprocess.SubprocessError
このモジュールの他のすべての例外のための基底クラスです。
バージョン 3.3 で追加.
exception subprocess.TimeoutExpired
SubprocessError のサブクラスです。子プロセスの終了を待機している間にタイムアウトが発生した場合に送出されます。
cmd
子プロセスの生成に使用されるコマンド本文。
timeout
タイムアウト秒数。
output
run() または check_output() によって捕捉された子プロセスの出力。捕捉されなかったら None になります。
stdout
output の別名。stderr と対になります。
stderr
run() によって捕捉された子プロセスの標準エラー出力。捕捉されなかったら None になります。
バージョン 3.3 で追加.
バージョン 3.5 で変更: 属性 stdout および stderr が追加されました。
exception subprocess.CalledProcessError
SubprocessError のサブクラスです。check_call() または check_output() によって実行されたプロセスが非ゼロの終了ステータスを返した場合に送出されます。
returncode
子プロセスの終了ステータスです。もしプロセスがシグナルによって終了したなら、これは負のシグナル番号になります。
cmd
子プロセスの生成に使用されるコマンド本文。
output
run() または check_output() によって捕捉された子プロセスの出力。捕捉されなかったら None になります。
stdout
output の別名。stderr と対になります。
stderr
run() によって捕捉された子プロセスの標準エラー出力。捕捉されなかったら None になります。
バージョン 3.5 で変更: 属性 stdout および stderr が追加されました。
よく使われる引数
幅広い使用例をサポートするために、Popen コンストラクター (とその他の簡易関数) は、多くのオプション引数を受け付けます。一般的な用法については、これらの引数の多くはデフォルト値のままで問題ありません。通常必要とされる引数は以下の通りです:
args はすべての呼び出しに必要で、文字列あるいはプログラム引数のシーケンスでなければなりません。一般に、引数のシーケンスを渡す方が望ましいです。なぜなら、モジュールが必要な引数のエスケープやクオート (例えばファイル名中のスペースを許すこと) の面倒を見ることができるためです。単一の文字列を渡す場合、shell は True でなければなりません (以下を参照)。もしくは、その文字列は引数を指定せずに実行される単なるプログラムの名前でなければなりません。
stdin, stdout および stderr には、実行するプログラムの標準入力、標準出力、および標準エラー出力のファイルハンドルをそれぞれ指定します。有効な値は PIPE、DEVNULL、既存のファイル記述子 (正の整数)、既存のファイルオブジェクトおよび None です。PIPE を指定すると新しいパイプが子プロセスに向けて作られます。DEVNULL を指定すると特殊ファイル os.devnull が使用されます。デフォルト設定の None を指定するとリダイレクトは起こりません。子プロセスのファイルハンドルはすべて親から受け継がれます。加えて、stderr を STDOUT にすると、子プロセスの stderr からの出力は stdout と同じファイルハンドルに出力されます。
バージョン 3.6 で追加: encoding と error がパラメータに追加されました。
バージョン 3.7 で追加: Added the text parameter as an alias for universal_newlines.
注釈 ファイルオブジェクト Popen.stdin、Popen.stdout ならびに Popen.stderr の改行属性は Popen.communicate() メソッドで更新されません。
shell が True なら、指定されたコマンドはシェルによって実行されます。あなたが Python を主として (ほとんどのシステムシェル以上の) 強化された制御フローのために使用していて、さらにシェルパイプ、ファイル名ワイルドカード、環境変数展開、~ のユーザーホームディレクトリへの展開のような他のシェル機能への簡単なアクセスを望むなら、これは有用かもしれません。しかしながら、Python 自身が多くのシェル的な機能の実装を提供していることに注意してください (特に glob, fnmatch, os.walk(), os.path.expandvars(), os.path.expanduser(), shutil)。
バージョン 3.3 で変更: universal_newlines が True の場合、クラスはエンコーディング locale.getpreferredencoding() の代わりに locale.getpreferredencoding(False) を使用します。この変更についての詳細は、 io.TextIOWrapper クラスを参照してください。
注釈 shell=True を使う前に セキュリティで考慮すべき点 を読んでください。
これらのオプションは、他のすべてのオプションとともに Popen コンストラクターのドキュメントの中でより詳細に説明されています。
Popen コンストラクター
このモジュールの中で、根底のプロセス生成と管理は Popen クラスによって扱われます。簡易関数によってカバーされないあまり一般的でないケースを開発者が扱えるように、Popen クラスは多くの柔軟性を提供しています。
class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=None, startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *, group=None, extra_groups=None, user=None, umask=-1, encoding=None, errors=None, text=None)
新しいプロセスで子のプログラムを実行します。POSIX においては、子のプログラムを実行するために、このクラスは os.execvp() のような挙動を使用します。Windows においては、このクラスは Windows の CreateProcess() 関数を使用します。Popen への引数は以下の通りです。
args should be a sequence of program arguments or else a single string or path-like object. By default, the program to execute is the first item in args if args is a sequence. If args is a string, the interpretation is platform-dependent and described below. See the shell and executable arguments for additional differences from the default behavior. Unless otherwise stated, it is recommended to pass args as a sequence.
An example of passing some arguments to an external program as a sequence is:
Popen(["/usr/bin/git", "commit", "-m", "Fixes a bug."])
POSIX 上では、args が文字列の場合、その文字列は実行すべきプログラムの名前またはパスとして解釈されます。しかし、これはプログラムに引数を渡さない場合にのみ可能です。
注釈 It may not be obvious how to break a shell command into a sequence of arguments, especially in complex cases. shlex.split() can illustrate how to determine the correct tokenization for args:
>>>
>>> import shlex, subprocess
>>> command_line = input()
/bin/vikings -input eggs.txt -output "spam spam.txt" -cmd "echo '$MONEY'"
>>> args = shlex.split(command_line)
>>> print(args)
['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
>>> p = subprocess.Popen(args) # Success!
特に注意すべき点は、シェル内でスペースで区切られたオプション (-input など) と引数 (eggs.txt など) はリストの別々の要素になるのに対し、シェル内で (上記のスペースを含むファイル名や echo コマンドのように) クォーティングやバックスラッシュエスケープが必要なものは単一のリスト要素であることです。
Windows 上では、args がシーケンスなら Windows における引数シーケンスから文字列への変換 に記述された方法で文字列に変換されます。これは根底の CreateProcess() が文字列上で動作するからです。
バージョン 3.6 で変更: args parameter accepts a path-like object if shell is False and a sequence containing path-like objects on POSIX.
バージョン 3.8 で変更: args parameter accepts a path-like object if shell is False and a sequence containing bytes and path-like objects on Windows.
shell 引数 (デフォルトでは False) は、実行するプログラムとしてシェルを使用するかどうかを指定します。 shell が True の場合、 args をシーケンスとしてではなく文字列として渡すことが推奨されます。
POSIX で shell=True の場合、シェルのデフォルトは /bin/sh になります。args が文字列の場合、この文字列はシェルを介して実行されるコマンドを指定します。したがって、文字列は厳密にシェルプロンプトで打つ形式と一致しなければなりません。例えば、文字列の中にスペースを含むファイル名がある場合は、クォーティングやバックスラッシュエスケープが必要です。args がシーケンスの場合には、最初の要素はコマンド名を表わす文字列として、残りの要素は追加の引数としてシェルに渡されます。つまり、以下の Popen と等価ということです:
Popen(['/bin/sh', '-c', args[0], args[1], ...])
Windows で shell=True とすると、COMSPEC 環境変数がデフォルトシェルを指定します。Windows で shell=True を指定する必要があるのは、実行したいコマンドがシェルに組み込みの場合だけです (例えば dir や copy)。バッチファイルやコンソールベースの実行ファイルを実行するために shell=True は必要ありません。
注釈 shell=True を使う前に セキュリティで考慮すべき点 を読んでください。
bufsize は標準入力/標準出力/標準エラー出力パイプファイルオブジェクトを生成するときに open() 関数の対応する引数に渡されます:
0 はバッファーされないことを意味します (読み込みおよび書き出しのたびにシステムコールが行われ、すぐに復帰します)。
1 はラインバッファーを意味します (universal_newlines=True、すなわちテキストモードの場合のみ使用可能)。
それ以外の正の整数はバッファーのおよそのサイズになることを意味します。
負のサイズ (デフォルト) は io.DEFAULT_BUFFER_SIZE のシステムデフォルトが使用されることを意味します。
バージョン 3.3.1 で変更: ほとんどのコードが期待する振る舞いに合わせてデフォルトでバッファリングが有効となるよう bufsize のデフォルト値が -1 になりました。Python 3.2.4 および 3.3.1 より前のバージョンでは、誤ってバッファーされず短い読み込みを許可する 0 がデフォルトになっていました。これは意図したものではなく、ほとんどのコードが期待する Python 2 での振る舞いとも一致していませんでした。
executable 引数は、実行する置換プログラムを指定します。これが必要になるのは極めて稀です。shell=False のときは、executable は args で指定されている実行プログラムを置換します。しかし、オリジナルの args は依然としてプログラムに渡されます。ほとんどのプログラムは、args で指定されたプログラムをコマンド名として扱います。そして、それは実際に実行されたプログラムとは異なる可能性があります。POSIX において、ps のようなユーティリティの中では、args 名が実行ファイルの表示名になります。shell=True の場合、POSIX において executable 引数はデフォルトの /bin/sh に対する置換シェルを指定します。
バージョン 3.6 で変更: executable parameter accepts a path-like object on POSIX.
バージョン 3.8 で変更: executable parameter accepts a bytes and path-like object on Windows.
stdin、stdout および stderr には、実行するプログラムの標準入力、標準出力、および標準エラー出力のファイルハンドルをそれぞれ指定します。有効な値は PIPE, DEVNULL, 既存のファイル記述子 (正の整数)、既存の ファイルオブジェクト 、そして None です。PIPE を指定すると新しいパイプが子プロセスに向けて作られます。DEVNULL を指定すると特殊ファイル os.devnull が使用されます。デフォルト設定の None を指定するとリダイレクトは起こりません。子プロセスのファイルハンドルはすべて親から受け継がれます。加えて、stderr を STDOUT にすると、子プロセスの標準エラー出力からの出力は標準出力と同じファイルハンドルに出力されます。
preexec_fn に呼び出し可能オブジェクトが指定されている場合、このオブジェクトは子プロセスが実行される直前 (fork されたあと、exec される直前) に子プロセス内で呼ばれます。(POSIXのみ)
警告 アプリケーション中に複数のスレッドが存在する状態で preexec_fn 引数を使用するのは安全ではありません。exec が呼ばれる前に子プロセスがデッドロックを起こすことがあります。それを使用しなければならない場合、プログラムを自明なものにしておいてください! 呼び出すライブラリの数を最小にしてください。
注釈 子プロセスのために環境を変更する必要がある場合は、preexec_fn の中でそれをするのではなく env 引数を使用します。start_new_session 引数は、子プロセスの中で os.setsid() を呼ぶ過去の一般的な preexec_fn の使用方法の代わりになります。
バージョン 3.8 で変更: The preexec_fn parameter is no longer supported in subinterpreters. The use of the parameter in a subinterpreter raises RuntimeError. The new restriction may affect applications that are deployed in mod_wsgi, uWSGI, and other embedded environments.
バージョン 3.2 で変更: close_fds のデフォルトは、False から上記のものに変更されました。
バージョン 3.7 で変更: On Windows the default for close_fds was changed from False to True when redirecting the standard handles. It's now possible to set close_fds to True when redirecting the standard handles.
pass_fds はオプションで、親と子の間で開いたままにしておくファイル記述子のシーケンスを指定します。何らかの pass_fds を渡した場合、close_fds は強制的に True になります。(POSIXのみ)
バージョン 3.2 で変更: pass_fds 引数が追加されました。
バージョン 3.6 で変更: cwd parameter accepts a path-like object on POSIX.
バージョン 3.7 で変更: cwd parameter accepts a path-like object on Windows.
バージョン 3.8 で変更: cwd parameter accepts a bytes object on Windows.
restore_signals が真の場合 (デフォルト)、Python が SIG_IGN に設定したすべてのシグナルは子プロセスが exec される前に子プロセスの SIG_DFL に格納されます。現在これには SIGPIPE, SIGXFZ および SIGXFSZ シグナルが含まれています。(POSIX のみ)
バージョン 3.2 で変更: restore_signals が追加されました。
start_new_session が真の場合、サブプロセスの実行前に子プロセス内で setsid() システムコールが作成されます。(POSIX のみ)
バージョン 3.2 で変更: start_new_session が追加されました。
If group is not None, the setregid() system call will be made in the child process prior to the execution of the subprocess. If the provided value is a string, it will be looked up via grp.getgrnam() and the value in gr_gid will be used. If the value is an integer, it will be passed verbatim. (POSIX only)
Availability: POSIX
バージョン 3.9 で追加.
If extra_groups is not None, the setgroups() system call will be made in the child process prior to the execution of the subprocess. Strings provided in extra_groups will be looked up via grp.getgrnam() and the values in gr_gid will be used. Integer values will be passed verbatim. (POSIX only)
Availability: POSIX
バージョン 3.9 で追加.
If user is not None, the setreuid() system call will be made in the child process prior to the execution of the subprocess. If the provided value is a string, it will be looked up via pwd.getpwnam() and the value in pw_uid will be used. If the value is an integer, it will be passed verbatim. (POSIX only)
Availability: POSIX
バージョン 3.9 で追加.
Availability: POSIX
バージョン 3.9 で追加.
env が None 以外の場合、これは新しいプロセスでの環境変数を定義します。デフォルトでは、子プロセスは現在のプロセスの環境変数を引き継ぎます。
注釈 env を指定する場合、プログラムを実行するのに必要な変数すべてを与えなければなりません。Windows で Side-by-Side アセンブリ を実行するためには、env は正しい SystemRoot を 含まなければなりません 。
バージョン 3.6 で追加: encoding と errors が追加されました。
バージョン 3.7 で追加: text が、universal_newlines のより読みやすい別名として追加されました。
If given, startupinfo will be a STARTUPINFO object, which is passed to the underlying CreateProcess function. creationflags, if given, can be one or more of the following flags:
CREATE_NEW_CONSOLE
CREATE_NEW_PROCESS_GROUP
ABOVE_NORMAL_PRIORITY_CLASS
BELOW_NORMAL_PRIORITY_CLASS
HIGH_PRIORITY_CLASS
IDLE_PRIORITY_CLASS
NORMAL_PRIORITY_CLASS
REALTIME_PRIORITY_CLASS
CREATE_NO_WINDOW
DETACHED_PROCESS
CREATE_DEFAULT_ERROR_MODE
CREATE_BREAKAWAY_FROM_JOB
Popen オブジェクトは with 文によってコンテキストマネージャーとしてサポートされます: 終了時には標準ファイル記述子が閉じられ、プロセスを待機します:
with Popen(["ifconfig"], stdout=PIPE) as proc:
    log.write(proc.stdout.read())
バージョン 3.2 で変更: コンテキストマネージャーサポートが追加されました。
バージョン 3.6 で変更: Popen destructor now emits a ResourceWarning warning if the child process is still running.
バージョン 3.8 で変更: Popen can use os.posix_spawn() in some cases for better performance. On Windows Subsystem for Linux and QEMU User Emulation, Popen constructor using os.posix_spawn() no longer raise an exception on errors like missing program, but the child process fails with a non-zero returncode.
例外
もっとも一般的に起こる例外は OSError です。これは、たとえば存在しないファイルを実行しようとしたときなどに発生します。アプリケーションは OSError 例外に備えておかなければなりません。
不正な引数で Popen が呼ばれた場合は ValueError が発生します。
呼び出されたプロセスが非ゼロのリターンコードを返した場合 check_call() や check_output() は CalledProcessError を送出します。
call() や Popen.communicate() のような timeout 引数を受け取るすべての関数とメソッドは、プロセスが終了する前にタイムアウトが発生した場合に TimeoutExpired を送出します。
このモジュールで定義されたすべての例外は SubprocessError を継承しています。
バージョン 3.3 で追加: SubprocessError 基底クラスが追加されました。
セキュリティで考慮すべき点
その他一部の popen 関数と異なり、この実装は暗黙的にシステムシェルを呼び出すことはありません。これはシェルのメタ文字を含むすべての文字が子プロセスに安全に渡されることを意味します。shell=True でシェルを明示的に呼びだした場合、シェルインジェクション の脆弱性に対処するための、すべての空白やメタ文字の適切なクオートの保証はアプリケーションの責任になります。
shell=True を使用するときは、シェルコマンドで使用される文字列の空白やメタ文字は shlex.quote() 関数を使うと正しくエスケープできます。
Popen オブジェクト
Popen クラスのインスタンスには、以下のようなメソッドがあります:
Popen.poll()
Popen.wait(timeout=None)
子プロセスが終了するまで待ちます。returncode 属性を設定して返します。
プロセスが timeout 秒後に終了してない場合、TimeoutExpired 例外を送出します。この例外を捕捉して wait を再試行するのは安全です。
注釈 stdout=PIPE や stderr=PIPE を使っていて、より多くのデータを受け入れるために OS のパイプバッファーをブロックしているパイプに子プロセスが十分な出力を生成した場合、デッドロックが発生します。これを避けるには Popen.communicate() を使用してください。
注釈 この関数はビジーループ (非ブロック化呼び出しと短いスリープ) を使用して実装されています。非同期の待機には asyncio モジュールを使用してください (asyncio.create_subprocess_exec を参照)。
バージョン 3.3 で変更: timeout が追加されました
Popen.communicate(input=None, timeout=None)
communicate() returns a tuple (stdout_data, stderr_data). The data will be strings if streams were opened in text mode; otherwise, bytes.
子プロセスの標準入力にデータを送りたい場合は、 Popen オブジェクトを stdin=PIPE と指定して作成しなければなりません。同じく、戻り値のタプルから None ではない値を取得するためには、 stdout=PIPE かつ/または stderr=PIPE を指定しなければなりません。
プロセスが timeout 秒後に終了してない場合、TimeoutExpired 例外が送出されます。この例外を捕捉して通信を再試行しても出力データは失われません。
タイムアウトが発生した場合子プロセスは kill されません。したがって、適切にクリーンアップを行うために、正常に動作するアプリケーションは子プロセスを kill して通信を終了すべきです:
proc = subprocess.Popen(...)
try:
    outs, errs = proc.communicate(timeout=15)
except TimeoutExpired:
    proc.kill()
    outs, errs = proc.communicate()
注釈 受信したデータはメモリにバッファーされます。そのため、返されるデータが大きいかあるいは制限がないような場合はこのメソッドを使うべきではありません。
バージョン 3.3 で変更: timeout が追加されました
Popen.send_signal(signal)
signal シグナルを子プロセスに送ります。
注釈 Windows では、SIGTERM は terminate() の別名です。CTRL_C_EVENT と CTRL_BREAK_EVENT を、CREATE_NEW_PROCESS_GROUP を含む creationflags で始まった、プロセスに送れます。
Popen.terminate()
Popen.kill()
以下の属性も利用可能です:
Popen.args
Popen に渡された引数 args です -- プログラム引数のシーケンスまたは 1 個の文字列になります。
バージョン 3.3 で追加.
Popen.stdin
Popen.stdout
Popen.stderr
警告 .stdin.write, .stdout.read, .stderr.read を利用すると、別のパイプの OS パイプバッファーがいっぱいになってデッドロックが発生する恐れがあります。これを避けるためには communicate() を利用してください。
Popen.pid
子プロセスのプロセス ID が入ります。
shell 引数を True に設定した場合は、生成されたシェルのプロセス ID になります。
Popen.returncode
poll() か wait() (か、間接的に communicate()) から設定された、子プロセスの終了ステータスが入ります。None はまだその子プロセスが終了していないことを示します。
負の値 -N は子プロセスがシグナル N により中止させられたことを示します (POSIX のみ)。
Windows Popen ヘルパー
STARTUPINFO クラスと以下の定数は、Windows のみで利用できます。
class subprocess.STARTUPINFO(*, dwFlags=0, hStdInput=None, hStdOutput=None, hStdError=None, wShowWindow=0, lpAttributeList=None)
バージョン 3.7 で変更: Keyword-only argument support was added.
dwFlags
特定の STARTUPINFO の属性が、プロセスがウィンドウを生成するときに使われるかを決定するビットフィールドです:
si = subprocess.STARTUPINFO()
si.dwFlags = subprocess.STARTF_USESTDHANDLES | subprocess.STARTF_USESHOWWINDOW
hStdInput
dwFlags が STARTF_USESTDHANDLES を指定すれば、この属性がプロセスの標準入力処理です。STARTF_USESTDHANDLES が指定されなければ、標準入力のデフォルトはキーボードバッファーです。
hStdOutput
dwFlags が STARTF_USESTDHANDLES を指定すれば、この属性がプロセスの標準出力処理です。そうでなければ、この属性は無視され、標準出力のデフォルトはコンソールウィンドウのバッファーです。
hStdError
dwFlags が STARTF_USESTDHANDLES を指定すれば、この属性がプロセスの標準エラー処理です。そうでなければ、この属性は無視され、標準エラー出力のデフォルトはコンソールウィンドウのバッファーです。
wShowWindow
dwFlags が STARTF_USESHOWWINDOW を指定すれば、この属性は ShowWindow 関数の nCmdShow 引数で指定された値なら、 SW_SHOWDEFAULT 以外の任意のものにできます。しかし、この属性は無視されます。
この属性には SW_HIDE が提供されています。これは、Popen が shell=True として呼び出されたときに使われます。
lpAttributeList
Supported attributes:
handle_list
警告 In a multithreaded process, use caution to avoid leaking handles that are marked inheritable when combining this feature with concurrent calls to other process creation functions that inherit all handles such as os.system(). This also applies to standard handle redirection, which temporarily creates inheritable handles.
バージョン 3.7 で追加.
Windows Constants
subprocess モジュールは、以下の定数を公開しています。
subprocess.STD_INPUT_HANDLE
標準入力デバイスです。この初期値は、コンソール入力バッファ、 CONIN$ です。
subprocess.STD_OUTPUT_HANDLE
標準出力デバイスです。この初期値は、アクティブコンソールスクリーン、 CONOUT$ です。
subprocess.STD_ERROR_HANDLE
標準エラーデバイスです。この初期値は、アクティブコンソールスクリーン、 CONOUT$ です。
subprocess.SW_HIDE
ウィンドウを隠します。別のウィンドウがアクティブになります。
subprocess.STARTF_USESTDHANDLES
追加情報を保持する、STARTUPINFO.hStdInput, STARTUPINFO.hStdOutput, および STARTUPINFO.hStdError 属性を指定します。
subprocess.STARTF_USESHOWWINDOW
追加情報を保持する、 STARTUPINFO.wShowWindow 属性を指定します。
subprocess.CREATE_NEW_CONSOLE
新しいプロセスが、親プロセスのコンソールを継承する (デフォルト) のではなく、新しいコンソールを持ちます。
subprocess.CREATE_NEW_PROCESS_GROUP
新しいプロセスグループが生成されることを指定する Popen creationflags パラメーターです。このフラグは、サブプロセスで os.kill() を使うのに必要です。
CREATE_NEW_CONSOLE が指定されていたら、このフラグは無視されます。
subprocess.ABOVE_NORMAL_PRIORITY_CLASS
バージョン 3.7 で追加.
subprocess.BELOW_NORMAL_PRIORITY_CLASS
バージョン 3.7 で追加.
subprocess.HIGH_PRIORITY_CLASS
バージョン 3.7 で追加.
subprocess.IDLE_PRIORITY_CLASS
バージョン 3.7 で追加.
subprocess.NORMAL_PRIORITY_CLASS
A Popen creationflags parameter to specify that a new process will have an normal priority. (default)
バージョン 3.7 で追加.
subprocess.REALTIME_PRIORITY_CLASS
バージョン 3.7 で追加.
subprocess.CREATE_NO_WINDOW
バージョン 3.7 で追加.
subprocess.DETACHED_PROCESS
バージョン 3.7 で追加.
subprocess.CREATE_DEFAULT_ERROR_MODE
バージョン 3.7 で追加.
subprocess.CREATE_BREAKAWAY_FROM_JOB
バージョン 3.7 で追加.
古い高水準 API
Python 3.5 より前のバージョンでは、サブプロセスに対して以下の 3 つの関数からなる高水準 API が用意されていました。現在多くの場合 run() の使用で済みますが、既存の多くのコードではこれらの関数が使用されています。
subprocess.call(args, *, stdin=None, stdout=None, stderr=None, shell=False, cwd=None, timeout=None, **other_popen_kwargs)
args で指定されたコマンドを実行します。コマンドの終了を待ち、returncode 属性を返します。
Code needing to capture stdout or stderr should use run() instead:
run(...).returncode
注釈 この関数を使用する際は stdout=PIPE および stderr=PIPE を使用しないでください。子プロセスが OS のパイプバッファーを埋めてしまうほどの出力データを生成した場合、パイプからは読み込まれないので、子プロセスがブロックされることがあります。
バージョン 3.3 で変更: timeout が追加されました
subprocess.check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False, cwd=None, timeout=None, **other_popen_kwargs)
指定された引数でコマンドを実行し、完了を待ちます。コマンドのリターンコードがゼロならば返りますが、非ゼロなら CalledProcessError 例外が送出されます。CalledProcessError オブジェクトにはリターンコードが returncode 属性として格納されています。
Code needing to capture stdout or stderr should use run() instead:
run(..., check=True)
注釈 この関数を使用する際は stdout=PIPE および stderr=PIPE を使用しないでください。子プロセスが OS のパイプバッファーを埋めてしまうほどの出力データを生成した場合、パイプからは読み込まれないので、子プロセスがブロックされることがあります。
バージョン 3.3 で変更: timeout が追加されました
subprocess.check_output(args, *, stdin=None, stderr=None, shell=False, cwd=None, encoding=None, errors=None, universal_newlines=None, timeout=None, text=None, **other_popen_kwargs)
引数でコマンドを実行し、その出力を返します。
コマンドのリターンコードが非ゼロならば CalledProcessError 例外が送出されます。CalledProcessError オブジェクトには、リターンコードが returncode 属性に、コマンドからの出力が output 属性に、それぞれ格納されています。
これは次と等価です:
run(..., check=True, stdout=PIPE).stdout
デフォルトで、この関数はデータをエンコードされたバイトとして返します。出力されたデータの実際のエンコードは起動されているコマンドに依存するため、テキストへのデコードは通常アプリケーションレベルで扱う必要があります。
標準エラー出力も結果に含めるには、stderr=subprocess.STDOUT を使います:
>>>
>>> subprocess.check_output(
...     "ls non_existent_file; exit 0",
...     stderr=subprocess.STDOUT,
...     shell=True)
'ls: non_existent_file: No such file or directory\n'
バージョン 3.1 で追加.
バージョン 3.3 で変更: timeout が追加されました
バージョン 3.4 で変更: キーワード引数 input が追加されました。
バージョン 3.6 で変更: encoding and errors were added. See run() for details.
バージョン 3.7 で追加: text が、universal_newlines のより読みやすい別名として追加されました。
古い関数を subprocess モジュールで置き換える
この節では、 "a becomes b" と書かれているものは a の代替として b が使えるということを表します。
注釈 この節で紹介されている "a" 関数は全て、実行するプログラムが見つからないときは (おおむね) 静かに終了します。それに対して "b" 代替手段は OSError 例外を送出します。
また、要求された操作が非ゼロの終了コードを返した場合、check_output() を使用した置き換えは CalledProcessError で失敗します。その出力は、送出された例外の output 属性として利用可能です。
以下の例では、適切な関数が subprocess モジュールからすでにインポートされていることを前提としています。
Replacing /bin/sh shell command substitution
output=$(mycmd myarg)
これは以下のようになります:
output = check_output(["mycmd", "myarg"])
シェルのパイプラインを置き換える
output=$(dmesg | grep hda)
これは以下のようになります:
p1 = Popen(["dmesg"], stdout=PIPE)
p2 = Popen(["grep", "hda"], stdin=p1.stdout, stdout=PIPE)
p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.
output = p2.communicate()[0]
あるいは、信頼された入力に対しては、シェル自身のパイプラインサポートを直接使用することもできます:
output=$(dmesg | grep hda)
これは以下のようになります:
output=check_output("dmesg | grep hda", shell=True)
os.system() を置き換える
sts = os.system("mycmd" + " myarg")
# becomes
sts = call("mycmd" + " myarg", shell=True)
注釈:
このプログラムは普通シェル経由で呼び出す必要はありません。
より現実的な例ではこうなるでしょう:
try:
    retcode = call("mycmd" + " myarg", shell=True)
    if retcode < 0:
        print("Child was terminated by signal", -retcode, file=sys.stderr)
    else:
        print("Child returned", retcode, file=sys.stderr)
except OSError as e:
    print("Execution failed:", e, file=sys.stderr)
os.spawn 関数群を置き換える
P_NOWAIT の例:
pid = os.spawnlp(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg")
==>
pid = Popen(["/bin/mycmd", "myarg"]).pid
P_WAIT の例:
retcode = os.spawnlp(os.P_WAIT, "/bin/mycmd", "mycmd", "myarg")
==>
retcode = call(["/bin/mycmd", "myarg"])
シーケンスを使った例:
os.spawnvp(os.P_NOWAIT, path, args)
==>
Popen([path] + args[1:])
環境変数を使った例:
os.spawnlpe(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg", env)
==>
Popen(["/bin/mycmd", "myarg"], env={"PATH": "/usr/bin"})
os.popen(), os.popen2(), os.popen3() を置き換える
(child_stdin, child_stdout) = os.popen2(cmd, mode, bufsize)
==>
p = Popen(cmd, shell=True, bufsize=bufsize,
          stdin=PIPE, stdout=PIPE, close_fds=True)
(child_stdin, child_stdout) = (p.stdin, p.stdout)
(child_stdin,
 child_stdout,
 child_stderr) = os.popen3(cmd, mode, bufsize)
==>
p = Popen(cmd, shell=True, bufsize=bufsize,
          stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)
(child_stdin,
 child_stdout,
 child_stderr) = (p.stdin, p.stdout, p.stderr)
(child_stdin, child_stdout_and_stderr) = os.popen4(cmd, mode, bufsize)
==>
p = Popen(cmd, shell=True, bufsize=bufsize,
          stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
(child_stdin, child_stdout_and_stderr) = (p.stdin, p.stdout)
終了コードハンドリングは以下のように解釈します:
pipe = os.popen(cmd, 'w')
...
rc = pipe.close()
if rc is not None and rc >> 8:
    print("There were some errors")
==>
process = Popen(cmd, stdin=PIPE)
...
process.stdin.close()
if process.wait() != 0:
    print("There were some errors")
popen2 モジュールの関数群を置き換える
注釈 popen2 関数の cmd 引数が文字列の場合、コマンドは /bin/sh によって実行されます。リストの場合、コマンドは直接実行されます。
(child_stdout, child_stdin) = popen2.popen2("somestring", bufsize, mode)
==>
p = Popen("somestring", shell=True, bufsize=bufsize,
          stdin=PIPE, stdout=PIPE, close_fds=True)
(child_stdout, child_stdin) = (p.stdout, p.stdin)
(child_stdout, child_stdin) = popen2.popen2(["mycmd", "myarg"], bufsize, mode)
==>
p = Popen(["mycmd", "myarg"], bufsize=bufsize,
          stdin=PIPE, stdout=PIPE, close_fds=True)
(child_stdout, child_stdin) = (p.stdout, p.stdin)
popen2.Popen3 および popen2.Popen4 は以下の点を除けば、基本的に subprocess.Popen と同じです:
Popen は実行が失敗した場合に例外を送出します。
stdin=PIPE および stdout=PIPE を指定する必要があります。
popen2 はデフォルトですべてのファイル記述子を閉じます。しかし、全てのプラットフォーム上で、あるいは過去の Python バージョンでこの挙動を保証するためには、 Popen に対して close_fds=True を指定しなければなりません。
レガシーなシェル呼び出し関数
このモジュールでは、以下のような 2.x commands モジュールからのレガシー関数も提供しています。これらの操作は、暗黙的にシステムシェルを起動します。また、セキュリティに関して上述した保証や例外処理一貫性は、これらの関数では有効ではありません。
subprocess.getstatusoutput(cmd)
A trailing newline is stripped from the output. The exit code for the command can be interpreted as the return code of subprocess. Example:
>>>
>>> subprocess.getstatusoutput('ls /bin/ls')
(0, '/bin/ls')
>>> subprocess.getstatusoutput('cat /bin/junk')
(1, 'cat: /bin/junk: No such file or directory')
>>> subprocess.getstatusoutput('/bin/junk')
(127, 'sh: /bin/junk: not found')
>>> subprocess.getstatusoutput('/bin/kill $$')
(-15, '')
バージョン 3.3.4 で変更: Windows support was added.
subprocess.getoutput(cmd)
シェル中の cmd を実行して出力 (stdout と stderr) を返します。
Like getstatusoutput(), except the exit code is ignored and the return value is a string containing the command's output. Example:
>>>
>>> subprocess.getoutput('ls /bin/ls')
'/bin/ls'
バージョン 3.3.4 で変更: Windowsで利用可能になりました
注釈
Windows における引数シーケンスから文字列への変換
Windows では、 args シーケンスは以下の (MS C ランタイムで使われる規則に対応する) 規則を使って解析できる文字列に変換されます:
引数は、スペースかタブのどちらかの空白で分けられます。
ダブルクオーテーションマークで囲まれた文字列は、空白が含まれていたとしても 1 つの引数として解釈されます。クオートされた文字列は引数に埋め込めます。
バックスラッシュに続くダブルクオーテーションマークは、リテラルのダブルクオーテーションマークと解釈されます。
バックスラッシュは、ダブルクオーテーションが続かない限り、リテラルとして解釈されます。
複数のバックスラッシュにダブルクオーテーションマークが続くなら、バックスラッシュ 2 つで 1 つのバックスラッシュ文字と解釈されます。バックスラッシュの数が奇数なら、最後のバックスラッシュは規則 3 に従って続くダブルクオーテーションマークをエスケープします。
参考
shlex
コマンドラインを解析したりエスケープしたりする関数を提供するモジュール。
sched --- イベントスケジューラ
ソースコード: Lib/sched.py
sched モジュールは一般的な目的のためのイベントスケジューラを実装するクラスを定義します:
class sched.scheduler(timefunc=time.monotonic, delayfunc=time.sleep)
scheduler クラスはイベントをスケジュールするための一般的なインタフェースを定義します。それは "外の世界" を実際に扱うための2つの関数を必要とします --- timefunc は引数なしで呼ばれて 1 つの数値を返す callable オブジェクトでなければなりません (戻り値は任意の単位で「時間」を表します)。 delayfunc は 1 つの引数を持つ callable オブジェクトでなければならず、その時間だけ遅延する必要があります (引数は timefunc の出力と互換)。 delayfunc は、各々のイベントが実行された後に引数 0 で呼ばれることがあります。これは、マルチスレッドアプリケーションの中で他のスレッドが実行する機会を与えるためです。
バージョン 3.3 で変更: timefunc と delayfunc がオプション引数になりました。
バージョン 3.3 で変更: scheduler クラスをマルチスレッド環境で安全に使用出来るようになりました。
以下はプログラム例です:
>>>
>>> import sched, time
>>> s = sched.scheduler(time.time, time.sleep)
>>> def print_time(a='default'):
...     print("From print_time", time.time(), a)
...
>>> def print_some_times():
...     print(time.time())
...     s.enter(10, 1, print_time)
...     s.enter(5, 2, print_time, argument=('positional',))
...     s.enter(5, 1, print_time, kwargs={'a': 'keyword'})
...     s.run()
...     print(time.time())
...
>>> print_some_times()
930343690.257
From print_time 930343695.274 positional
From print_time 930343695.275 keyword
From print_time 930343700.273 default
930343700.276
スケジューラオブジェクト
scheduler インスタンスは以下のメソッドと属性を持っています:
scheduler.enterabs(time, priority, action, argument=(), kwargs={})
新しいイベントをスケジュールします。 引数 time は、コンストラクタへ渡された timefunc の戻り値と互換な数値型でなければいけません。 同じ time によってスケジュールされたイベントは、それらの priority によって実行されます。 数値の小さい方が高い優先度となります。
イベントを実行することは、 action(*argument, **kwargs) を実行することを意味します。 argument は action のための位置引数を保持するシーケンスでなければいけません。 kwargs は action のためのキーワード引数を保持する辞書でなければいけません。
戻り値は、後にイベントをキャンセルする時に使われる可能性のあるイベントです (cancel() を参照)。
バージョン 3.3 で変更: argument 引数が任意になりました。
バージョン 3.3 で変更: kwargs 引数が追加されました。
scheduler.enter(delay, priority, action, argument=(), kwargs={})
時間単位以上の delay でイベントをスケジュールします。相対的時間以外の、引数、効果、戻り値は、 enterabs() に対するものと同じです。
バージョン 3.3 で変更: argument 引数が任意になりました。
バージョン 3.3 で変更: kwargs 引数が追加されました。
scheduler.cancel(event)
キューからイベントを消去します。もし event がキューにある現在のイベントでないならば、このメソッドは ValueError を送出します。
scheduler.empty()
もしイベントキューが空ならば、 True を返します。
scheduler.run(blocking=True)
すべてのスケジュールされたイベントを実行します。このメソッドは次のイベントを待ち、それを実行し、スケジュールされたイベントがなくなるまで同じことを繰り返します。(イベントの待機は、 コンストラクタへ渡された関数 delayfunc() を使うことで行います。)
blocking が False の場合、最も早く期限が来るスケジュールされたイベントを (存在する場合) 実行し、スケジューラ内で次にスケジュールされた呼び出しの期限を (存在する場合) 返します。
action あるいは delayfunc は例外を投げることができます。いずれの場合も、スケジューラは一貫した状態を維持し、例外を伝播するでしょう。例外が action によって投げられる場合、イベントは run() への呼出しを未来に行なわないでしょう。
イベントのシーケンスが、次イベントの前に、利用可能時間より実行時間が長いと、スケジューラは単に遅れることになるでしょう。イベントが落ちることはありません; 呼出しコードはもはや適切でないキャンセルイベントに対して責任があります。
バージョン 3.3 で変更: blocking 引数が追加されました。
scheduler.queue
読み出し専用の属性で、これから起こるイベントが実行される順序で格納されたリストを返します。各イベントは、次の属性 time, priority, action, argument, kwargs を持った named tuple の形式になります。
queue --- 同期キュークラス
ソースコード: Lib/queue.py
このモジュールでは3種類のキューが実装されています。それらはキューから取り出されるエントリの順番だけが違います。 FIFO キューでは、最初に追加されたエントリが最初に取り出されます。 LIFO キューでは、最後に追加されたエントリが最初に取り出されます(スタックのように振る舞います)。 優先順位付きキュー(priority queue)では、エントリは(heapq モジュールを利用して)ソートされ、 最も低い値のエントリが最初に取り出されます。
内部的には、これらの3種類のキューは競争スレッドを一時的にブロックするためにロックを使っています; しかし、スレッド内での再入を扱うようには設計されていません。
queue モジュールは以下のクラスと例外を定義します:
class queue.Queue(maxsize=0)
FIFO キューのコンストラクタです。 maxsize はキューに入れられる要素数の上限を設定する整数です。 いったんこの大きさに達したら、挿入処理はキューの要素が消費されるまでブロックされます。 maxsize が0以下の場合は、キューの大きさは無限です。
class queue.LifoQueue(maxsize=0)
LIFO キューのコンストラクタです。 maxsize はキューに入れられる要素数の上限を設定する整数です。 いったんこの大きさに達したら、挿入処理はキューの要素が消費されるまでブロックされます。 maxsize が0以下の場合は、キューの大きさは無限です。
class queue.PriorityQueue(maxsize=0)
優先順位付きキューのコンストラクタです。maxsize はキューに置くことのできる要素数の上限を設定する整数です。いったんこの大きさに達したら、挿入はキューの要素が消費されるまでブロックされます。もし maxsize が0以下であるならば、キューの大きさは無限です。
最小の値を持つ要素が最初に検索されます (最小の値を持つ値は、sorted(list(entries))[0] によって返されるものです)。典型的な要素のパターンは、(priority_number, data) 形式のタプルです。
If the data elements are not comparable, the data can be wrapped in a class that ignores the data item and only compares the priority number:
from dataclasses import dataclass, field
from typing import Any
@dataclass(order=True)
class PrioritizedItem:
    priority: int
    item: Any=field(compare=False)
class queue.SimpleQueue
バージョン 3.7 で追加.
exception queue.Empty
空の Queue オブジェクトで、非ブロックメソッド get() (または get_nowait()) が呼ばれたとき、送出される例外です。
exception queue.Full
満杯の Queue オブジェクトで、非ブロックメソッド put() (または put_nowait()) が呼ばれたとき、送出される例外です。
キューオブジェクト
キューオブジェクト(Queue, LifoQueue, PriorityQueue)は、以下のpublicメソッドを提供しています。
Queue.qsize()
キューの近似サイズを返します。ここで、qsize() > 0 は後続の get() がブロックしないことを保証しないこと、また qsize() < maxsize が put() がブロックしないことを保証しないことに注意してください。
Queue.empty()
キューが空の場合は True を返し、そうでなければ False を返します。empty() が True を返しても、後続の put() の呼び出しがブロックしないことは保証されません。同様に、empty() が False を返しても、後続の get() の呼び出しがブロックしないことは保証されません。
Queue.full()
キューが一杯の場合は True を返し、そうでなければ False を返します。full() が True を返しても、後続の get() の呼び出しがブロックしないことは保証されません。同様に、full() が False を返しても、後続の put() の呼び出しがブロックしないことは保証されません。
Queue.put(item, block=True, timeout=None)
item をキューに入れます。 もしオプション引数 block が真で timeout が None (デフォルト) の場合は、必要であればフリースロットが利用可能になるまでブロックします。 timeout が正の数の場合は、最大で timeout 秒間ブロックし、その時間内に空きスロットが利用可能にならなければ、例外 Full を送出します。 そうでない場合 (block が偽) は、空きスロットが直ちに利用できるならば、キューにアイテムを置きます。 できないならば、例外 Full を送出します (この場合 timeout は無視されます)。
Queue.put_nowait(item)
put(item, False) と等価です。
Queue.get(block=True, timeout=None)
キューからアイテムを取り除き、それを返します。 オプション引数 block が真で timeout が None (デフォルト) の場合は、必要であればアイテムが取り出せるようになるまでブロックします。 もし timeout が正の数の場合は、最大で timeout 秒間ブロックし、その時間内でアイテムが取り出せるようにならなければ、例外 Empty を送出します。 そうでない場合 (block が偽) は、直ちにアイテムが取り出せるならば、それを返します。 できないならば、例外 Empty を送出します (この場合 timeout は無視されます)。
Queue.get_nowait()
get(False) と等価です。
キューに入れられたタスクが全てコンシューマスレッドに処理されたかどうかを追跡するために 2つのメソッドが提供されます。
Queue.task_done()
過去にキューに入れられたタスクが完了した事を示します。キューのコンシューマスレッドに利用されます。タスクの取り出しに使われた各 get() の後に task_done() を呼び出すと、取り出したタスクに対する処理が完了した事をキューに教えます。
join() がブロックされていた場合、全itemが処理された (キューに put() された全てのitemに対して task_done() が呼び出されたことを意味します) 時に復帰します。
キューにある要素より多く呼び出された場合 ValueError が発生します。
Queue.join()
キューにあるすべてのアイテムが取り出されて処理されるまでブロックします。
キューにitemが追加される度に、未完了タスクカウントが増やされます。コンシューマスレッドが task_done() を呼び出して、itemを受け取ってそれに対する処理が完了した事を知らせる度に、未完了タスクカウントが減らされます。未完了タスクカウントが0になったときに、 join() のブロックが解除されます。
キューに入れたタスクが完了するのを待つ例:
import threading, queue
q = queue.Queue()
def worker():
    while True:
        item = q.get()
        print(f'Working on {item}')
        print(f'Finished {item}')
        q.task_done()
# turn-on the worker thread
threading.Thread(target=worker, daemon=True).start()
# send thirty task requests to the worker
for item in range(30):
    q.put(item)
print('All task requests sent\n', end='')
# block until all tasks are done
q.join()
print('All work completed')
SimpleQueue オブジェクト
SimpleQueue オブジェクトは以下のpublicメソッドを提供しています。
SimpleQueue.qsize()
キューの近似サイズを返します。ここで、qsize() > 0 であるからといって、後続の get() の呼び出しがブロックしないことが保証されないことに注意してください。
SimpleQueue.empty()
キューが空の場合は True を返し、そうでなければ False を返します。 empty() が False を返しても、後続の get() の呼び出しがブロックしないことは保証されません。
SimpleQueue.put(item, block=True, timeout=None)
SimpleQueue.put_nowait(item)
put(item) と等価です。:meth:`Queue.put_nowait`との互換性のためのメソッドです。
SimpleQueue.get(block=True, timeout=None)
キューからアイテムを取り除き、それを返します。 オプション引数 block が真で timeout が None (デフォルト) の場合は、必要であればアイテムが取り出せるようになるまでブロックします。 もし timeout が正の数の場合は、最大で timeout 秒間ブロックし、その時間内でアイテムが取り出せるようにならなければ、例外 Empty を送出します。 そうでない場合 (block が偽) は、直ちにアイテムが取り出せるならば、それを返します。 できないならば、例外 Empty を送出します (この場合 timeout は無視されます)。
SimpleQueue.get_nowait()
get(False) と等価です。
参考
multiprocessing.Queue クラス
(マルチスレッドではなく) マルチプロセスの文脈で使用されるキュークラス。
collections.deque is an alternative implementation of unbounded queues with fast atomic append() and popleft() operations that do not require locking and also support indexing.
contextvars --- コンテキスト変数
このモジュールは、コンテキストローカルな状態を管理し、保持し、アクセスするための API を提供します。 ContextVar クラスは コンテキスト変数 を宣言し、取り扱うために使われます。 非同期フレームワークで現時点のコンテキストを管理するのには、 copy_context() 関数と Context クラスを使うべきです。
状態を持っているコンテキストマネージャは threading.local() ではなくコンテキスト変数を使い、並行処理のコードから状態が意図せず他のコードへ漏れ出すのを避けるべきです。
より詳しくは PEP 567 を参照をしてください。
バージョン 3.7 で追加.
コンテキスト変数
class contextvars.ContextVar(name[, *, default])
このクラスは新しいコンテキスト変数を宣言するのに使われます。例えば、次の通りです:
var: ContextVar[int] = ContextVar('var', default=42)
必須のパラメータの name は内観やデバッグの目的で使われます。
オプションのキーワード専用引数 default は、現在のコンテキストにその変数の値が見付からなかったときに ContextVar.get() から返されます。
重要: コンテキスト変数は、モジュールのトップレベルで生成する必要があり、クロージャの中で作成すべきではありません。Context オブジェクトはコンテキスト変数への強参照を持っており、コンテキスト変数がガーベジコレクトされるのを防ぎます。
name
変数の名前。読み出し専用のプロパティです。
バージョン 3.7.1 で追加.
get([default])
現在のコンテキストのコンテキスト変数の値を返します。
現在のコンテキストのコンテキスト変数に値がなければ、メソッドは:
メソッドの default 引数に値が指定されていればその値を返します。さもなければ
コンテキスト変数が生成された時にデフォルト値が渡されていれば、その値を返します。さもなければ
LookupError を送出します。
set(value)
現在のコンテキストのコンテキスト変数に新しい値を設定する際に呼び出します。
value は必須の引数で、コンテキスト変数の新しい値を指定します。
Token オブジェクトを返します。このオブジェクトを ContextVar.reset() メソッドに渡すことで、以前の値に戻すことができます。
reset(token)
コンテキスト変数の値を、 token を生成した ContextVar.set() が呼び出される前の値にリセットします。
例えば:
var = ContextVar('var')
token = var.set('new value')
# code that uses 'var'; var.get() returns 'new value'.
var.reset(token)
# After the reset call the var has no value again, so
# var.get() would raise a LookupError.
class contextvars.Token
Token オブジェクトは、ContextVar.set() メソッドによって返されるオブジェクトです。このオブジェクトを ContextVar.reset() メソッドに渡すことで、対応する set を呼び出す前のコンテキスト変数の値に戻せます。
Token.var
読み出し専用のプロパティです。トークンを生成した ContextVar オブジェクトを指します。
Token.old_value
読み出し専用のプロパティです。このトークンを返した ContextVar.set() メソッドの呼び出し前に設定されていた値を返します。もし呼び出しの前に値が設定されていなければ Token.MISSING を返します。
Token.MISSING
Token.old_value で利用されるマーカーオブジェクトです。
マニュアルでのコンテキスト管理
contextvars.copy_context()
現在の Context オブジェクトのコピーを返します。
次のスニペットは、現在のコンテキストのコピーを取得し、コンテキストに設定されているすべての変数とその値を表示します:
ctx: Context = copy_context()
print(list(ctx.items()))
この関数の複雑性はO(1) です。つまり、少数のコンテキスト変数を持つコンテキストと多くの変数を持つコンテキストで同程度の速度で動作します。
class contextvars.Context
ContextVars とその値の対応付け。
Context() は、値を持たない空のコンテキストを生成します。現在のコンテキストのコピーを得るには、copy_context() 関数を利用します。
Context は、 collections.abc.Mapping インタフェースを実装します。
run(callable, *args, **kwargs)
callable(*args, **kwargs) を run メソッドが呼ばれたコンテキストオブジェクトの中で実行します。実行した結果を返すか、例外が発生した場合はその例外を伝播します。
callable が行ったコンテキスト変数へのいかなる変更も、コンテキストオブジェクトに格納されます:
var = ContextVar('var')
var.set('spam')
def main():
    # 'var' was set to 'spam' before
    # calling 'copy_context()' and 'ctx.run(main)', so:
    # var.get() == ctx[var] == 'spam'
    var.set('ham')
    # Now, after setting 'var' to 'ham':
    # var.get() == ctx[var] == 'ham'
ctx = copy_context()
# Any changes that the 'main' function makes to 'var'
# will be contained in 'ctx'.
ctx.run(main)
# The 'main()' function was run in the 'ctx' context,
# so changes to 'var' are contained in it:
# ctx[var] == 'ham'
# However, outside of 'ctx', 'var' is still set to 'spam':
# var.get() == 'spam'
2つ以上の OS スレッドから同一のコンテキストオブジェクトを呼び出すか、再帰的に呼び出したとき、メソッドは RuntimeError を送出します。
copy()
コンテキストオブジェクトの浅いコピーを返します。
var in context
context に var の値が設定されていた場合 True を返します; そうでない場合は False を返します。
context[var]
ContextVar var の値を返します。コンテキストオブジェクト内で変数が設定されていない場合は、KeyError を送出します。
get(var[, default])
var がコンテキストオブジェクトの中に値を持てば、その値を返します。さもなければ、default を返します。default を指定していなければ、None を返します。
iter(context)
コンテキストオブジェクトに格納されている変数群のイテレータを返します。
len(proxy)
コンテキストオブジェクトに格納されている変数の数を返します。
keys()
コンテキストオブジェクト中のすべての変数のリストを返します。
values()
コンテキストオブジェクト中のすべての変数の値のリストを返します。
items()
コンテキストオブジェクト中のすべての変数について、変数とその値からなる2要素のタプルのリストを返します。
asyncio サポート
コンテキスト変数は、追加の設定なしに asyncio をサポートします。例えば、次の単純なechoサーバーは、クライアントを扱う Task の中でリモートクライアントのアドレスが利用できるように、コンテキスト変数を利用します:
import asyncio
import contextvars
client_addr_var = contextvars.ContextVar('client_addr')
def render_goodbye():
    # The address of the currently handled client can be accessed
    # without passing it explicitly to this function.
    client_addr = client_addr_var.get()
    return f'Good bye, client @ {client_addr}\n'.encode()
async def handle_request(reader, writer):
    addr = writer.transport.get_extra_info('socket').getpeername()
    client_addr_var.set(addr)
    # In any code that we call is now possible to get
    # client's address by calling 'client_addr_var.get()'.
    while True:
        line = await reader.readline()
        print(line)
        if not line.strip():
            break
        writer.write(line)
    writer.write(render_goodbye())
    writer.close()
async def main():
    srv = await asyncio.start_server(
        handle_request, '127.0.0.1', 8081)
    async with srv:
        await srv.serve_forever()
asyncio.run(main())
# To test it you can use telnet:
#     telnet 127.0.0.1 8081
_thread --- 低水準の スレッド API
このモジュールはマルチスレッド (別名 軽量プロセス (light-weight processes)または タスク (tasks)) に用いられる低水準プリミティブを提供します --- グローバルデータ空間を共有するマルチスレッドを制御します。同期のための単純なロック (別名 mutexes またはバイナリセマフォ (binary semaphores))が提供されています。 threading モジュールは、このモジュール上で、より使い易く高級なスレッディングの API を提供します。
バージョン 3.7 で変更: このモジュールは以前はオプションでしたが、常に利用可能なモジュールとなりました。
This module defines the following constants and functions:
exception _thread.error
スレッド固有の例外です。
バージョン 3.3 で変更: 現在は組み込みの RuntimeError の別名です。
_thread.LockType
これはロックオブジェクトのタイプです。
_thread.start_new_thread(function, args[, kwargs])
バージョン 3.8 で変更: sys.unraisablehook() is now used to handle unhandled exceptions.
_thread.interrupt_main()
_thread.exit()
SystemExit を送出します。それが捕えられないときは、静かにスレッドを終了させます。
_thread.allocate_lock()
新しいロックオブジェクトを返します。ロックのメソッドはこの後に記述されます。ロックは初期状態としてアンロック状態です。
_thread.get_ident()
現在のスレッドの 'スレッドID' を返します。非ゼロの整数です。この値は直接の意味を持っていません; 例えばスレッド特有のデータの辞書に索引をつけるためのような、マジッククッキーとして意図されています。スレッドが終了し、他のスレッドが作られたとき、スレッド ID は再利用されるかもしれません。
_thread.get_native_id()
バージョン 3.8 で追加.
_thread.stack_size([size])
新しいスレッドを作るときのスレッドスタックサイズを返します。オプションの size 引数にはこれ以降に作成するスレッドのスタックサイズを指定し、0 (プラットフォームのデフォルト値または設定されたデフォルト値) か、 32,768 (32 KiB) 以上の正の整数でなければなりません。size が指定されない場合 0 が使われます。スレッドのスタックサイズの変更がサポートされていない場合、 RuntimeError を送出します。不正なスタックサイズが指定された場合、 ValueError を送出して、スタックサイズは変更されません。32 KiB は現在のインタープリタ自身のために十分であると保証された最小のスタックサイズです。いくつかのプラットフォームではスタックサイズに対して制限があることに注意してください。例えば最小のスタックサイズが 32 KiB より大きかったり、システムのメモリページサイズ の整数倍の必要があるなどです。この制限についてはプラットフォームのドキュメントを参照してください (一般的なページサイズは 4 KiB なので、プラットフォームに関する情報がない場合は 4096 の整数倍のスタックサイズを選ぶといいかもしれません)。
_thread.TIMEOUT_MAX
Lock.acquire() の timeout 引数に許される最大値です。これ以上の値を timeout に指定すると OverflowError を発生させます。
バージョン 3.2 で追加.
ロックオブジェクトは次のようなメソッドを持っています:
lock.acquire(waitflag=1, timeout=-1)
オプションの引数なしで使用すると、このメソッドは他のスレッドがロックしているかどうかにかかわらずロックを獲得します。ただし、他のスレッドがすでにロックしている場合には解除されるまで待ってからロックを獲得します (同時にロックを獲得できるスレッドはひとつだけであり、これこそがロックの存在理由です)。
整数の引数 waitflag を指定すると、その値によって動作が変わります。引数が 0 のときは、待たずにすぐ獲得できる場合にだけロックを獲得します。0 以外の値を与えると、先の例と同様、ロックの状態にかかわらず獲得をおこないます。
timeout 引数に正の float 値が指定された場合、返る前に待つ最大の時間を秒数で指定します。負の timeout 引数は無制限に待つことを指定します。waitflag が 0 の時は timeout を指定することはできません。
なお、ロックを獲得できた場合は True、できなかった場合は False を返します。
バージョン 3.2 で変更: 新しい timeout 引数。
バージョン 3.2 で変更: POSIX ではロックの取得がシグナルに割り込まれるようになりました。
lock.release()
ロックを解放します。そのロックは既に獲得されたものでなければなりませんが、しかし同じスレッドによって獲得されたものである必要はありません。
lock.locked()
ロックの状態を返します: 同じスレッドによって獲得されたものなら True 、違うのなら False を返します。
これらのメソッドに加えて、ロックオブジェクトは with 文を通じて以下の例のように使うこともできます。
import _thread
a_lock = _thread.allocate_lock()
with a_lock:
    print("a_lock is locked while this executes")
警告:
スレッドは割り込みと奇妙な相互作用をします: KeyboardInterrupt 例外は任意のスレッドによって受け取られます。 (signal モジュールが利用可能なとき、割り込みは常にメインスレッドへ行きます。)
sys.exit() を呼び出す、あるいは SystemExit 例外を送出することは、 _thread.exit() を呼び出すことと同じです。
ロックの acquire() メソッドに割り込むことはできません --- KeyboardInterrupt 例外は、ロックが獲得された後に発生します。
メインスレッドが終了したとき、他のスレッドが生き残るかどうかは、システムに依存します。多くのシステムでは、 try ... finally 節や、オブジェクトデストラクタを実行せずに終了されます。
メインスレッドが終了したとき、それの通常のクリーンアップは行なわれず、 (try ... finally 節が尊重されることは除きます)、標準 I/O ファイルはフラッシュされません。
hashlib --- セキュアハッシュおよびメッセージダイジェスト
ソースコード: Lib/hashlib.py
このモジュールは、セキュアハッシュやメッセージダイジェスト用のさまざまなアルゴリズムを実装したものです。FIPSのセキュアなハッシュアルゴリズムである SHA1、SHA224、SHA256、SHA384およびSHA512 (FIPS 180-2 で定義されているもの) だけでなくRSAのMD5アルゴリズム (Internet RFC 1321 で定義されています)も実装しています。「セキュアなハッシュ」と「メッセージダイジェスト」はどちらも同じ意味です。古くからあるアルゴリズムは「メッセージダイジェスト」と呼ばれていますが、最近は「セキュアハッシュ」という用語が用いられています。
注釈 adler32 や crc32 ハッシュ関数は zlib モジュールで提供されています。
警告 幾つかのアルゴリズムはハッシュの衝突に弱いことが知られています。最後の "参考" セクションを見てください。
ハッシュアルゴリズム
各 hash の名前が付いたコンストラクタがあります。いずれも同一で簡単なインターフェイスのあるハッシュオブジェクトを返します。例えば、SHA-256 ハッシュオブジェクトを作るには sha256() を使います。このオブジェクトには update() メソッドを用いて bytes-like オブジェクト (通常 bytes) を渡すことができます。digest() や hexdigest() メソッドを用いて、それまでに渡したデータを連結したものの digest をいつでも要求することができます。
注釈 マルチスレッドにおける良好なパフォーマンスを得るために、オブジェクトの生成時または更新時に与えるデータが 2047 バイトを超えている場合、Python GIL が解除されます。
注釈 文字列オブジェクトを update() に渡すのはサポートされていません。ハッシュはバイトには機能しますが、文字には機能しないからです。
バージョン 3.6 で追加: SHA3 (Keccak) ならびに SHAKE コンストラクタ sha3_224(), sha3_256(), sha3_384(), sha3_512(), shake_128(), shake_256()。
バージョン 3.6 で追加: blake2b() と blake2s() が追加されました。
バージョン 3.9 で変更: All hashlib constructors take a keyword-only argument usedforsecurity with default value True. A false value allows the use of insecure and blocked hashing algorithms in restricted environments. False indicates that the hashing algorithm is not used in a security context, e.g. as a non-cryptographic one-way compression function.
たとえば、b'Nobody inspects the spammish repetition' というバイト文字列のダイジェストを取得するには次のようにします:
>>>
>>> import hashlib
>>> m = hashlib.sha256()
>>> m.update(b"Nobody inspects")
>>> m.update(b" the spammish repetition")
>>> m.digest()
b'\x03\x1e\xdd}Ae\x15\x93\xc5\xfe\\\x00o\xa5u+7\xfd\xdf\xf7\xbcN\x84:\xa6\xaf\x0c\x95\x0fK\x94\x06'
>>> m.digest_size
32
>>> m.block_size
64
もっと簡潔に書くと、このようになります:
>>>
hashlib.sha224(b"Nobody inspects the spammish repetition").hexdigest()
'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'
hashlib.new(name, [data, ]*, usedforsecurity=True)
一般的なコンストラクタで、第一引数にアルゴリズム名を文字列 name で受け取ります。他にも、前述のハッシュアルゴリズムだけでなく OpenSSL ライブラリーが提供するような他のアルゴリズムにアクセスすることができます。名前のあるコンストラクタの方が new() よりもずっと速いので望ましいです。
new() にOpenSSLのアルゴリズムを指定する例です:
>>>
h = hashlib.new('ripemd160')
h.update(b"Nobody inspects the spammish repetition")
h.hexdigest()
'cc4a5ce1b3df48aec5d22d1f16b894a0b894eccc'
Hashlib は以下の定数属性を提供しています:
hashlib.algorithms_guaranteed
このモジュールによってすべてのプラットフォームでサポートされていることが保証されるハッシュアルゴリズムの名前を含む集合です。一部のアップストリームのベンダーが提供する奇妙な "FIPS準拠の" Pythonビルドではmd5のサポートを除外していますが、その場合であっても 'md5' がリストに含まれることに注意してください。
バージョン 3.2 で追加.
hashlib.algorithms_available
実行中の Python インタープリタで利用可能なハッシュアルゴリズム名の set です。これらの名前は new() に渡すことができます。algorithms_guaranteed は常にサブセットです。この set の中に同じアルゴリズムが違う名前で複数回現れることがあります (OpenSSL 由来)。
バージョン 3.2 で追加.
コンストラクタが返すハッシュオブジェクトには、次のような定数属性が用意されています:
hash.digest_size
生成されたハッシュのバイト数。
hash.block_size
内部で使われるハッシュアルゴリズムのブロックのバイト数。
ハッシュオブジェクトには次のような属性があります:
hash.name
このハッシュの正規名です。常に小文字で、new() の引数として渡してこのタイプの別のハッシュを生成することができます。
バージョン 3.4 で変更: name 属性は CPython には最初からありましたが、Python 3.4 までは正式に明記されていませんでした。そのため、プラットフォームによっては存在しないかもしれません。
ハッシュオブジェクトには次のようなメソッドがあります:
hash.update(data)
hash オブジェクトを bytes-like object で更新します。このメソッドの呼出しの繰り返しは、それらの引数を全て結合した引数で単一の呼び出しをした際と同じになります。すなわち m.update(a); m.update(b) は m.update(a + b) と等価です。
バージョン 3.1 で変更: ハッシュアルゴリズムが OpenSSL によって提供されていて、データが 2047 バイトを超えている場合には、ハッシュの更新が実行中でも他のスレッドが実行できるように、Python GIL が解放されます。
hash.digest()
これまで update() メソッドに渡されたデータのダイジェスト値を返します。これは digest_size と同じ長さの、0 から 255 の範囲全てを含み得るバイトの列です。
hash.hexdigest()
digest() と似ていますが、倍の長さの、16進形式文字列を返します。これは、電子メールなどの非バイナリ環境で値を交換する場合に便利です。
hash.copy()
ハッシュオブジェクトのコピー ("クローン") を返します。これは、最初の部分文字列が共通なデータのダイジェストを効率的に計算するために使用します。
SHAKE 可変長ダイジェスト
shake.digest(length)
これまで update() メソッドに渡されたデータのダイジェスト値を返します。これは length と同じ長さの、0 から 255 の範囲全てを含み得るバイトの列です。
shake.hexdigest(length)
digest() と似ていますが、倍の長さの、16進形式文字列を返します。これは、電子メールなどの非バイナリ環境で値を交換する場合に便利です。
鍵導出
鍵の導出 (derivation) と引き伸ばし (stretching) のアルゴリズムはセキュアなパスワードのハッシュ化のために設計されました。 sha1(password) のような甘いアルゴリズムは、ブルートフォース攻撃に抵抗できません。良いパスワードハッシュ化は調節可能で、遅くて、 salt を含まなければなりません。
hashlib.pbkdf2_hmac(hash_name, password, salt, iterations, dklen=None)
この関数は PKCS#5 のパスワードに基づいた鍵導出関数 2 を提供しています。疑似乱数関数として HMAC を使用しています。
文字列 hash_name は、HMAC のハッシュダイジェストアルゴリズムの望ましい名前で、例えば 'sha1' や 'sha256' です。 password と salt はバイト列のバッファとして解釈されます。アプリケーションとライブラリは、 password を適切な長さ (例えば 1024) に制限すべきです。 salt は os.urandom() のような適切なソースからの、およそ 16 バイトかそれ以上のバイト列にするべきです。
iterations 数はハッシュアルゴリズムと計算機の能力に基づいて決めるべきです。2013 年現在の場合、 SHA-256 に対して最低でも 100,000 反復が推奨されています。
dklen は、導出された鍵の長さです。 dklen が None の場合、ハッシュアルゴリズム hash_name のダイジェストサイズが使われます。例えば SHA-512 では 64 です。
>>>
import hashlib
dk = hashlib.pbkdf2_hmac('sha256', b'password', b'salt', 100000)
dk.hex()
'0394a2ede332c9a13eb82e9b24631604c31df978b4e2f0fbd2c549944f9d79a5'
バージョン 3.4 で追加.
注釈 pbkdf2_hmac の高速な実装は OpenSSL 使用版で利用可能です。Python 実装は hmac のインラインバージョンを使います。それはおよそ 3 倍遅く、GIL を解放しません。
hashlib.scrypt(password, *, salt, n, r, p, maxmem=0, dklen=64)
この関数は、 RFC 7914 で定義されるscrypt のパスワードに基づいた鍵導出関数を提供します。
password と salt は bytes-like objects でなければなりません。アプリケーションとライブラリは、 password を適切な長さ (例えば 1024) に制限すべきです。 salt は os.urandom() のような適切なソースからの、およそ 16 バイトかそれ以上のバイト列にするべきです。
n is the CPU/Memory cost factor, r the block size, p parallelization factor and maxmem limits memory (OpenSSL 1.1.0 defaults to 32 MiB). dklen is the length of the derived key.
バージョン 3.6 で追加.
BLAKE2
BLAKE2 is a cryptographic hash function defined in RFC 7693 that comes in two flavors:
BLAKE2b, optimized for 64-bit platforms and produces digests of any size between 1 and 64 bytes,
このモジュールのハッシュオブジェクトは標準ライブラリーの hashlib オブジェクトの API に従います。
ハッシュオブジェクトの作成
新しいハッシュオブジェクトは、コンストラクタ関数を呼び出すことで生成されます:
hashlib.blake2b(data=b'', *, digest_size=64, key=b'', salt=b'', person=b'', fanout=1, depth=1, leaf_size=0, node_offset=0, node_depth=0, inner_size=0, last_node=False, usedforsecurity=True)
hashlib.blake2s(data=b'', *, digest_size=32, key=b'', salt=b'', person=b'', fanout=1, depth=1, leaf_size=0, node_offset=0, node_depth=0, inner_size=0, last_node=False, usedforsecurity=True)
These functions return the corresponding hash objects for calculating BLAKE2b or BLAKE2s. They optionally take these general parameters:
data: initial chunk of data to hash, which must be bytes-like object. It can be passed only as positional argument.
digest_size: 出力するダイジェストのバイト数。
key: key for keyed hashing (up to 64 bytes for BLAKE2b, up to 32 bytes for BLAKE2s).
salt: salt for randomized hashing (up to 16 bytes for BLAKE2b, up to 8 bytes for BLAKE2s).
person: personalization string (up to 16 bytes for BLAKE2b, up to 8 bytes for BLAKE2s).
下の表は一般的なパラメータの上限 (バイト単位) です:
Hash
digest_size
len(key)
len(salt)
len(person)
BLAKE2b
64
64
16
16
BLAKE2s
32
32
8
8
注釈 BLAKE2 specification defines constant lengths for salt and personalization parameters, however, for convenience, this implementation accepts byte strings of any size up to the specified length. If the length of the parameter is less than specified, it is padded with zeros, thus, for example, b'salt' and b'salt\x00' is the same value. (This is not the case for key.)
これらのサイズは以下に述べるモジュール constants で利用できます。
コンストラクタ関数は以下のツリーハッシングパラメタを受け付けます:
fanout: fanout (0 to 255, 0 if unlimited, 1 in sequential mode).
depth: ツリーの深さの最大値（1から255までの値で、無制限であれば255、シーケンスモードでは1）。
leaf_size: maximal byte length of leaf (0 to 2**32-1, 0 if unlimited or in sequential mode).
node_offset: node offset (0 to 2**64-1 for BLAKE2b, 0 to 2**48-1 for BLAKE2s, 0 for the first, leftmost, leaf, or in sequential mode).
node_depth: node depth (0 to 255, 0 for leaves, or in sequential mode).
inner_size: inner digest size (0 to 64 for BLAKE2b, 0 to 32 for BLAKE2s, 0 in sequential mode).
last_node: boolean indicating whether the processed node is the last one (False for sequential mode).
定数
blake2b.SALT_SIZE
blake2s.SALT_SIZE
ソルト長（コンストラクタが受け付けれる最大長）
blake2b.PERSON_SIZE
blake2s.PERSON_SIZE
blake2b.MAX_KEY_SIZE
blake2s.MAX_KEY_SIZE
最大キー長
blake2b.MAX_DIGEST_SIZE
blake2s.MAX_DIGEST_SIZE
ハッシュ関数が出力しうるダイジェストの最大長
使用例
簡単なハッシュ化
>>>
from hashlib import blake2b
h = blake2b()
h.update(b'Hello world')
h.hexdigest()
'6ff843ba685842aa82031d3f53c48b66326df7639a63d128974c5c14f31a0f33343a8c65551134ed1ae0f2b0dd2bb495dc81039e3eeb0aa1bb0388bbeac29183'
As a shortcut, you can pass the first chunk of data to update directly to the constructor as the positional argument:
>>>
from hashlib import blake2b
blake2b(b'Hello world').hexdigest()
'6ff843ba685842aa82031d3f53c48b66326df7639a63d128974c5c14f31a0f33343a8c65551134ed1ae0f2b0dd2bb495dc81039e3eeb0aa1bb0388bbeac29183'
You can call hash.update() as many times as you need to iteratively update the hash:
>>>
from hashlib import blake2b
items = [b'Hello', b' ', b'world']
h = blake2b()
for item in items:
    h.update(item)
h.hexdigest()
'6ff843ba685842aa82031d3f53c48b66326df7639a63d128974c5c14f31a0f33343a8c65551134ed1ae0f2b0dd2bb495dc81039e3eeb0aa1bb0388bbeac29183'
Using different digest sizes
BLAKE2 はダイジェストの長さを、BLAKE2bでは64バイトまで、BLAKE2sでは32バイトまでのダイジェスト長を指定できます。例えばSHA-1を、出力を同じ長さのままでBLAKE2bで置き換えるには、BLAKE2bに20バイトのダイジェストを生成するように指示できます:
>>>
from hashlib import blake2b
h = blake2b(digest_size=20)
h.update(b'Replacing SHA1 with the more secure function')
h.hexdigest()
'd24f26cf8de66472d58d4e1b1774b4c9158b1f4c'
h.digest_size
20
len(h.digest())
20
Hash objects with different digest sizes have completely different outputs (shorter hashes are not prefixes of longer hashes); BLAKE2b and BLAKE2s produce different outputs even if the output length is the same:
>>>
from hashlib import blake2b, blake2s
blake2b(digest_size=10).hexdigest()
'6fa1d8fcfd719046d762'
blake2b(digest_size=11).hexdigest()
'eb6ec15daf9546254f0809'
blake2s(digest_size=10).hexdigest()
'1bf21a98c78a1c376ae9'
blake2s(digest_size=11).hexdigest()
'567004bf96e4a25773ebf4'
Keyed hashing
This example shows how to get a (hex-encoded) 128-bit authentication code for message b'message data' with key b'pseudorandom key':
>>>
>>> from hashlib import blake2b
>>> h = blake2b(key=b'pseudorandom key', digest_size=16)
>>> h.update(b'message data')
>>> h.hexdigest()
'3d363ff7401e02026f4a4687d4863ced'
As a practical example, a web application can symmetrically sign cookies sent to users and later verify them to make sure they weren't tampered with:
>>>
>>> from hashlib import blake2b
>>> from hmac import compare_digest
>>>
>>> SECRET_KEY = b'pseudorandomly generated server secret key'
>>> AUTH_SIZE = 16
>>>
>>> def sign(cookie):
...     h = blake2b(digest_size=AUTH_SIZE, key=SECRET_KEY)
...     h.update(cookie)
...     return h.hexdigest().encode('utf-8')
>>>
>>> def verify(cookie, sig):
...     good_sig = sign(cookie)
...     return compare_digest(good_sig, sig)
>>>
>>> cookie = b'user-alice'
>>> sig = sign(cookie)
>>> print("{0},{1}".format(cookie.decode('utf-8'), sig))
user-alice,b'43b3c982cf697e0c5ab22172d1ca7421'
>>> verify(cookie, sig)
True
>>> verify(b'user-bob', sig)
False
>>> verify(cookie, b'0102030405060708090a0b0c0d0e0f00')
False
Even though there's a native keyed hashing mode, BLAKE2 can, of course, be used in HMAC construction with hmac module:
>>>
>>> import hmac, hashlib
>>> m = hmac.new(b'secret key', digestmod=hashlib.blake2s)
>>> m.update(b'message')
>>> m.hexdigest()
'e3c8102868d28b5ff85fc35dda07329970d1a01e273c37481326fe0c861c8142'
Randomized hashing
(NIST SP-800-106 "Randomized Hashing for Digital Signatures")
警告 Salted hashing (or just hashing) with BLAKE2 or any other general-purpose cryptographic hash function, such as SHA-256, is not suitable for hashing passwords. See BLAKE2 FAQ for more information.
>>>
import os
from hashlib import blake2b
msg = b'some message'
# Calculate the first hash with a random salt.
salt1 = os.urandom(blake2b.SALT_SIZE)
h1 = blake2b(salt=salt1)
h1.update(msg)
# Calculate the second hash with a different random salt.
salt2 = os.urandom(blake2b.SALT_SIZE)
h2 = blake2b(salt=salt2)
h2.update(msg)
# The digests are different.
h1.digest() != h2.digest()
True
Personalization
Sometimes it is useful to force hash function to produce different digests for the same input for different purposes. Quoting the authors of the Skein hash function:
(The Skein Hash Function Family, p. 21)
BLAKE2は person 引数にバイト列を渡すことでパーソナライズできます:
>>>
>>> from hashlib import blake2b
>>> FILES_HASH_PERSON = b'MyApp Files Hash'
>>> BLOCK_HASH_PERSON = b'MyApp Block Hash'
>>> h = blake2b(digest_size=32, person=FILES_HASH_PERSON)
>>> h.update(b'the same content')
>>> h.hexdigest()
'20d9cd024d4fb086aae819a1432dd2466de12947831b75c5a30cf2676095d3b4'
>>> h = blake2b(digest_size=32, person=BLOCK_HASH_PERSON)
>>> h.update(b'the same content')
>>> h.hexdigest()
'cf68fb5761b9c44e7878bfb2c4c9aea52264a80b75005e65619778de59f383a3'
>>>
from hashlib import blake2s
from base64 import b64decode, b64encode
orig_key = b64decode(b'Rm5EPJai72qcK3RGBpW3vPNfZy5OZothY+kHY6h21KM=')
enc_key = blake2s(key=orig_key, person=b'kEncrypt').digest()
mac_key = blake2s(key=orig_key, person=b'kMAC').digest()
print(b64encode(enc_key).decode('utf-8'))
rbPb15S/Z9t+agffno5wuhB77VbRi6F9Iv2qIxU7WHw=
print(b64encode(mac_key).decode('utf-8'))
G9GtHFE1YluXY1zWPlYk1e/nWfu0WSEb0KRcjhDeP/o=
ツリーモード
これが二つの葉ノードからなる最小の木をハッシュする例です:
  10
 /  \
00  01
次の例では、64バイトの内部桁が使われ、32バイトの最終的なダイジェストを返しています:
>>>
>>> from hashlib import blake2b
>>>
>>> FANOUT = 2
>>> DEPTH = 2
>>> LEAF_SIZE = 4096
>>> INNER_SIZE = 64
>>>
>>> buf = bytearray(6000)
>>>
>>> # Left leaf
... h00 = blake2b(buf[0:LEAF_SIZE], fanout=FANOUT, depth=DEPTH,
...               leaf_size=LEAF_SIZE, inner_size=INNER_SIZE,
...               node_offset=0, node_depth=0, last_node=False)
>>> # Right leaf
... h01 = blake2b(buf[LEAF_SIZE:], fanout=FANOUT, depth=DEPTH,
...               leaf_size=LEAF_SIZE, inner_size=INNER_SIZE,
...               node_offset=1, node_depth=0, last_node=True)
>>> # Root node
... h10 = blake2b(digest_size=32, fanout=FANOUT, depth=DEPTH,
...               leaf_size=LEAF_SIZE, inner_size=INNER_SIZE,
...               node_offset=0, node_depth=1, last_node=True)
>>> h10.update(h00.digest())
>>> h10.update(h01.digest())
>>> h10.hexdigest()
'3ad2a9b37c6070e374c7a8c508fe20ca86b6ed54e286e93a0318e95e881db5aa'
クレジット:
BLAKE2 は*Jean-Philippe Aumasson*、 Luca Henzen、 Willi Meier そして Raphael C.-W. Phan によって作成された SHA-3 の最終候補である BLAKE を元に、Jean-Philippe Aumasson、 Samuel Neves、 Zooko Wilcox-O'Hearn, そして Christian Winnerlein によって設計されました。
それは、 Daniel J. Bernstein によって設計されたChaCha 暗号由来のアルゴリズムを用いています。
標準ライブラリは pyblake2 モジュールを基礎として実装されています。 このモジュールは Dmitry Chestnykh によって、Samuel Neves が作成した C実装を元に書かれました。 このドキュメントは、pyblake2 からコピーされ、Dmitry Chestnykh によって書かれました。
Christian Heimes によって、一部のCコードがPython向けに書き直されました。
以下の public domain dedicationが、Cのハッシュ関数実装と、拡張コードと、このドキュメントに適用されます:
The following people have helped with development or contributed their changes to the project and the public domain according to the Creative Commons Public Domain Dedication 1.0 Universal:
Alexandr Sokolovskiy
参考
hmac モジュール
ハッシュを用いてメッセージ認証コードを生成するモジュールです。
base64 モジュール
バイナリハッシュを非バイナリ環境用にエンコードするもうひとつの方法です。
https://blake2.net
BLAKE2 の公式ウェブサイト
https://csrc.nist.gov/csrc/media/publications/fips/180/2/archive/2002-08-01/documents/fips180-2.pdf
FIPS 180-2 のセキュアハッシュアルゴリズムについての説明。
https://en.wikipedia.org/wiki/Cryptographic_hash_function#Cryptographic_hash_algorithms (日本語版: https://暗号学的ハッシュ関数)
どのアルゴリズムにどんな既知の問題があって、それが実際に利用する際にどう影響するかについての Wikipedia の記事。
https://www.ietf.org/rfc/rfc2898.txt
PKCS #5: Password-Based Cryptography Specification Version 2.0
hmac --- メッセージ認証のための鍵付きハッシュ化
ソースコード: Lib/hmac.py
このモジュールでは RFC 2104 で記述されている HMAC アルゴリズムを実装しています。
hmac.new(key, msg=None, digestmod='')
バージョン 3.4 で変更: 引数 key に bytes または bytearray オブジェクトを渡せるようになりました。引数 msg に hashlib がサポートする全てのタイプを渡せるようになりました。引数 digestmod にハッシュアルゴリズム名を渡せるようになりました。
hmac.digest(key, msg, digest)
与えられたsecret key と digest の msg のダイジェストを返します。この関数は HMAC(key, msg, digest).digest() に似ていますが、最適化されたCやインラインの実装を使用しており、メモリに収まるメッセージに対しては高速です。パラメータ key 、 msg 、および digest は、 new() と同じ意味を持ちます。
CPython実装の詳細、最適化されたC実装は、OpenSSLがサポートするダイジェストアルゴリズムの文字列と名前が digest の場合にのみ使用されます。
バージョン 3.7 で追加.
HMAC オブジェクトは以下のメソッドを持っています:
HMAC.update(msg)
hmac オブジェクトを msg で更新します。このメソッドの呼出の繰り返しは、それらの引数を全て結合した引数で単一の呼び出しをした際と同じになります。すなわち m.update(a); m.update(b) は m.update(a + b) と等価です。
バージョン 3.4 で変更: 引数 msg は hashlib がサポートしているあらゆる型のいずれかです。
HMAC.digest()
これまで update() メソッドに渡されたバイト列のダイジェスト値を返します。これはコンストラクタに与えられた digest_size と同じ長さのバイト列で、 NUL バイトを含む非 ASCII 文字が含まれることがあります。
警告 digest() の出力結果と外部から供給されたダイジェストを検証ルーチン内で比較しようとするのであれば、タイミング攻撃への脆弱性を減らすために、 == 演算子ではなく compare_digest() を使うことをお奨めします。
HMAC.hexdigest()
digest() と似ていますが、返される文字列は倍の長さとなり、16進形式となります。これは、電子メールなどの非バイナリ環境で値を交換する場合に便利です。
警告 hexdigest() の出力結果と外部から供給されたダイジェストを検証ルーチン内で比較しようとするのであれば、タイミング攻撃への脆弱性を減らすために、 == 演算子ではなく compare_digest() を使うことをお奨めします。
HMAC.copy()
hmac オブジェクトのコピー ("クローン") を返します。このコピーは最初の部分文字列が共通になっている文字列のダイジェスト値を効率よく計算するために使うことができます。
ハッシュオブジェクトには次のような属性があります:
HMAC.digest_size
生成された HMAC ダイジェストのバイト数。
HMAC.block_size
内部で使われるハッシュアルゴリズムのブロックのバイト数。
バージョン 3.4 で追加.
HMAC.name
このHMAC の正規名で、例えば hmac-md5 のように常に小文字です。
バージョン 3.4 で追加.
バージョン 3.9 で非推奨: The undocumented attributes HMAC.digest_cons, HMAC.inner, and HMAC.outer are internal implementation details and will be removed in Python 3.10.
このモジュールは以下のヘルパ関数も提供しています:
hmac.compare_digest(a, b)
a == b を返します。この関数は、内容ベースの短絡的な振る舞いを避けることによってタイミング分析を防ぐよう設計されたアプローチを用い、暗号化に用いるのに相応しいものとしています。 a と b は両方が同じ型でなければなりません: (例えば HMAC.hexdigest() が返したような ASCII のみの) str または bytes-like object のどちらか一方。
注釈 a と b が異なる長さであったりエラーが発生した場合には、タイミング攻撃で理論上 a と b の型と長さについての情報が暴露されますが、その値は明らかになりません。
バージョン 3.3 で追加.
バージョン 3.9 で変更: The function uses OpenSSL's CRYPTO_memcmp() internally when available.
参考
hashlib モジュール
セキュアハッシュ関数を提供する Python モジュールです。
secrets --- 機密を扱うために安全な乱数を生成する
バージョン 3.6 で追加.
ソースコード: Lib/secrets.py
secrets モジュールを使って、パスワードやアカウント認証、セキュリティトークンなどの機密を扱うのに適した、暗号学的に強い乱数を生成することができます。
参考 PEP 506
乱数
secrets モジュールは OS が提供する最も安全な乱雑性のソースへのアクセスを提供します。
class secrets.SystemRandom
OS が提供する最も高品質なソースを用いて乱数を生成するためのクラスです。更に詳しいことについては random.SystemRandom を参照してください。
secrets.choice(sequence)
空でないシーケンスから要素をランダムに選択して返します。
secrets.randbelow(n)
[0, n) のランダムな整数を返します。
secrets.randbits(k)
ランダムな k ビットの整数を返します。
トークンの生成
secrets モジュールはパスワードのリセットや想像しにくい URL などの用途に適した、安全なトークンを生成するための関数を提供します。
secrets.token_bytes([nbytes=None])
nbytes バイトを含むバイト文字列を返します。nbytes が None の場合や与えられなかった場合は妥当なデフォルト値が使われます。
>>> token_bytes(16)  
b'\xebr\x17D*t\xae\xd4\xe3S\xb6\xe2\xebP1\x8b'
secrets.token_hex([nbytes=None])
十六進数のランダムなテキスト文字列を返します。文字列は nbytes のランダムなバイトを持ち、各バイトは二つの十六進数に変換されます。nbytes が None の場合や与えられなかった場合は妥当なデフォルト値が使われます。
>>> token_hex(16)  
'f9bf78b9a18ce6d46a0cd2b0b86df9da'
secrets.token_urlsafe([nbytes=None])
nbytes のランダムなバイトを持つ URL 安全なテキスト文字列を返します。テキストは Base64 でエンコードされていて、平均的に各バイトは約 1.3 文字になります。 nbytes が None の場合や与えられなかった場合は妥当なデフォルト値が使われます。
>>> token_urlsafe(16)  
'Drmhze6EPcv0fN_81Bj-nA'
トークンは何バイト使うべきか？
総当たり攻撃 に耐えるには、トークンは十分にランダムでなければなりません。残念なことに、コンピュータの性能が向上し、より短時間により多くの推測ができるようになるにつれ、十分とされるランダムさというのは必然的に増えます。2015 年の時点で、secrets モジュールに想定される通常の用途では、32 バイト (256 ビット) のランダムさは十分と考えられています。
独自の長さのトークンを扱いたい場合、様々な token_* 関数に int 引数で渡すことで、トークンに使用するランダムさを明示的に指定することができます。引数はランダムさのバイト数として使用されます。
それ以外の場合、すなわち引数がない場合や None の場合、token_* 関数は妥当なデフォルト値を代わりに使います。
注釈 デフォルトはメンテナンスリリースの間を含め、いつでも変更される可能性があります。
その他の関数
secrets.compare_digest(a, b)
文字列 a と b が等しければ True を、そうでなければ False を返します。比較は タイミング攻撃 のリスクを減らす方法で行われます。詳細については hmac.compare_digest() を参照してください。
レシピとベストプラクティス
この節では secrets を使用してセキュリティの基礎的なレベルを扱う際のレシピとベストプラクティスを説明します。
8文字のアルファベットと数字を含むパスワードを生成するには:
import string
import secrets
alphabet = string.ascii_letters + string.digits
password = ''.join(secrets.choice(alphabet) for i in range(8))
注釈 アプリケーションは、平文であろうと暗号化されていようと、復元可能な形式でパスワードを保存 してはいけません。パスワードは暗号学的に強い一方向 (非可逆) ハッシュ関数を用いてソルトしハッシュしなければなりません。
アルファべットと数字からなり、小文字を少なくとも1つと数字を少なくとも3つ含む、10文字のパスワードを生成するには:
import string
import secrets
alphabet = string.ascii_letters + string.digits
while True:
    password = ''.join(secrets.choice(alphabet) for i in range(10))
    if (any(c.islower() for c in password)
            and any(c.isupper() for c in password)
            and sum(c.isdigit() for c in password) >= 3):
        break
XKCD スタイルのパスフレーズ を生成するには:
import secrets
# On standard Linux systems, use a convenient dictionary file.
# Other platforms may need to provide their own word-list.
with open('/usr/share/dict/words') as f:
    words = [word.strip() for word in f]
    password = ' '.join(secrets.choice(words) for i in range(4))
パスワードの復元用途に適したセキュリティトークンを含む、推測しにくい一時 URL を生成するには:
import secrets
url = 'https://mydomain.com/reset=' + secrets.token_urlsafe()
pickle --- Python オブジェクトの直列化
ソースコード: Lib/pickle.py
pickle モジュールは Python オブジェクトの直列化および直列化されたオブジェクトの復元のためのバイナリプロトコルを実装しています。"Pickle 化" は Python オブジェクト階層をバイトストリームに変換する処理、"非 pickle 化" は (バイナリファイル または バイトライクオブジェクト から) バイトストリームをオブジェクト階層に復元する処理を意味します。pickle 化 (および非 pickle 化) は "直列化 (serialization)"、"整列化 (marshalling)"、あるいは 1 "平坦化 (flattening)" とも呼ばれますが、混乱を避けるため、ここでは "Pickle 化"、"非 pickle 化" で統一します。
警告 The pickle module is not secure. Only unpickle data you trust.
他の Python モジュールとの関係
marshal との比較
Python には marshal と呼ばれるより原始的な直列化モジュールがありますが、一般的に Python オブジェクトを直列化する方法としては pickle を選ぶべきです。 marshal は基本的に .pyc ファイルをサポートするために存在しています。
pickle モジュールはいくつかの点で marshal と明確に異なります:
pickle モジュールでは、同じオブジェクトが再度直列化されることのないよう、すでに直列化されたオブジェクトについて追跡情報を保持します。 marshal はこれを行いません。
この機能は再帰的オブジェクトと共有オブジェクトの両方に重要な関わりをもっています。再帰的オブジェクトとは自分自身に対する参照を持っているオブジェクトです。再帰的オブジェクトは marshal で扱うことができず、実際、再帰的オブジェクトを marshal 化しようとすると Python インタプリタをクラッシュさせてしまいます。共有オブジェクトは、直列化しようとするオブジェクト階層の異なる複数の場所で同じオブジェクトに対する参照が存在する場合に生じます。共有オブジェクトを共有のままにしておくことは、変更可能なオブジェクトの場合には非常に重要です。
marshal はユーザ定義クラスやそのインスタンスを直列化するために使うことができません。 pickle はクラスインスタンスを透過的に保存したり復元したりすることができますが、クラス定義をインポートすることが可能で、かつオブジェクトが保存された際と同じモジュールで定義されていなければなりません。
json との比較
pickle プロトコルと JSON (JavaScript Object Notation) との基本的な違いは以下のとおりです:
JSON はテキストの直列化フォーマット (大抵の場合 utf-8 にエンコードされますが、その出力は Unicode 文字列です) で、pickle はバイナリの直列化フォーマットです;
JSON は人間が読める形式ですが、pickle はそうではありません;
JSON は相互運用可能で Python 以外でも広く使用されていますが、pickle は Python 固有です;
JSON, by default, can only represent a subset of the Python built-in types, and no custom classes; pickle can represent an extremely large number of Python types (many of them automatically, by clever usage of Python's introspection facilities; complex cases can be tackled by implementing specific object APIs);
参考 json モジュール: JSON への直列化および復元を行うための標準ライブラリモジュール。
データストリームの形式
pickle によって使用されるデータフォーマットは Python 固有です。これは、JSON や XDR のような外部標準によって (例えばポインター共有を表わすことができないといったような) 制限を受けることがないという利点があります; ただし、これは非 Python プログラムが pickle された Python オブジェクトを再構成することができないということも意味します。
デフォルトでは、pickle データフォーマットは比較的コンパクトなバイナリ表現を使用します。サイズの抑制目的の最適化が必要なら、pickle されたデータを効率的に 圧縮する ことができます。
pickletools モジュールには pickle によって生成されたデータストリームを解析するためのツールが含まれます。pickletools のソースコードには、pickle プロトコルで使用される命令コードに関する詳細なコメントがあります。
プロトコルバージョン 0 はオリジナルの「人間に判読可能な」プロトコルで、Python の初期のバージョンとの後方互換性を持ちます。
プロトコルバージョン 1 は旧形式のバイナリフォーマットで、これも Python の初期バージョンと互換性があります。
プロトコルバージョン 2 は Python 2.3 で導入されました。このバージョンでは 新方式のクラス のより効率的な pickle 化を提供しました。プロトコル 2 による改良に関する情報は PEP 307 を参照してください。
注釈 直列化は永続性より原始的な概念です。 pickle はファイルオブジェクトの読み書きを行いますが、永続オブジェクトの命名に関する問題にも、(さらに困難な) 永続オブジェクトへの並列アクセスに関する問題にも対応しません。pickle モジュールは複雑なオブジェクトをバイトストリームに変換し、バイトストリームから同じ内部構造のオブジェクトに復元することができます。これらのバイトストリームはファイルに出力されることが多いでしょうが、ネットワークを介して送信したり、データベースに格納することもありえます。shelve モジュールは、オブジェクトを DBM 方式のデータベースファイル上で pickle 化および非 pickle 化するシンプルなインターフェースを提供します。
モジュールインタフェース
オブジェクト階層を直列化するには、dumps() 関数を呼ぶだけです。同様に、データストリームを復元するには、loads() 関数を呼びます。しかし、直列化および復元に対してより多くのコントロールを行いたい場合、それぞれ Pickler または Unpickler オブジェクトを作成することができます。
pickle モジュールは以下の定数を提供しています:
pickle.HIGHEST_PROTOCOL
利用可能なうち最も高い プロトコルバージョン (整数)。この値は protocol 値として関数 dump() および dumps() と、Pickler コンストラクターに渡すことができます。
pickle.DEFAULT_PROTOCOL
バージョン 3.0 で変更: The default protocol is 3.
バージョン 3.8 で変更: The default protocol is 4.
この pickle 化の手続きを便利にするために、 pickle モジュールでは以下の関数を提供しています:
pickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)
バージョン 3.8 で変更: The buffer_callback argument was added.
pickle.dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)
バージョン 3.8 で変更: The buffer_callback argument was added.
pickle.load(file, *, fix_imports=True, encoding="ASCII", errors="strict", buffers=None)
バージョン 3.8 で変更: The buffers argument was added.
pickle.loads(data, /, *, fix_imports=True, encoding="ASCII", errors="strict", buffers=None)
バージョン 3.8 で変更: The buffers argument was added.
pickle モジュールでは 3 つの例外を定義しています:
exception pickle.PickleError
他の pickle 化例外の共通基底クラス。Exception を継承しています。
exception pickle.PicklingError
Pickler が pickle 化不可能なオブジェクトに遭遇したときに送出されるエラー。PickleError を継承しています。
どんな種類のオブジェクトが pickle 化できるのか確認するには pickle 化、非 pickle 化できるもの を参照してください。
exception pickle.UnpicklingError
データ破損やセキュリティ違反のような、オブジェクトを非 pickle 化するのに問題がある場合に送出されるエラー。PickleError を継承します。
非 picke 化の最中に他の例外が送出されることもあるので注意してください。これには AttributeError, EOFError, ImportError, IndexError が含まれます (ただし必ずしもこれらに限定されません)。
The pickle module exports three classes, Pickler, Unpickler and PickleBuffer:
class pickle.Pickler(file, protocol=None, *, fix_imports=True, buffer_callback=None)
pickle 化されたオブジェクトのデータストリームを書き込むためのバイナリファイルを引数にとります。
任意の引数 protocol は、整数で、pickle 化で使用するプロトコルを指定します; サポートされているプロトコルは 0 から HIGHEST_PROTOCOL までになります。指定されない場合、DEFAULT_PROTOCOL が使用されます。負数が与えられた場合、HIGHEST_PROTOCOL が使用されます。
引数 file は、1 バイトの引数一つを受け付ける write() メソッドを持たなければなりません。すなわち、file には、バイナリの書き込み用にオープンされたファイルオブジェクト、io.BytesIO オブジェクト、このインタフェースに適合するその他のカスタムオブジェクトをとることができます。
fix_imports が真であり、かつ、protocol が 3 未満の場合、pickle は新しい Python 3 の名前と Python 2 で使用されていた古いモジュール名との対応付けを試みるので、pickle データストリームは Python 2 でも読み込み可能です。
バージョン 3.8 で変更: The buffer_callback argument was added.
dump(obj)
persistent_id(obj)
デフォルトでは何もしません。このメソッドはサブクラスがオーバーライドできるように存在します。
persistent_id() が None を返す場合、通常通り obj が pickle 化されます。それ以外の値を返した場合、Pickler がその値を obj のために永続的な ID として出力するようになります。この永続的な ID の意味は Unpickler.persistent_load() によって定義されています。persistent_id() によって返された値自身は永続的な ID を持つことができないことに注意してください。
詳細および使用例については 外部オブジェクトの永続化 を参照してください。
dispatch_table
pickler オブジェクトのディスパッチテーブルは copyreg.pickle() を使用して宣言できる種類の reduction functions のレジストリです。これはキーがクラスでその値が減少関数のマッピング型オブジェクトです。減少関数は関連するクラスの引数を 1 個とり、__reduce__() メソッドと同じインタフェースでなければなりません。
デフォルトでは、pickler オブジェクトは dispatch_table 属性を持たず、代わりに copyreg モジュールによって管理されるグローバルなディスパッチテーブルを使用します。しかし、特定の pickler オブジェクトによる pickle 化をカスタマイズするために dispatch_table 属性に dict-like オブジェクトを設定することができます。あるいは、Pickler のサブクラスが dispatch_table 属性を持てば、そのクラスのインスタンスに対するデフォルトのディスパッチテーブルとして使用されます。
使用例については ディスパッチテーブル を参照してください。
バージョン 3.3 で追加.
reducer_override(self, obj)
バージョン 3.8 で追加.
fast
廃止予定です。真値が設定されれば高速モードを有効にします。高速モードは、メモの使用を無効にします。それにより余分な PUT 命令コードを生成しなくなるので pickle 化処理が高速化します。自己参照オブジェクトに対しては使用すべきではありません。さもなければ Pickler に無限再帰を起こさせるでしょう。
よりコンパクトな pickle 化を必要とする場合は、pickletools.optimize() を使用してください。
class pickle.Unpickler(file, *, fix_imports=True, encoding="ASCII", errors="strict", buffers=None)
これは pickle データストリームの読み込みのためにバイナリファイルをとります。
pickle のプロトコルバージョンは自動的に検出されます。したがって protocol 引数は必要ありません。
バージョン 3.8 で変更: The buffers argument was added.
load()
persistent_load(pid)
デフォルトで UnpicklingError を送出します。
もし定義されていれば、persistent_load() は永続的な ID pid によって指定されたオブジェクトを返す必要があります。永続的な ID が無効な場合、UnpicklingError を送出しなければなりません。
詳細および使用例については 外部オブジェクトの永続化 を参照してください。
find_class(module, name)
必要なら module をインポートして、そこから name という名前のオブジェクトを返します。ここで module および name 引数は str オブジェクトです。その名前が示唆することに反して find_class() は関数を探すためにも使われることに注意してください。
サブクラスは、どんな型のオブジェクトを、どのようにロードするか (潜在的にはセキュリティリスクの減少) に関する制御を得るためにこれをオーバーライドすることができます。詳細に関しては グローバル変数を制限する を参照してください。
class pickle.PickleBuffer(buffer)
バージョン 3.8 で追加.
raw()
release()
pickle 化、非 pickle 化できるもの
以下の型は pickle 化できます:
None 、 True 、および False
整数、浮動小数点数、複素数
文字列、バイト列、バイト配列
pickle 化可能なオブジェクトからなるタプル、リスト、集合および辞書
モジュールのトップレベルで定義された関数 (def で定義されたもののみで lambda で定義されたものは含まない)
モジュールのトップレベルで定義されている組込み関数
モジュールのトップレベルで定義されているクラス
__dict__ 属性を持つクラス、あるいは __getstate__() メソッドの返り値が pickle 化可能なクラス (詳細は クラスインスタンスの pickle 化 を参照)。
pickle 化できないオブジェクトを pickle 化しようとすると、PicklingError 例外が送出されます。この例外が起きたとき、すでに元のファイルには未知の長さのバイト列が書き込まれている場合があります。極端に再帰的なデータ構造を pickle 化しようとした場合には再帰の深さ制限を越えてしまうかもしれず、この場合には RecursionError が送出されます。この制限は、sys.setrecursionlimit() で慎重に上げていくことは可能です。
関数 (組込みおよびユーザー定義) は、値ではなく、"完全修飾" された名前参照で pickle 化されます。2 これは関数が定義されたモジュールをともにした関数名のみが pickle 化されることを意味します。関数のコードやその属性は pickle 化されません。すなわち、非 pickle 化する環境で定義したモジュールがインポート可能な状態になっており、そのモジュール内に関数名のオブジェクトが含まれていなければなりません。この条件を満たさなかった場合は例外が送出されます。3
クラスも同様に名前参照で pickle 化されるので、unpickle 化環境には同じ制限が課せられます。クラス中のコードやデータは何も pickle 化されないので、以下の例ではクラス属性 attr が unpickle 化環境で復元されないことに注意してください
class Foo:
    attr = 'A class attribute'
picklestring = pickle.dumps(Foo)
pickle 化可能な関数やクラスがモジュールのトップレベルで定義されていなければならないのはこれらの制限のためです。
同様に、クラスのインスタンスが pickle 化された際、そのクラスのコードおよびデータはオブジェクトと一緒に pickle 化されることはありません。インスタンスのデータのみが pickle 化されます。この仕様は、クラス内のバグを修正したりメソッドを追加した後でも、そのクラスの以前のバージョンで作られたオブジェクトを読み出せるように意図的に行われています。あるクラスの多くのバージョンで使われるような長命なオブジェクトを作ろうと計画しているなら、そのクラスの __setstate__() メソッドによって適切な変換が行われるようにオブジェクトのバージョン番号を入れておくとよいかもしれません。
クラスインスタンスの pickle 化
この節では、クラスインスタンスがどのように pickle 化または非 pickle 化されるのかを定義したり、カスタマイズしたり、コントロールしたりするのに利用可能な一般的機構について説明します。
ほとんどの場合、インスタンスを pickle 化できるようにするために追加のコードは必要ありません。デフォルトで、pickle はインスタンスのクラスと属性を内省によって検索します。クラスインスタンスが非 pickle 化される場合、通常その __init__() メソッドは実行 されません 。デフォルトの振る舞いは、最初に初期化されていないインスタンスを作成して、次に保存された属性を復元します。次のコードはこの振る舞いの実装を示しています:
def save(obj):
    return (obj.__class__, obj.__dict__)
def load(cls, attributes):
    obj = cls.__new__(cls)
    obj.__dict__.update(attributes)
    return obj
クラスは、いくつかの特殊メソッドを提供することによって、デフォルトの振る舞いを変更することができます:
object.__getnewargs_ex__()
クラスの __new__() メソッドがキーワード専用引数を求める場合はこのメソッドを実装すべきです。 そうしない場合、互換性のため __getnewargs__() メソッドの実装を推奨します。
バージョン 3.6 で変更: __getnewargs_ex__() is now used in protocols 2 and 3.
object.__getnewargs__()
__getnewargs__() will not be called if __getnewargs_ex__() is defined.
バージョン 3.6 で変更: Before Python 3.6, __getnewargs__() was called instead of __getnewargs_ex__() in protocols 2 and 3.
object.__getstate__()
クラスはそのインスタンスをどう pickle 化するかについてさらに影響を与えることができます; クラスに __getstate__() メソッドが定義されていた場合それが呼ばれ、返り値のオブジェクトはインスタンスの辞書ではなく、インスタンスの内容が pickle 化されたものになります。__getstate__() がないときは通常通りインスタンスの __dict__ が pickle 化されます。
object.__setstate__(state)
非 pickle 化に際して、クラスが __setstate__() を定義している場合、それは非 pickle 化された状態とともに呼び出されます。その場合、状態オブジェクトが辞書でなければならないという要求はありません。そうでなければ、 pickle された状態は辞書で、その要素は新しいインスタンスの辞書に割り当てられます。
注釈 __getstate__() が偽値を返す場合、非 pickle 化時に __setstate__() メソッドは呼ばれません。
__getstate__() および __setstate__() メソッドの使い方に関する詳細な情報については 状態を持つオブジェクトの扱い 節を参照してください。
注釈 At unpickling time, some methods like __getattr__(), __getattribute__(), or __setattr__() may be called upon the instance. In case those methods rely on some internal invariant being true, the type should implement __new__() to establish such an invariant, as __init__() is not called when unpickling an instance.
これらから見るように、pickle は上記のメソッドを直接使用しません。実際には、これらのメソッドは __reduce__() 特殊メソッドを実装するコピープロトコルの一部です。コピープロトコルは、pickle 化とオブジェクトのコピーに必要な、データを取得するための統一されたインタフェースを提供します。 4
強力ですが、クラスに __reduce__() メソッドを直接実装することはエラーを起こしやすくなります。この理由のため、クラスの設計者は可能なかぎり高レベルインタフェース (__getnewargs_ex__()、__getstate__() および __setstate__()) を使用するべきです。公開はしているものの、__reduce__() の使用は、あくまでオプションとして、より効果的な pickle 化につながる場合、あるいはその両方の場合のみにしてください。
object.__reduce__()
このインタフェースは現在、以下のように定義されています。 __reduce__() メソッドは引数を取らず、文字列あるいは (こちらの方が好まれますが) タプルのいずれかを返すべきです (返されたオブジェクトは、しばしば "reduce value" と呼ばれます)。
文字列が返された場合、その文字列はグローバル変数の名前として解釈されます。それはオブジェクトのモジュールから見たローカル名であるべきです; pickle モジュールは、オブジェクトのモジュールを決定するためにモジュールの名前空間を検索します。この振る舞いは、典型的にシングルトンで便利です。
When a tuple is returned, it must be between two and six items long. Optional items can either be omitted, or None can be provided as their value. The semantics of each item are in order:
オブジェクトの初期バージョンを作成するために呼ばれる呼び出し可能オブジェクト。
呼出し可能オブジェクトに対する引数のタプル。呼出し可能オブジェクトが引数を受け取らない場合、空のタプルが与えられなければなりません。
任意で、前述のオブジェクトの __setstate__() メソッドに渡されるオブジェクトの状態。オブジェクトがそのようなメソッドを持たない場合、値は辞書でなければならず、それはオブジェクトの __dict__ 属性に追加されます。
任意で、連続した要素を yield する (シーケンスではなく) イテレーター。これらの要素は obj.append(item) を使用して、あるいはバッチでは obj.extend(list_of_items) を使用して、オブジェクトに追加されます。これは主としてリストのサブクラスに対して使用されますが、適切なシグネチャを持つ append() および extend() メソッドがあるかぎり、他のクラスで使用することもできます。 (append() または extend() のどちらが使用されるかは、どの pickle プロトコルバージョンが使われるかに加えて追加されるアイテムの数にも依存します。したがって、両方をサポートする必要があります)
任意で、連続する key-value ペアを yield する (シーケンスでなく) イテレーター。これらの要素は obj[key] = value を使用して、オブジェクトに格納されます。これは主として辞書のサブクラスに対して使用されますが、__setitem__() を実装しているかぎり他のクラスで使用することもできます。
バージョン 3.8 で追加: The optional sixth tuple item, (obj, state), was added.
object.__reduce_ex__(protocol)
別の方法として、__reduce_ex__() メソッドを定義することもできます。唯一の違いは、このメソッドは単一の整数引数、プロトコルバージョンを取る必要があるということです。もし定義された場合、pickle は __reduce__() メソッドよりもこのメソッドを優先します。さらに、__reduce__() は自動的に拡張版の同義語になります。このメソッドの主な用途は、古い Python リリースに対して後方互換性のある reduce value を提供することです。
外部オブジェクトの永続化
オブジェクトの永続化のために、pickle モジュールは、pickle データストリーム外のオブジェクトに対する参照の概念をサポートしています。そのようなオブジェクトは永続的 ID によって参照されます。それは、英数文字の文字列 (プロトコル 0 に対して) 5 あるいは単に任意のオブジェクト (より新しい任意のプロトコルに対して) のいずれかです。
外部オブジェクトを非 pickle 化するには、unpickler は永続的 ID オブジェクトを取り被参照オブジェクトを返すカスタム persistent_load() メソッドを持たなくてはなりません。
これは、外部のオブジェクトを参照によって pickle 化するために永続的 ID をどのように使用するかを示す包括的な例です。
# Simple example presenting how persistent ID can be used to pickle
# external objects by reference.
import pickle
import sqlite3
from collections import namedtuple
# Simple class representing a record in our database.
MemoRecord = namedtuple("MemoRecord", "key, task")
class DBPickler(pickle.Pickler):
    def persistent_id(self, obj):
        # Instead of pickling MemoRecord as a regular class instance, we emit a
        # persistent ID.
        if isinstance(obj, MemoRecord):
            # Here, our persistent ID is simply a tuple, containing a tag and a
            # key, which refers to a specific record in the database.
            return ("MemoRecord", obj.key)
        else:
            # If obj does not have a persistent ID, return None. This means obj
            # needs to be pickled as usual.
            return None
class DBUnpickler(pickle.Unpickler):
    def __init__(self, file, connection):
        super().__init__(file)
        self.connection = connection
    def persistent_load(self, pid):
        # This method is invoked whenever a persistent ID is encountered.
        # Here, pid is the tuple returned by DBPickler.
        cursor = self.connection.cursor()
        type_tag, key_id = pid
        if type_tag == "MemoRecord":
            # Fetch the referenced record from the database and return it.
            cursor.execute("SELECT * FROM memos WHERE key=?", (str(key_id),))
            key, task = cursor.fetchone()
            return MemoRecord(key, task)
        else:
            # Always raises an error if you cannot return the correct object.
            # Otherwise, the unpickler will think None is the object referenced
            # by the persistent ID.
            raise pickle.UnpicklingError("unsupported persistent object")
def main():
    import io
    import pprint
    # Initialize and populate our database.
    conn = sqlite3.connect(":memory:")
    cursor = conn.cursor()
    cursor.execute("CREATE TABLE memos(key INTEGER PRIMARY KEY, task TEXT)")
    tasks = (
        'give food to fish',
        'prepare group meeting',
        'fight with a zebra',
        )
    for task in tasks:
        cursor.execute("INSERT INTO memos VALUES(NULL, ?)", (task,))
    # Fetch the records to be pickled.
    cursor.execute("SELECT * FROM memos")
    memos = [MemoRecord(key, task) for key, task in cursor]
    # Save the records using our custom DBPickler.
    file = io.BytesIO()
    DBPickler(file).dump(memos)
    print("Pickled records:")
    pprint.pprint(memos)
    # Update a record, just for good measure.
    cursor.execute("UPDATE memos SET task='learn italian' WHERE key=1")
    # Load the records from the pickle data stream.
    file.seek(0)
    memos = DBUnpickler(file, conn).load()
    print("Unpickled records:")
    pprint.pprint(memos)
if __name__ == '__main__':
    main()
ディスパッチテーブル
pickle 化に依存する他のコードの邪魔をせずに、一部のクラスの pickle 化だけをカスタマイズしたい場合、プライベートのディスパッチテーブルを持つ pickler を作成することができます。
copyreg モジュールによって管理されるグローバルなディスパッチテーブルは copyreg.dispatch_table として利用可能です。したがって、copyreg.dispatch_table の修正済のコピーをプライベートのディスパッチテーブルとして使用することを選択できます。
例えば
f = io.BytesIO()
p = pickle.Pickler(f)
p.dispatch_table = copyreg.dispatch_table.copy()
p.dispatch_table[SomeClass] = reduce_SomeClass
これは SomeClass クラスを特別に扱うプライベートのディスパッチテーブルを持つ pickle.Pickler のインスタンスを作成します。あるいは、次のコード
class MyPickler(pickle.Pickler):
    dispatch_table = copyreg.dispatch_table.copy()
    dispatch_table[SomeClass] = reduce_SomeClass
f = io.BytesIO()
p = MyPickler(f)
も同じことをしますが、 MyPickler のすべてのインスタンスはデフォルトで同じディスパッチテーブルを共有します。 copyreg モジュールを使用する等価なコードは
copyreg.pickle(SomeClass, reduce_SomeClass)
f = io.BytesIO()
p = pickle.Pickler(f)
状態を持つオブジェクトの扱い
ここでは、クラスを pickle 化する振る舞いの変更手順を紹介しています。TextReader クラスはテキストファイルをオープンし、readline() メソッドが呼ばれると、その度に行番号と行の内容を返します。TextReader インスタンスが pickle 化されるとき、ファイルオブジェクトメンバーを 除く すべての属性が保存されます。インスタンスが非 pickle 化されるとき、ファイルは再びオープンされ、最後に読み込んだ位置から読み込みを再開します。このような振る舞いを実装するには __setstate__() および __getstate__() メソッドを使用します。
class TextReader:
    """Print and number lines in a text file."""
    def __init__(self, filename):
        self.filename = filename
        self.file = open(filename)
        self.lineno = 0
    def readline(self):
        self.lineno += 1
        line = self.file.readline()
        if not line:
            return None
        if line.endswith('\n'):
            line = line[:-1]
        return "%i: %s" % (self.lineno, line)
    def __getstate__(self):
        # Copy the object's state from self.__dict__ which contains
        # all our instance attributes. Always use the dict.copy()
        # method to avoid modifying the original state.
        state = self.__dict__.copy()
        # Remove the unpicklable entries.
        del state['file']
        return state
    def __setstate__(self, state):
        # Restore instance attributes (i.e., filename and lineno).
        self.__dict__.update(state)
        # Restore the previously opened file's state. To do so, we need to
        # reopen it and read from it until the line count is restored.
        file = open(self.filename)
        for _ in range(self.lineno):
            file.readline()
        # Finally, save the file.
        self.file = file
使用例は以下のようになるでしょう:
>>>
>>> reader = TextReader("hello.txt")
>>> reader.readline()
'1: Hello world!'
>>> reader.readline()
'2: I am line number two.'
>>> new_reader = pickle.loads(pickle.dumps(reader))
>>> new_reader.readline()
'3: Goodbye!'
Custom Reduction for Types, Functions, and Other Objects
バージョン 3.8 で追加.
注釈 For performance reasons, reducer_override() may not be called for the following objects: None, True, False, and exact instances of int, float, bytes, str, dict, set, frozenset, list and tuple.
Here is a simple example where we allow pickling and reconstructing a given class:
import io
import pickle
class MyClass:
    my_attribute = 1
class MyPickler(pickle.Pickler):
    def reducer_override(self, obj):
        """Custom reducer for MyClass."""
        if getattr(obj, "__name__", None) == "MyClass":
            return type, (obj.__name__, obj.__bases__,
                          {'my_attribute': obj.my_attribute})
        else:
            # For any other object, fallback to usual reduction
            return NotImplemented
f = io.BytesIO()
p = MyPickler(f)
p.dump(MyClass)
del MyClass
unpickled_class = pickle.loads(f.getvalue())
assert isinstance(unpickled_class, type)
assert unpickled_class.__name__ == "MyClass"
assert unpickled_class.my_attribute == 1
Out-of-band Buffers
バージョン 3.8 で追加.
Provider API
Consumer API
使用例
Here is a trivial example where we implement a bytearray subclass able to participate in out-of-band buffer pickling:
class ZeroCopyByteArray(bytearray):
    def __reduce_ex__(self, protocol):
        if protocol >= 5:
            return type(self)._reconstruct, (PickleBuffer(self),), None
        else:
            # PickleBuffer is forbidden with pickle protocols <= 4.
            return type(self)._reconstruct, (bytearray(self),)
    @classmethod
    def _reconstruct(cls, obj):
        with memoryview(obj) as m:
            # Get a handle over the original buffer object
            obj = m.obj
            if type(obj) is cls:
                # Original buffer object is a ZeroCopyByteArray, return it
                # as-is.
                return obj
            else:
                return cls(obj)
On the consumer side, we can pickle those objects the usual way, which when unserialized will give us a copy of the original object:
b = ZeroCopyByteArray(b"abc")
data = pickle.dumps(b, protocol=5)
new_b = pickle.loads(data)
print(b == new_b)  # True
print(b is new_b)  # False: a copy was made
But if we pass a buffer_callback and then give back the accumulated buffers when unserializing, we are able to get back the original object:
b = ZeroCopyByteArray(b"abc")
buffers = []
data = pickle.dumps(b, protocol=5, buffer_callback=buffers.append)
new_b = pickle.loads(data, buffers=buffers)
print(b == new_b)  # True
print(b is new_b)  # True: no copy was made
参考 PEP 574 -- Pickle protocol 5 with out-of-band data
グローバル変数を制限する
デフォルトで、非 pickle 化は pickle データ内で見つけたあらゆるクラスや関数をインポートします。多くのアプリケーションでは、この振る舞いは受け入れられません。なぜなら、それによって unpickler が任意のコードをインポートして実行することが可能になるからです。この手の巧妙に作られた pickle データストリームがロードされたときに何を行うかをちょっと考えてみてください:
>>>
>>> import pickle
>>> pickle.loads(b"cos\nsystem\n(S'echo hello world'\ntR.")
hello world
0
この例において、unpickler は os.system() 関数をインポートして、次に文字列の引数 "echo hello world" を適用しています。この例は無害ですが、システムを破壊する例を想像するのは難しくありません。
この理由のため、Unpickler.find_class() をカスタマイズすることで非 pickle 化で何を得るかを制御したくなるかもしれません。その名前が示唆するのと異なり、Unpickler.find_class() はグローバル (クラスや関数) が必要とした時にはいつでも呼びだされます。したがって、グローバルを完全に禁止することも安全なサブセットに制限することも可能です。
これは、一部の安全なクラスについてのみ builtins モジュールからロードすることを許可する unpickler の例です:
import builtins
import io
import pickle
safe_builtins = {
    'range',
    'complex',
    'set',
    'frozenset',
    'slice',
}
class RestrictedUnpickler(pickle.Unpickler):
    def find_class(self, module, name):
        # Only allow safe classes from builtins.
        if module == "builtins" and name in safe_builtins:
            return getattr(builtins, name)
        # Forbid everything else.
        raise pickle.UnpicklingError("global '%s.%s' is forbidden" %
                                     (module, name))
def restricted_loads(s):
    """Helper function analogous to pickle.loads()."""
    return RestrictedUnpickler(io.BytesIO(s)).load()
この unpickler が働く使用例は次のように意図されます:
>>>
>>> restricted_loads(pickle.dumps([1, 2, range(15)]))
[1, 2, range(0, 15)]
>>> restricted_loads(b"cos\nsystem\n(S'echo hello world'\ntR.")
Traceback (most recent call last):
  ...
pickle.UnpicklingError: global 'os.system' is forbidden
>>> restricted_loads(b'cbuiltins\neval\n'
...                  b'(S\'getattr(__import__("os"), "system")'
...                  b'("echo hello world")\'\ntR.')
Traceback (most recent call last):
  ...
pickle.UnpicklingError: global 'builtins.eval' is forbidden
この例が示すように、非 pickle 化を認めるものに注意しなければなりません。したがって、セキュリティが重要な場合は xmlrpc.client の marshal API や、サードパーティのソリューションのような別の選択肢を考慮した方がよいでしょう。
性能
pickle プロトコルの最近のバージョン (プロトコル 2 以降) は一部の一般的な機能と組み込みデータ型を効率的にバイナリにエンコードするよう考慮されています。また、pickle モジュールは C 言語で書かれた透過的オプティマイザーを持っています。
使用例
最も単純なコードでは、dump() および load() 関数を使用してください。
import pickle
# An arbitrary collection of objects supported by pickle.
data = {
    'a': [1, 2.0, 3, 4+6j],
    'b': ("character string", b"byte string"),
    'c': {None, True, False}
}
with open('data.pickle', 'wb') as f:
    # Pickle the 'data' dictionary using the highest protocol available.
    pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)
次の例は、pickle 化されたデータを読み込みます。
import pickle
with open('data.pickle', 'rb') as f:
    # The protocol version used is detected automatically, so we do not
    # have to specify it.
    data = pickle.load(f)
参考
copyreg モジュール
拡張型を登録するための Pickle インタフェース構成機構。
pickletools モジュール
pickle データの処理や分析を行うためのツール。
shelve モジュール
オブジェクトのインデクス付きデータベース; pickle を使います。
copy モジュール
オブジェクトの浅いコピーおよび深いコピー。
marshal モジュール
組み込み型の高性能な直列化。
copyreg --- pickle サポート関数を登録する
ソースコード: Lib/copyreg.py
copyreg モジュールは、特定のオブジェクトを pickle する際に使われる関数を定義する手段を提供します。 pickle モジュールと copy モジュールは、オブジェクトを pickle/コピーする場合にそれらの関数を使用します。このモジュールは、クラスでないオブジェクトコンストラクタに関する設定情報を提供します。そのようなコンストラクタは、ファクトリ関数か、クラスインスタンスかもしれません。
copyreg.constructor(object)
object を有効なコンストラクタであると宣言します。 object が呼び出し可能でなければ(したがってコンストラクタとして有効でなければ)、 TypeError を発生します。
copyreg.pickle(type, function, constructor=None)
function が型 type のオブジェクトに対する"リダクション"関数として使われるように宣言します。function は文字列か、2要素または3要素を含んだタプルを返さなければなりません。
オプションの constructor パラメータが与えられた場合、それは呼び出し可能オブジェクトで、 function が返した引数のタプルとともに pickle 化時に呼ばれてオブジェクトを再構築するために使われます。 object がクラスの場合、または constructor が呼び出し可能でない場合には TypeError が発生します。
function と constructor に期待されるインタフェースについての詳細については pickle モジュールを参照してください。 pickler オブジェクトまたは pickle.Pickler のサブクラスの dispatch_table 属性を、リダクション関数の宣言のために使うこともできるということは覚えておいてください。
使用例
下記の例は、pickle 関数を登録する方法と、それがどのように使用されるかを示そうとしています:
>>>
import copyreg, copy, pickle
class C:
    def __init__(self, a):
        self.a = a
def pickle_c(c):
    print("pickling a C instance...")
    return C, (c.a,)
copyreg.pickle(C, pickle_c)
c = C(1)
d = copy.copy(c)  
pickling a C instance...
p = pickle.dumps(c)  
pickling a C instance...
shelve --- Python オブジェクトの永続化
ソースコード: Lib/shelve.py
"シェルフ (shelf, 棚)" は辞書に似た永続性を持つオブジェクトです。 "dbm" データベースとの違いは、シェルフの値 (キーではありません！) は実質上どんな Python オブジェクトにも --- pickle モジュールが扱えるなら何でも --- できるということです。これにはほとんどのクラスインスタンス、再帰的なデータ型、沢山の共有されたサブオブジェクトを含むオブジェクトが含まれます。キーは通常の文字列です。
shelve.open(filename, flag='c', protocol=None, writeback=False)
永続的な辞書を開きます。指定された filename は、根底にあるデータベースの基本ファイル名となります。副作用として、 filename には拡張子がつけられる場合があり、ひとつ以上のファイルが生成される可能性もあります。デフォルトでは、根底にあるデータベースファイルは読み書き可能なように開かれます。オプションの flag パラメータは dbm.open() における flag パラメータと同様に解釈されます。
デフォルトでは、値を整列化する際にはバージョン 3 の pickle 化が用いられます。pickle 化プロトコルのバージョンは protocol パラメータで指定することができます。
Python の意味論により、シェルフには永続的な辞書の可変エントリがいつ変更されたかを知る術がありません。 デフォルトでは、変更されたオブジェクトはシェルフに代入されたとき だけ 書き込まれます (使用例 参照)。 オプションの writeback パラメータが True に設定されている場合は、アクセスされたすべてのエントリはメモリ上にキャッシュされ、 sync() および close() を呼び出した際に書き戻されます; この機能は永続的な辞書上の可変の要素に対する変更を容易にしますが、多数のエントリがアクセスされた場合、膨大な量のメモリがキャッシュのために消費され、アクセスされた全てのエントリを書き戻す (アクセスされたエントリが可変であるか、あるいは実際に変更されたかを決定する方法は存在しないのです) ために、ファイルを閉じる操作が非常に低速になります。
注釈 シェルフが自動的に閉じることに依存しないでください; それがもう必要ない場合は常に close() を明示的に呼ぶか、 shelve.open() をコンテキストマネージャとして使用してください:
with shelve.open('spam') as db:
    db['eggs'] = 'eggs'
警告 shelve モジュールは裏で pickle を使っているので、信頼できないソースからシェルフを読み込むのは危険です。 pickle と同じく、 shelf の読み込みでも任意のコードを実行できるからです。
シェルフオブジェクトは辞書がサポートする全てのメソッドをサポートしています。これにより、辞書ベースのスクリプトから永続的な記憶媒体を必要とするスクリプトに容易に移行できるようになります。
追加でサポートされるメソッドが二つあります:
Shelf.sync()
シェルフが writeback を True にセットして開かれている場合に、キャッシュ中の全てのエントリを書き戻します。また可能な場合は、キャッシュを空にしてディスク上の永続的な辞書を同期します。このメソッドはシェルフを close() によって閉じるとき自動的に呼び出されます。
Shelf.close()
永続的な 辞書 オブジェクトを同期して閉じます。既に閉じられているシェルフに対して呼び出すと ValueError を出し失敗します。
参考 通常の辞書に近い速度をもち、いろいろなストレージフォーマットに対応した、 永続化辞書のレシピ 。
制限事項
どのデータベースパッケージが使われるか (例えば dbm.ndbm 、 dbm.gnu) は、どのインタフェースが利用可能かに依存します。従って、データベースを dbm を使って直接開く方法は安全ではありません。データベースはまた、 dbm が使われた場合 (不幸なことに) その制約に縛られます --- これはデータベースに記録されたオブジェクト (の pickle 化された表現) はかなり小さくなければならず、キー衝突が生じた場合に、稀にデータベースを更新することができなくなることを意味します。
shelve モジュールは、シェルフに置かれたオブジェクトの 並列した 読み出し/書き込みアクセスをサポートしません (複数の同時読み出しアクセスは安全です)。あるプログラムが書き込みのために開かれたシェルフを持っているとき、他のプログラムはそのシェルフを読み書きのために開いてはいけません。この問題を解決するために Unix のファイルロック機構を使うことができますが、この機構は Unix のバージョン間で異なり、使われているデータベースの実装について知識が必要となります。
class shelve.Shelf(dict, protocol=None, writeback=False, keyencoding='utf-8')
collections.abc.MutableMapping のサブクラスで、 dict オブジェクト内にpickle化された値を保持します。
デフォルトでは、値を整列化する際にはバージョン 3 の pickle 化が用いられます。pickle 化プロトコルのバージョンは protocol パラメータで指定することができます。pickle 化プロトコルについては pickle のドキュメントを参照してください。
writeback パラメータが True に設定されていれば、アクセスされたすべてのエントリはメモリ上にキャッシュされ、ファイルを閉じる際に dict に書き戻されます; この機能により、可変のエントリに対して自然な操作が可能になりますが、さらに多くのメモリを消費し、辞書をファイルと同期して閉じる際に長い時間がかかるようになります。
keyencoding パラメータは、shelf の背後にある dict に対して使われる前にキーをエンコードするのに使用されるエンコーディングです。
Shelf オブジェクトは、コンテキストマネージャとしても使用できます。この場合、 with ブロックが終了する際に、自動的に閉じられます。
バージョン 3.2 で変更: keyencoding パラメータを追加; 以前はキーは常に UTF-8 でエンコードされていました。
バージョン 3.4 で変更: コンテキストマネージャーサポートが追加されました。
class shelve.BsdDbShelf(dict, protocol=None, writeback=False, keyencoding='utf-8')
Shelf のサブクラスで、 first(), next(), previous(), last(), set_location() メソッドを外部に提供しています。これらのメソッドは pybsddb にあるサードパーティの bsddb モジュールでは利用可能ですが、他のデータベースモジュールでは利用できません。コンストラクタに渡される dict オブジェクトは上記のメソッドをサポートしていなくてはなりません。通常は、 bsddb.hashopen(), bsddb.btopen() または bsddb.rnopen() のいずれかを呼び出して得られるオブジェクトが条件を満たしています。オプションの protocol, writeback および keyencoding パラメータは Shelf クラスにおけるパラメータと同様に解釈されます。
class shelve.DbfilenameShelf(filename, flag='c', protocol=None, writeback=False)
Shelf のサブクラスで、辞書に似たオブジェクトの代わりに filename を受理します。根底にあるファイルは dbm.open() を使って開かれます。デフォルトでは、ファイルは読み書き可能な状態で開かれます。オプションの flag パラメータは open() 関数におけるパラメータと同様に解釈されます。オプションの protocol および writeback パラメータは Shelf クラスにおけるパラメータと同様に解釈されます。
使用例
インタフェースは以下のコードに集約されています (key は文字列で、data は任意のオブジェクトです):
import shelve
d = shelve.open(filename)  # open -- file may get suffix added by low-level
                           # library
d[key] = data              # store data at key (overwrites old data if
                           # using an existing key)
data = d[key]              # retrieve a COPY of data at key (raise KeyError
                           # if no such key)
del d[key]                 # delete data stored at key (raises KeyError
                           # if no such key)
flag = key in d            # true if the key exists
klist = list(d.keys())     # a list of all existing keys (slow!)
# as d was opened WITHOUT writeback=True, beware:
d['xx'] = [0, 1, 2]        # this works as expected, but...
d['xx'].append(3)          # *this doesn't!* -- d['xx'] is STILL [0, 1, 2]!
# having opened d without writeback=True, you need to code carefully:
temp = d['xx']             # extracts the copy
temp.append(5)             # mutates the copy
d['xx'] = temp             # stores the copy right back, to persist it
# or, d=shelve.open(filename,writeback=True) would let you just code
# d['xx'].append(5) and have it work as expected, BUT it would also
# consume more memory and make the d.close() operation slower.
d.close()                  # close it
参考
dbm モジュール
dbm スタイルのデータベースに対する共通インタフェース。
pickle モジュール
shelve によって使われるオブジェクト整列化機構。
marshal --- 内部使用向けの Python オブジェクト整列化
このモジュールには Python 値をバイナリ形式で読み書きできるような関数が含まれています。このバイナリ形式は Python 特有のものですが、マシンアーキテクチャ非依存のものです (つまり、Python の値を PC 上でファイルに書き込み、Sun に転送し、そこで読み戻すことができます)。バイナリ形式の詳細は意図的にドキュメント化されていません; この形式は (稀にしかないことですが) Python のバージョン間で変更される可能性があるからです。1
このモジュールは汎用の "永続化 (persistence)" モジュールではありません。汎用的な永続化や、RPC 呼び出しを通じた Python オブジェクトの転送については、モジュール pickle および shelve を参照してください。 marshal モジュールは主に、 "擬似コンパイルされた (pseudo-compiled)" コードの .pyc ファイルへの読み書きをサポートするために存在します。したがって、 Python のメンテナンス担当者は、必要が生じれば marshal 形式を後方互換性のないものに変更する権利を有しています。 Python オブジェクトを直列化 (シリアライズ) および非直列化 (デシリアライズ) する場合には、 pickle モジュールを使ってください。 pickle は速度は同等で、バージョン間の互換性が保証されていて、 marshal より広範囲のオブジェクトをサポートしています。
警告 marshal モジュールは、誤ったデータや悪意を持って作成されたデータに対する安全性を考慮していません。信頼できない、もしくは認証されていない出所からのデータを非整列化してはなりません。
すべての Python オブジェクト型がサポートされているわけではありません。一般に、このモジュールによって読み書きすることができるオブジェクトは、その値が Python の特定の起動に依存していないオブジェクトに限ります。次の型がサポートされています。真偽値、整数、浮動小数点数、複素数、文字列、 byte 、bytearray 、タプル、リスト、 set 、frozenset 、辞書、コードオブジェクト。ここで、タプル、リスト、 set 、 frozenset 、辞書は、その中に含まれる値がそれ自身サポートされる場合に限りサポートされます。シングルトン None 、 Ellipsis 、 StopIteration も読み書き (marshalled and unmarshalled) できます。3 未満のフォーマット version では、再帰的なリスト、 set 、辞書を書き出すことはできません (下記参照)。
このモジュールでは、以下の関数が定義されています。
marshal.dump(value, file[, version])
値 (または値に含まれるオブジェクト) がサポートされていない型の場合、 ValueError 例外が送出されます --- しかし、同時にごみのデータがファイルに書き込まれます。このオブジェクトは load() で適切に読み出されることはありません。
version 引数は dump が使用するデータフォーマットを指定します (下記を参照してください)。
marshal.load(file)
注釈 サポートされていない型を含むオブジェクトが dump() で整列化されている場合、 load() は整列化不能な値を None で置き換えます。
marshal.dumps(value[, version])
version 引数は dumps が使用するデータフォーマットを指定します (下記を参照してください)。
marshal.loads(bytes)
これに加えて、以下の定数が定義されています:
marshal.version
このモジュールが利用するバージョンを表します。バージョン0 は歴史的なフォーマットです。バージョン1 は文字列の再利用をします。バージョン2 は浮動小数点数にバイナリフォーマットを使用します。バージョン3 はオブジェクトのインスタンス化と再帰をサポートします。現在のバージョンは4です。
脚注
1
このモジュールの名前は (特に) Modula-3 の設計者の間で使われていた用語の一つに由来しています。彼らはデータを自己充足的な形式で輸送する操作に "整列化 (marshalling)" という用語を使いました。厳密に言えば、"整列させる (to marshal)" とは、あるデータを (例えば RPC バッファのように) 内部表現形式から外部表現形式に変換することを意味し、"非整列化 (unmarshalling)" とはその逆を意味します。
dbm --- Unix "データベース" へのインタフェース
ソースコード: Lib/dbm/__init__.py
dbm は DBM データベースのいくつかの種類 ( dbm.gnu または dbm.ndbm ) に対する汎用的なインタフェースです。これらのモジュールのどれもインストールされていなければ、モジュール dbm.dumb に含まれる低速だが単純な実装が使用されます。Oracle Berkeley DB に対する サードパーティのインタフェース があります。
exception dbm.error
サポートされているモジュールそれぞれによって送出される可能性のある例外を含むタプル。これにはユニークな例外があり、最初の要素として同じく dbm.error という名前の例外が含まれます --- dbm.error が送出される場合、後者(訳注:タプルの dbm.error ではなく例外 dbm.error)が使用されます。
dbm.whichdb(filename)
この関数は、与えられたファイルを開くために、利用可能ないくつかの単純なデータベースモジュール --- dbm.gnu, dbm.ndbm, dbm.dumb --- のどれを使用すべきか推測を試みます。
次の値のうち１つを返します: ファイルが読み取れないか存在しないために開くことができない場合は None; ファイルのフォーマットを推測することができない場合は空文字列 (''); それ以外は 'dbm.ndbm' や 'dbm.gnu' のような、必要なモジュール名を含む文字列。
dbm.open(file, flag='r', mode=0o666)
データベースファイル file を開いて対応するオブジェクトを返します。
データベースファイルが既に存在する場合、その種類を決定するために whichdb() 関数が使用され、適切なモジュールが使用されます; データベースファイルが存在しない場合、上記のリストの中でインポート可能な最初のモジュールが使用されます。
オプションの flag は:
値
意味
'r'
既存のデータベースを読み込み専用で開く (デフォルト)
'w'
既存のデータベースを読み書き用に開く
'c'
データベースを読み書き用に開く。ただし存在しない場合には新たに作成する
'n'
常に新たに読み書き用の新規のデータベースを作成する
オプションの mode 引数は、新たにデータベースを作成しなければならない場合に使われる Unix のファイルモードです。標準の値は 8 進数の 0o666 です (この値は現在有効な umask で修飾されます)。
open() によって返されたオブジェクトは辞書とほとんど同じ機能をサポートします; キーとそれに対応付けられた値を記憶し、取り出し、削除することができ、 in 演算子や keys() メソッド、また get() や setdefault() を使うことができます。
バージョン 3.2 で変更: get() と setdefault() がすべてのデータベースモジュールで利用できるようになりました。
バージョン 3.8 で変更: 読み出し専用のデータベースからキーを削除しようとすると、 KeyError ではなくデータベースモジュール専用のエラーが送出されるようになりました。
キーと値は常に byte 列として格納されます。これは、文字列が使用された場合は格納される前に暗黙的にデフォルトエンコーディングに変換されるということを意味します。
これらのオブジェクトは、 with 文での使用にも対応しています。with 文を使用した場合、終了時に自動的に閉じられます。
バージョン 3.4 で変更: open() が返すオブジェクトに対するコンテキスト管理のプロトコルがネイティブにサポートされました。
以下の例ではホスト名と対応するタイトルをいくつか記録し、データベースの内容を出力します:
import dbm
# Open database, creating it if necessary.
with dbm.open('cache', 'c') as db:
    # Record some values
    db[b'hello'] = b'there'
    db['www.python.org'] = 'Python Website'
    db['www.cnn.com'] = 'Cable News Network'
    # Note that the keys are considered bytes now.
    assert db[b'www.python.org'] == b'Python Website'
    # Notice how the value is now in bytes.
    assert db['www.cnn.com'] == b'Cable News Network'
    # Often-used methods of the dict interface work too.
    print(db.get('python.org', b'not present'))
    # Storing a non-string key or value will raise an exception (most
    # likely a TypeError).
    db['www.yahoo.com'] = 4
# db is automatically closed when leaving the with statement.
参考
shelve モジュール
非文字列データを記録する永続化モジュール。
個々のサブモジュールは以降の節で説明されます。
dbm.gnu --- GNU による dbm 拡張
ソースコード: Lib/dbm/gnu.py
このモジュールは dbm モジュールによく似ていますが、GNU ライブラリ gdbm を使っていくつかの追加機能を提供しています。 dbm.gnu と dbm.ndbm では生成されるファイル形式に互換性がないので注意してください。
dbm.gnu モジュールでは GNU DBM ライブラリへのインタフェースを提供します。 dbm.gnu.gdbm オブジェクトはキーと値が必ず保存の前にバイト列に変換されることを除き、マップ型 (辞書型) と同じように動作します。 gdbm オブジェクトに対して print() を適用してもキーや値を印字することはなく、 items() 及び values() メソッドはサポートされていません。
exception dbm.gnu.error
I/O エラーのような dbm.gnu 特有のエラーで送出されます。誤ったキーの指定のように、一般的なマップ型のエラーに対しては KeyError が送出されます。
dbm.gnu.open(filename[, flag[, mode]])
gdbm データベースを開いて gdbm オブジェクトを返します。 filename 引数はデータベースファイルの名前です。
オプションの flag は:
値
意味
'r'
既存のデータベースを読み込み専用で開く (デフォルト)
'w'
既存のデータベースを読み書き用に開く
'c'
データベースを読み書き用に開く。ただし存在しない場合には新たに作成する
'n'
常に新たに読み書き用の新規のデータベースを作成する
以下の追加の文字を flag に追加して、データベースの開きかたを制御することができます:
値
意味
'f'
データベースを高速モードで開きます。書き込みが同期されません。
's'
同期モード。データベースへの変更がすぐにファイルに書き込まれます。
'u'
データベースをロックしません。
全てのバージョンの gdbm で全てのフラグが有効とは限りません。モジュール定数 open_flags はサポートされているフラグ文字からなる文字列です。無効なフラグが指定された場合、例外 error が送出されます。
オプションの mode 引数は、新たにデータベースを作成しなければならない場合に使われる Unix のファイルモードです。標準の値は 8 進数の 0o666 です。
辞書型形式のメソッドに加えて、gdbm オブジェクトには以下のメソッドがあります:
gdbm.firstkey()
このメソッドと nextkey() メソッドを使って、データベースの全てのキーにわたってループ処理を行うことができます。探索は gdbm の内部ハッシュ値の順番に行われ、キーの値に順に並んでいるとは限りません。このメソッドは最初のキーを返します。
gdbm.nextkey(key)
データベースの順方向探索において、key よりも後に来るキーを返します。以下のコードはデータベース db について、キー全てを含むリストをメモリ上に生成することなく全てのキーを出力します:
k = db.firstkey()
while k != None:
    print(k)
    k = db.nextkey(k)
gdbm.reorganize()
大量の削除を実行した後、gdbm ファイルの占めるスペースを削減したい場合、このルーチンはデータベースを再組織化します。この再組織化を使用する方法以外に gdbm オブジェクトがデータベースファイルの大きさを短くすることはありません。サイズを縮小しない場合、削除された部分のファイルスペースは保持され、新たな (キー、値の) ペアが追加される際に再利用されます。
gdbm.sync()
データベースが高速モードで開かれていた場合、このメソッドはディスクにまだ書き込まれていないデータを全て書き込ませます。
gdbm.close()
gdbm データベースをクローズします。
dbm.ndbm --- ndbm に基づくインタフェース
ソースコード: Lib/dbm/ndbm.py
dbm.ndbm モジュールはUnixの"(n)dbm"ライブラリのインタフェースを提供します。 dbmオブジェクトは、キーと値が必ずバイト列である以外は辞書オブジェクトのようなふるまいをします。 print関数などで dbm オブジェクトを出力してもキーと値は出力されません。また、 items() と values() メソッドはサポートされません。
このモジュールは、GNU GDBM互換インタフェースを持った "クラシックな" ndbmインタフェースを使うことができます。 Unix上のビルド時に configure スクリプトで適切なヘッダファイルが割り当られます。
exception dbm.ndbm.error
I/O エラーのような dbm.ndbm 特有のエラーで送出されます。誤ったキーの指定のように、一般的なマップ型のエラーに対しては KeyError が送出されます。
dbm.ndbm.library
ndbm が使用している実装ライブラリ名です。
dbm.ndbm.open(filename[, flag[, mode]])
dbmデータベースを開いて ndbm オブジェクトを返します。引数 filename はデータベースのファイル名を指定します。 (拡張子 .dir や .pag は付けません)。
オプションの flag は以下の値のいずれかです:
値
意味
'r'
既存のデータベースを読み込み専用で開く (デフォルト)
'w'
既存のデータベースを読み書き用に開く
'c'
データベースを読み書き用に開く。ただし存在しない場合には新たに作成する
'n'
常に新たに読み書き用の新規のデータベースを作成する
オプションの mode 引数は、新たにデータベースを作成しなければならない場合に使われる Unix のファイルモードです。標準の値は 8 進数の 0o666 です (この値は現在有効な umask で修飾されます)。
辞書型様のメソッドに加えて、ndbm オブジェクトには以下のメソッドがあります。
ndbm.close()
ndbm データベースをクローズします。
dbm.dumb --- 可搬性のある DBM 実装
ソースコード: Lib/dbm/dumb.py
注釈 dbm.dumb モジュールは、 dbm が頑健なモジュールを他に見つけることができなかった際の最後の手段とされています。 dbm.dumb モジュールは速度を重視して書かれているわけではなく、他のデータベースモジュールのように重い使い方をするためのものではありません。
dbm.dumb モジュールは永続性辞書に類似したインタフェースを提供し、全て Python で書かれています。 dbm.gnu のようなモジュールと異なり、外部ライブラリは必要ありません。他の永続性マップ型のように、キーおよび値は常にバイト列として保存されます。
このモジュールは以下を定義します:
exception dbm.dumb.error
I/O エラーのような dbm.dumb 特有のエラーの際に送出されます。不正なキーを指定したときのような、一般的な対応付けエラーの際には KeyError が送出されます。
dbm.dumb.open(filename[, flag[, mode]])
dumbdbm データベースを開き、 dubmdbm オブジェクトを返します。 filename 引数はデータベースファイル名の雛型 (特定の拡張子をもたないもの) です。dumbdbm データベースが生成される際、 .dat および .dir の拡張子を持ったファイルが生成されます。
オプションの flag は:
値
意味
'r'
既存のデータベースを読み込み専用で開く (デフォルト)
'w'
既存のデータベースを読み書き用に開く
'c'
データベースを読み書き用に開く。ただし存在しない場合には新たに作成する
'n'
常に新たに読み書き用の新規のデータベースを作成する
オプションの mode 引数は、新たにデータベースを作成しなければならない場合に使われる Unix のファイルモードです。標準の値は 8 進数の 0o666 です (この値は現在有効な umask で修飾されます)。
警告 十分に大きかったり複雑だったりするエントリーのあるデータベースを読み込んでいるときに、 Python の抽象構文木コンパイラのスタックの深さの限界を越えるせいで、 Python インタプリタをクラッシュさせることができます。
バージョン 3.5 で変更: フラグに値 'n' を与えると、 open() が常に新しいデータベースを作成するようになりました。
バージョン 3.8 で変更: フラグ 'r' で開いたデータベースは読み出し専用となりました。 データベースが存在していない場合にフラグ 'r' と 'w' で開いても、データベースを作成しなくなりました。
collections.abc.MutableMapping クラスによって提供されるメソッドに加えて、 dumbdbm オブジェクトは以下のメソッドを提供します:
dumbdbm.sync()
ディスク上の辞書とデータファイルを同期します。このメソッドは Shelve.sync() メソッドから呼び出されます。
dumbdbm.close()
dumbdbm データベースをクローズします。
sqlite3 --- SQLite データベースに対する DB-API 2.0 インタフェース
ソースコード: Lib/sqlite3/
SQLite は、軽量なディスク上のデータベースを提供する C ライブラリです。別のサーバプロセスを用意する必要なく、 SQL クエリー言語の非標準的な一種を使用してデータベースにアクセスできます。一部のアプリケーションは内部データ保存に SQLite を使えます。また、SQLite を使ってアプリケーションのプロトタイプを作り、その後そのコードを PostgreSQL や Oracle のような大規模データベースに移植するということも可能です。
sqlite3 モジュールの著者は Gerhard Häring です。 PEP 249 で記述されている DB-API 2.0 に準拠した SQL インターフェイスを提供します。
このモジュールを使うには、最初にデータベースを表す Connection オブジェクトを作ります。ここではデータはファイル example.db に格納されているものとします:
import sqlite3
con = sqlite3.connect('example.db')
特別な名前である :memory: を使うと RAM 上にデータベースを作ることもできます。
Connection があれば、 Cursor オブジェクトを作りその execute() メソッドを呼んで SQL コマンドを実行することができます:
cur = con.cursor()
# Create table
cur.execute('''CREATE TABLE stocks
               (date text, trans text, symbol text, qty real, price real)''')
# Insert a row of data
cur.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")
# Save (commit) the changes
con.commit()
# We can also close the connection if we are done with it.
# Just be sure any changes have been committed or they will be lost.
con.close()
保存されたデータは永続的であり、次回のセッションでもそのまま使用できます:
import sqlite3
con = sqlite3.connect('example.db')
cur = con.cursor()
たいてい、SQL 操作では Python 変数の値を使う必要があります。この時、クエリーを Python の文字列操作を使って構築することは安全とは言えないので、すべきではありません。そのようなことをするとプログラムが SQL インジェクション攻撃に対し脆弱になります (https://xkcd.com/327/ ではどうなってしまうかをユーモラスに描いています)。
代わりに、DB-API のパラメータ割り当てを使います。 ? を変数の値を使いたいところに埋めておきます。その上で、値のタプルをカーソルの execute() メソッドの第2引数として引き渡します。(他のデータベースモジュールでは変数の場所を示すのに %s や :1 などの異なった表記を用いることがあります。) 例を示します:
# Never do this -- insecure!
symbol = 'RHAT'
cur.execute("SELECT * FROM stocks WHERE symbol = '%s'" % symbol)
# Do this instead
t = ('RHAT',)
cur.execute('SELECT * FROM stocks WHERE symbol=?', t)
print(cur.fetchone())
# Larger example that inserts many records at a time
purchases = [('2006-03-28', 'BUY', 'IBM', 1000, 45.00),
             ('2006-04-05', 'BUY', 'MSFT', 1000, 72.00),
             ('2006-04-06', 'SELL', 'IBM', 500, 53.00),
            ]
cur.executemany('INSERT INTO stocks VALUES (?,?,?,?,?)', purchases)
SELECT 文を実行した後データを取得する方法は3つありどれを使っても構いません。一つはカーソルを イテレータ として扱う、一つはカーソルの fetchone() メソッドを呼んで一致した内の一行を取得する、もう一つは fetchall() メソッドを呼んで一致した全ての行のリストとして受け取る、という3つです。
以下の例ではイテレータの形を使います:
>>>
>>> for row in cur.execute('SELECT * FROM stocks ORDER BY price'):
        print(row)
('2006-01-05', 'BUY', 'RHAT', 100, 35.14)
('2006-03-28', 'BUY', 'IBM', 1000, 45.0)
('2006-04-06', 'SELL', 'IBM', 500, 53.0)
('2006-04-05', 'BUY', 'MSFT', 1000, 72.0)
参考
https://www.sqlite.org
SQLite のウェブページ。ここの文書ではサポートされる SQL 方言の文法と使えるデータ型を説明しています。
https://www.w3schools.com/sql/
SQL 学習に効くチュートリアル、リファレンス、実例集。
PEP 249 - Database API Specification 2.0
Marc-Andre Lemburg により書かれた PEP。
モジュールの関数と定数
sqlite3.version
文字列で表現されたモジュールのバージョン番号です。これは SQLite ライブラリのバージョンではありません。
sqlite3.version_info
整数のタプルで表現されたモジュールのバージョン番号です。これは SQLite ライブラリのバージョンではありません。
sqlite3.sqlite_version
文字列で表現された SQLite ランタイムライブラリのバージョン番号です。
sqlite3.sqlite_version_info
整数のタプルで表現された SQLite ランタイムライブラリのバージョン番号です。
sqlite3.PARSE_DECLTYPES
この定数は connect() 関数の detect_types パラメータとして使われます。
この定数を設定すると sqlite3 モジュールは戻り値のカラムの宣言された型を読み取るようになります。意味を持つのは宣言の最初の単語です。すなわち、"integer primary key" においては "integer" が読み取られます。また、 "number(10)" では、 "number" が読み取られます。そして、そのカラムに対して、変換関数の辞書を探してその型に対して登録された関数を使うようにします。
sqlite3.PARSE_COLNAMES
この定数は connect() 関数の detect_types パラメータとして使われます。
sqlite3.connect(database[, timeout, detect_types, isolation_level, check_same_thread, factory, cached_statements, uri])
database is a path-like object giving the pathname (absolute or relative to the current working directory) of the database file to be opened. You can use ":memory:" to open a database connection to a database that resides in RAM instead of on disk.
データベースが複数の接続からアクセスされている状況で、その内の一つがデータベースに変更を加えたとき、SQLite データベースはそのトランザクションがコミットされるまでロックされます。timeout パラメータで、例外を送出するまで接続がロックが解除されるのをどれだけ待つかを決めます。デフォルトは 5.0 (5秒) です。
isolation_level パラメータについては、 Connection オブジェクトの、 isolation_level プロパティを参照してください。
SQLite はネイティブで TEXT、INTEGER、REAL、BLOB および NULL のみをサポートしています。その他のタイプを使用したい場合はあなた自身で追加しなければなりません。detect_types パラメータおよび、register_converter() 関数でモジュールレベルで登録できるカスタム 変換関数 を使用することで簡単に追加できます。
detect_types defaults to 0 (i. e. off, no type detection), you can set it to any combination of PARSE_DECLTYPES and PARSE_COLNAMES to turn type detection on. Due to SQLite behaviour, types can't be detected for generated fields (for example max(data)), even when detect_types parameter is set. In such case, the returned type is str.
デフォルトでは、 sqlite3 モジュールは connect の呼び出しの際にモジュールの Connection クラスを使います。しかし、 Connection クラスを継承したクラスを factory パラメータに渡して connect() にそのクラスを使わせることもできます。
詳しくはこのマニュアルの SQLite と Python の型 節を参考にしてください。
sqlite3 モジュールは SQL 解析のオーバーヘッドを避けるために内部で文キャッシュを使っています。接続に対してキャッシュされる文の数を自分で指定したいならば、 cached_statements パラメータに設定してください。現在の実装ではデフォルトでキャッシュされる SQL 文の数を 100 にしています。
uri が真の場合、 database は URI として解釈されます。これにより、オプションを指定することができます。例えば、データベースを読み出し専用モードで使用できるように開くには、次のようにします:
db = sqlite3.connect('file:path/to/database?mode=ro', uri=True)
バージョン 3.4 で変更: uri パラメータが追加されました。
バージョン 3.7 で変更: database can now also be a path-like object, not only a string.
sqlite3.register_converter(typename, callable)
sqlite3.register_adapter(type, callable)
自分が使いたい Python の型 type を SQLite がサポートしている型に変換する呼び出し可能オブジェクト (callable) を登録します。その呼び出し可能オブジェクト callable はただ一つの引数に Python の値を受け取り、int, float, str または bytes のいずれかの型の値を返さなければなりません。
sqlite3.complete_statement(sql)
文字列 sql がセミコロンで終端された一つ以上の完全な SQL 文を含んでいる場合、 True を返します。判定は SQL 文として文法的に正しいかではなく、閉じられていない文字列リテラルが無いことおよびセミコロンで終端されていることだけで行われます。
この関数は以下の例にあるような SQLite のシェルを作る際に使われます:
# A minimal SQLite shell for experiments
import sqlite3
con = sqlite3.connect(":memory:")
con.isolation_level = None
cur = con.cursor()
buffer = ""
print("Enter your SQL commands to execute in sqlite3.")
print("Enter a blank line to exit.")
while True:
    line = input()
    if line == "":
        break
    buffer += line
    if sqlite3.complete_statement(buffer):
        try:
            buffer = buffer.strip()
            cur.execute(buffer)
            if buffer.lstrip().upper().startswith("SELECT"):
                print(cur.fetchall())
        except sqlite3.Error as e:
            print("An error occurred:", e.args[0])
        buffer = ""
con.close()
sqlite3.enable_callback_tracebacks(flag)
デフォルトでは、ユーザ定義の関数、集計関数、変換関数、認可コールバックなどはトレースバックを出力しません。デバッグの際にはこの関数を flag に True を指定して呼び出します。そうした後は先に述べたような関数のトレースバックが sys.stderr に出力されます。元に戻すには False を使います。
Connection オブジェクト
class sqlite3.Connection
SQLite データベースコネクション。以下の属性やメソッドを持ちます:
isolation_level
in_transaction
トランザクションがアクティブなら (未コミットの変更があるなら) True 、そうでなければ False 。リードオンリー属性です。
バージョン 3.2 で追加.
cursor(factory=Cursor)
cursor メソッドはオション引数 factory を 1 つだけ受け付けます。 渡された場合は、 Cursor またはそのサブクラスのインスタンスを返す呼び出し可能オブジェクトでなければなりません。
commit()
このメソッドは現在のトランザクションをコミットします。このメソッドを呼ばないと、前回 commit() を呼び出してから行ったすべての変更は、他のデータベースコネクションから見ることができません。もし、データベースに書き込んだはずのデータが見えなくて悩んでいる場合は、このメソッドの呼び出しを忘れていないかチェックしてください。
rollback()
このメソッドは最後に行った commit() 後の全ての変更をロールバックします。
close()
このメソッドはデータベースコネクションを閉じます。このメソッドが自動的に commit() を呼び出さないことに注意してください。 commit() をせずにコネクションを閉じると、変更が消えてしまいます！
execute(sql[, parameters])
executemany(sql[, parameters])
executescript(sql_script)
create_function(name, num_params, func, *, deterministic=False)
バージョン 3.8 で変更: The deterministic parameter was added.
例:
import sqlite3
import hashlib
def md5sum(t):
    return hashlib.md5(t).hexdigest()
con = sqlite3.connect(":memory:")
con.create_function("md5", 1, md5sum)
cur = con.cursor()
cur.execute("select md5(?)", (b"foo",))
print(cur.fetchone()[0])
con.close()
create_aggregate(name, num_params, aggregate_class)
ユーザ定義の集計関数を作成します。
例:
import sqlite3
class MySum:
    def __init__(self):
        self.count = 0
    def step(self, value):
        self.count += value
    def finalize(self):
        return self.count
con = sqlite3.connect(":memory:")
con.create_aggregate("mysum", 1, MySum)
cur = con.cursor()
cur.execute("create table test(i)")
cur.execute("insert into test(i) values (1)")
cur.execute("insert into test(i) values (2)")
cur.execute("select mysum(i) from test")
print(cur.fetchone()[0])
con.close()
create_collation(name, callable)
name と callable で指定される照合順序を作成します。呼び出し可能オブジェクトには二つの文字列が渡されます。一つめのものが二つめのものより低く順序付けられるならば -1 を返し、等しければ 0 を返し、一つめのものが二つめのものより高く順序付けられるならば 1 を返すようにしなければなりません。この関数はソート(SQL での ORDER BY)をコントロールするもので、比較を行なうことは他の SQL 操作には影響を与えないことに注意しましょう。
また、呼び出し可能オブジェクトに渡される引数は Python のバイト文字列として渡されますが、それは通常 UTF-8 で符号化されたものになります。
以下の例は「間違った方法で」ソートする自作の照合順序です:
import sqlite3
def collate_reverse(string1, string2):
    if string1 == string2:
        return 0
    elif string1 < string2:
        return 1
    else:
        return -1
con = sqlite3.connect(":memory:")
con.create_collation("reverse", collate_reverse)
cur = con.cursor()
cur.execute("create table test(x)")
cur.executemany("insert into test(x) values (?)", [("a",), ("b",)])
cur.execute("select x from test order by x collate reverse")
for row in cur:
    print(row)
con.close()
照合順序を取り除くには callable に None を指定して create_collation を呼び出します:
con.create_collation("reverse", None)
interrupt()
このメソッドを別スレッドから呼び出して接続上で現在実行中であろうクエリを中断させられます。クエリが中断されると呼び出し元は例外を受け取ります。
set_authorizer(authorizer_callback)
このルーチンはコールバックを登録します。コールバックはデータベースのテーブルのカラムにアクセスしようとするたびに呼び出されます。コールバックはアクセスが許可されるならば SQLITE_OK を、SQL 文全体がエラーとともに中断されるべきならば SQLITE_DENY を、カラムが NULL 値として扱われるべきなら SQLITE_IGNORE を返さなければなりません。これらの定数は sqlite3 モジュールに用意されています。
コールバックの第一引数はどの種類の操作が許可されるかを決めます。第二第三引数には第一引数に依存して本当に使われる引数か None かが渡されます。第四引数はもし適用されるならばデータベースの名前("main", "temp", etc.)です。第五引数はアクセスを試みる要因となった最も内側のトリガまたはビューの名前、またはアクセスの試みが入力された SQL コードに直接起因するものならば None です。
第一引数に与えることができる値や、その第一引数によって決まる第二第三引数の意味については、SQLite の文書を参考にしてください。必要な定数は全て sqlite3 モジュールに用意されています。
set_progress_handler(handler, n)
このメソッドはコールバックを登録します。コールバックは SQLite 仮想マシン上の n 個の命令を実行するごとに呼び出されます。これは、GUI 更新などのために、長時間かかる処理中に SQLite からの呼び出しが欲しい場合に便利です。
以前登録した progress handler をクリアしたい場合は、このメソッドを、 handler 引数に None を渡して呼び出してください。
set_trace_callback(trace_callback)
各 SQL 文が SQLite バックエンドによって実際に実行されるたびに呼び出される trace_callback を登録します。
コールバックに渡される唯一の引数は、実行されている SQL 文 (の文字列)です。コールバックの戻り値は無視されます。バックエンドは Cursor.execute() メソッドに渡された SQL 文だけを実行するわけではないことに注意してください。他のソースには、 Python モジュールのトランザクション管理や、現在のデータベースに定義されたトリガーの実行が含まれます。
trace_callback として None を渡すと、トレースコールバックを無効にできます。
バージョン 3.3 で追加.
enable_load_extension(enabled)
このメソッドは SQLite エンジンが共有ライブラリから SQLite 拡張を読み込むのを許可したり、禁止したりします。SQLite 拡張は新しい関数や集計関数や仮想テーブルの実装を定義できます。1つの有名な拡張は SQLite によって頒布されている全テキスト検索拡張です。
SQLite 拡張はデフォルトで無効にされています。1 を見てください。
バージョン 3.2 で追加.
import sqlite3
con = sqlite3.connect(":memory:")
# enable extension loading
con.enable_load_extension(True)
# Load the fulltext search extension
con.execute("select load_extension('./fts3.so')")
# alternatively you can load the extension using an API call:
# con.load_extension("./fts3.so")
# disable extension loading again
con.enable_load_extension(False)
# example from SQLite wiki
con.execute("create virtual table recipe using fts3(name, ingredients)")
con.executescript("""
    insert into recipe (name, ingredients) values ('broccoli stew', 'broccoli peppers cheese tomatoes');
    insert into recipe (name, ingredients) values ('pumpkin stew', 'pumpkin onions garlic celery');
    insert into recipe (name, ingredients) values ('broccoli pie', 'broccoli cheese onions flour');
    insert into recipe (name, ingredients) values ('pumpkin pie', 'pumpkin sugar flour butter');
    """)
for row in con.execute("select rowid, name, ingredients from recipe where name match 'pie'"):
    print(row)
con.close()
load_extension(path)
このメソッドは共有ライブラリから SQLite 拡張を読み込みます。このメソッドを使う前に enable_load_extension() で拡張の読み込みを許可しておかなくてはなりません。
SQLite 拡張はデフォルトで無効にされています。1 を見てください。
バージョン 3.2 で追加.
row_factory
この属性を変更して、カーソルと元の行をタプル形式で受け取り、本当の結果の行を返す呼び出し可能オブジェクトにすることができます。これによって、より進んだ結果の返し方を実装することができます。例えば、各列に列名でもアクセスできるようなオブジェクトを返すことができます。
例:
import sqlite3
def dict_factory(cursor, row):
    d = {}
    for idx, col in enumerate(cursor.description):
        d[col[0]] = row[idx]
    return d
con = sqlite3.connect(":memory:")
con.row_factory = dict_factory
cur = con.cursor()
cur.execute("select 1 as a")
print(cur.fetchone()["a"])
con.close()
タプルを返すのでは物足りず、名前に基づいて列へアクセスしたい場合は、 row_factory に高度に最適化された sqlite3.Row 型を設定することを検討してください。 Row クラスではインデックスでも大文字小文字を無視した名前でも列にアクセスでき、しかもほとんどメモリーを浪費しません。おそらく独自実装の辞書を使うアプローチよりも良いもので、もしかすると db の行に基づいた解法よりも優れているかもしれません。
text_factory
この属性を使って TEXT データ型をどのオブジェクトで返すかを制御できます。デフォルトではこの属性は str に設定されており、 sqlite3 モジュールは TEXT を Unicode オブジェクトで返します。もしバイト列で返したいならば、 bytes に設定してください。
バイト列を受け取って望みの型のオブジェクトを返すような呼び出し可能オブジェクトを何でも設定して構いません。
以下の説明用のコード例を参照してください:
import sqlite3
con = sqlite3.connect(":memory:")
cur = con.cursor()
AUSTRIA = "\xd6sterreich"
# by default, rows are returned as Unicode
cur.execute("select ?", (AUSTRIA,))
row = cur.fetchone()
assert row[0] == AUSTRIA
# but we can make sqlite3 always return bytestrings ...
con.text_factory = bytes
cur.execute("select ?", (AUSTRIA,))
row = cur.fetchone()
assert type(row[0]) is bytes
# the bytestrings will be encoded in UTF-8, unless you stored garbage in the
# database ...
assert row[0] == AUSTRIA.encode("utf-8")
# we can also implement a custom text_factory ...
# here we implement one that appends "foo" to all strings
con.text_factory = lambda x: x.decode("utf-8") + "foo"
cur.execute("select ?", ("bar",))
row = cur.fetchone()
assert row[0] == "barfoo"
con.close()
total_changes
データベース接続が開始されて以来の行の変更・挿入・削除がなされた行の総数を返します。
iterdump()
データベースをSQL testフォーマットでダンプするためのイテレータを返します。 メモリ内のデータベースの内容を、後で復元するために保存する場合に便利です。この関数には、 sqlite3 シェルの中の .dump コマンドと同じ機能があります。
以下はプログラム例です:
# Convert file existing_db.db to SQL dump file dump.sql
import sqlite3
con = sqlite3.connect('existing_db.db')
with open('dump.sql', 'w') as f:
    for line in con.iterdump():
        f.write('%s\n' % line)
con.close()
backup(target, *, pages=-1, progress=None, name="main", sleep=0.250)
Example 1, copy an existing database into another:
import sqlite3
def progress(status, remaining, total):
    print(f'Copied {total-remaining} of {total} pages...')
con = sqlite3.connect('existing_db.db')
bck = sqlite3.connect('backup.db')
with bck:
    con.backup(bck, pages=1, progress=progress)
bck.close()
con.close()
Example 2, copy an existing database into a transient copy:
import sqlite3
source = sqlite3.connect('existing_db.db')
dest = sqlite3.connect(':memory:')
source.backup(dest)
Availability: SQLite 3.6.11 or higher
バージョン 3.7 で追加.
カーソルオブジェクト
class sqlite3.Cursor
Cursor インスタンスは以下の属性やメソッドを持ちます。
execute(sql[, parameters])
SQL 文を実行します。SQL 文はパラメータ化できます(すなわち SQL リテラルの代わりの場所確保文字 (placeholder) を入れておけます)。 sqlite3 モジュールは2種類の場所確保記法をサポートします。一つは疑問符(qmark スタイル)、もう一つは名前(named スタイル)です。
両方のスタイルの例です:
import sqlite3
con = sqlite3.connect(":memory:")
cur = con.cursor()
cur.execute("create table people (name_last, age)")
who = "Yeltsin"
age = 72
# This is the qmark style:
cur.execute("insert into people values (?, ?)", (who, age))
# And this is the named style:
cur.execute("select * from people where name_last=:who and age=:age", {"who": who, "age": age})
print(cur.fetchone())
con.close()
execute() will only execute a single SQL statement. If you try to execute more than one statement with it, it will raise a Warning. Use executescript() if you want to execute multiple SQL statements with one call.
executemany(sql, seq_of_parameters)
import sqlite3
class IterChars:
    def __init__(self):
        self.count = ord('a')
    def __iter__(self):
        return self
    def __next__(self):
        if self.count > ord('z'):
            raise StopIteration
        self.count += 1
        return (chr(self.count - 1),) # this is a 1-tuple
con = sqlite3.connect(":memory:")
cur = con.cursor()
cur.execute("create table characters(c)")
theIter = IterChars()
cur.executemany("insert into characters(c) values (?)", theIter)
cur.execute("select c from characters")
print(cur.fetchall())
con.close()
もう少し短い ジェネレータ を使った例です:
import sqlite3
import string
def char_generator():
    for c in string.ascii_lowercase:
        yield (c,)
con = sqlite3.connect(":memory:")
cur = con.cursor()
cur.execute("create table characters(c)")
cur.executemany("insert into characters(c) values (?)", char_generator())
cur.execute("select c from characters")
print(cur.fetchall())
con.close()
executescript(sql_script)
これは非標準の便宜メソッドで、一度に複数の SQL 文を実行することができます。メソッドは最初に COMMIT 文を発行し、次いで引数として渡された SQLスクリプトを実行します。
sql_script can be an instance of str.
例:
import sqlite3
con = sqlite3.connect(":memory:")
cur = con.cursor()
cur.executescript("""
    create table person(
        firstname,
        lastname,
        age
    );
    create table book(
        title,
        author,
        published
    );
    insert into book(title, author, published)
    values (
        'Dirk Gently''s Holistic Detective Agency',
        'Douglas Adams',
        1987
    );
    """)
con.close()
fetchone()
クエリ結果から次の row をフェッチして、1つのシーケンスを返します。これ以上データがない場合は None を返します。
fetchmany(size=cursor.arraysize)
クエリ結果から次の幾つかの row をフェッチして、リストを返します。これ以上データがない場合は空のリストを返します。
一回の呼び出しで返される row の数は、size 引数で指定できます。この引数が与えられない場合、cursor の arraysize 属性が利用されます。このメソッドは可能な限り指定された size の数の row を fetch しようとするべきです。もし、指定された数の row が利用可能でない場合、それより少ない数の row が返されます。
size 引数とパフォーマンスの関係についての注意です。パフォーマンスを最適化するためには、大抵、 arraysize 属性を利用するのがベストです。 size 引数を利用したのであれば、次の fetchmany() の呼び出しでも同じ数を利用するのがベストです。
fetchall()
全ての(残りの)クエリ結果の row をフェッチして、リストを返します。cursor の arraysize 属性がこの操作のパフォーマンスに影響することに気をつけてください。これ以上の row がない場合は、空のリストが返されます。
close()
rowcount
一応 sqlite3 モジュールの Cursor クラスはこの属性を実装していますが、データベースエンジン自身の「影響を受けた行」/「選択された行」の決定方法は少し風変わりです。
executemany() では、変更数が rowcount に合計されます。
Python DB API 仕様で要求されるように、rowcount 属性は「カーソルに対して executeXX() が行なわれていないか、最後の操作の rowcount がインターフェースによって決定できなかった場合は -1 」です。これには SELECT 文も含まれます。すべての列を取得するまでクエリによって生じた列の数を決定できないからです。
SQLite のバージョン 3.6.5 以前は、条件なしで DELETE FROM table を実行すると rowcount が 0 にセットされます。
lastrowid
バージョン 3.6 で変更: Added support for the REPLACE statement.
arraysize
description
この読み出し専用の属性は、最後のクエリの結果のカラム名を提供します。 Python DB API との互換性を維持するために、各カラムに対して 7つのタプルを返しますが、タプルの後ろ6つの要素は全て None です。
この属性は SELECT 文にマッチする row が1つもなかった場合でもセットされます。
connection
この読み出し専用の属性は、 Cursor オブジェクトが使用する SQLite データベースの Connection を提供します。con.cursor() を呼び出すことにより作成される Cursor オブジェクトは、 con を参照する connection 属性を持ちます:
>>>
>>> con = sqlite3.connect(":memory:")
>>> cur = con.cursor()
>>> cur.connection == con
True
Row オブジェクト
class sqlite3.Row
Row インスタンスは、 Connection オブジェクトの row_factory として高度に最適化されています。タプルによく似た機能を持つ row を作成します。
カラム名とインデックスによる要素へのアクセス, イテレーション, repr(), 同値テスト, len() をサポートしています。
もし、2つの Row オブジェクトが完全に同じカラムと値を持っていた場合、それらは同値になります。
keys()
このメソッドはカラム名のリストを返します。クエリ直後から、これは Cursor.description の各タプルの最初のメンバになります。
バージョン 3.5 で変更: スライスがサポートされました。
Rowの例のために、まずサンプルのテーブルを初期化します:
con = sqlite3.connect(":memory:")
cur = con.cursor()
cur.execute('''create table stocks
(date text, trans text, symbol text,
 qty real, price real)''')
cur.execute("""insert into stocks
            values ('2006-01-05','BUY','RHAT',100,35.14)""")
con.commit()
cur.close()
そして、 Row を使ってみます:
>>>
>>> con.row_factory = sqlite3.Row
>>> cur = con.cursor()
>>> cur.execute('select * from stocks')
<sqlite3.Cursor object at 0x7f4e7dd8fa80>
>>> r = cur.fetchone()
>>> type(r)
<class 'sqlite3.Row'>
>>> tuple(r)
('2006-01-05', 'BUY', 'RHAT', 100.0, 35.14)
>>> len(r)
5
>>> r[2]
'RHAT'
>>> r.keys()
['date', 'trans', 'symbol', 'qty', 'price']
>>> r['qty']
100.0
>>> for member in r:
...     print(member)
...
2006-01-05
BUY
RHAT
100.0
35.14
例外
exception sqlite3.Warning
exception sqlite3.Error
このモジュールにおける他の例外クラスの基底クラスです。 Exception のサブクラスです。
exception sqlite3.DatabaseError
exception sqlite3.IntegrityError
exception sqlite3.ProgrammingError
exception sqlite3.OperationalError
exception sqlite3.NotSupportedError
SQLite と Python の型
はじめに
SQLite は以下の型をネイティブにサポートします: NULL, INTEGER, REAL, TEXT, BLOB。
したがって、次の Python の型は問題なく SQLite に送り込めます:
Python の型
SQLite の型
None
NULL
int
INTEGER
float
REAL
str
TEXT
bytes
BLOB
SQLite の型から Python の型へのデフォルトでの変換は以下の通りです:
SQLite の型
Python の型
NULL
None
INTEGER
int
REAL
float
TEXT
text_factory に依存する。デフォルトでは str 。
BLOB
bytes
sqlite3 モジュールの型システムは二つの方法で拡張できます。一つはオブジェクト適合(adaptation)を通じて追加された Python の型を SQLite に格納することです。もう一つは変換関数(converter)を通じて sqlite3 モジュールに SQLite の型を違った Python の型に変換させることです。
追加された Python の型を SQLite データベースに格納するために適合関数を使う
既に述べたように、SQLite が最初からサポートする型は限られたものだけです。それ以外の Python の型を SQLite で使うには、その型を sqlite3 モジュールがサポートしている型の一つに 適合 させなくてはなりません。サポートしている型というのは、NoneType, int, float, str, bytes です。
sqlite3 モジュールで望みの Python の型をサポートされている型の一つに適合させる方法は二つあります。
オブジェクト自身で適合するようにする
自分でクラスを書いているならばこの方法が良いでしょう。次のようなクラスがあるとします:
class Point:
    def __init__(self, x, y):
        self.x, self.y = x, y
import sqlite3
class Point:
    def __init__(self, x, y):
        self.x, self.y = x, y
    def __conform__(self, protocol):
        if protocol is sqlite3.PrepareProtocol:
            return "%f;%f" % (self.x, self.y)
con = sqlite3.connect(":memory:")
cur = con.cursor()
p = Point(4.0, -3.2)
cur.execute("select ?", (p,))
print(cur.fetchone()[0])
con.close()
適合関数を登録する
もう一つの可能性は型を文字列表現に変換する関数を作り register_adapter() でその関数を登録することです。
import sqlite3
class Point:
    def __init__(self, x, y):
        self.x, self.y = x, y
def adapt_point(point):
    return "%f;%f" % (point.x, point.y)
sqlite3.register_adapter(Point, adapt_point)
con = sqlite3.connect(":memory:")
cur = con.cursor()
p = Point(4.0, -3.2)
cur.execute("select ?", (p,))
print(cur.fetchone()[0])
con.close()
sqlite3 モジュールには二つの Python 標準型 datetime.date と datetime.datetime に対するデフォルト適合関数があります。いま datetime.datetime オブジェクトを ISO 表現でなく Unix タイムスタンプとして格納したいとしましょう。
import sqlite3
import datetime
import time
def adapt_datetime(ts):
    return time.mktime(ts.timetuple())
sqlite3.register_adapter(datetime.datetime, adapt_datetime)
con = sqlite3.connect(":memory:")
cur = con.cursor()
now = datetime.datetime.now()
cur.execute("select ?", (now,))
print(cur.fetchone()[0])
con.close()
SQLite の値を好きな Python 型に変換する
適合関数を書くことで好きな Python 型を SQLite に送り込めるようになりました。しかし、本当に使い物になるようにするには Python から SQLite さらに Python へという往還(roundtrip)の変換ができる必要があります。
そこで変換関数(converter)です。
Point クラスの例に戻りましょう。x, y 座標をセミコロンで区切った文字列として SQLite に格納したのでした。
まず、文字列を引数として取り Point オブジェクトをそれから構築する変換関数を定義します。
注釈 変換関数は SQLite に送り込んだデータ型に関係なく 常に bytes オブジェクトを渡されます。
def convert_point(s):
    x, y = map(float, s.split(b";"))
    return Point(x, y)
次に sqlite3 モジュールにデータベースから取得したものが本当に点であることを教えなければなりません。二つの方法があります:
宣言された型を通じて暗黙的に
カラム名を通じて明示的に
どちらの方法も モジュールの関数と定数 節の中で説明されています。それぞれ PARSE_DECLTYPES 定数と PARSE_COLNAMES 定数の項目です。
以下の例で両方のアプローチを紹介します。
import sqlite3
class Point:
    def __init__(self, x, y):
        self.x, self.y = x, y
    def __repr__(self):
        return "(%f;%f)" % (self.x, self.y)
def adapt_point(point):
    return ("%f;%f" % (point.x, point.y)).encode('ascii')
def convert_point(s):
    x, y = list(map(float, s.split(b";")))
    return Point(x, y)
# Register the adapter
sqlite3.register_adapter(Point, adapt_point)
# Register the converter
sqlite3.register_converter("point", convert_point)
p = Point(4.0, -3.2)
#########################
# 1) Using declared types
con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES)
cur = con.cursor()
cur.execute("create table test(p point)")
cur.execute("insert into test(p) values (?)", (p,))
cur.execute("select p from test")
print("with declared types:", cur.fetchone()[0])
cur.close()
con.close()
#######################
# 1) Using column names
con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)
cur = con.cursor()
cur.execute("create table test(p)")
cur.execute("insert into test(p) values (?)", (p,))
cur.execute('select p as "p [point]" from test')
print("with column names:", cur.fetchone()[0])
cur.close()
con.close()
デフォルトの適合関数と変換関数
datetime モジュールの date 型および datetime 型のためのデフォルト適合関数があります。これらの型は ISO 日付 / ISO タイムスタンプとして SQLite に送られます。
デフォルトの変換関数は datetime.date 用が "date" という名前で、 datetime.datetime 用が "timestamp" という名前で登録されています。
これにより、多くの場合特別な細工無しに Python の日付 / タイムスタンプを使えます。適合関数の書式は実験的な SQLite の date/time 関数とも互換性があります。
以下の例でこのことを確かめます。
import sqlite3
import datetime
con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)
cur = con.cursor()
cur.execute("create table test(d date, ts timestamp)")
today = datetime.date.today()
now = datetime.datetime.now()
cur.execute("insert into test(d, ts) values (?, ?)", (today, now))
cur.execute("select d, ts from test")
row = cur.fetchone()
print(today, "=>", row[0], type(row[0]))
print(now, "=>", row[1], type(row[1]))
cur.execute('select current_date as "d [date]", current_timestamp as "ts [timestamp]"')
row = cur.fetchone()
print("current_date", row[0], type(row[0]))
print("current_timestamp", row[1], type(row[1]))
con.close()
SQLite に格納されているタイムスタンプが6桁より長い小数部を持っている場合、タイムスタンプの変換関数によってマイクロ秒精度に丸められます。
トランザクション制御
autocommit mode means that statements that modify the database take effect immediately. A BEGIN or SAVEPOINT statement disables autocommit mode, and a COMMIT, a ROLLBACK, or a RELEASE that ends the outermost transaction, turns autocommit mode back on.
バージョン 3.6 で変更: sqlite3 used to implicitly commit an open transaction before DDL statements. This is no longer the case.
sqlite3 の効率的な使い方
ショートカットメソッドを使う
Connection オブジェクトの非標準的なメソッド execute(), executemany(), executescript() を使うことで、 (しばしば余計な) Cursor オブジェクトをわざわざ作り出さずに済むので、コードをより簡潔に書くことができます。 Cursor オブジェクトは暗黙裡に生成されショートカットメソッドの戻り値として受け取ることができます。この方法を使えば、 SELECT 文を実行してその結果について反復することが、 Connection オブジェクトに対する呼び出し一つで行なえます。
import sqlite3
persons = [
    ("Hugo", "Boss"),
    ("Calvin", "Klein")
    ]
con = sqlite3.connect(":memory:")
# Create the table
con.execute("create table person(firstname, lastname)")
# Fill the table
con.executemany("insert into person(firstname, lastname) values (?, ?)", persons)
# Print the table contents
for row in con.execute("select firstname, lastname from person"):
    print(row)
print("I just deleted", con.execute("delete from person").rowcount, "rows")
# close is not a shortcut method and it's not called automatically,
# so the connection object should be closed manually
con.close()
位置ではなく名前でカラムにアクセスする
sqlite3 モジュールの有用な機能の一つに、行生成関数として使われるための sqlite3.Row クラスがあります。
このクラスでラップされた行は、位置インデクス(タプルのような)でも大文字小文字を区別しない名前でもアクセスできます:
import sqlite3
con = sqlite3.connect(":memory:")
con.row_factory = sqlite3.Row
cur = con.cursor()
cur.execute("select 'John' as name, 42 as age")
for row in cur:
    assert row[0] == row["name"]
    assert row["name"] == row["nAmE"]
    assert row[1] == row["age"]
    assert row[1] == row["AgE"]
con.close()
コネクションをコンテキストマネージャーとして利用する
Connection オブジェクトはコンテキストマネージャーとして利用して、トランザクションを自動的にコミットしたりロールバックすることができます。例外が発生したときにトランザクションはロールバックされ、それ以外の場合、トランザクションはコミットされます:
import sqlite3
con = sqlite3.connect(":memory:")
con.execute("create table person (id integer primary key, firstname varchar unique)")
# Successful, con.commit() is called automatically afterwards
with con:
    con.execute("insert into person(firstname) values (?)", ("Joe",))
# con.rollback() is called after the with block finishes with an exception, the
# exception is still raised and must be caught
try:
    with con:
        con.execute("insert into person(firstname) values (?)", ("Joe",))
except sqlite3.IntegrityError:
    print("couldn't add Joe twice")
# Connection object used as context manager only commits or rollbacks transactions,
# so the connection object should be closed manually
con.close()
string --- 一般的な文字列操作
ソースコード: Lib/string.py
参考 テキストシーケンス型 --- str
文字列メソッド
文字列定数
このモジュールで定義されている定数は以下の通りです:
string.ascii_letters
後述の ascii_lowercase と ascii_uppercase を合わせたもの。この値はロケールに依存しません。
string.ascii_lowercase
小文字 'abcdefghijklmnopqrstuvwxyz' 。この値はロケールに依存せず、固定です。
string.ascii_uppercase
大文字 'ABCDEFGHIJKLMNOPQRSTUVWXYZ' 。この値はロケールに依存せず、固定です。
string.digits
文字列 '0123456789' です。
string.hexdigits
文字列 '0123456789abcdefABCDEF' です。
string.octdigits
文字列 '01234567' です。
string.punctuation
string.printable
印刷可能な ASCII 文字で構成される文字列です。 digits, ascii_letters, punctuation および whitespace を組み合わせたものです。
string.whitespace
空白 (whitespace) として扱われる ASCII 文字全てを含む文字列です。ほとんどのシステムでは、これはスペース (space)、タブ (tab)、改行 (linefeed)、復帰 (return)、改頁 (formfeed)、垂直タブ (vertical tab) です。
カスタムの文字列書式化
組み込みの文字列 (string) クラスには、 PEP 3101 で記述されている format() メソッドによって複雑な変数置換と値のフォーマットを行う機能があります。 string モジュールの Formatter クラスでは、組み込みの format() メソッドと同じ実装を使用して、独自の文字列フォーマットの振る舞いを作成してカスタマイズすることができます。
class string.Formatter
Formatter クラスは、以下のメソッドを持ちます:
format(format_string, /, *args, **kwargs)
主要な API メソッドです。書式文字列と、任意の位置引数およびキーワード引数のセットを取ります。これは、vformat() を呼び出す単なるラッパーです。
バージョン 3.7 で変更: 書式文字列は 位置専用 の引数となりました。
vformat(format_string, args, kwargs)
この関数はフォーマットの実際の仕事をします。この関数は、 *args および **kwargs シンタックスを使用して、辞書を個々の引数として unpack してから再度 pack するのではなく、引数としてあらかじめ用意した辞書を渡したい場合のために、独立した関数として公開されます。 vformat() は、書式文字列を文字データと置換フィールドに分解する仕事をします。それは、以下に記述する様々なメソッドを呼び出します。
さらに、 Formatter ではサブクラスによって置き換えられることを意図した次のようないくつかのメソッドが定義されています。
parse(format_string)
format_stringを探査し、タプル、 (literal_text, field_name, format_spec, conversion) のイテラブルを返します。これは vformat() が文字列を文字としての文字データや置換フィールドに展開するために使用されます。
タプルの値は、概念的に文字としての文字データと、それに続く単一の置換フィールドを表現します。文字としての文字データが無い場合は (ふたつの置換フィールドが連続した場合などに起き得ます) 、 literal_text は長さが 0 の文字列となります。置換フィールドが無い場合は、 field_name, format_spec および conversion が None となります。
get_field(field_name, args, kwargs)
引数として与えた parse() (上記参照) により返される field_name を書式指定対象オブジェクトに変換します。返り値はタプル、 (obj, used_key) です。デフォルトでは PEP 3101 に規定される "0[name]" や "label.title" のような形式の文字列を引数としてとります。 args と kwargs は vformat() に渡されます。返り値 used_key は、 get_value() の key 引数と同じ意味を持ちます。
get_value(key, args, kwargs)
与えられたフィールドの値を取り出します。 key 引数は整数でも文字列でも構いません。整数の場合は、位置引数 args のインデックス番号を示します。文字列の場合は、名前付きの引数 kwargs を意味します。
args 引数は、 vformat() への位置引数のリストに設定され、 kwargs 引数は、キーワード引数の辞書に設定されます。
つまり、例えば、フィールドが '0.name' と表現されるとき、 get_value() は、 key 引数が 0 として呼び出されます。属性 name は、組み込みの getattr() 関数が呼び出され、 get_value() が返されたのちに検索されます。
インデックスまたはキーワードが存在しないアイテムを参照した場合、 IndexError または KeyError が送出されます。
check_unused_args(used_args, args, kwargs)
希望に応じて未使用の引数がないか確認する機能を実装します。この関数への引数は、書式指定文字列で実際に参照されるすべての引数のキーの set (位置引数の整数、名前付き引数の文字列) と、vformat に渡される args と kwargs への参照です。使用されない引数の set は、これらのパラメータから計算されます。 check_unused_args() は、確認の結果が偽である場合に例外を送出するものとみなされます。
format_field(value, format_spec)
format_field() は単純に組み込みのグローバル関数 format() を呼び出します。このメソッドは、サブクラスをオーバーライドするために提供されます。
convert_field(value, conversion)
(get_field() が返す) 値を (parse() メソッドが返すタプルの形式で) 与えられた変換タイプとして変換します。デフォルトバージョンは 's' (str), 'r' (repr), 'a' (ascii) 変換タイプを理解します。
書式指定文字列の文法
str.format() メソッドと Formatter クラスは、文字列の書式指定に同じ文法を共有します (ただし、 Formatter サブクラスでは、独自の書式指定文法を定義することが可能です)。 この文法は フォーマット済み文字列リテラル の文法と関係してはいますが、異なるものです。
書式指定文字列は波括弧 {} に囲まれた "置換フィールド" を含みます。波括弧に囲まれた部分以外は全て単純な文字として扱われ、変更を加えることなく出力へコピーされます。波括弧を文字として扱う必要がある場合は、二重にすることでエスケープすることができます: {{ および }} 。
置換フィールドの文法は以下です:
replacement_field ::=  "{" [field_name] ["!" conversion] [":" format_spec] "}"
field_name        ::=  arg_name ("." attribute_name | "[" element_index "]")*
arg_name          ::=  [identifier | digit+]
attribute_name    ::=  identifier
element_index     ::=  digit+ | index_string
index_string      ::=  <any source character except "]"> +
conversion        ::=  "r" | "s" | "a"
format_spec       ::=  <described in the next section>
もっと簡単にいうと、置換フィールドは field_name で始められます。これによって指定したオブジェクトの値が、置換フィールドの代わりに書式化され出力に挿入されます。field_name の後に、感嘆符 '!' を挟んで conversion フィールドを続けることができます。最後にコロン ':' を挟んで、 format_spec を書くことができます。これは、置換される値の非デフォルトの書式を指定します。
書式指定ミニ言語仕様 節も参照して下さい。
field_name それ自身は、数かキーワードのいずれかである arg_name から始まります。それが数である場合、位置引数を参照します。また、それがキーワードである場合、指定されたキーワード引数を参照します。書式文字列中で数の arg_names が順に 0, 1, 2, ... である場合、それらはすべて (いくつかではありません) 省略することができます。そして数 0, 1, 2, ... は、自動的にその順で挿入されます。 arg_name は引用符で区切られていないので、書式文字列内の任意の辞書キー (例えば文字列 '10' や ':-]' など) を指定することはできません。 arg_name の後に任意の数のインデックス式または属性式を続けることができます。 '.name' 形式の式は getattr() を使用して指定された属性を選択します。一方、 '[index]' 形式の式は __getitem__() を使用してインデックス参照を行います。
バージョン 3.1 で変更: str.format() を使い、位置引数指定を省略することができます。 '{} {}'.format(a, b) は '{0} {1}'.format(a, b) と同じになります。
バージョン 3.4 で変更: Formatter を使い、位置引数指定を省略することができます。
簡単な書式指定文字列の例を挙げます:
"First, thou shalt count to {0}"  # References first positional argument
"Bring me a {}"                   # Implicitly references the first positional argument
"From {} to {}"                   # Same as "From {0} to {1}"
"My quest is {name}"              # References keyword argument 'name'
"Weight in tons {0.weight}"       # 'weight' attribute of first positional arg
"Units destroyed: {players[0]}"   # First element of keyword argument 'players'.
置換 (conversion) フィールドにより書式変換前に型の強制変換が実施されます。通常、値の書式変換は __format__() によって実施されます。しかしながら、場合によっては、文字列として変換することを強制したり、書式指定の定義をオーバーライドしたくなることもあります。 __format__() の呼び出し前に値を文字列に変換すると、通常の書式変換の処理は飛ばされます。
現在 3つの変換フラグがサポートされています: 値に対して str() を呼ぶ '!s' 、 repr() を呼ぶ '!r' 、 ascii() を呼ぶ '!a'。
いくつかの例です:
"Harold's a clever {0!s}"        # Calls str() on the argument first
"Bring out the holy {name!r}"    # Calls repr() on the argument first
"More {!a}"                      # Calls ascii() on the argument first
format_spec フィールドは、フィールド幅、文字揃え、埋め方、精度などの、値を表現する仕様を含みます。それぞれの値の型は、 "formatting mini-language" 、または、 format_spec の実装で定義されます。
ほとんどの組み込み型は、次のセクションに記載された共通の formatting mini-language をサポートします。
format_spec フィールド内には入れ子になった置換フィールドを含めることもできます。入れ子になった置換フィールドにはフィールド名、変換フラグ、書式指定を含めることができますが、さらに入れ子の階層を含めることはできません。 format_spec 中の置換フィールドは format_spec 文字列が解釈される前に置き換えられます。これにより、値の書式を動的に指定することができます。
書式指定例 のいくつかの例も参照して下さい。
書式指定ミニ言語仕様
書式指定 ("Format specifications") は書式指定文字列の個々の値を表現する方法を指定するための、置換フィールドで使用されます (書式指定文字列の文法 および フォーマット済み文字列リテラル を参照してください) 。 それらは、組み込み関数の format() 関数に直接渡されます。 それぞれの書式指定可能な型について、書式指定がどのように解釈されるかが規定されます。
多くの組み込み型は、書式指定に関して以下のオプションを実装します。しかしながら、いくつかの書式指定オプションは数値型でのみサポートされます。
一般的な書式指定子 (standard format specifier) の書式は以下です:
format_spec     ::=  [[fill]align][sign][#][0][width][grouping_option][.precision][type]
fill            ::=  <any character>
align           ::=  "<" | ">" | "=" | "^"
sign            ::=  "+" | "-" | " "
width           ::=  digit+
grouping_option ::=  "_" | ","
precision       ::=  digit+
type            ::=  "b" | "c" | "d" | "e" | "E" | "f" | "F" | "g" | "G" | "n" | "o" | "s" | "x" | "X" | "%"
有効な align 値を指定する場合、その前に fill 文字を付けることができます。 この文字には任意の文字を指定でき、省略された場合はデフォルトの空白文字となります。 formatted string literal の中や str.format() メソッドを使う場合はリテラルの波括弧 ("{" と "}") を fill 文字として使えないことに注意してください。 ただし、波括弧を入れ子になった置換フィールド内に挿入することはできます。 この制限は format() 関数には影響しません。
様々な align オプションの意味は以下のとおりです:
オプション
意味
'<'
利用可能なスペースにおいて、左詰めを強制します (ほとんどのオブジェクトにおいてのデフォルト)。
'>'
利用可能なスペースにおいて、右詰めを強制します (いくつかのオブジェクトにおいてのデフォルト)。
'='
符号 (があれば) の後ろを埋めます。 '+000000120' のような形で表示されます。このオプションは数値型に対してのみ有効です。フィールド幅の直前が '0' の時はこれがデフォルトになります。
'^'
利用可能なスペースにおいて、中央寄せを強制します。
最小のフィールド幅が定義されない限り、フィールド幅はデータを表示するために必要な幅と同じになることに注意して下さい。そのため、その場合には、 align オプションは意味を持ちません。
sign オプションは数値型に対してのみ有効であり、以下のうちのひとつとなります:
オプション
意味
'+'
符号の使用を、正数、負数の両方に対して指定します。
'-'
符号の使用を、負数に対してのみ指定します (デフォルトの挙動です)。
空白
空白を正数の前に付け、負号を負数の前に使用することを指定します。
',' オプションは、千の位のセパレータにカンマを使うことを合図します。ロケール依存のセパレータには、代わりに 'n' の整数表現形式を使ってください。
バージョン 3.1 で変更: ',' オプションが追加されました (PEP 378 も参照)。
'_' オプションは、浮動小数点数の表現型と整数の表現型 'd' における千倍ごとの区切り文字にアンダースコアを使うというしるしです。 整数の表現型の 'b', 'o', 'x', 'X' では、4桁ごとにアンダースコアが挿入されます。 他の表現型でこのオプションを指定するとエラーになります。
バージョン 3.6 で変更: '_' オプションが追加されました (PEP 515 も参照)。
width is a decimal integer defining the minimum total field width, including any prefixes, separators, and other formatting characters. If not specified, then the field width will be determined by the content.
alignment が明示的に与えられない場合、 width フィールドにゼロ ('0') 文字を前置することは、数値型のための符号を意識した 0 パディングを可能にします。これは fill 文字に '0' を指定して、 alignment タイプに '=' を指定したことと等価です。
precision は10進数で、'f' および 'F' で指定される浮動小数点数の小数点以下、あるいは 'g' および 'G' で指定される浮動小数点数の小数点の前後に表示される桁数を指定します。非数型に対しては、最大フィールド幅を表します。言い換えると、フィールドの内容から何文字を使用するかということです。precision は整数型に対しては使うことができません。
最後に、type は、データがどのように表現されるかを決定します。
利用可能な文字列の表現型は以下です:
型
意味
's'
文字列。これがデフォルトの値で、多くの場合省略されます。
None
's' と同じです。
利用可能な整数の表現型は以下です:
型
意味
'b'
2進数。出力される数値は2を基数とします。
'c'
文字。数値を対応する Unicode 文字に変換します。
'd'
10進数。出力される数値は10を基数とします。
'o'
8進数。出力される数値は8を基数とします。
'x'
16進数。出力される数値は16を基数とします。 10進で9を超える数字には小文字が使われます。
'X'
16進数。出力される数値は16を基数とします。 10進で9を越える数字には大文字が使われます。
'n'
数値。現在のロケールに従い、区切り文字を挿入することを除けば、 'd' と同じです。
None
'd' と同じです。
これらの表現型に加えて、整数は ('n' と None を除く) 以下の浮動小数点数の表現型で書式指定できます。 そうすることで整数は書式変換される前に float() を使って浮動小数点数に変換されます。
The available presentation types for float and Decimal values are:
型
意味
'e'
'E'
'f'
'F'
固定小数点数表記です。nan が NAN に、inf が INF に変換されることを除き 'f' と同じです。
'g'
正と負の無限大と 0 および NaN は精度に関係なくそれぞれ inf, -inf, 0, -0 および nan となります。
'G'
汎用フォーマットです。数値が大きくなったとき、 'E' に切り替わることを除き、 'g' と同じです。無限大と NaN の表示も大文字になります。
'n'
数値です。現在のロケールに合わせて、数値分割文字が挿入されることを除き、 'g' と同じです。
'%'
パーセンテージです。数値は 100 倍され、固定小数点数フォーマット ('f') でパーセント記号付きで表示されます。
None
書式指定例
この節では、 str.format() 構文の例を紹介し、さらに従来の %-書式と比較します。
多くの場合、新構文に {} を加え、 % の代わりに : を使うことで、古い %-書式に類似した書式になります。例えば、'%03.2f' は '{:03.2f}' と変換できます。
以下の例で示すように、新構文はさらに新たに様々なオプションもサポートしています。
位置引数を使ったアクセス:
>>>
>>> '{0}, {1}, {2}'.format('a', 'b', 'c')
'a, b, c'
>>> '{}, {}, {}'.format('a', 'b', 'c')  # 3.1+ only
'a, b, c'
>>> '{2}, {1}, {0}'.format('a', 'b', 'c')
'c, b, a'
>>> '{2}, {1}, {0}'.format(*'abc')      # unpacking argument sequence
'c, b, a'
>>> '{0}{1}{0}'.format('abra', 'cad')   # arguments' indices can be repeated
'abracadabra'
名前を使ったアクセス:
>>>
>>> 'Coordinates: {latitude}, {longitude}'.format(latitude='37.24N', longitude='-115.81W')
'Coordinates: 37.24N, -115.81W'
>>> coord = {'latitude': '37.24N', 'longitude': '-115.81W'}
>>> 'Coordinates: {latitude}, {longitude}'.format(**coord)
'Coordinates: 37.24N, -115.81W'
引数の属性へのアクセス:
>>>
>>> c = 3-5j
>>> ('The complex number {0} is formed from the real part {0.real} '
...  'and the imaginary part {0.imag}.').format(c)
'The complex number (3-5j) is formed from the real part 3.0 and the imaginary part -5.0.'
>>> class Point:
...     def __init__(self, x, y):
...         self.x, self.y = x, y
...     def __str__(self):
...         return 'Point({self.x}, {self.y})'.format(self=self)
...
>>> str(Point(4, 2))
'Point(4, 2)'
引数の要素へのアクセス:
>>>
>>> coord = (3, 5)
>>> 'X: {0[0]};  Y: {0[1]}'.format(coord)
'X: 3;  Y: 5'
%s と %r の置き換え:
>>>
>>> "repr() shows quotes: {!r}; str() doesn't: {!s}".format('test1', 'test2')
"repr() shows quotes: 'test1'; str() doesn't: test2"
テキストの幅を指定した整列:
>>>
>>> '{:<30}'.format('left aligned')
'left aligned                  '
>>> '{:>30}'.format('right aligned')
'                 right aligned'
>>> '{:^30}'.format('centered')
'           centered           '
>>> '{:*^30}'.format('centered')  # use '*' as a fill char
'***********centered***********'
%+f と %-f, % f の置換、そして符号の指定:
>>>
>>> '{:+f}; {:+f}'.format(3.14, -3.14)  # show it always
'+3.140000; -3.140000'
>>> '{: f}; {: f}'.format(3.14, -3.14)  # show a space for positive numbers
' 3.140000; -3.140000'
>>> '{:-f}; {:-f}'.format(3.14, -3.14)  # show only the minus -- same as '{:f}; {:f}'
'3.140000; -3.140000'
%x と %o の置換、そして値に対する異なる底の変換:
>>>
>>> # format also supports binary numbers
>>> "int: {0:d};  hex: {0:x};  oct: {0:o};  bin: {0:b}".format(42)
'int: 42;  hex: 2a;  oct: 52;  bin: 101010'
>>> # with 0x, 0o, or 0b as prefix:
>>> "int: {0:d};  hex: {0:#x};  oct: {0:#o};  bin: {0:#b}".format(42)
'int: 42;  hex: 0x2a;  oct: 0o52;  bin: 0b101010'
千の位のセパレータにカンマを使用する:
>>>
>>> '{:,}'.format(1234567890)
'1,234,567,890'
パーセントを表示する:
>>>
>>> points = 19
>>> total = 22
>>> 'Correct answers: {:.2%}'.format(points/total)
'Correct answers: 86.36%'
型特有の書式指定を使う:
>>>
>>> import datetime
>>> d = datetime.datetime(2010, 7, 4, 12, 15, 58)
>>> '{:%Y-%m-%d %H:%M:%S}'.format(d)
'2010-07-04 12:15:58'
引数をネストする、さらに複雑な例:
>>>
>>> for align, text in zip('<^>', ['left', 'center', 'right']):
...     '{0:{fill}{align}16}'.format(text, fill=align, align=align)
...
'left<<<<<<<<<<<<'
'^^^^^center^^^^^'
'>>>>>>>>>>>right'
>>>
>>> octets = [192, 168, 0, 1]
>>> '{:02X}{:02X}{:02X}{:02X}'.format(*octets)
'C0A80001'
>>> int(_, 16)
3232235521
>>>
>>> width = 5
>>> for num in range(5,12): 
...     for base in 'dXob':
...         print('{0:{width}{base}}'.format(num, base=base, width=width), end=' ')
...     print()
...
    5     5     5   101
    6     6     6   110
    7     7     7   111
    8     8    10  1000
    9     9    11  1001
   10     A    12  1010
   11     B    13  1011
テンプレート文字列
テンプレート文字列では PEP 292 で解説されている単純な文字列置換ができます。 テンプレート文字列の主な使い道は国際化 (i18n) です。というのは、その国際化の文脈において、より簡潔な文法と機能を持つテンプレート文字列を使うと、 Python にある他の組み込みの文字列フォーマット機能よりも翻訳がしやすいからです。 テンプレート文字列の上に構築された国際化のためのライプラリの例として、 flufl.i18n を調べてみてください。
テンプレート文字列は $ に基づいた置換をサポートしていて、次の規則が使われています:
$$ はエスケープ文字です; $ 一つに置換されます。
$identifier は "identifier" のマッピングキーに合致する置換プレースホルダーを指定します。デフォルトでは、 "identifier" は大文字と小文字を区別しない ASCII 英数字 (アンダースコアを含む) からなら文字列に制限されています。文字列はアンダースコアか ASCII 文字から始まるものでなければなりません。$ の後に識別子に使えない文字が出現すると、そこでプレースホルダ名の指定が終わります。
${identifier} は $identifier と同じです。プレースホルダ名の後ろに識別子として使える文字列が続いていて、それをプレースホルダ名の一部として扱いたくない場合、例えば "${noun}ification" のような場合に必要な書き方です。
上記以外の書き方で文字列中に $ を使うと ValueError を送出します。
string モジュールでは、上記のような規則を実装した Template クラスを提供しています。 Template のメソッドを以下に示します:
class string.Template(template)
コンストラクタはテンプレート文字列になる引数を一つだけ取ります。
substitute(mapping={}, /, **kwds)
テンプレート置換を行い、新たな文字列を生成して返します。mapping はテンプレート中のプレースホルダに対応するキーを持つような任意の辞書類似オブジェクトです。辞書を指定する代わりに、キーワード引数も指定でき、その場合にはキーワードをプレースホルダ名に対応させます。mapping と kwds の両方が指定され、内容が重複した場合には、kwds に指定したプレースホルダを優先します。
safe_substitute(mapping={}, /, **kwds)
substitute() と同じですが、プレースホルダに対応するものを mapping や kwds から見つけられなかった場合に、 KeyError 例外を送出する代わりにもとのプレースホルダがそのまま入ります。また、 substitute() とは違い、規則外の書き方で $ を使った場合でも、 ValueError を送出せず単に $ を返します。
その他の例外も発生し得る一方で、このメソッドが「安全 (safe) 」と呼ばれているのは、置換操作は常に、例外を送出する代わりに利用可能な文字列を返そうとするからです。別の見方をすれば、 safe_substitute() は区切り間違いによるぶら下がり (dangling delimiter) や波括弧の非対応、 Python の識別子として無効なプレースホルダ名を含むような不正なテンプレートを何も警告せずに無視するため、安全とはいえないのです。
Template のインスタンスは、次のような public な属性を提供しています:
template
コンストラクタの引数 template に渡されたオブジェクトです。通常、この値を変更すべきではありませんが、読み出し専用アクセスを強制しているわけではありません。
Templateの使い方の例を以下に示します:
>>>
>>> from string import Template
>>> s = Template('$who likes $what')
>>> s.substitute(who='tim', what='kung pao')
'tim likes kung pao'
>>> d = dict(who='tim')
>>> Template('Give $who $100').substitute(d)
Traceback (most recent call last):
...
ValueError: Invalid placeholder in string: line 1, col 11
>>> Template('$who likes $what').substitute(d)
Traceback (most recent call last):
...
KeyError: 'what'
>>> Template('$who likes $what').safe_substitute(d)
'tim likes $what'
さらに進んだ使い方: Template のサブクラスを派生して、プレースホルダの書式、区切り文字、テンプレート文字列の解釈に使われている正規表現全体をカスタマイズできます。こうした作業には、以下のクラス属性をオーバライドします:
delimiter -- プレースホルダの開始を示すリテラル文字列です。 デフォルトの値は $ です。 実装系はこの文字列に対して必要に応じて re.escape() を呼び出すので、正規表現になってしまうような文字列にしては なりません 。 さらにクラスを作成した後に delimiter を変更できない (つまり、別の delimiter を設定したいのであれば、サブクラスの名前空間で行わなければならない) ことに注意してください。
idpattern -- This is the regular expression describing the pattern for non-braced placeholders. The default value is the regular expression (?a:[_a-z][_a-z0-9]*). If this is given and braceidpattern is None this pattern will also apply to braced placeholders.
注釈 flags のデフォルトは re.IGNORECASE なので、 [a-z] というパターンはいくつかの非 ASCII 文字に適合できます。 そのため、ここではローカルの a フラグを使っています。
バージョン 3.7 で変更: braceidpattern を使用すると、中括弧の内側と外側で使用する別々のパターンを定義できます。
braceidpattern -- This is like idpattern but describes the pattern for braced placeholders. Defaults to None which means to fall back to idpattern (i.e. the same pattern is used both inside and outside braces). If given, this allows you to define different patterns for braced and unbraced placeholders.
バージョン 3.7 で追加.
flags -- 代入の認識のために使用される正規表現をコンパイルする際に適用される正規表現フラグ。デフォルト値は re.IGNORECASE です。re.VERBOSE が常にフラグに追加されるということに注意してください。したがって、カスタムな idpattern は verbose 正規表現の規約に従わなければなりません。
バージョン 3.2 で追加.
他にも、クラス属性 pattern をオーバライドして、正規表現パターン全体を指定できます。オーバライドを行う場合、 pattern の値は 4 つの名前つきキャプチャグループ (capturing group) を持った正規表現オブジェクトでなければなりません。これらのキャプチャグループは、上で説明した規則と、無効なプレースホルダに対する規則に対応しています:
escaped -- このグループはエスケープシーケンス、すなわちデフォルトパターンにおける $$ に対応します。
named -- このグループは波括弧でくくらないプレースホルダ名に対応します; キャプチャグループに区切り文字を含めてはなりません。
braced -- このグループは波括弧でくくったプレースホルダ名に対応します; キャプチャグループに区切り文字を含めてはなりません。
invalid -- このグループはそのほかの区切り文字のパターン (通常は区切り文字一つ) に対応し、正規表現の末尾に出現しなければなりません。
ヘルパー関数
string.capwords(s, sep=None)
str.split() を使って引数を単語に分割し、 str.capitalize() を使ってそれぞれの単語の先頭の文字を大文字に変換し、 str.join() を使ってつなぎ合わせます。オプションの第2引数 sep が与えられないか None の場合、この置換処理は文字列中の連続する空白文字をスペース一つに置き換え、先頭と末尾の空白を削除します、それ以外の場合には sep は split と join に使われます。
re --- 正規表現操作
ソースコード: Lib/re.py
このモジュールは Perl に見られる正規表現マッチング操作と同様のものを提供します。
パターンおよび検索される文字列には、Unicode 文字列 (str) や 8 ビット文字列 (bytes) を使います。ただし、Unicode 文字列と 8 ビット文字列の混在はできません。つまり、Unicode 文字列にバイト列のパターンでマッチングしたり、その逆はできません。同様に、置換時の置換文字列はパターンおよび検索文字列の両方と同じ型でなくてはなりません。
正規表現では、特殊な形式を表すためや、特殊文字をその特殊な意味を発動させず使うために、バックスラッシュ文字 ('\') を使います。こうしたバックスラッシュの使い方は、 Python の文字列リテラルにおける同じ文字の使い方と衝突します。例えば、リテラルのバックスラッシュにマッチさせるには、パターン文字列として '\\\\' と書かなければなりません。なぜなら、正規表現は \\ でなければならないうえ、それぞれのバックスラッシュは標準の Python 文字列リテラルで \\ と表現せねばならないからです。 Python の文字列リテラルにおいて、バックスラッシュの使用による不正なエスケープ文字がある場合は、DeprecationWarning が発生し、将来的には SyntaxError になることにも注意してください。この動作は、正規表現として有効な文字列に対しても同様です。
これを解決するには、正規表現パターンに Python の raw 文字列記法を使います。 'r' を前置した文字列リテラル内ではバックスラッシュが特別扱いされません。従って "\n" が改行一文字からなる文字列であるのに対して、 r"\n" は '\' と 'n' の二文字からなる文字列です。通常、 Python コード中では、パターンをこの raw 文字列記法を使って表現します。
重要なこととして、大抵の正規表現操作は、モジュールレベルの関数としても、 コンパイル済み正規表現 のメソッドとしても利用できます。関数は正規表現オブジェクトを前もってコンパイルする必要がない近道ですが、微調整のための変数が減ります。
参考 サードパーティの regex モジュールは、標準ライブラリの re モジュールと互換な API を持ちながら、追加の機能とより徹底した Unicode サポートを提供します。
正規表現のシンタックス
正規表現 (または RE) は、その表現にマッチ (match) する文字列の集合を指定します。このモジュールの関数を使えば、ある文字列が与えられた正規表現にマッチするか (または、与えられた正規表現がある文字列にマッチするか、と言い換えても同じことになります) を検査できます。
正規表現を連結することで新しい正規表現を作れます。A と B がともに正規表現であれば AB も正規表現です。一般的に、ある文字列 p が A にマッチし、別の文字列 q が B にマッチするなら、文字列 pq は AB にマッチします。ただし、 A または B に優先度の低い演算が含まれる場合や、 A と B との間に境界条件がある場合や、番号付けされたグループ参照をしている場合、を除きます。こうして、ここで述べるような簡単な基本表現から、複雑な表現を容易に構築できます。正規表現に関する理論と実装の詳細については Friedl 本 [Frie09] か、コンパイラの構築に関するテキストを参照してください。
以下で正規表現の形式を簡単に説明します。詳細な情報ややさしい説明は、 正規表現 HOWTO を参照してください。
正規表現には、特殊文字と通常文字の両方を含められます。 'A' 、 'a' 、または '0' のようなほとんどの通常文字は、最も単純な正規表現です。これは単純に、その文字自体にマッチします。通常文字は連結できるので、 last は文字列 'last' にマッチします。 (この節では以降、正規表現は一般にクオートを使わず この特殊スタイルで 表記し、マッチ対象の文字列は、 'シングルクオートで括って' 表記します。)
'|' や '(' といったいくつかの文字は特殊です。特殊文字は通常文字の種別を表したり、周辺の通常文字に対する解釈方法に影響します。
繰り返しの修飾子 (*、 +、 ?、 {m,n} など) は直接入れ子にはできません。これは、非貪欲な修飾子の接尾辞 ? や他の実装での他の修飾子との曖昧さを回避します。内側で繰り返したものをさらに繰り返すには、丸括弧が使えます。例えば、正規表現 (?:a{6})* は 6 の倍数個の 'a' 文字にマッチします。
特殊文字を以下に示します:
(ドット) デフォルトのモードでは改行以外の任意の文字にマッチします。 DOTALL フラグが指定されていれば改行も含む全ての文字にマッチします。
^
(キャレット) 文字列の先頭にマッチし、 MULTILINE モードでは各改行の直後にもマッチします。
$
文字列の末尾、あるいは文字列の末尾の改行の直前にマッチし、 MULTILINE モードでは改行の前にもマッチします。 foo は 'foo' と 'foobar' の両方にマッチしますが、正規表現 foo$ は 'foo' だけにマッチします。興味深いことに、 'foo1\nfoo2\n' を foo.$ で検索した場合、通常は 'foo2' だけにマッチしますが、 MULTILINE モードでは 'foo1' にもマッチします。 $ だけで 'foo\n' を検索した場合、2 つの (空の) マッチを見つけます: 1つは改行の直前で、もう1つは文字列の末尾です。
*
直前の正規表現を 0 回以上、できるだけ多く繰り返したものにマッチさせる結果の正規表現にします。例えば ab* は 'a'、'ab'、または 'a' に任意個数の 'b' を続けたものにマッチします。
+
直前の正規表現を 1 回以上繰り返したものにマッチさせる結果の正規表現にします。例えば ab+ は 'a' に 1 つ以上の 'b' が続いたものにマッチし、単なる 'a' にはマッチしません。
?
直前の正規表現を 0 回か 1 回繰り返したものにマッチさせる結果の正規表現にします。例えば ab? は 'a' あるいは 'ab' にマッチします。
*?, +?, ??
'*' 、 '+' 、および '?' 修飾子は全て 貪欲 (greedy) マッチで、できるだけ多くのテキストにマッチします。この挙動が望ましくない時もあります。例えば正規表現 <.*> が '<a> b <c>' に対してマッチされると、 '<a>' だけでなく文字列全体にマッチしてしまいます。修飾子の後に ? を追加すると、 非貪欲 (non-greedy) あるいは 最小 (minimal) のマッチが行われ、できるだけ 少ない 文字にマッチします。正規表現 <.*?> を使うと '<a>' だけにマッチします。
{m}
直前の正規表現をちょうど m 回繰り返したものにマッチさせるよう指定します。それより少ないマッチでは正規表現全体がマッチしません。例えば、 a{6} は 6 個ちょうどの 'a' 文字にマッチしますが、 5 個ではマッチしません。
{m,n}
直前の正規表現を m 回から n 回、できるだけ多く繰り返したものにマッチさせる結果の正規表現にします。例えば、a{3,5} は、3 個から 5 個の 'a' 文字にマッチします。m を省略すると下限は 0 に指定され、n を省略すると上限は無限に指定されます。例として、 a{4,}b は 'aaaab' や、1,000 個の 'a' 文字に 'b' が続いたものにマッチしますが、'aaab' にはマッチしません。コンマは省略できません、省略すると修飾子が上で述べた形式と混同されてしまうからです。
{m,n}?
結果の正規表現は、前にある正規表現を、m 回から n 回まで繰り返したものにマッチし、できるだけ 少なく 繰り返したものにマッチするようにします。これは、前の修飾子の非貪欲版です。例えば、 6 文字文字列 'aaaaaa' では、 a{3,5} は、5 個の 'a' 文字にマッチしますが、 a{3,5}? は 3 個の文字にマッチするだけです。
\
特殊文字をエスケープ ( '*' や '?' などの文字にマッチできるようにする) し、または特殊シーケンスを合図します。特殊シーケンスは後で議論します。
パターンを表現するのに raw 文字列を使っていないのであれば、 Python ももまた、バックスラッシュを文字列リテラルでエスケープシーケンスとして使うことを思い出して下さい。そのエスケープシーケンスを Python のパーザが認識しないなら、そのバックスラッシュとそれに続く文字が結果の文字列に含まれます。しかし、Python が結果のシーケンスを認識するなら、そのバックスラッシュは 2 回繰り返さなければいけません。これは複雑で理解しにくいので、ごく単純な表現以外は、全て raw 文字列を使うことを強く推奨します。
[]
文字の集合を指定するのに使います。集合の中では:
文字を個別に指定できます。 [amk] は 'a' 、 'm' または 'k' にマッチします。
連続した文字の範囲を、 '-' を2 つの文字で挟んで指定できます。例えば、 [a-z] はあらゆる小文字の ASCII 文字にマッチします。[0-5][0-9] は 00 から 59 まで全ての 2 桁の数字にマッチします。[0-9A-Fa-f] は任意の 16 進数字にマッチします。- がエスケープされているか (例: [a\-z])、先頭や末尾の文字にされていると (例: [-a] や [a-])、リテラル '-' にマッチします。
集合の中では、特殊文字はその特殊な意味を失います。例えば [(+*)] はリテラル文字 '(' 、 '+' 、 '*' 、または ')' のどれにでもマッチします。
\w や \S のような文字クラス (後述) も集合の中で受理されますが、それにマッチする文字は ASCII や LOCALE モードが有効であるかに依存します。
補集合 をとって範囲内にない文字にマッチできます。集合の最初の文字が '^' なら、集合に 含まれない 全ての文字にマッチします。例えば、 [^5] は '5' を除くあらゆる文字にマッチし、 [^^] は '^' を除くあらゆる文字にマッチします。 ^ は集合の最初の文字でなければ特別の意味を持ちません。
集合の中でリテラル ']' にマッチさせるには、その前にバックスラッシュをつけるか、集合の先頭に置きます。例えば、 [()[\]{}] と []()[{}] はどちらも括弧にマッチします。
Unicode Technical Standard #18 にあるような集合の入れ子や集合操作が将来追加される可能性があります。これは構文を変化させるもので、この変化を容易にするために、さしあたって曖昧な事例には FutureWarning が送出されます。これはリテラル '[' で始まる集合や、リテラル文字の連続 '--' 、 '&&' 、 '~~' および '||' を含む集合を含みます。警告を避けるにはバックスラッシュでエスケープしてください。
バージョン 3.7 で変更: 文字セットが将来意味論的に変化する構造を含むなら FutureWarning が送出されます。
|
A と B を任意の正規表現として、 A|B は A と B のいずれかにマッチする正規表現を作成します。この方法で任意の数の正規表現を '|' で分離できます。これはグループ (下記参照) 中でも使えます。対象文字列を走査するとき、'|' で分離された正規表現は左から右へ順に試されます。一つのパターンが完全にマッチしたとき、そのパターン枝が受理されます。つまり、ひとたび A がマッチしてしまえば、例え B によって全体のマッチが長くなるとしても、 B はもはや走査されません。言いかえると、 '|' 演算子は決して貪欲にはなりません。リテラル '|' にマッチするには、 \| を使うか、 [|] のように文字クラス中に囲みます。
(...)
丸括弧で囲まれた正規表現にマッチするとともに、グループの開始と終了を表します。グループの中身は以下で述べるように、マッチが実行された後で回収したり、その文字列中で以降 \number 特殊シーケンスでマッチしたりできます。リテラル '(' や ')' にマッチするには、\( や \) を使うか、文字クラス中に囲みます: [(]、 [)] 。
(?...)
これは拡張記法です ('(' に続く '?' はそれ以上の意味を持ちません) 。 '?' に続く最初の文字がこの構造の意味と特有の構文を決定します。拡張は一般に新しいグループを作成しません。ただし (?P<name>...) はこの法則の唯一の例外です。現在サポートされている拡張は以下の通りです。
(?aiLmsux)
('a' 、 'i' 、 'L' 、 'm' 、 's' 、 'u' 、 'x' の集合から 1 文字以上。) このグループは空文字列にマッチします。文字は正規表現全体に、対応するフラグを設定します。 re.A (ASCII 限定マッチング)、 re.I (大文字・小文字を区別しない)、 re.L (ロケール依存)、 re.M (複数行)、 re.S (ドットが全てにマッチ)、 re.U (Unicode マッチング)、 re.X (冗長)。 (各フラグについては モジュールコンテンツ で説明します。) これは、 flag 引数を re.compile() 関数に渡すのではなく、フラグを正規表現の一部として含めたいときに便利です。フラグは表現文字列の先頭で使うべきです。
(?:...)
普通の丸括弧の、キャプチャしない版です。丸括弧で囲まれた正規表現にマッチしますが、このグループがマッチした部分文字列は、マッチを実行したあとで回収することも、そのパターン中で以降参照することも できません 。
(?aiLmsux-imsx:...)
('a' 、 'i' 、 'L' 、 'm' 、 's' 、 'u' 、 'x' の集合から 0 文字以上、必要ならさらに '-' に続けて 'i' 、 'm' 、 's' 、 'x' の集合から 1 文字以上。) 文字は表現の一部に、対応するフラグを設定または除去します。 re.A (ASCII 限定マッチング)、 re.I (大文字・小文字を区別しない)、 re.L (ロケール依存)、 re.M (複数行)、 re.S (ドットが全てにマッチ)、 re.U (Unicode マッチング)、 re.X (冗長)。 (各フラグについては モジュールコンテンツ で説明します。)
文字 'a' 、 'L' および 'u' は相互に排他であり、組み合わせることも '-' に続けることもできません。その代わり、これらの内一つがインライングループ中に現れると、外側のグループでのマッチングモードを上書きします。 Unicode パターン中では (?a:...) は ASCII 限定マッチングに切り替え、 (?u:...) は Unicode マッチング (デフォルト) に切り替えます。バイト列パターン中では、 (?L:...) はロケール依存マッチングに切り替え、 (?a:...) は ASCII 限定マッチング (デフォルト) に切り替えます。この上書きは狭いインライングループにのみ影響し、元のマッチングモードはグループ外では復元されます。
バージョン 3.6 で追加.
バージョン 3.7 で変更: 文字 'a' 、 'L' および 'u' もグループ中で使えます。
(?P<name>...)
通常の丸括弧に似ていますが、このグループがマッチした部分文字列はシンボリックグループ名 name でアクセスできます。グループ名は有効な Python 識別子でなければならず、各グループ名は 1 個の正規表現内で一度だけ定義されていなければなりません。シンボリックグループは、そのグループが名前付けされていなかったかのように番号付けされたグループでもあります。
名前付きグループは 3 つのコンテキストで参照できます。パターンが (?P<quote>['\"]).*?(?P=quote) (シングルまたはダブルクオートで囲まれた文字列にマッチ) ならば:
グループ "quote" を参照するコンテキスト
参照する方法
その同じパターン中
(?P=quote) (示したとおり)
\1
マッチオブジェクト m の処理時
m.group('quote')
m.end('quote') (など)
re.sub() の repl 引数へ渡される文字列中
\g<quote>
\g<1>
\1
(?P=name)
名前付きグループへの後方参照です。これは name という名前の既出のグループがマッチした文字列にマッチします。
(?#...)
コメントです。括弧の中身は単純に無視されます。
(?=...)
... が次に続くものにマッチすればマッチしますが、文字列をまったく消費しません。これは 先読みアサーション (lookahead assertion) と呼ばれます。例えば、Isaac (?=Asimov) は 'Isaac ' に、その後に 'Asimov' が続く場合にのみ、マッチします。
(?!...)
... が次に続くものにマッチしなければマッチします。これは 否定先読みアサーション (negative lookahead assertion) です。例えば、Isaac (?!Asimov) は 'Isaac ' に、その後に 'Asimov' が続か ない 場合にのみ、マッチします。
(?<=...)
その文字列における現在位置の前に、現在位置で終わる ... とのマッチがあれば、マッチします。これは 後読みアサーション と呼ばれます。(?<=abc)def は、後読みは 3 文字をバックアップし、含まれているパターンがマッチするか検査するので 'abcdef' にマッチを見つけます。含まれるパターンは、固定長の文字列にのみマッチしなければなりません。すなわち、 abc や a|b は許されますが、a* や a{3,4} は許されません。肯定後読みアサーションで始まるパターンは、検索される文字列の先頭とは決してマッチしないことに注意して下さい。match() 関数ではなく search() 関数を使う方が望ましいでしょう:
>>>
>>> import re
>>> m = re.search('(?<=abc)def', 'abcdef')
>>> m.group(0)
'def'
この例ではハイフンに続く単語を探します:
>>>
>>> m = re.search(r'(?<=-)\w+', 'spam-egg')
>>> m.group(0)
'egg'
バージョン 3.5 で変更: 固定長のグループ参照をサポートするようになりました。
(?<!...)
その文字列における現在位置の前に ... とのマッチがなければ、マッチします。これは 否定後読みアサーション(negative lookbehind assertion) と呼ばれます。肯定後読みアサーションと同様に、含まれるパターンは固定長の文字列にのみマッチしなければなりません。否定後読みアサーションで始まるパターンは検索される文字列の先頭でマッチできます。
(?(id/name)yes-pattern|no-pattern)
与えられた id や name のグループが存在すれば yes-pattern との、存在しなければ no-pattern とのマッチを試みます。no-pattern はオプションであり省略できます。例えば、(<)?(\w+@\w+(?:\.\w+)+)(?(1)>|$) は貧弱な E-mail マッチングパターンで、'<user@host.com>' や 'user@host.com' にはマッチしますが、'<user@host.com' や 'user@host.com>' にはマッチしません。
特殊シーケンスは '\' と以下のリストの文字から構成されます。通常文字が ASCII 数字でも ASCII 文字でもなければ、結果の正規表現は 2 番目の文字にマッチします。例えば、\$ は文字 '$' にマッチします。
\number
同じ番号のグループの中身にマッチします。グループは 1 から始まる番号をつけられます。例えば、 (.+) \1 は、 'the the' あるいは '55 55' にマッチしますが、 'thethe' にはマッチしません(グループの後のスペースに注意して下さい)。この特殊シーケンスは最初の 99 グループのうちの一つとのマッチにのみ使えます。 number の最初の桁が 0 であるか、 number が 3 桁の 8 進数であれば、それはグループのマッチとしてではなく、 8 進値 number を持つ文字として解釈されます。文字クラスの '[' と ']' の間では全ての数値エスケープが文字として扱われます。
\A
文字列の先頭でのみマッチします。
\b
空文字列にマッチしますが、単語の先頭か末尾でのみです。単語は単語文字の並びとして定義されます。形式的には、 \b は \w と \W 文字 (またはその逆) との、あるいは \w と文字列の先頭・末尾との境界として定義されます。例えば、 r'\bfoo\b' は 'foo' 、 'foo.' 、 '(foo)' 、 'bar foo baz' にはマッチしますが、 'foobar' や 'foo3' にはマッチしません。
デフォルトの Unicode 英数字は Unicode パターン中で使われるものと同じですが、これは ASCII フラグを使って変更できます。 LOCALE フラグが使われているなら単語の境界は現在のロケールによって決定されます。Python の文字列リテラルとの互換性のため、文字列範囲中では、 \b は後退 (backspace) 文字を表します。
\B
空文字列にマッチしますが、それが単語の先頭か末尾 でない ときのみです。つまり r'py\B' は 'python' 、 'py3' 、'py2' にマッチしますが、 'py' 、 'py.' 、 または 'py!' にはマッチしません。 \B は \b のちょうど反対で、 Unicode パターンにおける単語文字は Unicode 英数字およびアンダースコアですが、 これは ASCII フラグを使って変更できます。 LOCALE フラグが使われているなら単語の境界は現在のロケールによって決定されます。
\d
Unicode (str) パターンでは:
任意の Unicode 10 進数字 (Unicode 文字カテゴリ [Nd]) にマッチします。これは [0-9] とその他多数の数字を含みます。 ASCII フラグが使われているなら [0-9] のみにマッチします。
8 ビット (bytes) パターンでは:
任意の 10 進数字にマッチします。これは [0-9] と等価です。
\D
10 進数字でない任意の文字にマッチします。これは \d の反対です。ASCII フラグが使われているならこれは [^0-9] と等価になります。
\s
Unicode (str) パターンでは:
Unicode 空白文字 (これは [ \t\n\r\f\v] その他多くの文字、例えば多くの言語におけるタイポグラフィ規則で定義されたノーブレークスペースなどを含みます) にマッチします。 ASCII フラグが使われているなら、[ \t\n\r\f\v] のみにマッチします。
8 ビット (bytes) パターンでは:
ASCII 文字セットで空白文字と見なされる文字にマッチします。これは [ \t\n\r\f\v] と等価です。
\S
空白文字ではない任意の文字にマッチします。これは \s の反対です。ASCII フラグが使われているならこれは [^ \t\n\r\f\v] と等価になります。
\w
Unicode (str) パターンでは:
Unicode 単語文字にマッチします。これはあらゆる言語で単語の一部になりうるほとんどの文字、数字、およびアンダースコアを含みます。ASCII フラグが使われているなら、 [a-zA-Z0-9_] のみにマッチします。
8 ビット (bytes) パターンでは:
ASCII 文字セットで英数字と見なされる文字にマッチします。これは [a-zA-Z0-9_] と等価です。LOCALE フラグが使われているなら、現在のロケールで英数字と見なされる文字およびアンダースコアにマッチします。
\W
単語文字ではない任意の文字にマッチします。これは \w の反対です。 ASCII フラグが使われているなら、これは [^a-zA-Z0-9_] と等価になります。LOCALE フラグが使われているなら、現在のロケールの英数字でもアンダースコアでもない文字にマッチします。
\Z
文字列の末尾でのみマッチします。
Python 文字列リテラルでサポートされている標準エスケープのほとんども正規表現パーザで受理されます:
\a      \b      \f      \n
\N      \r      \t      \u
\U      \v      \x      \\
(\b は単語の境界を表すのに使われ、文字クラス中でのみ "後退 (backspace)" 文字を意味することに注意してください。)
'\u'、'\U' および '\N' エスケープシーケンスは、Unicode パターン内でのみ認識されます。バイト列ではエラーとなります。ASCII 文字のエスケープで未知のものは将来使うために予約されていて、エラーとして扱われます。
8 進エスケープは限られた形式でのみ含まれます。その最初の桁が 0 であるか、それが 3 桁の 8 進数であるならば、それは 8 進エスケープと見なされます。そうでなければ、それはグループ参照です。文字列リテラルでは、8 進エスケープは常にたかだか 3 桁長です。
バージョン 3.3 で変更: '\u' と '\U' エスケープシーケンスが追加されました。
バージョン 3.6 で変更: '\' と ASCII 文字からなる未知のエスケープはエラーになります。
バージョン 3.8 で変更: '\N{name}' エスケープシーケンスが追加されました。文字列リテラルでは、同名のUnicode 文字に展開されます。('\N{EM DASH}' など)
モジュールコンテンツ
このモジュールはいくつかの関数、定数、例外を定義します。このうちいくつかの関数は、コンパイル済み正規表現がそなえる完全な機能のメソッドを簡易にしたものです。些細なものを除くほとんどのアプリケーションは常にコンパイル済み形式を使います。
バージョン 3.6 で変更: フラグ定数は、enum.IntFlag のサブクラスである RegexFlag のインスタンスになりました。
re.compile(pattern, flags=0)
正規表現パターンを 正規表現オブジェクト にコンパイルし、以下に述べる match() 、 search() その他のメソッドを使ってマッチングに使えるようにします。
式の挙動は flags の値を指定することで加減できます。値は以下の変数のうち任意のものを、ビット単位 OR ( | 演算子) で組み合わせたものです。
シーケンス
prog = re.compile(pattern)
result = prog.match(string)
は、以下と同等です
result = re.match(pattern, string)
が、 re.compile() を使い、結果の正規表現オブジェクトを保存して再利用するほうが、一つのプログラムでその表現を何回も使うときに効率的です。
注釈 re.compile() やモジュールレベルのマッチング関数に渡された最新のパターンはコンパイル済みのものがキャッシュされるので、一度に正規表現を少ししか使わないプログラムでは正規表現をコンパイルする必要はありません。
re.A
re.ASCII
\w 、\W 、\b 、\B 、\d 、\D 、\s 、および \S に、完全な Unicode マッチングではなく ASCII 限定マッチングを行わせます。これは Unicode パターンでのみ意味があり、バイト列パターンでは無視されます。インラインフラグの (?a) に相当します。
後方互換性のため、re.U フラグ (と同義の re.UNICODE および埋め込みで使用する (?u)) はまだ存在しますが、Python 3 では文字列のマッチがデフォルトで Unicode (そしてバイト列では Unicode マッチングが扱えない) なので冗長です。
re.DEBUG
コンパイル済み表現に関するデバッグ情報を表示します。相当するインラインフラグはありません。
re.I
re.IGNORECASE
大文字・小文字を区別しないマッチングを行います; [A-Z] のような正規表現は小文字にもマッチします。 re.ASCII フラグを使い、非 ASCII マッチが無効化されていない限り、 (Ü が ü にマッチするような) 完全な Unicode マッチングも有効です。 re.LOCALE フラグも一緒に使われていない限り、現在のロケールがこのフラグの効果を変更することはありません。 インラインフラグの (?i) に相当します。
Unicode パターン [a-z] または [A-Z] が IGNORECASE フラグとあわせて使われたとき、52 の ASCII 文字に加えて 4 の非 ASCII 文字 'İ' (U+0130, Latin capital letter I with dot above) 、 'ı' (U+0131, Latin small letter dotless i) 、 'ſ' (U+017F, Latin small letter long s) および 'K' (U+212A, Kelvin sign) にマッチすることに注意してください。 ASCII フラグが使われているなら、文字 'a' から 'z' および 'A' から 'Z' にのみマッチします。
re.L
re.LOCALE
\w 、 \W 、 \b 、 \B および大文字・小文字を区別しないマッチングを、現在のロケールに依存させます。ロケールの仕組みは信頼できず、一度に一つの "文化" しか扱えず、 8 ビットロケールでしか働かないので、このフラグを使うことは推奨されません。Python 3 において Unicode (str) パターンでは Unicode マッチングはデフォルトですでに有効にされていて、異なるロケールや言語を扱えます。インラインフラグの (?L) に相当します。
バージョン 3.6 で変更: re.LOCALE はバイト列パターンにのみ使え、re.ASCII と互換ではありません。
バージョン 3.7 で変更: re.LOCALE フラグがあるコンパイル済み正規表現オブジェクトはコンパイル時のロケールに依存しなくなりました。マッチング時のロケールのみがマッチングの結果に影響します。
re.M
re.MULTILINE
指定されていると、パターン文字 '^' は文字列の先頭で、および各行の先頭 (各改行の直後) で、マッチします。そしてパターン文字 '$' は文字列の末尾で、および各行の末尾 (各改行の直前) で、マッチします。デフォルトでは、 '^' は文字列の先頭でのみ、'$' は文字列の末尾および文字列の末尾の改行 (もしあれば) の直前でのみマッチします。インラインフラグの (?m) に相当します。
re.S
re.DOTALL
'.' 特殊文字を、改行を含むあらゆる文字にマッチさせます。このフラグがなければ、'.' は、改行 以外の あらゆる文字とマッチします。インラインフラグの (?s) に相当します。
re.X
re.VERBOSE
このフラグは正規表現を、パターンの論理的な節を視覚的に分割し、コメントを加えることで、見た目よく読みやすく書けるようにします。パターン中の空白は、文字クラス中にあるときと、エスケープされていないバックスラッシュの後にあるときと、 *? 、 (?: や (?P<...> のようなトークン中を除いて無視されます。ある行が文字クラス中でもエスケープされていないバックスラッシュの後でもない # を含むなら、一番左のそのような # から行末までの全ての文字は無視されます。
つまり、10 進数字にマッチする下記のふたつの正規表現オブジェクトは、機能的に等価です:
a = re.compile(r"""\d +  # the integral part
                   \.    # the decimal point
                   \d *  # some fractional digits""", re.X)
b = re.compile(r"\d+\.\d*")
インラインフラグの (?x) に相当します。
re.search(pattern, string, flags=0)
string を走査し、正規表現 pattern がマッチを生じさせる最初の場所を探して、対応する マッチオブジェクト を返します。文字列内にパターンにマッチする場所がなければ None を返します。これは文字列のどこかで長さ 0 のマッチを見つけるのとは異なることに注意してください。
re.match(pattern, string, flags=0)
string の先頭で 0 個以上の文字が正規表現 pattern にマッチすれば、対応する マッチオブジェクト を返します。文字列がパターンにマッチしなければ None を返します。これは長さ 0 のマッチとは異なることに注意して下さい。
MULTILINE モードにおいても、re.match() は各行の先頭でマッチするのではなく、文字列の先頭でのみマッチすることに注意してください。
string 中のどこででもマッチさせたいなら、代わりに search() を使ってください (search() vs. match() も参照してください)。
re.fullmatch(pattern, string, flags=0)
string 全体が正規表現 pattern にマッチするなら、対応する マッチオブジェクト を返します。文字列がパターンにマッチしないなら None を返します。これは長さ 0 のマッチとは異なることに注意して下さい。
バージョン 3.4 で追加.
re.split(pattern, string, maxsplit=0, flags=0)
string を、出現した pattern で分割します。 pattern 中でキャプチャの丸括弧が使われていれば、パターン中の全てのグループのテキストも結果のリストの一部として返されます。maxsplit が 0 でなければ、分割は最大 maxsplit 回起こり、残りの文字列はリストの最終要素として返されます。
>>>
>>> re.split(r'\W+', 'Words, words, words.')
['Words', 'words', 'words', '']
>>> re.split(r'(\W+)', 'Words, words, words.')
['Words', ', ', 'words', ', ', 'words', '.', '']
>>> re.split(r'\W+', 'Words, words, words.', 1)
['Words', 'words, words.']
>>> re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE)
['0', '3', '9']
セパレータ中にキャプチャグループがあり、それが文字列の先頭にマッチするなら、結果は空文字列で始まります。同じことが文字列の末尾にも言えます。
>>>
>>> re.split(r'(\W+)', '...words, words...')
['', '...', 'words', ', ', 'words', '...', '']
そうして、結果のリストにおいて、セパレータの構成要素は常に同じ相対的インデックスに見つかります。
パターンへの空マッチは、直前の空マッチに隣接していないときのみ文字列を分割します。
>>>
>>> re.split(r'\b', 'Words, words, words.')
['', 'Words', ', ', 'words', ', ', 'words', '.']
>>> re.split(r'\W*', '...words...')
['', '', 'w', 'o', 'r', 'd', 's', '', '']
>>> re.split(r'(\W*)', '...words...')
['', '...', '', '', 'w', '', 'o', '', 'r', '', 'd', '', 's', '...', '', '', '']
バージョン 3.1 で変更: オプションの flags 引数が追加されました。
バージョン 3.7 で変更: 空文字列にマッチしうるパターンでの分割をサポートするようになりました。
re.findall(pattern, string, flags=0)
string 中の pattern による全ての重複しないマッチを、文字列のリストとして返します。 string は左から右へ走査され、マッチは見つかった順で返されます。パターン中に 1 つ以上のグループがあれば、グループのリストを返します。パターンに複数のグループがあればタプルのリストになります。空マッチは結果に含まれます。
バージョン 3.7 で変更: 空でないマッチが前の空マッチの直後から始められるようになりました。
re.finditer(pattern, string, flags=0)
string 中の正規表現 pattern の重複しないマッチ全てに渡る マッチオブジェクト を yield する イテレータ を返します。 string は左から右へ走査され、マッチは見つかった順で返されます。空マッチは結果に含まれます。
バージョン 3.7 で変更: 空でないマッチが前の空マッチの直後から始められるようになりました。
re.sub(pattern, repl, string, count=0, flags=0)
string 中に出現する最も左の重複しない pattern を置換 repl で置換することで得られる文字列を返します。 パターンが見つからない場合、 string がそのまま返されます。 repl は文字列または関数です。 repl が文字列の場合は、その中の全てのバックスラッシュエスケープが処理されます。 \n は 1 つの改行文字に変換され、 \r はキャリッジリターンに変換される、などです。 ASCII 文字のエスケープで未知のものは将来使うために予約されていて、エラーとして扱われます。 それ以外の \& のような未知のエスケープは残されます。 \6 のような後方参照は、パターンのグループ 6 がマッチした部分文字列で置換されます。 例えば:
>>>
>>> re.sub(r'def\s+([a-zA-Z_][a-zA-Z_0-9]*)\s*\(\s*\):',
...        r'static PyObject*\npy_\1(void)\n{',
...        'def myfunc():')
'static PyObject*\npy_myfunc(void)\n{'
repl が関数であれば、それは重複しない pattern が出現するたびに呼び出されます。この関数は一つの マッチオブジェクト 引数を取り、置換文字列を返します。例えば:
>>>
>>> def dashrepl(matchobj):
...     if matchobj.group(0) == '-': return ' '
...     else: return '-'
>>> re.sub('-{1,2}', dashrepl, 'pro----gram-files')
'pro--gram files'
>>> re.sub(r'\sAND\s', ' & ', 'Baked Beans And Spam', flags=re.IGNORECASE)
'Baked Beans & Spam'
パターンは、文字列でも パターンオブジェクト でも構いません。
オプション引数 count は出現したパターンを置換する最大の回数です。 count は非負整数です。省略されるか 0 なら、出現した全てが置換されます。パターンへの空マッチは前の空マッチに隣接していないときのみ置換されるので、 sub('x*', '-', 'abxd') は '-a-b--d-' を返します。
文字列型 repl 引数では、上で述べた文字エスケープや後方参照に加えて、 \g<name> は (?P<name>...) 構文で定義された name という名前のグループがマッチした部分文字列を使い、 \g<number> は対応するグループ番号を使います。よって \g<2> は \2 と等価ですが、 \g<2>0 のような置換においても曖昧になりません。 \20 は、グループ 20 への参照として解釈され、グループ 2 への参照にリテラル文字 '0' が続いたものとしては解釈されません。後方参照 \g<0> は正規表現とマッチした部分文字列全体で置き換わります。
バージョン 3.1 で変更: オプションの flags 引数が追加されました。
バージョン 3.5 で変更: マッチしなかったグループは空文字列に置き換えられます。
バージョン 3.6 で変更: pattern 中に '\' と ASCII 文字からなる未知のエスケープがあると、エラーになります。
バージョン 3.7 で変更: repl 中に '\' と ASCII 文字からなる未知のエスケープがあると、エラーになります。
バージョン 3.7 で変更: パターンへの空マッチは前の空でないマッチに隣接しているとき置き換えられます。
re.subn(pattern, repl, string, count=0, flags=0)
sub() と同じ操作を行いますが、タプル (new_string、 number_of_subs_made) を返します。
バージョン 3.1 で変更: オプションの flags 引数が追加されました。
バージョン 3.5 で変更: マッチしなかったグループは空文字列に置き換えられます。
re.escape(pattern)
pattern 中の特殊文字をエスケープします。これは正規表現メタ文字を含みうる任意のリテラル文字列にマッチしたい時に便利です。
>>>
>>> print(re.escape('http://www.python.org'))
http://www\.python\.org
>>> legal_chars = string.ascii_lowercase + string.digits + "!#$%&'*+-.^_`|~:"
>>> print('[%s]+' % re.escape(legal_chars))
[abcdefghijklmnopqrstuvwxyz0123456789!\#\$%\&'\*\+\-\.\^_`\|\~:]+
>>> operators = ['+', '-', '*', '/', '**']
>>> print('|'.join(map(re.escape, sorted(operators, reverse=True))))
/|\-|\+|\*\*|\*
この関数は、バックスラッシュのみをエスケープするべき sub() および subn() における置換文字列に使われてはなりません。例えば:
>>>
>>> digits_re = r'\d+'
>>> sample = '/usr/sbin/sendmail - 0 errors, 12 warnings'
>>> print(re.sub(digits_re, digits_re.replace('\\', r'\\'), sample))
/usr/sbin/sendmail - \d+ errors, \d+ warnings
バージョン 3.3 で変更: '_' 文字がエスケープされなくなりました。
バージョン 3.7 で変更: 正規表現で特別な意味を持つ文字だけがエスケープされます。結果として、 '!'、 '"'、 '%'、 "'"、 ','、 '/'、 ':'、 ';'、 '<'、 '='、 '>'、 '@'、 と "`" はもはやエスケープされません。
re.purge()
正規表現キャッシュをクリアします。
exception re.error(msg, pattern=None, pos=None)
ここの関数のいずれかに渡された文字列が有効な正規表現ではない (例: 括弧が対になっていない) とき、またはコンパイルやマッチングの際にその他なんらかのエラーが発生した場合に送出される例外です。文字列にパターンとマッチする部分がなくても、それはエラーではありません。エラーインスタンスには、次のような追加の属性があります。
msg
フォーマットされていないエラーメッセージです。
pattern
正規表現のパターンです。
pos
pattern のコンパイルに失敗した場所のインデックスです (None の場合もあります)。
lineno
pos に対応する行です (None の場合もあります)。
colno
pos に対応する列です (None の場合もあります)。
バージョン 3.5 で変更: 追加の属性が追加されました。
正規表現オブジェクト
コンパイル済み正規表現オブジェクトは以下のメソッドと属性をサポートします:
Pattern.search(string[, pos[, endpos]])
string を走査し、この正規表現がマッチを生じさせる最初の場所を探して、対応する マッチオブジェクト を返します。文字列内にパターンにマッチする場所がなければ None を返します。これは文字列内のある場所で長さが 0 のマッチが見つかった場合とは異なることに注意してください。
オプションの第二引数 pos は、文字列のどこから探し始めるかを指定するインデックスで、デフォルトでは 0 です。これは文字列のスライスと完全には同じではありません。パターン文字 '^' は本当の文字列の先頭と改行の直後でマッチしますが、検索を開始するインデックスでマッチするとは限りません。
オプションの引数 endpos は文字列がどこまで検索されるかを制限します。文字列の長さが endpos 文字だったかのようになるので、pos から endpos - 1 の文字に対してだけマッチを探します。endpos が pos よりも小さいと、マッチは見つかりません。そうでなければ、rx をコンパイル済み正規表現オブジェクトとして、rx.search(string, 0, 50) は rx.search(string[:50], 0) と等価です。
>>>
>>> pattern = re.compile("d")
>>> pattern.search("dog")     # Match at index 0
<re.Match object; span=(0, 1), match='d'>
>>> pattern.search("dog", 1)  # No match; search doesn't include the "d"
Pattern.match(string[, pos[, endpos]])
string の 先頭 で 0 文字以上がこの正規表現とマッチするなら、対応する マッチオブジェクト を返します。文字列がパターンにマッチしなければ None を返します。これは長さ 0 のマッチとは異なることに注意してください。
オプションの pos および endpos 引数は search() メソッドのものと同じ意味です。
>>>
>>> pattern = re.compile("o")
>>> pattern.match("dog")      # No match as "o" is not at the start of "dog".
>>> pattern.match("dog", 1)   # Match as "o" is the 2nd character of "dog".
<re.Match object; span=(1, 2), match='o'>
string 中のどこででもマッチさせたいなら、代わりに search() を使ってください (search() vs. match() も参照してください)。
Pattern.fullmatch(string[, pos[, endpos]])
string 全体がこの正規表現にマッチすれば、対応する マッチオブジェクト を返します。文字列がパターンにマッチしなければ None を返します。これは長さ 0 のマッチとは異なることに注意してください。
オプションの pos および endpos 引数は search() メソッドのものと同じ意味です。
>>>
>>> pattern = re.compile("o[gh]")
>>> pattern.fullmatch("dog")      # No match as "o" is not at the start of "dog".
>>> pattern.fullmatch("ogre")     # No match as not the full string matches.
>>> pattern.fullmatch("doggie", 1, 3)   # Matches within given limits.
<re.Match object; span=(1, 3), match='og'>
バージョン 3.4 で追加.
Pattern.split(string, maxsplit=0)
split() 関数にこのコンパイル済みパターンを使うのと同じです。
Pattern.findall(string[, pos[, endpos]])
findall() 関数にこのコンパイル済みパターンを使うのと似ていますが、オプションの pos および endpos 引数で search() のように検索範囲を制限できます。
Pattern.finditer(string[, pos[, endpos]])
finditer() 関数にこのコンパイル済みパターンを使うのと似ていますが、オプションの pos および endpos 引数で search() のように検索範囲を制限できます。
Pattern.sub(repl, string, count=0)
sub() 関数にこのコンパイル済みパターンを使うのと同じです。
Pattern.subn(repl, string, count=0)
subn() 関数にこのコンパイル済みパターンを使うのと同じです。
Pattern.flags
正規表現のマッチングフラグです。これは compile() に与えられたフラグ、パターン中の (?...) インラインフラグ、およびパターンが Unicode 文字列だった時の UNICODE のような暗黙のフラグの組み合わせです。
Pattern.groups
パターン中のキャプチャグループの数です。
Pattern.groupindex
(?P<id>) で定義されたあらゆるシンボリックグループ名をグループ番号へ写像する辞書です。シンボリックグループがパターン中で全く使われていなければ、この辞書は空です。
Pattern.pattern
パターンオブジェクトがコンパイルされた元のパターン文字列です。
バージョン 3.7 で変更: copy.copy() および copy.deepcopy() をサポートするようになりました。コンパイル済み正規表現オブジェクトはアトミックであると見なされます。
マッチオブジェクト
マッチオブジェクトのブール値は常に True です。 match() および search() はマッチがないとき None を返すので、マッチがあるか単純な if 文で判定できます。
match = re.search(pattern, string)
if match:
    process(match)
マッチオブジェクトは以下のメソッドおよび属性をサポートしています:
Match.expand(template)
テンプレート文字列 template に sub() メソッドの行うバックスラッシュ置換を行って得られる文字列を返します。 \n のようなエスケープは適切な文字に変換され、数後方参照 (\1, \2) および名前付き後方参照 (\g<1>, \g<name>) は対応するグループの内容に置換されます。
バージョン 3.5 で変更: マッチしなかったグループは空文字列に置き換えられます。
Match.group([group1, ...])
このマッチの 1 つ以上のサブグループを返します。引数が 1 つなら結果は 1 つの文字列です。複数の引数があれば、結果は引数ごとに 1 項目のタプルです。引数がなければ、 group1 はデフォルトで 0 (マッチ全体が返される) です。 groupN 引数が 0 なら、対応する返り値はマッチした文字列全体です。1 以上 99 以下なら、丸括弧による対応するグループにマッチする文字列です。グループ番号が負であるかパターン中で定義されたグループの数より大きければ、 IndexError 例外が送出されます。あるグループがパターンのマッチしなかった部分に含まれているなら、対応する結果は None です。あるグループがパターンの複数回マッチした部分に含まれているなら、最後のマッチが返されます。
>>>
>>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")
>>> m.group(0)       # The entire match
'Isaac Newton'
>>> m.group(1)       # The first parenthesized subgroup.
'Isaac'
>>> m.group(2)       # The second parenthesized subgroup.
'Newton'
>>> m.group(1, 2)    # Multiple arguments give us a tuple.
('Isaac', 'Newton')
正規表現が (?P<name>...) 構文を使うなら、 groupN 引数はグループ名でグループを識別する文字列でも構いません。文字列引数がパターン中でグループ名として使われていなければ、 IndexError 例外が送出されます。
やや複雑な例:
>>>
>>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
>>> m.group('first_name')
'Malcolm'
>>> m.group('last_name')
'Reynolds'
名前付きグループはインデックスでも参照できます:
>>>
>>> m.group(1)
'Malcolm'
>>> m.group(2)
'Reynolds'
あるグループが複数回マッチすると、その最後のマッチにのみアクセスできます:
>>>
>>> m = re.match(r"(..)+", "a1b2c3")  # Matches 3 times.
>>> m.group(1)                        # Returns only the last match.
'c3'
Match.__getitem__(g)
これは m.group(g) と同等です。これでマッチの個別のグループに簡単にアクセスできます:
>>>
>>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")
>>> m[0]       # The entire match
'Isaac Newton'
>>> m[1]       # The first parenthesized subgroup.
'Isaac'
>>> m[2]       # The second parenthesized subgroup.
'Newton'
バージョン 3.6 で追加.
Match.groups(default=None)
このマッチの、1 からパターン中のグループ数まで、全てのサブグループを含むタプルを返します。default 引数はマッチに関係しなかったグループに使われます。デフォルトでは None です。
例えば:
>>>
>>> m = re.match(r"(\d+)\.(\d+)", "24.1632")
>>> m.groups()
('24', '1632')
少数位およびその後の全てをオプションにすると、全てのグループがマッチに関係するとは限りません。そういったグループは default 引数が与えられない限りデフォルトで None になります。
>>>
>>> m = re.match(r"(\d+)\.?(\d+)?", "24")
>>> m.groups()      # Second group defaults to None.
('24', None)
>>> m.groups('0')   # Now, the second group defaults to '0'.
('24', '0')
Match.groupdict(default=None)
このマッチの、全ての 名前付き サブグループを含む、サブグループ名をキーとする辞書を返します。 default 引数はマッチに関係しなかったグループに使われます。デフォルトは None です。例えば:
>>>
>>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
>>> m.groupdict()
{'first_name': 'Malcolm', 'last_name': 'Reynolds'}
Match.start([group])
Match.end([group])
group がマッチした部分文字列の先頭と末尾のインデックスを返します。 group はデフォルトで 0 (マッチした部分文字列全体という意味) です。 group が存在してかつマッチには寄与していなかったなら -1 を返します。マッチオブジェクト m と、マッチに寄与したグループ g に対して、グループ g がマッチした部分文字列 (m.group(g) と等価です) は以下の通りです
m.string[m.start(g):m.end(g)]
group が空文字列にマッチしていたら m.start(group) は m.end(group) と等しくなることに注意して下さい。例えば、 m = re.search('b(c?)', 'cba') とすると、 m.start(0) は 1 で、 m.end(0) は 2 で、 m.start(1) と m.end(1) はともに 2 であり、 m.start(2) は IndexError 例外を発生します。
メールアドレスから remove_this を取り除く例:
>>>
>>> email = "tony@tiremove_thisger.net"
>>> m = re.search("remove_this", email)
>>> email[:m.start()] + email[m.end():]
'tony@tiger.net'
Match.span([group])
マッチ m について、2 タプル (m.start(group), m.end(group)) を返します。 group がマッチに寄与していなければ、これは (-1, -1) です。 group はデフォルトで 0 、マッチ全体です。
Match.pos
正規表現オブジェクト の search() や match() に渡された pos の値です。これは正規表現エンジンがマッチを探し始める位置の文字列のインデックスです。
Match.endpos
正規表現オブジェクト の search() や match() に渡された endpos の値です。これは正規表現エンジンがそれ以上は進まない文字列のインデックスです。
Match.lastindex
最後にマッチしたキャプチャグループの整数インデックスです。どのグループも全くマッチしなければ None です。例えば、表現 (a)b 、 ((a)(b)) や ((ab)) が 'ab' に適用されると lastindex == 1 となり、同じ文字列に (a)(b) が適用されると lastindex == 2 となります。
Match.lastgroup
最後にマッチしたキャプチャグループの名前です。そのグループに名前がないか、どのグループも全くマッチしていなければ None です。
Match.re
このマッチインスタンスを生じさせた match() または search() メソッドの属する 正規表現オブジェクト です。
Match.string
match() や search() へ渡された文字列です。
バージョン 3.7 で変更: copy.copy() および copy.deepcopy() をサポートするようになりました。マッチオブジェクトはアトミックであると見なされます。
正規表現の例
ペアの確認
この例では、マッチオブジェクトをより美しく表示するために、この補助関数を使用します:
def displaymatch(match):
    if match is None:
        return None
    return '<Match: %r, groups=%r>' % (match.group(), match.groups())
あなたがポーカープログラムを書いているとします。プレイヤーの手札は 5 文字の文字列によって表され、それぞれの文字が 1 枚のカードを表します。 "a" はエース、 "k" はキング、 "q" はクイーン、 "j" はジャック、 "t" は 10、そして "2" から "9" はその数字のカードを表します。
与えられた文字列が有効な手札であるか見るには、以下のようにできます:
>>>
>>> valid = re.compile(r"^[a2-9tjqk]{5}$")
>>> displaymatch(valid.match("akt5q"))  # Valid.
"<Match: 'akt5q', groups=()>"
>>> displaymatch(valid.match("akt5e"))  # Invalid.
>>> displaymatch(valid.match("akt"))    # Invalid.
>>> displaymatch(valid.match("727ak"))  # Valid.
"<Match: '727ak', groups=()>"
最後の手札、 "727ak" 、はペア、すなわち同じ値の 2 枚のカードを含みます。正規表現でこれにマッチするには、このように後方参照を使えます:
>>>
>>> pair = re.compile(r".*(.).*\1")
>>> displaymatch(pair.match("717ak"))     # Pair of 7s.
"<Match: '717', groups=('7',)>"
>>> displaymatch(pair.match("718ak"))     # No pairs.
>>> displaymatch(pair.match("354aa"))     # Pair of aces.
"<Match: '354aa', groups=('a',)>"
ペアになっているのがどのカードか調べるには、このようにマッチオブジェクトの group() メソッドを使えます:
>>>
>>> pair = re.compile(r".*(.).*\1")
>>> pair.match("717ak").group(1)
'7'
# Error because re.match() returns None, which doesn't have a group() method:
>>> pair.match("718ak").group(1)
Traceback (most recent call last):
  File "<pyshell#23>", line 1, in <module>
    re.match(r".*(.).*\1", "718ak").group(1)
AttributeError: 'NoneType' object has no attribute 'group'
>>> pair.match("354aa").group(1)
'a'
scanf() をシミュレートする
Python には現在のところ、 scanf() に相当するものがありません。正規表現は一般的に、 scanf() のフォーマット文字列より強力ですが、冗長でもあります。以下の表に、 scanf() のフォーマットトークンと正規表現のおおよその対応付けを示します。
scanf() トークン
正規表現
%c
%5c
.{5}
%d
[-+]?\d+
%e, %E, %f, %g
[-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?
%i
[-+]?(0[xX][\dA-Fa-f]+|0[0-7]*|\d+)
%o
[-+]?[0-7]+
%s
\S+
%u
\d+
%x, %X
[-+]?(0[xX])?[\dA-Fa-f]+
以下のような文字列からファイル名と数を抽出するには
/usr/sbin/sendmail - 0 errors, 4 warnings
以下のように scanf() フォーマットを使えます
%s - %d errors, %d warnings
等価な正規表現はこうです
(\S+) - (\d+) errors, (\d+) warnings
search() vs. match()
Python は正規表現ベースの 2 つの異なる基本的な関数、文字列の先頭でのみのマッチを確認する re.match() および、文字列中の位置にかかわらずマッチを確認する re.search() (これが Perl でのデフォルトの挙動です) を提供しています。
例えば:
>>>
>>> re.match("c", "abcdef")    # No match
>>> re.search("c", "abcdef")   # Match
<re.Match object; span=(2, 3), match='c'>
'^' で始まる正規表現を search() で使って、マッチを文字列の先頭でのみに制限できます:
>>>
>>> re.match("c", "abcdef")    # No match
>>> re.search("^c", "abcdef")  # No match
>>> re.search("^a", "abcdef")  # Match
<re.Match object; span=(0, 1), match='a'>
ただし、 MULTILINE モードにおいて match() は文字列の先頭でのみマッチし、 '^' で始まる正規表現で search() を使うと各行の先頭でマッチすることに注意してください。
>>>
>>> re.match('X', 'A\nB\nX', re.MULTILINE)  # No match
>>> re.search('^X', 'A\nB\nX', re.MULTILINE)  # Match
<re.Match object; span=(4, 5), match='X'>
電話帳を作る
split() は渡されたパターンで文字列を分割してリストにします。このメソッドは、テキストデータをデータ構造に変換して、読みやすくしたり、以下の例で実演する電話帳作成のように Python で編集したりしやすくするのに、非常に役に立ちます。
最初に、入力を示します。通常、これはファイルからの入力になるでしょう。ここでは、3重引用符の書式とします。
>>> text = """Ross McFluff: 834.345.1254 155 Elm Street
...
... Ronald Heathmore: 892.345.3428 436 Finley Avenue
... Frank Burger: 925.541.7625 662 South Dogwood Way
...
...
... Heather Albrecht: 548.326.4584 919 Park Place"""
各項目は 1 つ以上の改行で区切られています。まずは文字列を変換して、空行でない各行を項目とするリストにします:
>>> entries = re.split("\n+", text)
>>> entries
['Ross McFluff: 834.345.1254 155 Elm Street',
'Ronald Heathmore: 892.345.3428 436 Finley Avenue',
'Frank Burger: 925.541.7625 662 South Dogwood Way',
'Heather Albrecht: 548.326.4584 919 Park Place']
そして各項目を、ファーストネーム、ラストネーム、電話番号、住所に分割してリストにします。分割パターンである空白文字は住所にも含まれるので、 split() の maxsplit 引数を使います:
>>> [re.split(":? ", entry, 3) for entry in entries]
[['Ross', 'McFluff', '834.345.1254', '155 Elm Street'],
['Ronald', 'Heathmore', '892.345.3428', '436 Finley Avenue'],
['Frank', 'Burger', '925.541.7625', '662 South Dogwood Way'],
['Heather', 'Albrecht', '548.326.4584', '919 Park Place']]
この :? パターンはラストネームの次のコロンにマッチして、分割結果のリストに出てこないようにします。 maxsplit を 4 にすれば、家屋番号とストリート名を分割できます:
>>> [re.split(":? ", entry, 4) for entry in entries]
[['Ross', 'McFluff', '834.345.1254', '155', 'Elm Street'],
['Ronald', 'Heathmore', '892.345.3428', '436', 'Finley Avenue'],
['Frank', 'Burger', '925.541.7625', '662', 'South Dogwood Way'],
['Heather', 'Albrecht', '548.326.4584', '919', 'Park Place']]
テキストの秘匿
sub() は出現する各パターンを文字列で、または関数の返り値で置き換えます。この例ではテキストを「秘匿」する関数と合わせて sub() を使うところを実演します。具体的には、文中の各単語について、最初と最後の文字を除く全ての文字をランダムに並び替えます:
>>>
>>> def repl(m):
...     inner_word = list(m.group(2))
...     random.shuffle(inner_word)
...     return m.group(1) + "".join(inner_word) + m.group(3)
>>> text = "Professor Abdolmalek, please report your absences promptly."
>>> re.sub(r"(\w)(\w+)(\w)", repl, text)
'Poefsrosr Aealmlobdk, pslaee reorpt your abnseces plmrptoy.'
>>> re.sub(r"(\w)(\w+)(\w)", repl, text)
'Pofsroser Aodlambelk, plasee reoprt yuor asnebces potlmrpy.'
全ての副詞を見つける
search() は最初のパターンにのみマッチしますが、 findall() は出現する 全ての パターンにマッチします。例えば、ライターがあるテキストの全ての副詞を見つけたいなら、以下のように findall() を使えます:
>>>
>>> text = "He was carefully disguised but captured quickly by police."
>>> re.findall(r"\w+ly", text)
['carefully', 'quickly']
全ての副詞とその位置を見つける
パターンの全てのマッチについて、マッチしたテキスト以上の情報が必要なら、文字列ではなく マッチオブジェクト を返す finditer() が便利です。先の例に続いて、ライターがあるテキストの全ての副詞 およびその位置 を見つけたいなら、以下のように finditer() を使えます:
>>>
>>> text = "He was carefully disguised but captured quickly by police."
>>> for m in re.finditer(r"\w+ly", text):
...     print('%02d-%02d: %s' % (m.start(), m.end(), m.group(0)))
07-16: carefully
40-47: quickly
Raw 文字列記法
Raw 文字列記法 (r"text") で正規表現をまともに保てます。それがなければ、正規表現中のバックスラッシュ ('\') を個々にバックスラッシュを前置してエスケープしなければなりません。例えば、以下の 2 行のコードは機能的に等価です:
>>>
>>> re.match(r"\W(.)\1\W", " ff ")
<re.Match object; span=(0, 4), match=' ff '>
>>> re.match("\\W(.)\\1\\W", " ff ")
<re.Match object; span=(0, 4), match=' ff '>
リテラルのバックスラッシュにマッチさせたいなら、正規表現中ではエスケープする必要があります。Raw 文字列記法では、r"\\" になります。Raw 文字列記法を用いないと、"\\\\" としなくてはならず、以下のコードは機能的に等価です:
>>>
>>> re.match(r"\\", r"\\")
<re.Match object; span=(0, 1), match='\\'>
>>> re.match("\\\\", r"\\")
<re.Match object; span=(0, 1), match='\\'>
トークナイザを書く
トークナイザやスキャナ は文字列を解析し、文字のグループにカテゴリ分けします。これはコンパイラやインタプリタを書くうえで役立つ第一段階です。
テキストのカテゴリは正規表現で指定されます。この技法では、それらを一つのマスター正規表現に結合し、マッチの連続についてループします:
from typing import NamedTuple
import re
class Token(NamedTuple):
    type: str
    value: str
    line: int
    column: int
def tokenize(code):
    keywords = {'IF', 'THEN', 'ENDIF', 'FOR', 'NEXT', 'GOSUB', 'RETURN'}
    token_specification = [
        ('NUMBER',   r'\d+(\.\d*)?'),  # Integer or decimal number
        ('ASSIGN',   r':='),           # Assignment operator
        ('END',      r';'),            # Statement terminator
        ('ID',       r'[A-Za-z]+'),    # Identifiers
        ('OP',       r'[+\-*/]'),      # Arithmetic operators
        ('NEWLINE',  r'\n'),           # Line endings
        ('SKIP',     r'[ \t]+'),       # Skip over spaces and tabs
        ('MISMATCH', r'.'),            # Any other character
    ]
    tok_regex = '|'.join('(?P<%s>%s)' % pair for pair in token_specification)
    line_num = 1
    line_start = 0
    for mo in re.finditer(tok_regex, code):
        kind = mo.lastgroup
        value = mo.group()
        column = mo.start() - line_start
        if kind == 'NUMBER':
            value = float(value) if '.' in value else int(value)
        elif kind == 'ID' and value in keywords:
            kind = value
        elif kind == 'NEWLINE':
            line_start = mo.end()
            line_num += 1
            continue
        elif kind == 'SKIP':
            continue
        elif kind == 'MISMATCH':
            raise RuntimeError(f'{value!r} unexpected on line {line_num}')
        yield Token(kind, value, line_num, column)
statements = '''
    IF quantity THEN
        total := total + price * quantity;
        tax := price * 0.05;
    ENDIF;
'''
for token in tokenize(statements):
    print(token)
このトークナイザは以下の出力を作成します:
Token(type='IF', value='IF', line=2, column=4)
Token(type='ID', value='quantity', line=2, column=7)
Token(type='THEN', value='THEN', line=2, column=16)
Token(type='ID', value='total', line=3, column=8)
Token(type='ASSIGN', value=':=', line=3, column=14)
Token(type='ID', value='total', line=3, column=17)
Token(type='OP', value='+', line=3, column=23)
Token(type='ID', value='price', line=3, column=25)
Token(type='OP', value='*', line=3, column=31)
Token(type='ID', value='quantity', line=3, column=33)
Token(type='END', value=';', line=3, column=41)
Token(type='ID', value='tax', line=4, column=8)
Token(type='ASSIGN', value=':=', line=4, column=12)
Token(type='ID', value='price', line=4, column=15)
Token(type='OP', value='*', line=4, column=21)
Token(type='NUMBER', value=0.05, line=4, column=23)
Token(type='END', value=';', line=4, column=27)
Token(type='ENDIF', value='ENDIF', line=5, column=4)
Token(type='END', value=';', line=5, column=9)
Frie09
Friedl, Jeffrey. Mastering Regular Expressions. 3rd ed., O'Reilly Media, 2009. 当書の第三版ではもはや Python についてまったく取り扱っていませんが、初版では良い正規表現を書くことを綿密に取り扱っていました。
difflib --- 差分の計算を助ける
ソースコード: Lib/difflib.py
class difflib.SequenceMatcher
柔軟性のあるクラスで、二つのシーケンスの要素が ハッシュ可能 な型であれば、どの型の要素を含むシーケンスも比較可能です。基本的なアルゴリズムは、1980年代の後半に発表された Ratcliff と Obershelp による"ゲシュタルトパターンマッチング"と大げさに名づけられたアルゴリズム以前から知られている、やや凝ったアルゴリズムです。その考え方は、"junk" 要素を含まない最も長い互いに隣接したマッチ列を探すことです。ここで、 "junk" 要素とは、空行や空白などの、意味を持たない要素のことです。 (junk を処理するのは、Ratcliff と Obershelp のアルゴリズムに追加された拡張です。)この考え方は、マッチ列の左右に隣接するシーケンスの断片に対して再帰的にあてはめられます。この方法では編集を最小にするシーケンスは生まれませんが、人間の目からみて「正しい感じ」にマッチする傾向があります。
実行時間: 基本的な Ratcliff-Obershelp アルゴリズムは、最悪の場合3乗、期待値で2乗となります。 SequenceMatcher オブジェクトでは、最悪のケースで2乗、期待値は比較されるシーケンス中に共通に現れる要素数に非常にややこしく依存しています。最良の場合は線形時間になります。
自動 junk ヒューリスティック: SequenceMatcher は、シーケンスの特定の要素を自動的に junk として扱うヒューリスティックをサポートしています。このヒューリスティックは、各個要素がシーケンス内に何回現れるかを数えます。ある要素の重複数が (最初のものは除いて) 合計でシーケンスの 1% 以上になり、そのシーケンスが 200 要素以上なら、その要素は "popular" であるものとしてマークされ、シーケンスのマッチングの目的からは junk として扱われます。このヒューリスティックは、 SequenceMatcher の作成時に autojunk パラメタを False に設定することで無効化できます。
バージョン 3.2 で追加: autojunk パラメータ。
class difflib.Differ
テキスト行からなるシーケンスを比較するクラスです。人が読むことのできる差分を作成します。 Differ クラスは SequenceMatcher クラスを利用して、行からなるシーケンスを比較したり、(ほぼ)同一の行内の文字を比較したりします。
Differ クラスによる差分の各行は、2文字のコードで始まります:
コード
意味
'- '
行はシーケンス1にのみ存在する
'+ '
行はシーケンス2にのみ存在する
'  '
行は両方のシーケンスで同一
'? '
行は入力シーケンスのどちらにも存在しない
'?' で始まる行は、行内のどこに差異が存在するかに注意を向けようとします。その行は、入力されたシーケンスのどちらにも存在しません。シーケンスがタブ文字を含むとき、これらの行は判別しづらいものになることがあります。
class difflib.HtmlDiff
このクラスは、二つのテキストを左右に並べて比較表示し、行間あるいは行内の変更点を強調表示するような HTML テーブル (またはテーブルの入った完全な HTML ファイル) を生成するために使います。テーブルは完全差分モード、コンテキスト差分モードのいずれでも生成できます。
このクラスのコンストラクタは以下のようになっています:
__init__(tabsize=8, wrapcolumn=None, linejunk=None, charjunk=IS_CHARACTER_JUNK)
HtmlDiff のインスタンスを初期化します。
tabsize はオプションのキーワード引数で、タブストップ幅を指定します。デフォルトは 8 です。
wrapcolumn はオプションのキーワード引数で、テキストを折り返すカラム幅を指定します。デフォルトは None で折り返しを行いません。
linejunk および charjunk はオプションのキーワード引数で、 ndiff() (HtmlDiff はこの関数を使って左右のテキストの差分を HTML で生成します) に渡されます。それぞれの引数のデフォルト値および説明は ndiff() のドキュメントを参照してください。
以下のメソッドが public になっています:
make_file(fromlines, tolines, fromdesc='', todesc='', context=False, numlines=5, *, charset='utf-8')
fromlines と tolines (いずれも文字列のリスト) を比較し、行間または行内の変更点が強調表示された行差分の入った表を持つ完全な HTML ファイルを文字列で返します。
fromdesc および todesc はオプションのキーワード引数で、差分表示テーブルにおけるそれぞれ差分元、差分先ファイルのカラムのヘッダになる文字列を指定します (いずれもデフォルト値は空文字列です)。
context および numlines はともにオプションのキーワード引数です。context を True にするとコンテキスト差分を表示し、デフォルトの False にすると完全なファイル差分を表示します。numlines のデフォルト値は 5 で、context が True の場合、numlines は強調部分の前後にあるコンテキスト行の数を制御します。context が False の場合、numlines は "next" と書かれたハイパーリンクをたどった時に到達する場所が次の変更部分より何行前にあるかを制御します (値をゼロにした場合、"next" ハイパーリンクを辿ると変更部分の強調表示がブラウザの最上部に表示されるようになります)。
注釈 fromdesc と todesc はエスケープされていないHTMLとして解釈されます。信頼できないソースからの入力を受け取る際には適切にエスケープされるべきです。
バージョン 3.5 で変更: charset キーワード専用引数が追加されました。HTML 文書のデフォルトの文字集合が 'ISO-8859-1' から 'utf-8' に変更されました。
make_table(fromlines, tolines, fromdesc='', todesc='', context=False, numlines=5)
fromlines と tolines (いずれも文字列のリスト) を比較し、行間または行内の変更点が強調表示された行差分の入った完全な HTML テーブルを文字列で返します。
このメソッドの引数は、 make_file() メソッドの引数と同じです。
Tools/scripts/diff.py はこのクラスへのコマンドラインフロントエンドで、使い方を学ぶ上で格好の例題が入っています。
difflib.context_diff(a, b, fromfile='', tofile='', fromfiledate='', tofiledate='', n=3, lineterm='\n')
a と b (文字列のリスト) を比較し、差分 (差分形式の行を生成する ジェネレータ) を、 context diff のフォーマット(以下「コンテキスト形式」)で返します。
コンテキスト形式は、変更があった行に前後数行を加えてある、コンパクトな表現方法です。変更箇所は、変更前/変更後に分けて表します。コンテキスト (変更箇所前後の行) の行数は n で指定し、デフォルト値は 3 です。
デフォルトで、 diff 制御行 (*** や --- を含む行) は改行付きで生成されます。 io.IOBase.readlines() で作られた入力が io.IOBase.writelines() で扱うのに適した diff になるので (なぜなら入力と出力の両方が改行付きのため) 、これは有用です。
行末に改行文字を持たない入力に対しては、出力でも改行文字を付加しないように lineterm 引数に "" を渡してください。
コンテキスト形式は、通常、ヘッダにファイル名と変更時刻を持っています。この情報は、文字列 fromfile, tofile, fromfiledate, tofiledate で指定できます。変更時刻の書式は、通常、ISO 8601 フォーマットで表されます。指定しなかった場合のデフォルト値は、空文字列です。
>>>
>>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
>>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
>>> sys.stdout.writelines(context_diff(s1, s2, fromfile='before.py', tofile='after.py'))
*** before.py
--- after.py
***************
*** 1,4 ****
! bacon
! eggs
! ham
  guido
--- 1,4 ----
! python
! eggy
! hamster
  guido
より詳細な例は、 difflib のコマンドラインインタフェース を参照してください。
difflib.get_close_matches(word, possibilities, n=3, cutoff=0.6)
「十分」なマッチの上位のリストを返します。word はマッチさせたいシーケンス (大概は文字列) です。possibilities は word にマッチさせるシーケンスのリスト (大概は文字列のリスト) です。
オプションの引数 n (デフォルトでは 3)はメソッドの返すマッチの最大数です。n は 0 より大きくなければなりません。
オプションの引数 cutoff (デフォルトでは 0.6)は、区間 [0, 1] に入る小数の値です。word との一致率がそれ未満の possibilities の要素は無視されます。
possibilities の要素でマッチした上位(多くても n 個)は、類似度のスコアに応じて(一番似たものを先頭に)ソートされたリストとして返されます。
>>>
>>> get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])
['apple', 'ape']
>>> import keyword
>>> get_close_matches('wheel', keyword.kwlist)
['while']
>>> get_close_matches('pineapple', keyword.kwlist)
[]
>>> get_close_matches('accept', keyword.kwlist)
['except']
difflib.ndiff(a, b, linejunk=None, charjunk=IS_CHARACTER_JUNK)
a と b (文字列のリスト) を比較し、差分 (差分形式の行を生成する ジェネレータ) を、 Differ のスタイルで返します。
オプションのキーワード引数 linejunk と charjunk には、フィルタ関数 (または None) を渡します。
linejunk: 文字列型の引数 1 つを受け取る関数です。文字列が junk の場合は真を、そうでない場合は偽を返します。デフォルトでは None です。モジュールレべルの関数 IS_LINE_JUNK() は、高々 1 つのシャープ記号('#')を除いて可視の文字を含まない行をフィルタリングするものです。しかし、下層にある SequenceMatcher クラスが、どの行が雑音となるほど頻繁に登場するかを動的に分析します。このクラスによる分析は、この関数を使用するよりも通常うまく動作します。
charjunk: 文字 (長さ1の文字列) を受け取る関数です。文字列が junk の場合は真を、そうでない場合は偽を返します。デフォルトでは、モジュールレべルの関数 IS_CHARACTER_JUNK() であり、これは空白文字類 (空白またはタブ、改行文字をこれに含めてはいけません) をフィルタして排除します。
Tools/scripts/ndiff.py は、この関数のコマンドラインのフロントエンド（インターフェイス）です。
>>>
>>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
...              'ore\ntree\nemu\n'.splitlines(keepends=True))
>>> print(''.join(diff), end="")
- one
?  ^
+ ore
?  ^
- two
- three
?  -
+ tree
+ emu
difflib.restore(sequence, which)
差分を生成した元の二つのシーケンスのうち一つを返します。
Differ.compare() または ndiff() によって生成された sequence を与えられると、行頭のプレフィクスを取りのぞいてファイル 1 または 2 (引数 which で指定される) に由来する行を復元します。
例:
>>>
>>> diff = ndiff('one\ntwo\nthree\n'.splitlines(keepends=True),
...              'ore\ntree\nemu\n'.splitlines(keepends=True))
>>> diff = list(diff) # materialize the generated delta into a list
>>> print(''.join(restore(diff, 1)), end="")
one
two
three
>>> print(''.join(restore(diff, 2)), end="")
ore
tree
emu
difflib.unified_diff(a, b, fromfile='', tofile='', fromfiledate='', tofiledate='', n=3, lineterm='\n')
a と b (文字列のリスト) を比較し、差分 (差分形式の行を生成する ジェネレータ) を、 unified diff フォーマット(以下「ユニファイド形式」)で返します。
ユニファイド形式は変更があった行にコンテキストとなる前後数行を加えた、コンパクトな表現方法です。変更箇所は (変更前/変更後を分離したブロックではなく) インラインスタイルで表されます。コンテキストの行数は、n で指定し、デフォルト値は 3 です。
デフォルトで、 diff 制御行 (---, +++, @@ を含む行) は改行付きで生成されます。 io.IOBase.readlines() で作られた入力が io.IOBase.writelines() で扱うのに適した diff になるので (なぜなら入力と出力の両方が改行付きのため) 、これは有用です。
行末に改行文字を持たない入力に対しては、出力でも改行文字を付加しないように lineterm 引数に "" を渡してください。
コンテキスト形式は、通常、ヘッダにファイル名と変更時刻を持っています。この情報は、文字列 fromfile, tofile, fromfiledate, tofiledate で指定できます。変更時刻の書式は、通常、ISO 8601 フォーマットで表されます。指定しなかった場合のデフォルト値は、空文字列です。
>>>
>>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
>>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
>>> sys.stdout.writelines(unified_diff(s1, s2, fromfile='before.py', tofile='after.py'))
--- before.py
+++ after.py
@@ -1,4 +1,4 @@
-bacon
-eggs
-ham
+python
+eggy
+hamster
 guido
より詳細な例は、 difflib のコマンドラインインタフェース を参照してください。
difflib.diff_bytes(dfunc, a, b, fromfile=b'', tofile=b'', fromfiledate=b'', tofiledate=b'', n=3, lineterm=b'\n')
dfunc を使用して a と b (bytes オブジェクトのリスト) を比較して、差分形式の行 (これも bytes オブジェクトです) を*dfunc* の戻り値の形式で返します。dfunc は、呼び出し可能である必要があります。一般に、これは unified_diff() または context_diff() です。
未知のエンコーディングまたは一貫性のないエンコーディングのデータ同士を比較できます。n 以外のすべての入力は、bytes オブジェクトである必要があります。n 以外のすべての入力を損失なく str に変換して、dfunc(a, b, fromfile, tofile, fromfiledate, tofiledate, n, lineterm) を呼び出すことにより動作します。dfunc の出力は、bytes 型に変換されます。これにより、受け取る差分形式の行のエンコーディングは、a と b の未知または一貫性のないエンコーディングと同一になります。
バージョン 3.5 で追加.
difflib.IS_LINE_JUNK(line)
無視できる行のとき True を返します。行 line は空白、または '#' ひとつのときに無視できます。それ以外のときには無視できません。古いバージョンでは ndiff() の引数 linejunk にデフォルトで使用されました。
difflib.IS_CHARACTER_JUNK(ch)
無視できる文字のとき True を返します。文字 ch が空白、またはタブ文字のときには無視できます。それ以外の時には無視できません。 ndiff() の引数 charjunk としてデフォルトで使用されます。
参考
Pattern Matching: The Gestalt Approach
John W. Ratcliff と D. E. Metzener による類似のアルゴリズムに関する議論。Dr. Dobb's Journal 1988年7月号掲載。
SequenceMatcherオブジェクト
SequenceMatcher クラスには、以下のようなコンストラクタがあります:
class difflib.SequenceMatcher(isjunk=None, a='', b='', autojunk=True)
オプションの引数 isjunk は、None (デフォルトの値です) にするか、単一の引数をとる関数でなければなりません。後者の場合、関数はシーケンスの要素を受け取り、要素が junk であり、無視すべきである場合に限り真を返すようにしなければなりません。isjunk に None を渡すと、lambda x: False を渡したのと同じになります; すなわち、いかなる要素も無視しなくなります。例えば以下のような引数を渡すと:
lambda x: x in " \t"
空白とタブ文字を無視して文字のシーケンスを比較します。
オプションの引数 a と b は、比較される文字列で、デフォルトでは空の文字列です。両方のシーケンスの要素は、 ハッシュ可能 である必要があります。
オプションの引数 autojunk は、自動 junk ヒューリスティックを無効にするために使えます。
バージョン 3.2 で追加: autojunk パラメータ。
SequenceMatcher オブジェクトは3つのデータ属性を持っています: bjunk は、 isjunk が True であるような b の要素の集合です; bpopular は、 (無効でなければ) ヒューリスティックによって popular であると考えられる非ジャンク要素の集合です; b2j は、 b の残りの要素をそれらが生じる位置のリストに写像する dict です。この 3 つは set_seqs() または set_seq2() で b がリセットされる場合は常にリセットされます。
バージョン 3.2 で追加: bjunk および bpopular 属性。
SequenceMatcher オブジェクトは以下のメソッドを持ちます:
set_seqs(a, b)
比較される2つの文字列を設定します。
SequenceMatcher オブジェクトは、2つ目のシーケンスについての詳細な情報を計算し、キャッシュします。 1つのシーケンスをいくつものシーケンスと比較する場合、まず set_seq2() を使って文字列を設定しておき、別の文字列を1つずつ比較するために、繰り返し set_seq1() を呼び出します。
set_seq1(a)
比較を行う1つ目のシーケンスを設定します。比較される2つ目のシーケンスは変更されません。
set_seq2(b)
比較を行う2つ目のシーケンスを設定します。比較される1つ目のシーケンスは変更されません。
find_longest_match(alo=0, ahi=None, blo=0, bhi=None)
a[alo:ahi] と b[blo:bhi] の中から、最長のマッチ列を探します。
isjunk が省略されたか None の時、 find_longest_match() は a[i:i+k] が b[j:j+k] と等しいような (i, j, k) を返します。その値は alo <= i <= i+k <= ahi かつ blo <= j <= j+k <= bhi となります。 (i', j', k') でも、同じようになります。さらに k >= k', i <= i' が i == i', j <= j' でも同様です。言い換えると、いくつものマッチ列すべてのうち、 a 内で最初に始まるものを返します。そしてその a 内で最初のマッチ列すべてのうち b 内で最初に始まるものを返します。
>>>
>>> s = SequenceMatcher(None, " abcd", "abcd abcd")
>>> s.find_longest_match(0, 5, 0, 9)
Match(a=0, b=4, size=5)
引数 isjunk が与えられている場合、上記の通り、はじめに最長のマッチ列を判定します。ブロック内に junk 要素が見当たらないような追加条件の際はこれに該当しません。次にそのマッチ列を、その両側の junk 要素にマッチするよう、できる限り広げていきます。そのため結果となる列は、探している列のたまたま直前にあった同一の junk 以外の junk にはマッチしません。
以下は前と同じサンプルですが、空白を junk とみなしています。これは ' abcd' が2つ目の列の末尾にある ' abcd' にマッチしないようにしています。代わりに 'abcd' にはマッチします。そして 2つ目の文字列中、一番左の 'abcd' にマッチします:
>>>
>>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
>>> s.find_longest_match(0, 5, 0, 9)
Match(a=1, b=0, size=4)
どんな列にもマッチしない時は、(alo, blo, 0) を返します。
このメソッドは named tuple Match(a, b, size) を返します。
バージョン 3.9 で変更: デフォルト引数が追加されました。
get_matching_blocks()
マッチした互いに重複の無いシーケンスを表す、3つ組の値のリストを返します。 それぞれの値は (i, j, n) という形式で表され、a[i:i+n] == b[j:j+n] という関係を意味します。3つの値は i と j の間で単調に増加します。
最後の3つ組はダミーで、(len(a), len(b), 0) という値を持ちます。これは n == 0 である唯一のタプルです。もし (i, j, n) と (i', j', n') がリストで並んでいる3つ組で、2つ目が最後の3つ組でなければ、i+n < i' または j+n < j' です。言い換えると並んでいる3つ組は常に隣接していない同じブロックを表しています。
>>> s = SequenceMatcher(None, "abxcd", "abcd")
>>> s.get_matching_blocks()
[Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]
get_opcodes()
a を b にするための方法を記述する5つのタプルを返します。それぞれのタプルは (tag, i1, i2, j1, j2) という形式であらわされます。最初のタプルは i1 == j1 == 0 であり、i1 はその前にあるタプルの i2 と同じ値です。同様に j1 は前の j2 と同じ値になります。
tag の値は文字列であり、次のような意味です:
値
意味
'replace'
a[i1:i2] は b[j1:j2] に置き換えられる。
'delete'
a[i1:i2] は削除される。この時、j1 == j2 である。
'insert'
b[j1:j2] が a[i1:i1] に挿入される。この時 i1 == i2 である。
'equal'
a[i1:i2] == b[j1:j2] (サブシーケンスは等しい).
例えば:
>>>
>>> a = "qabxcd"
>>> b = "abycdf"
>>> s = SequenceMatcher(None, a, b)
>>> for tag, i1, i2, j1, j2 in s.get_opcodes():
...     print('{:7}   a[{}:{}] --> b[{}:{}] {!r:>8} --> {!r}'.format(
...         tag, i1, i2, j1, j2, a[i1:i2], b[j1:j2]))
delete    a[0:1] --> b[0:0]      'q' --> ''
equal     a[1:3] --> b[0:2]     'ab' --> 'ab'
replace   a[3:4] --> b[2:3]      'x' --> 'y'
equal     a[4:6] --> b[3:5]     'cd' --> 'cd'
insert    a[6:6] --> b[5:6]       '' --> 'f'
get_grouped_opcodes(n=3)
最大 n 行までのコンテキストを含むグループを生成するような、 ジェネレータ を返します。
このメソッドは、 get_opcodes() で返されるグループの中から、似たような差異のかたまりに分け、間に挟まっている変更の無い部分を省きます。
グループは get_opcodes() と同じ書式で返されます。
ratio()
[0, 1] の範囲の浮動小数点数で、シーケンスの類似度を測る値を返します。
T が2つのシーケンスの要素数の総計だと仮定し、M をマッチした数とすると、この値は 2.0*M / T であらわされます。もしシーケンスがまったく同じ場合、値は 1.0 となり、まったく異なる場合には 0.0 となります。
このメソッドは get_matching_blocks() または get_opcodes() がまだ呼び出されていない場合には非常にコストが高いです。この場合、上限を素早く計算するために、 quick_ratio() もしくは real_quick_ratio() を最初に試してみる方がいいかもしれません。
注釈 注意: ratio() の呼び出しの結果は引数の順序に依存します。例えば次の通りです:
>>>
>>> SequenceMatcher(None, 'tide', 'diet').ratio()
0.25
>>> SequenceMatcher(None, 'diet', 'tide').ratio()
0.5
quick_ratio()
ratio() の上界を、より高速に計算します。
real_quick_ratio()
ratio() の上界を、非常に高速に計算します。
この文字列全体のマッチ率を返す3つのメソッドは、精度の異なる近似値を返します。 quick_ratio() と real_quick_ratio() は、常に ratio() 以上の値を返します:
>>>
>>> s = SequenceMatcher(None, "abcd", "bcde")
>>> s.ratio()
0.75
>>> s.quick_ratio()
0.75
>>> s.real_quick_ratio()
1.0
SequenceMatcher の例
この例は2つの文字列を比較します。空白を "junk" とします:
>>>
>>> s = SequenceMatcher(lambda x: x == " ",
...                     "private Thread currentThread;",
...                     "private volatile Thread currentThread;")
ratio() は、[0, 1] の範囲の値を返し、シーケンスの類似度を測ります。経験によると、 ratio() の値が0.6を超えると、シーケンスがよく似ていることを示します:
>>>
>>> print(round(s.ratio(), 3))
0.866
シーケンスのどこがマッチしているかにだけ興味のある時には get_matching_blocks() が手軽でしょう:
>>>
>>> for block in s.get_matching_blocks():
...     print("a[%d] and b[%d] match for %d elements" % block)
a[0] and b[0] match for 8 elements
a[8] and b[17] match for 21 elements
a[29] and b[38] match for 0 elements
get_matching_blocks() が返す最後のタプルが常にダミーであることに注目してください。このダミーは (len(a), len(b), 0) であり、これはタプルの最後の要素（マッチする要素の数）が 0 となる唯一のケースです。
はじめのシーケンスがどのようにして2番目のものになるのかを知るには、 get_opcodes() を使います:
>>>
>>> for opcode in s.get_opcodes():
...     print("%6s a[%d:%d] b[%d:%d]" % opcode)
 equal a[0:8] b[0:8]
insert a[8:8] b[8:17]
 equal a[8:29] b[17:38]
参考
SequenceMatcher を使った、シンプルで使えるコードを知るには、このモジュールの関数 get_close_matches() を参照してください。
Simple version control recipe SequenceMatcher で作った小規模アプリケーション。
Differ オブジェクト
Differ オブジェクトによって生成された差分が 最小 であるなどとは言いません。むしろ、最小の差分はしばしば直観に反しています。その理由は、どこでもできるとなれば一致を見いだしてしまうからで、ときには思いがけなく100ページも離れたマッチになってしまうのです。一致点を互いに隣接したマッチに制限することで、場合によって長めの差分を出力するというコストを掛けることにはなっても、ある種の局所性を保つことができるのです。
Differ は、以下のようなコンストラクタを持ちます:
class difflib.Differ(linejunk=None, charjunk=None)
オプションのキーワードパラメータ linejunk と charjunk は、フィルタ関数を渡します (使わないときは None):
linejunk: ひとつの文字列引数を受け取る関数です。文字列が junk のときに真を返します。デフォルトでは、None であり、どんな行であっても junk とは見なされません。
charjunk: この関数は文字(長さ1の文字列)を引数として受け取り、文字が junk であるときに真を返します。デフォルトは None であり、どんな文字も junk とは見なされません。
これらの junk フィルター関数により、差分を発見するマッチングが高速化し、差分の行や文字が無視されることがなくなります。説明については、 find_longest_match() メソッドの isjunk 引数の説明をご覧ください。
Differ オブジェクトは、以下の1つのメソッドを通して利用されます。（差分を生成します）:
compare(a, b)
文字列からなる2つのシーケンスを比較し、差分（を表す文字列からなるシーケンス）を生成します。
各シーケンスの要素は、改行で終わる独立した単一行からなる文字列でなければなりません。そのようなシーケンスは、ファイル風オブジェクトの readlines() メソッドによって得ることができます。（得られる）差分は改行文字で終了する文字列のシーケンスとして得られ、ファイル風オブジェクトの writelines() メソッドによって出力できる形になっています。
Differ の例
以下の例は2つのテキストを比較しています。最初に、テキストを行毎に改行で終わる文字列のシーケンスにセットアップします (そのようなシーケンスは、ファイル風オブジェクトの readlines() メソッドからも得ることができます):
>>>
>>> text1 = '''  1. Beautiful is better than ugly.
...   2. Explicit is better than implicit.
...   3. Simple is better than complex.
...   4. Complex is better than complicated.
... '''.splitlines(keepends=True)
>>> len(text1)
4
>>> text1[0][-1]
'\n'
>>> text2 = '''  1. Beautiful is better than ugly.
...   3.   Simple is better than complex.
...   4. Complicated is better than complex.
...   5. Flat is better than nested.
... '''.splitlines(keepends=True)
次に Differ オブジェクトをインスタンス化します:
>>>
>>> d = Differ()
注意: Differ オブジェクトをインスタンス化するとき、行 junk と文字 junk をフィルタリングする関数を渡すことができます。詳細は Differ() コンストラクタを参照してください。
最後に、2つを比較します:
>>>
>>> result = list(d.compare(text1, text2))
result は文字列のリストなので、pretty-printしてみましょう:
>>>
>>> from pprint import pprint
>>> pprint(result)
['    1. Beautiful is better than ugly.\n',
 '-   2. Explicit is better than implicit.\n',
 '-   3. Simple is better than complex.\n',
 '+   3.   Simple is better than complex.\n',
 '?     ++\n',
 '-   4. Complex is better than complicated.\n',
 '?            ^                     ---- ^\n',
 '+   4. Complicated is better than complex.\n',
 '?           ++++ ^                      ^\n',
 '+   5. Flat is better than nested.\n']
これは、複数行の文字列として、次のように出力されます:
>>>
>>> import sys
>>> sys.stdout.writelines(result)
    1. Beautiful is better than ugly.
-   2. Explicit is better than implicit.
-   3. Simple is better than complex.
+   3.   Simple is better than complex.
?     ++
-   4. Complex is better than complicated.
?            ^                     ---- ^
+   4. Complicated is better than complex.
?           ++++ ^                      ^
+   5. Flat is better than nested.
difflib のコマンドラインインタフェース
この例は、 difflib を使って diff に似たユーティリティーを作成する方法を示します。これは、 Python のソース配布物にも、 Tools/scripts/diff.py として含まれています。
#!/usr/bin/env python3
""" Command line interface to difflib.py providing diffs in four formats:
* ndiff:    lists every line and highlights interline changes.
* context:  highlights clusters of changes in a before/after format.
* unified:  highlights clusters of changes in an inline format.
* html:     generates side by side comparison with change highlights.
"""
import sys, os, difflib, argparse
from datetime import datetime, timezone
def file_mtime(path):
    t = datetime.fromtimestamp(os.stat(path).st_mtime,
                               timezone.utc)
    return t.astimezone().isoformat()
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('-c', action='store_true', default=False,
                        help='Produce a context format diff (default)')
    parser.add_argument('-u', action='store_true', default=False,
                        help='Produce a unified format diff')
    parser.add_argument('-m', action='store_true', default=False,
                        help='Produce HTML side by side diff '
                             '(can use -c and -l in conjunction)')
    parser.add_argument('-n', action='store_true', default=False,
                        help='Produce a ndiff format diff')
    parser.add_argument('-l', '--lines', type=int, default=3,
                        help='Set number of context lines (default 3)')
    parser.add_argument('fromfile')
    parser.add_argument('tofile')
    options = parser.parse_args()
    n = options.lines
    fromfile = options.fromfile
    tofile = options.tofile
    fromdate = file_mtime(fromfile)
    todate = file_mtime(tofile)
    with open(fromfile) as ff:
        fromlines = ff.readlines()
    with open(tofile) as tf:
        tolines = tf.readlines()
    if options.u:
        diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n)
    elif options.n:
        diff = difflib.ndiff(fromlines, tolines)
    elif options.m:
        diff = difflib.HtmlDiff().make_file(fromlines,tolines,fromfile,tofile,context=options.c,numlines=n)
    else:
        diff = difflib.context_diff(fromlines, tolines, fromfile, tofile, fromdate, todate, n=n)
    sys.stdout.writelines(diff)
if __name__ == '__main__':
    main()
目次
difflib --- 差分の計算を助ける
SequenceMatcherオブジェクト
SequenceMatcher の例
Differ オブジェクト
Differ の例
difflib のコマンドラインインタフェース
前のトピックへ
re --- 正規表現操作
次のトピックへ
textwrap --- テキストの折り返しと詰め込み
textwrap --- テキストの折り返しと詰め込み
ソースコード: Lib/textwrap.py
textwrap モジュールは、実際の処理を行う TextWrapper とともに、いくつかの便利な関数を提供しています。1つか2つの文字列を wrap あるいは fill するだけの場合は便利関数で十分ですが、多くの処理を行う場合は効率のために TextWrapper のインスタンスを使うべきでしょう。
textwrap.wrap(text, width=70, **kwargs)
text (文字列)内の段落を一つだけ折り返しを行います。したがって、すべての行が高々 width 文字の長さになります。最後に改行が付かない出力行のリストを返します。
オプションのキーワード引数は、以下で説明する TextWrapper のインスタンス属性に対応しています。 width はデフォルトで 70 です。
wrap() の動作についての詳細は TextWrapper.wrap() メソッドを参照してください。
textwrap.fill(text, width=70, **kwargs)
text 内の段落を一つだけ折り返しを行い、折り返しが行われた段落を含む一つの文字列を返します。 fill() はこれの省略表現です
"\n".join(wrap(text, ...))
特に、 fill() は wrap() とまったく同じ名前のキーワード引数を受け取ります。
textwrap.shorten(text, width, **kwargs)
与えられた text を折りたたみ、切り詰めて、与えられた width に収まるようにします。
最初に、text 内の空白が折りたたまれます (すべての空白を、1 文字の空白文字で置き換えます)。結果が width 内に収まった場合、その結果が返されます。width に収まらない場合、残りの文字数と placeholder との和が width 内に収まるように、末尾から単語が切り捨てられます:
>>>
>>> textwrap.shorten("Hello  world!", width=12)
'Hello world!'
>>> textwrap.shorten("Hello  world!", width=11)
'Hello [...]'
>>> textwrap.shorten("Hello world", width=10, placeholder="...")
'Hello...'
オプションのキーワード引数は、以下で説明する TextWrapper インスタンスの属性に対応します。文字列が TextWrapper の fill() 関数に渡される前に、空白が折りたたまれます。そのため、tabsize、expand_tabs、drop_whitespace、replace_whitespace の値を変更しても、意味がありません。
バージョン 3.4 で追加.
textwrap.dedent(text)
text の各行に対し、共通して現れる先頭の空白を削除します。
この関数は通常、三重引用符で囲われた文字列をスクリーン/その他の左端にそろえ、なおかつソースコード中ではインデントされた形式を損なわないようにするために使われます。
タブとスペースはともにホワイトスペースとして扱われますが、同じではないことに注意してください: "  hello" という行と "\thello" は、同じ先頭の空白文字をもっていないとみなされます。
空白文字しか含まない行は入力の際に無視され、出力の際に単一の改行文字に正規化されます。
例えば:
def test():
    # end first line with \ to avoid the empty line!
    s = '''\
    hello
      world
    '''
    print(repr(s))          # prints '    hello\n      world\n    '
    print(repr(dedent(s)))  # prints 'hello\n  world\n'
textwrap.indent(text, prefix, predicate=None)
text の中の選択された行の先頭に prefix を追加します。
行の分割は text.splitlines(True) で行います。
デフォルトでは、(改行文字を含む)空白文字だけの行を除いてすべての行に prefix を追加します。
例えば:
>>>
>>> s = 'hello\n\n \nworld'
>>> indent(s, '  ')
'  hello\n\n \n  world'
省略可能な predicate 引数を使って、どの行をインデントするかを制御することができます。例えば、空行や空白文字のみの行にも prefix を追加するのは簡単です:
>>>
>>> print(indent(s, '+ ', lambda line: True))
+ hello
+
+
+ world
バージョン 3.3 で追加.
wrap()、fill()、shorten() は TextWrapper インスタンスを作成し、その一つのメソッドを呼び出すことで機能します。そのインスタンスは再利用されません。したがって、wrap() や fill() を使用して多くのテキスト文字列を処理するアプリケーションについては、独自の TextWrapper オブジェクトを作成する方が効率が良い方法でしょう。
テキストはなるべく空白か、ハイフンを含む語のハイフンの直後で折り返されます。 TextWrapper.break_long_words が偽に設定されていなければ、必要な場合に長い語が分解されます。
class textwrap.TextWrapper(**kwargs)
TextWrapper コンストラクタはたくさんのオプションのキーワード引数を受け取ります。それぞれのキーワード引数は一つのインスタンス属性に対応します。したがって、例えば
wrapper = TextWrapper(initial_indent="* ")
はこれと同じです
wrapper = TextWrapper()
wrapper.initial_indent = "* "
あなたは同じ TextWrapper オブジェクトを何回も再利用できます。また、使用中にインスタンス属性へ代入することでそのオプションのどれでも変更できます。
TextWrapper インスタンス属性(とコンストラクタのキーワード引数)は以下の通りです:
width
(デフォルト: 70) 折り返しが行われる行の最大の長さ。入力行に width より長い単一の語が無い限り、 TextWrapper は width 文字より長い出力行が無いことを保証します。
expand_tabs
(デフォルト: True) もし真ならば、そのときは text 内のすべてのタブ文字は text の expandtabs() メソッドを用いて空白に展開されます。
tabsize
(デフォルト: 8) expand_tabs が真の場合、 text の中のすべてのTAB文字は tabsize と現在のカラムに応じて、ゼロ以上のスペースに展開されます。
バージョン 3.3 で追加.
replace_whitespace
(デフォルト: True) 真の場合、 wrap() メソッドはタブの展開の後、 wrap 処理の前に各種空白文字をスペース1文字に置換します。置換される空白文字は: TAB, 改行, 垂直TAB, FF, CR ('\t\n\v\f\r') です。
注釈 expand_tabs が偽で replace_whitespace が真ならば、各タブ文字は1つの空白に置き換えられます。それはタブ展開と同じでは ありません 。
注釈 replace_whitespace が偽の場合、改行が行の途中で現れることで出力がおかしくなることがあります。このため、テキストを(str.splitlines() などを使って)段落ごとに分けて別々に wrap する必要があります。
drop_whitespace
(デフォルト: True) 真の場合、(wrap 処理のあとインデント処理の前に) 各行の最初と最後の空白文字を削除します。ただし、段落の最初の空白については、次の文字が空白文字でない場合は削除されません。削除される空白文字が行全体に及ぶ場合は、行自体を削除します。
initial_indent
(default: '') wrap の出力の最初の行の先頭に付与する文字列。最初の行の長さに加算されます。空文字列の場合インデントされません。
subsequent_indent
(デフォルト: '') 一行目以外の折り返しが行われる出力のすべての行の先頭に付けられる文字列。一行目以外の各行の折り返しまでの長さにカウントされます。
fix_sentence_endings
(デフォルト: False) もし真ならば、 TextWrapper は文の終わりを見つけようとし、確実に文がちょうど二つの空白で常に区切られているようにします。これは一般的に固定スペースフォントのテキストに対して望ましいです。しかし、文の検出アルゴリズムは完全ではありません: 文の終わりには、後ろに空白がある '.', '!' または '?' の中の一つ、ことによると '"' あるいは "'" が付随する小文字があると仮定しています。これに伴う一つの問題はアルゴリズムで下記の"Dr."と
[...] Dr. Frankenstein's monster [...]
下記の"Spot."の間の差異を検出できないことです
[...] See Spot. See Spot run [...]
fix_sentence_endings はデフォルトで偽です。
break_long_words
(デフォルト: True) もし真ならば、そのとき width より長い行が確実にないようにするために、 width より長い語は切られます。偽ならば、長い語は切られないでしょう。そして、 width より長い行があるかもしれません。 (width を超える分を最小にするために、長い語は単独で一行に置かれるでしょう。)
break_on_hyphens
(デフォルト: True) 真の場合、英語で一般的なように、ラップ処理は空白か合成語に含まれるハイフンの直後で行われます。偽の場合、空白だけが改行に適した位置として判断されます。ただし、本当に語の途中で改行が行われないようにするためには、 break_long_words 属性を真に設定する必要があります。過去のバージョンでのデフォルトの振る舞いは、常にハイフンの直後での改行を許していました。
max_lines
(デフォルト None) None 以外の場合、出力は行数 max_lines を超えないようにされ、切り詰める際には出力の最後の行を placeholder に置き換えます。
バージョン 3.4 で追加.
placeholder
(デフォルト: ' [...]') 切り詰める場合に出力の最後の行に置く文字列です。
バージョン 3.4 で追加.
TextWrapper はモジュールレベルの簡易関数に類似したいくつかの公開メソッドも提供します:
wrap(text)
1段落の文字列 text を、各行が width 文字以下になるように wrap します。 wrap のすべてのオプションは TextWrapper インスタンスの属性から取得します。結果の、行末に改行のない行のリストを返します。出力の内容が空になる場合は、返すリストも空になります。
fill(text)
text 内の段落を一つだけ折り返しを行い、折り返しが行われた段落を含む一つの文字列を返します。
unicodedata --- Unicode データベース
このモジュールは、ユニコード標準付録 #44 「 ユニコード文字データベース 」で定義されているのと同じ名前およびシンボルを使用します。このモジュールは次のような関数を定義します:
unicodedata.lookup(name)
名前に対応する文字を探します。その名前の文字が見つかった場合、その文字が返されます。見つからなかった場合には、 KeyError を発生させます。
バージョン 3.3 で変更: name aliases 1 と named sequences 2 のサポートが追加されました。
unicodedata.name(chr[, default])
文字 chr に付いている名前を、文字列で返します。名前が定義されていない場合には default が返されますが、この引数が与えられていなければ ValueError を発生させます。
unicodedata.decimal(chr[, default])
文字 chr に割り当てられている十進数を、整数で返します。この値が定義されていない場合には default が返されますが、この引数が与えられていなければ ValueError を発生させます。
unicodedata.digit(chr[, default])
文字 chr に割り当てられている数値を、整数で返します。この値が定義されていない場合には default が返されますが、この引数が与えられていなければ ValueError を発生させます。
unicodedata.numeric(chr[, default])
文字 chr に割り当てられている数値を、float で返します。この値が定義されていない場合には default が返されますが、この引数が与えられていなければ ValueError を発生させます。
unicodedata.category(chr)
文字 chr に割り当てられた、汎用カテゴリを返します。
unicodedata.bidirectional(chr)
文字 chr に割り当てられた、双方向クラスを返します。そのような値が定義されていない場合、空の文字列が返されます。
unicodedata.combining(chr)
文字 chr に割り当てられた正規結合クラスを返します。結合クラス定義されていない場合、0 が返されます。
unicodedata.east_asian_width(chr)
ユニコード文字 chr に割り当てられたeast asian widthを文字列で返します。
unicodedata.mirrored(chr)
文字 chr に割り当てられた、鏡像化のプロパティを返します。その文字が双方向テキスト内で鏡像化された文字である場合には 1 を、それ以外の場合には 0 を返します。
unicodedata.decomposition(chr)
文字 chr に割り当てられた、文字分解マッピングを、文字列型で返します。そのようなマッピングが定義されていない場合、空の文字列が返されます。
unicodedata.normalize(form, unistr)
Unicode 文字列 unistr の正規形 form を返します。 form の有効な値は、'NFC'、'NFKC'、'NFD'、'NFKD' です。
Unicode 規格は標準等価性 (canonical equivalence) と互換等価性 (compatibility equivalence) に基づいて、様々な Unicode文字列の正規形を定義します。Unicode では、複数の方法で表現できる文字があります。たとえば、文字 U+00C7 (LATIN CAPITAL LETTER C WITH CEDILLA) は、U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA) というシーケンスとしても表現できます。
各文字には2つの正規形があり、それぞれ正規形 C と正規形 D といいます。正規形 D (NFD) は標準分解 (canonical decomposition) としても知られており、各文字を分解された形に変換します。正規形 C (NFC) は標準分解を適用した後、結合済文字を再構成します。
互換等価性に基づいて、2つの正規形が加えられています。Unicode では、一般に他の文字との統合がサポートされている文字があります。たとえば、U+2160 (ROMAN NUMERAL ONE) は事実上 U+0049 (LATIN CAPITAL LETTER I) と同じものです。しかし、Unicode では、既存の文字集合 (たとえば gb2312) との互換性のために、これがサポートされています。
正規形 KD (NFKD) は、互換分解 (compatibility decomposition) を適用します。すなわち、すべての互換文字を、等価な文字で置換します。正規形 KC (NFKC) は、互換分解を適用してから、標準分解を適用します。
2つのunicode文字列が正規化されていて人間の目に同じに見えても、片方が結合文字を持っていてもう片方が持っていない場合、それらは完全に同じではありません。
unicodedata.is_normalized(form, unistr)
バージョン 3.8 で追加.
更に、本モジュールは以下の定数を公開します:
unicodedata.unidata_version
このモジュールで使われている Unicode データベースのバージョン。
unicodedata.ucd_3_2_0
これはモジュール全体と同じメソッドを具えたオブジェクトですが、Unicode データベースバージョン 3.2 を代わりに使っており、この特定のバージョンの Unicode データベースを必要とするアプリケーション(IDNA など)のためものです。
例:
>>>
>>> import unicodedata
>>> unicodedata.lookup('LEFT CURLY BRACKET')
'{'
>>> unicodedata.name('/')
'SOLIDUS'
>>> unicodedata.decimal('9')
9
>>> unicodedata.decimal('a')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ValueError: not a decimal
>>> unicodedata.category('A')  # 'L'etter, 'u'ppercase
'Lu'
>>> unicodedata.bidirectional('\u0660') # 'A'rabic, 'N'umber
'AN'
stringprep --- インターネットのための文字列調製
ソースコード: Lib/stringprep.py
(ホスト名のような) インターネット上にある存在に識別名をつける際、しばしば識別名間の "等価性" 比較を行う必要があります。厳密には、例えば大小文字の区別をするかしないかいったように、比較をどのように行うかはアプリケーションの領域に依存します。また、例えば "印字可能な" 文字で構成された識別名だけを許可するといったように、可能な識別名を制限することも必要となるかもしれません。
RFC 3454 では、インターネットプロトコル上で Unicode 文字列を "調製 (prepare)" するためのプロシジャを定義しています。文字列は通信路に載せられる前に調製プロシジャで処理され、その結果ある正規化された形式になります。RFC ではあるテーブルの集合を定義しており、それらはプロファイルにまとめられています。各プロファイルでは、どのテーブルを使い、 stringprep プロシジャのどのオプション部分がプロファイルの一部になっているかを定義しています。 stringprep プロファイルの一つの例は nameprep で、国際化されたドメイン名に使われます。
stringprep は RFC 3454 のテーブルを公開しているに過ぎません。これらのテーブルは辞書やリストとして表現するにはバリエーションが大きすぎるので、このモジュールでは Unicode 文字データベースを内部的に利用しています。モジュールソースコード自体は mkstringprep.py ユーティリティを使って生成されました。
その結果、これらのテーブルはデータ構造体ではなく、関数として公開されています。RFC には 2 種類のテーブル: 集合およびマップ、が存在します。集合については、 stringprep は "特性関数 (characteristic function)" 、すなわち引数が集合の一部である場合に True を返す関数を提供します。マッピングについては、マップ関数: キーが与えられると、それに関連付けられた値を返す関数を提供します。以下はこのモジュールで利用可能な全ての関数を列挙したものです。
stringprep.in_table_a1(code)
code がテーブル A.1 (Unicode 3.2 における未割り当てコードポイント: unassigned code point) かどうか判定します。
stringprep.in_table_b1(code)
code がテーブル B.1 (一般には何にも対応付けられていない: commonly mapped to nothing) かどうか判定します。
stringprep.map_table_b2(code)
テーブル B.2 (NFKC で用いられる大小文字の対応付け) に従って、code に対応付けられた値を返します。
stringprep.map_table_b3(code)
テーブル B.3 (正規化を伴わない大小文字の対応付け) に従って、code に対応付けられた値を返します。
stringprep.in_table_c11(code)
code がテーブル C.1.1 (ASCII スペース文字) かどうか判定します。
stringprep.in_table_c12(code)
code がテーブル C.1.2 (非 ASCII スペース文字) かどうか判定します。
stringprep.in_table_c11_c12(code)
code がテーブル C.1 (スペース文字、C.1.1 および C.1.2 の和集合) かどうか判定します。
stringprep.in_table_c21(code)
code がテーブル C.2.1 (ASCII 制御文字) かどうか判定します。
stringprep.in_table_c22(code)
code がテーブル C.2.2 (非 ASCII 制御文字) かどうか判定します。
stringprep.in_table_c21_c22(code)
code がテーブル C.2 (制御文字、C.2.1 および C.2.2 の和集合) かどうか判定します。
stringprep.in_table_c3(code)
code がテーブル C.3 (プライベート利用) かどうか判定します。
stringprep.in_table_c4(code)
code がテーブル C.4 (非文字コードポイント: non-character code points) かどうか判定します。
stringprep.in_table_c5(code)
code がテーブル C.5 (サロゲーションコード) かどうか判定します。
stringprep.in_table_c6(code)
code がテーブル C.6 (平文:plain text として不適切) かどうか判定します。
stringprep.in_table_c7(code)
code がテーブル C.7 (標準表現:canonical representation として不適切) かどうか判定します。
stringprep.in_table_c8(code)
code がテーブル C.8 (表示プロパティの変更または撤廃) かどうか判定します。
stringprep.in_table_c9(code)
code がテーブル C.9 (タグ文字) かどうか判定します。
stringprep.in_table_d1(code)
code がテーブル D.1 (双方向プロパティ "R" または "AL" を持つ文字) かどうか判定します。
stringprep.in_table_d2(code)
code がテーブル D.2 (双方向プロパティ "L" を持つ文字) かどうか判定します。
readline --- GNU readline のインタフェース
readline モジュールでは、補完や Python インタプリタからの履歴ファイルの読み書きを容易にするための多くの関数を定義しています。 このモジュールは直接、または rlcompleter モジュールを介して使うことができます。 rlcompleter モジュールは対話的プロンプトで Python 識別子の補完をサポートするものです。 このモジュールで利用される設定は、インタプリタの対話プロンプトならびに組み込みの input() 関数の両方の挙動に影響します。
readline のキーバインディングは初期化ファイルで設定できます。 このファイルは、たいていはホームディレクトリに .inputrc という名前で置いてあります。 GNU Readline マニュアルの Readline Init File を参照して、そのファイルの形式や可能な構成、 Readline ライブラリ全体の機能を知ってください。
注釈 下層の Readline ライブラリー API は GNU readline ではなく libedit ライブラリーで実装される可能性があります。 macOS では readline モジュールはどのライブラリーが使われているかを実行時に検出します。
libedit の設定ファイルは GNU readline のものとは異なります。もし設定文字列をプログラムからロードしているなら、 GNU readline と libedit を区別するために "libedit" という文字列が readline.__doc__ に含まれているかどうかチェックしてください。
If you use editline/libedit readline emulation on macOS, the initialization file located in your home directory is named .editrc. For example, the following content in ~/.editrc will turn ON vi keybindings and TAB completion:
python:bind -v
python:bind ^I rl_complete
初期化ファイル
以下の関数は初期化ファイルならびにユーザ設定関連のものです:
readline.parse_and_bind(string)
string 引数で渡された最初の行を実行します。これにより下層のライブラリーの rl_parse_and_bind() が呼ばれます。
readline.read_init_file([filename])
readline 初期化ファイルを実行します。デフォルトのファイル名は最後に使用されたファイル名です。これにより下層のライブラリーの rl_read_init_file() が呼ばれます。
行バッファ
以下の関数は行バッファを操作します:
readline.get_line_buffer()
行バッファ (下層のライブラリーの rl_line_buffer) の現在の内容を返します。
readline.insert_text(string)
テキストをカーサー位置の行バッファに挿入します。これにより下層のライブラリーの rl_insert_text() が呼ばれますが、戻り値は無視されます。
readline.redisplay()
スクリーンの表示を変更して行バッファの現在の内容を反映させます。これにより下層のライブラリーの rl_redisplay() が呼ばれます。
履歴ファイル
以下の関数は履歴ファイルを操作します:
readline.read_history_file([filename])
readline 履歴ファイルを読み込み、履歴リストに追加します。デフォルトのファイル名は ~/.history です。これにより下層のライブラリーの read_history() が呼ばれます。
readline.write_history_file([filename])
履歴リストを readline 履歴ファイルに保存します。既存のファイルは上書きされます。デフォルトのファイル名は ~/.history です。これにより下層のライブラリーの write_history() が呼ばれます。
readline.append_history_file(nelements[, filename])
履歴の最後の nelements 項目をファイルに追加します。でふぉるのファイル名は ~/.history です。ファイルは存在していなくてはなりません。これにより下層のライブラリーの append_history() が呼ばれます。Python がこの機能をサポートするライブラリーのバージョンでコンパイルされたときのみ、この関数は存在します。
バージョン 3.5 で追加.
readline.get_history_length()
readline.set_history_length(length)
履歴リスト
以下の関数はグローバルな履歴リストを操作します:
readline.clear_history()
現在の履歴をクリアします。これにより下層のライブラリーの clear_history() が呼ばれます。Python がこの機能をサポートするライブラリーのバージョンでコンパイルされたときのみ、この関数は存在します。
readline.get_current_history_length()
履歴に現在ある項目の数を返します。 (get_history_length() は履歴ファイルに書かれる最大行数を返します。)
readline.get_history_item(index)
現在の履歴の index 番目の項目を返します。添字は1から始まります。これにより下層のライブラリーの history_get() が呼ばれます。
readline.remove_history_item(pos)
履歴から指定された位置の項目を削除します。添字は0から始まります。これにより下層のライブラリーの remove_history() が呼ばれます。
readline.replace_history_item(pos, line)
指定された位置の項目を line で置き換えます。添字は0から始まります。これにより下層のライブラリーの replace_history_entry() が呼ばれます。
readline.add_history(line)
最後に入力したかのように、 line を履歴バッファに追加します。これにより下層のライブラリーの add_history() が呼ばれます。
readline.set_auto_history(enabled)
バージョン 3.6 で追加.
開始フック
readline.set_startup_hook([function])
readline.set_pre_input_hook([function])
補完
readline.set_completer([function])
completer 関数を設定または削除します。function が指定された場合、新たな completer 関数として用いられます; 省略された場合や None の場合、現在インストールされている completer 関数は削除されます。completer 関数は function(text, state) の形式で、関数が文字列でない値を返すまで state を 0, 1, 2, ..., にして呼び出します。この関数は text から始まる補完結果として次に来そうなものを返さなければなりません。
readline.get_completer()
completer 関数を取得します。completer 関数が設定されていなければ None を返します。
readline.get_completion_type()
readline.get_begidx()
readline.get_endidx()
readline.set_completer_delims(string)
readline.get_completer_delims()
readline.set_completion_display_matches_hook([function])
使用例
以下の例では、ユーザのホームディレクトリにある履歴ファイル .python_history の読み込みと保存を自動的に行うために、 readline モジュールの履歴の読み書き関数をどのように使うかを示しています。以下のソースコードは通常、対話セッション中はユーザの PYTHONSTARTUP ファイルから自動的に実行されます:
import atexit
import os
import readline
histfile = os.path.join(os.path.expanduser("~"), ".python_history")
try:
    readline.read_history_file(histfile)
    # default history len is -1 (infinite), which may grow unruly
    readline.set_history_length(1000)
except FileNotFoundError:
    pass
atexit.register(readline.write_history_file, histfile)
Python が 対話モード で実行される時、このコードは実際には自動的に実行されます ( readline の設定 を参照してください)。
次の例では上記と同じ目的を達成できますが、ここでは新規の履歴のみを追加することで、並行して対話セッションがサポートされます:
import atexit
import os
import readline
histfile = os.path.join(os.path.expanduser("~"), ".python_history")
try:
    readline.read_history_file(histfile)
    h_len = readline.get_current_history_length()
except FileNotFoundError:
    open(histfile, 'wb').close()
    h_len = 0
def save(prev_h_len, histfile):
    new_h_len = readline.get_current_history_length()
    readline.set_history_length(1000)
    readline.append_history_file(new_h_len - prev_h_len, histfile)
atexit.register(save, h_len, histfile)
次の例では code.InteractiveConsole クラスを拡張し、履歴の保存・復旧をサポートします。
import atexit
import code
import os
import readline
class HistoryConsole(code.InteractiveConsole):
    def __init__(self, locals=None, filename="<console>",
                 histfile=os.path.expanduser("~/.console-history")):
        code.InteractiveConsole.__init__(self, locals, filename)
        self.init_history(histfile)
    def init_history(self, histfile):
        readline.parse_and_bind("tab: complete")
        if hasattr(readline, "read_history_file"):
            try:
                readline.read_history_file(histfile)
            except FileNotFoundError:
                pass
            atexit.register(self.save_history, histfile)
    def save_history(self, histfile):
        readline.set_history_length(1000)
        readline.write_history_file(histfile)
rlcompleter --- GNU readline向け補完関数
ソースコード: Lib/rlcompleter.py
rlcompleter モジュールではPythonの識別子やキーワードを定義した readline モジュール向けの補完関数を定義しています。
このモジュールが Unixプラットフォームでimportされ、 readline が利用できるときには、 Completer クラスのインスタンスが自動的に作成され、 complete() メソッドが readline 補完に設定されます。
以下はプログラム例です:
>>>
>>> import rlcompleter
>>> import readline
>>> readline.parse_and_bind("tab: complete")
>>> readline. <TAB PRESSED>
readline.__doc__          readline.get_line_buffer(  readline.read_init_file(
readline.__file__         readline.insert_text(      readline.set_completer(
readline.__name__         readline.parse_and_bind(
>>> readline.
rlcompleter モジュールは、 Python の 対話モード と一緒に使用するのを意図して設計されています。Python を -S オプションをつけずに実行している場合、このモジュールが自動的にインポートされ、構成されます (readline の設定 を参照)。
readline のないプラットフォームでも、このモジュールで定義される Completer クラスは独自の目的に使えます。
Completerオブジェクト
Completerオブジェクトは以下のメソッドを持っています:
Completer.complete(text, state)
text の state 番目の補完候補を返します。
もし text がピリオド('.')を含まない場合、 __main__ 、 builtins で定義されている名前か、キーワード (keyword モジュールで定義されている) から補完されます。
ピリオドを含む名前の場合、副作用を出さずに名前を最後まで評価しようとします(関数を明示的に呼び出しはしませんが、 __getattr__() を呼んでしまうことはあります)そして、 dir() 関数でマッチする語を見つけます。式を評価中に発生した全ての例外は補足して無視され、 None を返します。
Python チュートリアル
Python は強力で、学びやすいプログラミング言語です。効率的な高レベルデータ構造と、シンプルで効果的なオブジェクト指向プログラミング機構を備えています。 Python は、洗練された文法・動的なデータ型付け・インタープリタであることなどから、スクリプティングや高速アプリケーション開発(Rapid Application Development: RAD)に理想的なプログラミング言語となっています。
Python Web サイト(https://www.python.org) は、 Python インタープリタと標準ライブラリのソースコードと、主要プラットフォームごとにコンパイル済みのバイナリファイルを無料で配布しています。また、Python Web サイトには、無料のサードパーティモジュールやプログラム、ツール、ドキュメントなども紹介しています。
Python インタプリタは、簡単に C/C++ 言語などで実装された関数やデータ型を組み込み、拡張できます。また、アプリケーションのカスタマイズを行う、拡張言語としても適しています。
このチュートリアルは、Python 言語の基本的な概念と機能を、形式ばらずに紹介します。読むだけではなく、Pythonインタープリタで実際にサンプルを実行すると理解が深まりますが、サンプルはそれぞれ独立していますので、ただ読むだけでも良いでしょう。
標準オブジェクトやモジュールの詳細は、 Python 標準ライブラリ を参照してください。 また、正式な言語定義は、 Python 言語リファレンス にあります。 C 言語や C++ 言語で拡張モジュールを書くなら、 Python インタプリタの拡張と埋め込み や Python/C API リファレンスマニュアル を参照してください。Python の解説書も販売されています。
このチュートリアルは、Python全体を対象とした、包括的な解説書ではありません。よく使われる機能に限っても、全ては紹介していません。その代わり、このチュートリアルでは、Pythonのもっとも特徴的な機能を中心に紹介して、この言語の持ち味や、スタイルを感じられるようにしています。このチュートリアルを読み終えると、Python のモジュールやプログラムを読み書きできるようになっているでしょう。また、Python 標準ライブラリ のさまざまな Python ライブラリモジュールを、詳しく調べられるようになっているはずです。
用語集 にも目を通しておくと良いでしょう。
1. やる気を高めよう
コンピュータを使っていろいろな作業をしていると、自動化したい作業が出てくるでしょう。たとえば、たくさんのテキストファイルで検索-置換操作を行いたい、大量の写真ファイルを込み入ったやりかたでファイル名を整理して変更したり、などです。ちょっとした専用のデータベースや、何か専用のGUIアプリケーション、シンプルなゲームを作りたいかもしれません。
あなたがプロのソフト開発者として、C/C++/Java ライブラリを扱う必要があるけども、通常の編集/コンパイル/テスト/再コンパイルのサイクルを遅すぎると感じているかもしれません。上記ライブラリのためのテストを書くことにうんざりしているかもしれません。または、拡張言語を持つアプリケーションを書いているなら、そのために新しい言語一式の設計と実装をしたくないでしょう。
Pythonはそんなあなたのための言語です。
そういった処理は、Unix シェルスクリプトや Windows バッチファイルで書くこともできます。しかし、シェルスクリプトはファイル操作やテキストデータの操作には向いていますが、GUIアプリケーションやゲームにはむいていません。C/C++/Java プログラムを書くこともできますが、最初の試し書きだけでもかなりの時間がかかってしまいます。Pythonはもっと簡単に利用でき、Windows、Mac OS X、そして Unix オペレーティングシステムで動作し、あなたの仕事をすばやく片付ける助けになるでしょう。
Python は簡単に利用できますが、本物のプログラミング言語であり、シェルスクリプトやバッチファイルよりも多くの機構があり、大きなプログラムの開発にも適しています。一方では、Python は C よりたくさんのエラーチェックを実行時に行っており、また可変長配列や辞書などの高級な型を組込みで持つ 超高級言語(very-high-level language) です。Python は Awk や Perl などよりも汎用的なデータ型を備えており、より多くの領域で利用できます。また、Pythonはこれらの言語と比べても、少なくとも同じぐらいには簡単です。
Python では、プログラムをモジュールに分割して、他の Python プログラムで再利用できます。Python には膨大な標準モジュールが付属していて、プログラムを作る上での基盤として、あるいは Python プログラミングを学ぶためのサンプルとして利用できます。標準モジュールには、ファイル I/O、システムコール、ソケットといった機能や、Tk のようなグラフィカルユーザインタフェースツールキットを使うためのインターフェイスなども提供しています。
Python はインタプリタ言語です。コンパイルやリンクの必要がないので、プログラムを開発する際にかなりの時間を節約できます。インタプリタは対話的にも使えるので、言語の様々な機能について実験してみたり、書き捨てのプログラムを書いたり、ボトムアップでプログラムを開発する際に、関数をテストしたりといったことが簡単にできます。便利な電卓にもなります。
Python では、とてもコンパクトで読みやすいプログラムを書けます。Python で書かれたプログラムは大抵、同じ機能の C 言語, C++ 言語や Java のプログラムよりもはるかに短くなります。これには以下のようないくつかの理由があります:
高レベルのデータ型によって、複雑な操作を一つの実行文で表現できます。
実行文のグループ化を、グループの開始や終了の括弧ではなくインデントで行えます。
変数や引数の宣言が不要です。
Python には 拡張性 があります: C 言語でプログラムを書く方法を知っているなら、簡単に新たな組み込み関数やモジュールを、簡単にインタプリタに追加できます。これによって、いちばん時間のかかる処理を高速化したり、ベンダ特有のグラフィクスライブラリなどの、 バイナリ形式でしか手に入らないライブラリを Python にリンクしたりできます。その気になれば、Python インタプリタを C で書かれたアプリケーションにリンクして、アプリケーションに対する拡張言語や命令言語としても使えます。
ところで、この言語は BBC のショー番組、"モンティパイソンの空飛ぶサーカス (Monty Python's Flying Circus)" から取ったもので、爬虫類とは関係ありません。このドキュメントでは、モンティパイソンの寸劇への参照が許可されているだけでなく、むしろ推奨されています！
さて、皆さんはもう Python にワクワクして、もうちょっと詳しく調べてみたくなったはずです。プログラミング言語を習得する最良の方法は使ってみることですから、このチュートリアルではみなさんが読んだ内容を Python インタプリタで試してみることをおすすめします。
次の章では、まずインタプリタの使い方を説明します。これはわかりきった内容かもしれませんが、後に説明する例題を試してみる上で不可欠なことです。
チュートリアルの残りの部分では、Python プログラム言語と実行システムの様々な機能を例題を交えて紹介します。単純な式、実行文、データ型から始めて、関数とモジュールを経て、最後には例外処理やユーザ定義クラスといったやや高度な概念にも触れます。
2. Python インタプリタを使う
2.1. インタプリタを起動する
Python インタプリタは、それが使えるマシン上では通常 /usr/local/bin/python3.9 としてインストールされています; Unix シェルの検索パスに /usr/local/bin を入れることによって、次のコマンドをタイプしてインタプリタを開始することができます:
python3.9
1 どのディレクトリに Python インタプリタをインストールするかはインストール時に選択できるので、インタプリタは他のディレクトリにあるかもしれません; 身近な Python に詳しい人か、システム管理者に聞いてみてください。 (例えば、その他の場所としては /usr/local/python が一般的です。)
Microsoft ストア からPythonのインストールを行った Windows マシンでは、 python3.9 コマンドが利用可能です。 py.exe ランチャ をインストールした場合、 py コマンドが使えます。 Python を起動する他の方法については 補足: 環境変数の設定 を参照してください。
ファイル終端文字 (Unixでは Control-D 、DOS や Windows では Control-Z) を一次プロンプト (訳注: '>>>' のこと) に入力すると、インタプリタが終了ステータス 0 で終了します。もしこの操作がうまく働かないなら、コマンド: quit() と入力すればインタプリタを終了できます。
GNU Readline ライブラリをサポートしているシステム上では、対話的行編集やヒストリ置換、コード補完のインタプリタの行編集機能が利用できます。コマンドライン編集機能がサポートされているかを最も手っ取り早く調べる方法は、おそらく最初に表示された Python プロンプトに Control-P を入力してみることでしょう。ビープ音が鳴るなら、コマンドライン編集機能があります。編集キーについての解説は付録 対話入力編集と履歴置換 を参照してください。何も起こらないように見えるか、 ^P がエコーバックされるなら、コマンドライン編集機能は利用できません。この場合、現在編集中の行から文字を削除するにはバックスペースを使うしかありません。
インタプリタは Unix シェルと同じように使えます。標準入力が端末に接続された状態では、コマンドを対話的に読み込んで実行します。ファイル名を引数に指定するか、python3 < filename のように標準入力ファイルとして指定すると、インタプリタはファイルから スクリプト を読み込んで実行します。
インタプリタを python -c command [arg] ... のように起動する方法もあります。この形式では、シェルの -c オプションと同じように、 command に指定した文を実行します。 Python 文には、スペースなどのシェルにとって特殊な意味をもつ文字がしばしば含まれるので、 command 全体をシングルクォート(訳注: ')で囲っておいたほうが良いでしょう。
Python のモジュールには、スクリプトとしても便利に使えるものがあります。 python -m module [arg] ... のように起動すると、 module のソースファイルを、フルパスを指定して起動したかのように実行できます。
スクリプトファイルを使用する場合、スクリプトの実行が完了した後、そのまま対話モードに入れると便利なことがあります。これには -i をスクリプト名の前に追加します。
全てのコマンドラインオプションは コマンドラインと環境 で説明されています。
2.1.1. 引数の受け渡し
スクリプト名と引数を指定してインタプリタを起動した場合、スクリプト名やスクリプト名以後に指定した引数は、文字列のリストに変換されて sys モジュールの argv 変数に格納されます。 import sys とすることでこのリストにアクセスできます。 sys.argv には少なくとも一つ要素が入っています。スクリプト名も引数も指定しなければ、 sys.argv[0] は空の文字列になります。 スクリプト名の代わりに '-' (標準入力を意味します) を指定すると、 sys.argv[0] は '-' になります。 -c command を使うと、 sys.argv[0] は '-c' になります。 -m module を使った場合、 sys.argv[0] はモジュールのフルパスになります。 Python インタープリタは、-c command や -m module の後ろに指定したオプションは無視します。無視された引数は、sys.argv を使って command や module から参照できます。
2.1.2. 対話モード
インタプリタが命令を端末 (tty) やコマンドプロンプトから読み取っている場合、インタプリタは 対話モード (interactive mode) で動作しているといいます。 このモードでは、インタプリタは 一次プロンプト (primary prompt) を表示して、ユーザにコマンドを入力するよう促します。一次プロンプトは普通、三つの「大なり記号」 (>>>) です。継続行では、インタプリタは 二次プロンプト (secondary prompt) を表示します。二次プロンプトは、デフォルトでは三つのドット (...) です。 インタプリタは、最初のプロンプトを出す前にバージョン番号と著作権表示から始まる起動メッセージを出力します:
$ python3.9
Python 3.9 (default, June 4 2019, 09:25:04)
[GCC 4.8.2] on linux
>>>
継続行は、複数行の構文を入力するときに使います。例えば、 if 文は継続行を使用します
>>>
>>> the_world_is_flat = True
>>> if the_world_is_flat:
...     print("Be careful not to fall off!")
...
Be careful not to fall off!
対話モードについての詳細は 対話モード を参照してください。
2.2. インタプリタとその環境
2.2.1. ソースコードの文字コード
デフォルトでは、Python のソースコードは UTF-8 でエンコードされているものとして扱われます。UTF-8 では、世界中のほとんどの言語の文字を、同時に文字列リテラル、識別子、コメントなどに書けます。--- ただし、標準ライブラリは識別子に ASCII 文字のみを利用していて、その他のポータブルなコードもその慣習に従うべきです。それらの文字を正しく表示するためには、エディターはそのファイルが UTF-8 である事を識別して、そのファイルに含まれている文字を全てサポートしたフォントを使わなければなりません。
デフォルトエンコーディング以外のエンコーディングを使用するには、ファイルの 先頭 の行に特別なコメントを追加しなければなりません。書式は以下の通りです:
# -*- coding: encoding -*-
encoding には、Python が codecs でサポートしている有効なエンコーディングを指定します。
例えば、Windows-1252 エンコーディングを使用するには、ソースコードファイルの先頭行は下記のようにします:
# -*- coding: cp1252 -*-
ソースコードが UNIX "shebang" 行 で始まる場合には、先頭行 のルールは当てはまりません。 この場合には、エンコーディングの宣言はファイルの2行目に追加します。 例えば以下のようになります:
#!/usr/bin/env python3
# -*- coding: cp1252 -*-
脚注
1
Unixでは、Python 3.x インタープリタの実行ファイルはデフォルトでは python という名前ではインストールされません。同時にインストールされた Python 2.x 実行ファイルと衝突させないためです。
3. 形式ばらない Python の紹介
以下のサンプルでは、入力と出力はプロンプト (>>> や ...) の有無で区別します: 例を実際に試す場合は、プロンプトが表示されているときに、サンプル中のプロンプトから後ろの内容全てを入力します。
このマニュアルにあるサンプルの多くは、対話プロンプトで入力されるものでもコメントを含んでいます。 Python におけるコメント文は、ハッシュ文字 # で始まり、物理行の終わりまで続きます。コメントは行の先頭にも、空白やコードの後にも書くことができますが、文字列リテラルの内部に置くことはできません。文字列リテラル中のハッシュ文字はただのハッシュ文字です。コメントはコードを明快にするためのものであり、Pythonはコメントを解釈しません。なので、サンプルコードを実際に入力して試して見るときは、コメントを省いても大丈夫です。
いくつかの例です:
# this is the first comment
spam = 1  # and this is the second comment
          # ... and now a third!
text = "# This is not a comment because it's inside quotes."
3.1. Python を電卓として使う
それでは、簡単な Python コマンドをいくつか試してみましょう。インタプリタを起動して、一次プロンプト、 >>> が現れるのを待ちます。 (そう長くはかからないはずです)
3.1.1. 数
インタプリタは、簡単な電卓のように動作します: 式を入力すると、その結果が表示されます。式の文法は素直なものです: 演算子 +, -, *, / は (Pascal や C といった) 他のほとんどの言語と同じように動作します; 丸括弧 (()) をグループ化に使うこともできます。例えば:
>>>
>>> 2 + 2
4
>>> 50 - 5*6
20
>>> (50 - 5*6) / 4
5.0
>>> 8 / 5  # division always returns a floating point number
1.6
整数 (例えば、 2 、 4 、 20) は int 型であり、小数部を持つ数 (例えば、 5.0 、 1.6) は float 型です。数値型については後のチュートリアルでさらに見ていきます。
除算 (/) は常に浮動小数点数を返します。 // 演算子は 整数除算 を行い、(小数部を切り捨てた) 整数値を返します; 剰余は、% で求めます。:
>>>
>>> 17 / 3  # classic division returns a float
5.666666666666667
>>>
>>> 17 // 3  # floor division discards the fractional part
5
>>> 17 % 3  # the % operator returns the remainder of the division
2
>>> 5 * 3 + 2  # result * divisor + remainder
17
Python では、冪乗を計算するのに ** 演算子が使えます 1:
>>>
>>> 5 ** 2  # 5 squared
25
>>> 2 ** 7  # 2 to the power of 7
128
等号 (=) は変数に値を代入するときに使います。代入を行っても、結果は出力されず、次の入力プロンプトが表示されます。:
>>>
>>> width = 20
>>> height = 5 * 9
>>> width * height
900
変数が "定義" されていない (つまり値が代入されていない) 場合、その変数を使おうとするとエラーが発生します:
>>>
>>> n  # try to access an undefined variable
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'n' is not defined
浮動小数点を完全にサポートしています。演算対象の値(オペランド)に複数の型が入り混じっている場合、演算子は整数のオペランドを浮動小数点型に変換します:
>>>
>>> 4 * 3.75 - 1
14.0
対話モードでは、最後に表示された結果は変数 _ に代入されます。このことを利用すると、Python を電卓として使うときに、計算を連続して行う作業が多少楽になります。以下に例を示します:
>>>
>>> tax = 12.5 / 100
>>> price = 100.50
>>> price * tax
12.5625
>>> price + _
113.0625
>>> round(_, 2)
113.06
この変数には読取りだけを行い、明示的な代入を行ってはいけません --- そんなことをすれば、同じ名前で別のローカル変数が生成され、元の特別な動作をする組み込み変数を覆い隠してしておかしなことになってしまうかもしれません。
int と float に加え、 Python は Decimal や Fraction などの他の数値型もサポートしています。 複素数 も組み込み型としてサポートしており、 j もしくは J 接尾辞を使って虚部を示します (例: 3+5j)。
3.1.2. 文字列型 (string)
Python は、数だけではなく、文字列も操作できます。文字列を記述する方法は複数あり、単引用符 ('...') で囲むか、もしくは二重引用符 ("...") で囲みます。結果はどちらも同じ文字列になります。2 引用符は、\ でエスケープできます。:
>>>
>>> 'spam eggs'  # single quotes
'spam eggs'
>>> 'doesn\'t'  # use \' to escape the single quote...
"doesn't"
>>> "doesn't"  # ...or use double quotes instead
"doesn't"
>>> '"Yes," they said.'
'"Yes," they said.'
>>> "\"Yes,\" they said."
'"Yes," they said.'
>>> '"Isn\'t," they said.'
'"Isn\'t," they said.'
対話的インタプリタが文字列を出力するとき、出力文字列は引用符に囲まれ、特殊文字はバックスラッシュでエスケープされます。出力文字が入力とは違って見える (囲っている引用符が変わる) こともありますが、その 2 つの文字列は同じ文字列です。文字列が単引用符を含み二重引用符を含まない場合、二重引用符で囲われ、それ以外の場合は単引用符で囲われます。
>>>
>>> '"Isn\'t," they said.'
'"Isn\'t," they said.'
>>> print('"Isn\'t," they said.')
"Isn't," they said.
>>> s = 'First line.\nSecond line.'  # \n means newline
>>> s  # without print(), \n is included in the output
'First line.\nSecond line.'
>>> print(s)  # with print(), \n produces a new line
\ に続く文字を特殊文字として解釈されたくない場合は、最初の引用符の前に r を付けた raw strings が使えます:
>>>
>>> print('C:\some\name')  # here \n means newline!
C:\some
ame
>>> print(r'C:\some\name')  # note the r before the quote
C:\some\name
文字列リテラルは複数行にまたがって書けます。1 つの方法は三連引用符 ("""...""" や '''...''') を使うことです。改行文字は自動的に文字列に含まれますが、行末に \ を付けることで含めないようにすることもできます。次の例:
print("""\
Usage: thingy [OPTIONS]
     -h                        Display this usage message
     -H hostname               Hostname to connect to
""")
は次のような出力になります (最初の改行文字は含まれていないことに注意してください):
Usage: thingy [OPTIONS]
     -h                        Display this usage message
     -H hostname               Hostname to connect to
文字列は + 演算子で連結させる (くっつけて一つにする) ことができ、* 演算子で反復させることができます:
>>>
>>> # 3 times 'un', followed by 'ium'
>>> 3 * 'un' + 'ium'
'unununium'
連続して並んでいる複数の 文字列リテラル (つまり、引用符に囲われた文字列) は、自動的に連結されます。
>>>
>>> 'Py' 'thon'
'Python'
この機能は、長い文字列を改行したいときにとても役に立ちます:
>>>
>>> text = ('Put several strings within parentheses '
...         'to have them joined together.')
>>> text
'Put several strings within parentheses to have them joined together.'
これは 2 つのリテラルどうしに対してのみ働き、変数や式には働きません:
>>>
>>> prefix = 'Py'
>>> prefix 'thon'  # can't concatenate a variable and a string literal
  File "<stdin>", line 1
    prefix 'thon'
                ^
SyntaxError: invalid syntax
>>> ('un' * 3) 'ium'
  File "<stdin>", line 1
    ('un' * 3) 'ium'
                   ^
SyntaxError: invalid syntax
変数どうしや変数とリテラルを連結したい場合は、+ を使ってください:
>>>
>>> prefix + 'thon'
'Python'
文字列は インデックス (添字) を指定して文字を取得できます。最初の文字のインデックスは 0 になります。文字を表す、専用のデータ型は用意されていません; 文字とは、単に長さが 1 の文字列です:
>>>
>>> word = 'Python'
>>> word[0]  # character in position 0
'P'
>>> word[5]  # character in position 5
'n'
インデックスには、負の値も指定できまます。この場合、右から数えていきます:
>>>
>>> word[-1]  # last character
'n'
>>> word[-2]  # second-last character
'o'
>>> word[-6]
'P'
-0 は 0 と区別できないので、負のインデックスは -1 から始まります。
インデックスに加え、スライス もサポートされています。インデックスは一文字づつ取得するのに使いますが、スライス は部分文字列を取得します:
>>>
>>> word[0:2]  # characters from position 0 (included) to 2 (excluded)
'Py'
>>> word[2:5]  # characters from position 2 (included) to 5 (excluded)
'tho'
開始値は常に含まれ、終了値は常に含まれないことに注意してください。なので s[:i] + s[i:] は常に s と等しくなります:
>>>
>>> word[:2] + word[2:]
'Python'
>>> word[:4] + word[4:]
'Python'
スライスのインデックスには、便利なデフォルト値があります; 最初のインデックスを省略すると、0 と見なされます。二番め のインデックスを省略すると、スライスする文字列のサイズとみなされます。
>>>
>>> word[:2]   # character from the beginning to position 2 (excluded)
'Py'
>>> word[4:]   # characters from position 4 (included) to the end
'on'
>>> word[-2:]  # characters from the second-last (included) to the end
'on'
スライスの使い方をおぼえる良い方法は、インデックスが文字と文字の あいだ (between) を指しており、最初の文字の左端が 0 になっていると考えることです。そうすると、 n 文字からなる文字列中の最後の文字の右端はインデックス n となります。例えばこうです:
 +---+---+---+---+---+---+
 | P | y | t | h | o | n |
 +---+---+---+---+---+---+
 0   1   2   3   4   5   6
-6  -5  -4  -3  -2  -1
1行目の数字は文字列の 0 から 6 までのインデックスの位置を示しています; 2行目は対応する負のインデックスを示しています。i から j までのスライスは、それぞれ i と付いた境界から j と付いた境界までの全ての文字から成っています。
正のインデックスの場合、スライスされたシーケンスの長さは、スライスの両端のインデックスが範囲内にあるかぎり、インデックス間の差になります。例えば、 word[1:3] の長さは 2 になります。
大き過ぎるインデックスを使おうとするとエラーが発生します:
>>>
>>> word[42]  # the word only has 6 characters
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
IndexError: string index out of range
しかし、スライスで範囲外のインデックスを使ったときは、上手く対応して扱ってくれます:
>>>
>>> word[4:42]
'on'
>>> word[42:]
''
Python の文字列は変更できません -- つまり 不変 です。従って、文字列のインデックスで指定したある場所に代入を行うとエラーが発生します:
>>>
>>> word[0] = 'J'
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'str' object does not support item assignment
>>> word[2:] = 'py'
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'str' object does not support item assignment
元の文字列と別の文字列が必要な場合は、新しく文字列を作成してください:
>>>
>>> 'J' + word[1:]
'Jython'
>>> word[:2] + 'py'
'Pypy'
組込み関数 len() は文字列の長さ (length) を返します:
>>>
>>> s = 'supercalifragilisticexpialidocious'
>>> len(s)
34
参考
テキストシーケンス型 --- str
文字列は代表的な シーケンス型 で、シーケンス型でサポートされている共通の操作をサポートしています。
文字列メソッド
文字列は、基本的な変換や検索を行うための数多くのメソッドをサポートしています。
フォーマット済み文字列リテラル
式の埋め込みをサポートした文字列リテラル
書式指定文字列の文法
str.format() を使った文字列のフォーマットについての情報があります。
printf 形式の文字列書式化
文字列が % 演算子の左オペランドである場合に呼び出される古いフォーマット操作について、詳しく記述されています。
3.1.3. リスト型 (list)
Pythonは多くの 複合 (compound) データ型を備えており、複数の値をまとめるのに使われます。最も汎用性が高いのは リスト (list) で、コンマ区切りの値 (要素) の並びを角括弧で囲んだものとして書き表されます。リストは異なる型の要素を含むこともありますが、通常は同じ型の要素のみを持ちます。
>>>
>>> squares = [1, 4, 9, 16, 25]
>>> squares
[1, 4, 9, 16, 25]
文字列 (や他の全ての組み込みの シーケンス 型) のように、リストはインデックスやスライスができます:
>>>
>>> squares[0]  # indexing returns the item
1
>>> squares[-1]
25
>>> squares[-3:]  # slicing returns a new list
[9, 16, 25]
全てのスライス操作は、指定された要素を含む新しいリストを返します。例えば、次のスライスは、リストの 浅いコピー を返します。:
>>>
>>> squares[:]
[1, 4, 9, 16, 25]
リストは、リストの連結などもサポートしています:
>>>
>>> squares + [36, 49, 64, 81, 100]
[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
不変 な文字列とは違って、リストは 可変 型ですので、要素を入れ替えられます:
>>>
>>> cubes = [1, 8, 27, 65, 125]  # something's wrong here
>>> 4 ** 3  # the cube of 4 is 64, not 65!
64
>>> cubes[3] = 64  # replace the wrong value
>>> cubes
[1, 8, 27, 64, 125]
append() を使って、リストの末尾に新しい要素を追加できます (このメソッドについては後で詳しく見ていきます):
>>>
>>> cubes.append(216)  # add the cube of 6
>>> cubes.append(7 ** 3)  # and the cube of 7
>>> cubes
[1, 8, 27, 64, 125, 216, 343]
スライスには、代入もできます。スライスの代入で、リストのサイズを変更したり、全てを削除したりもできます:
>>>
>>> letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g']
>>> letters
['a', 'b', 'c', 'd', 'e', 'f', 'g']
>>> # replace some values
>>> letters[2:5] = ['C', 'D', 'E']
>>> letters
['a', 'b', 'C', 'D', 'E', 'f', 'g']
>>> # now remove them
>>> letters[2:5] = []
>>> letters
['a', 'b', 'f', 'g']
>>> # clear the list by replacing all the elements with an empty list
>>> letters[:] = []
>>> letters
[]
組込み関数 len() はリストにも使えます:
>>>
>>> letters = ['a', 'b', 'c', 'd']
>>> len(letters)
4
リストを入れ子 (ほかのリストを含むリストを造る) にできます。例えば:
>>>
>>> a = ['a', 'b', 'c']
>>> n = [1, 2, 3]
>>> x = [a, n]
>>> x
[['a', 'b', 'c'], [1, 2, 3]]
>>> x[0]
['a', 'b', 'c']
>>> x[0][1]
'b'
3.2. プログラミングへの第一歩
もちろん、2 たす 2 よりももっと複雑な課題にも Python を使えます。 例えば、Fibonacci 数列 の先頭の部分列は次のように書けます:
>>>
>>> # Fibonacci series:
... # the sum of two elements defines the next
... a, b = 0, 1
>>> while a < 10:
...     print(a)
...     a, b = b, a+b
...
0
1
1
2
3
5
8
上の例では、いくつか新しい機能を使用しています。
最初の行には 複数同時の代入 (multiple assignment) が入っています: 変数 a と b は、それぞれ同時に新しい値 0 と 1 になっています。この代入は、最後の行でも使われています。代入文では、まず右辺の式がすべて評価され、次に代入が行われます。右辺の式は、左から右へと順番に評価されます。
while は、条件 (ここでは `` a < 10``) が真である限り実行を繰り返し (ループし) ます。Python では、C 言語と同様に、ゼロでない整数値は真となり、ゼロは偽です。条件式には、文字列値やリスト値なども使えます。それ以外のシーケンスも、条件式として使用できます。長さが 1 以上のシーケンスは真で、空のシーケンスは偽になります。サンプルで使われている条件テストはシンプルな比較です。標準的な比較演算子は C 言語と同様です: すなわち、 < (より小さい)、 > (より大きい)、 == (等しい)、 <= (より小さいか等しい)、 >= (より大きいか等しい)、および != (等しくない)、です。
ループの 本体 (body) は、 インデント (indent, 字下げ) されています: インデントは Python において、実行文をグループにまとめる方法です。対話的プロンプトでは、インデントされた各行を入力するにはタブや (複数個の) スペースを使わなければなりません。実用的には、もっと複雑な処理を入力する場合はテキストエディタを使うことになるでしょう。 ほとんどのテキストエディタは、自動インデント機能を持っています。複合文を対話的に入力するときには、入力完了のしるしとして最後に空行を入力します。これは、パーザはどれが最後の行を入力なのか、判断できないためです。基本的なブロック内では、全ての行は同じだけインデントされていなければならないので注意してください。
print() 関数は、与えられた引数の値を書き出します。これは (前に電卓の例でやったような) 単に出力したい式を書くのとは、複数の引数や浮動小数点量や文字列に対する扱い方が違います。print() 関数では、文字列は引用符無しで出力され、要素の間に空白が挿入されて、このように出力の書式が整えられます:
>>>
>>> i = 256*256
>>> print('The value of i is', i)
The value of i is 65536
キーワード引数 end を使うと、出力の末尾に改行文字を出力しないようにしたり、別の文字列を末尾に出力したりできます:
>>>
>>> a, b = 0, 1
>>> while a < 1000:
...     print(a, end=',')
...     a, b = b, a+b
...
0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,
4. その他の制御フローツール
先ほど説明のあった while 文に加えて、他の言語での経験から分かるような通常のフロー制御文を少し工夫を効かせて使用します。
4.1. if 文
おそらく最もおなじみの文型は if 文でしょう。例えば:
>>>
>>> x = int(input("Please enter an integer: "))
Please enter an integer: 42
>>> if x < 0:
...     x = 0
...     print('Negative changed to zero')
... elif x == 0:
...     print('Zero')
... elif x == 1:
...     print('Single')
... else:
...     print('More')
...
More
ゼロ個以上の elif 部を使うことができ、 else 部を付けることもできます。キーワード 'elif' は 'else if' を短くしたもので、過剰なインデントを避けるのに役立ちます。一連の if ... elif ... elif ... は、他の言語における switch 文や case 文の代用となります。
4.2. for 文
Python の for 文は、読者が C 言語や Pascal 言語で使いなれているかもしれない for 文とは少し違います。 (Pascal のように) 常に算術型の数列にわたる反復を行ったり、 (C のように) 繰返しステップと停止条件を両方ともユーザが定義できるようにするのとは違い、Python の for 文は、任意のシーケンス型 (リストまたは文字列) にわたって反復を行います。反復の順番はシーケンス中に要素が現れる順番です。例えば:
>>>
>>> # Measure some strings:
... words = ['cat', 'window', 'defenestrate']
>>> for w in words:
...     print(w, len(w))
...
cat 3
window 6
defenestrate 12
コレクションオブジェクトの値を反復処理をしているときに、そのコレクションオブジェクトを変更するコードは理解するのが面倒になり得ます。 そうするよりも、コレクションオブジェクトのコピーに対して反復処理をするか、新しいコレクションオブジェクトを作成する方が通常は理解しやすいです:
# Strategy:  Iterate over a copy
for user, status in users.copy().items():
    if status == 'inactive':
        del users[user]
# Strategy:  Create a new collection
active_users = {}
for user, status in users.items():
    if status == 'active':
        active_users[user] = status
4.3. range() 関数
数列にわたって反復を行う必要がある場合、組み込み関数 range() が便利です。この関数は算術型の数列を生成します:
>>>
>>> for i in range(5):
...     print(i)
...
0
1
2
3
4
指定した終端値は生成されるシーケンスには入りません。range(10) は 10 個の値を生成し、長さ 10 のシーケンスにおける各項目のインデクスとなります。range を別の数から開始したり、他の増加量 (負でも; 増加量は時に 'ステップ(step)' と呼ばれることもあります) を指定することもできます:
range(5, 10)
   5, 6, 7, 8, 9
range(0, 10, 3)
   0, 3, 6, 9
range(-10, -100, -30)
  -10, -40, -70
あるシーケンスにわたってインデクスで反復を行うには、 range() と len() を次のように組み合わせられます:
>>>
>>> a = ['Mary', 'had', 'a', 'little', 'lamb']
>>> for i in range(len(a)):
...     print(i, a[i])
...
0 Mary
1 had
2 a
3 little
4 lamb
しかし、多くの場合は enumerate() 関数を使う方が便利です。 ループのテクニック を参照してください。
range を直接出力すると変なことになります:
>>>
>>> print(range(10))
range(0, 10)
range() が返すオブジェクトは、いろいろな点でリストであるかのように振る舞いますが、本当はリストではありません。これは、イテレートした時に望んだ数列の連続した要素を返すオブジェクトです。しかし実際にリストを作るわけではないので、スペースの節約になります。
このようなオブジェクトは イテラブル (iterable) と呼ばれます。 これらは関数や構成物のターゲットとして、あるだけの項目を逐次与えるのに適しています。 for 文がそのような構成物であることはすでに見てきており、イテラブルを受け取る関数の例には sum() があります:
>>>
>>> sum(range(4))  # 0 + 1 + 2 + 3
6
後ほど、イテラブルを返したりイテラブルを引数として取る関数をもっと見ていきます。 そして最後に、どうやって range からリストを作るのかが気になるかもしれません。 これが答えです:
>>>
>>> list(range(4))
[0, 1, 2, 3]
データ構造 の章では、 list() についてより詳細に議論します。
4.4. break 文と continue 文とループの else 節
break 文は、C 言語と同じく、最も内側の for または while ループを中断します。
ループ文は else 節を持つことができます。これは、 (for で) イテラブルを使い切ってループが終了したとき、または (while で) 条件が偽になったときに実行されますが、 break 文でループが終了したときは実行されません。この動作を、素数を探す下記のループを例にとって示します:
>>>
>>> for n in range(2, 10):
...     for x in range(2, n):
...         if n % x == 0:
...             print(n, 'equals', x, '*', n//x)
...             break
...     else:
...         # loop fell through without finding a factor
...         print(n, 'is a prime number')
...
2 is a prime number
3 is a prime number
4 equals 2 * 2
5 is a prime number
6 equals 2 * 3
7 is a prime number
8 equals 2 * 4
9 equals 3 * 3
(そう、これは正しいコードです。よく見てください: else 節は if 文 ではなく 、 for ループに属しています。)
ループの else 句は、 if 文の else よりも try 文の else に似ています。 try 文の else 句は例外が発生しなかった時に実行され、ループの else 句は break されなかった場合に実行されます。 try 文と例外についての詳細は 例外を処理する を参照してください。
continue 文も C 言語から借りてきたもので、ループの次のイテレーションを実行します:
>>>
>>> for num in range(2, 10):
...     if num % 2 == 0:
...         print("Found an even number", num)
...         continue
...     print("Found an odd number", num)
Found an even number 2
Found an odd number 3
Found an even number 4
Found an odd number 5
Found an even number 6
Found an odd number 7
Found an even number 8
Found an odd number 9
4.5. pass 文
pass 文は何もしません。 pass は、文を書くことが構文上要求されているが、プログラム上何の動作もする必要がない時に使われます:
>>>
>>> while True:
...     pass  # Busy-wait for keyboard interrupt (Ctrl+C)
...
これは最小のクラスを作るときによく使われる方法です:
>>>
>>> class MyEmptyClass:
...     pass
...
pass のもう 1 つの使い道は、新しいコードを書いているときの関数や条件文の仮置きの本体としてです。こうすることで、より抽象的なレベルで考え続けられます。 pass は何事も無く無視されます
>>>
>>> def initlog(*args):
...     pass   # Remember to implement this!
...
4.6. 関数を定義する
フィボナッチ数列 (Fibonacci series) を任意の上限値まで書き出すような関数を作成できます:
>>>
>>> def fib(n):    # write Fibonacci series up to n
...     """Print a Fibonacci series up to n."""
...     a, b = 0, 1
...     while a < n:
...         print(a, end=' ')
...         a, b = b, a+b
...     print()
...
>>> # Now call the function we just defined:
... fib(2000)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597
def は関数の 定義 (definition) を導くキーワードです。 def の後には、関数名と仮引数を丸括弧で囲んだリストを続けなければなりません。関数の実体を構成する実行文は次の行から始め、インデントされていなければなりません。
関数の本体の記述する文の最初の行は文字列リテラルにすることもできます。その場合、この文字列は関数のドキュメンテーション文字列 (documentation string)、または docstring と呼ばれます。 (docstring については ドキュメンテーション文字列 でさらに扱っています。) ドキュメンテーション文字列を使ったツールには、オンライン文書や印刷文書を自動的に生成したり、ユーザが対話的にコードから直接閲覧できるようにするものがあります。自分が書くコードにドキュメンテーション文字列を入れるのはよい習慣です。書く癖をつけてください。
関数を 実行 (execution) するとき、関数のローカル変数のために使われる新たなシンボルテーブル (symbol table) が用意されます。 もっと正確にいうと、関数内で変数への代入を行うと、その値はすべてこのローカルなシンボルテーブルに記憶されます。 一方、変数の参照を行うと、まずローカルなシンボルテーブルが検索され、次にさらに外側の関数のローカルなシンボルテーブルを検索し、その後グローバルなシンボルテーブルを調べ、最後に組み込みの名前テーブルを調べます。 従って、関数の中では (グローバル変数が global 文で指定されていたり、外側の関数の変数が nonlocal 文で指定されていない限り) グローバル変数や外側の関数の変数に直接値を代入できませんが、参照することはできます。
A function definition associates the function name with the function object in the current symbol table. The interpreter recognizes the object pointed to by that name as a user-defined function. Other names can also point to that same function object and can also be used to access the function:
>>>
>>> fib
<function fib at 10042ed0>
>>> f = fib
>>> f(100)
0 1 1 2 3 5 8 13 21 34 55 89
他の言語出身の人からは、 fib は値を返さないので関数ではなく手続き (procedure) だと異論があるかもしれませんね。技術的に言えば、実際には return 文を持たない関数もややつまらない値ですが値を返しています。この値は None と呼ばれます (これは組み込みの名前です)。 None だけを書き出そうとすると、インタプリタは通常出力を抑制します。本当に出力したいのなら、以下のように print() を使うと見ることができます:
>>>
>>> fib(0)
>>> print(fib(0))
None
フィボナッチ数列の数からなるリストを出力する代わりに、値を返すような関数を書くのは簡単です:
>>>
>>> def fib2(n):  # return Fibonacci series up to n
...     """Return a list containing the Fibonacci series up to n."""
...     result = []
...     a, b = 0, 1
...     while a < n:
...         result.append(a)    # see below
...         a, b = b, a+b
...     return result
...
>>> f100 = fib2(100)    # call it
>>> f100                # write the result
[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]
この例は Python の新しい機能を示しています:
return 文では、関数から一つ値を返します。 return の引数となる式がない場合、 None が返ります。関数が終了したときにも None が返ります。
文 result.append(a) では、リストオブジェクト result の メソッド (method) を呼び出しています。メソッドとは、オブジェクトに '属している' 関数のことで、 obj を何らかのオブジェクト (式であっても構いません)、 methodname をそのオブジェクトで定義されているメソッド名とすると、 obj.methodname と書き表されます。異なる型は異なるメソッドを定義しています。異なる型のメソッドで同じ名前のメソッドを持つことができ、あいまいさを生じることはありません。 (クラス (class) を使うことで、自前のオブジェクト型とメソッドを定義することもできます。 クラス 参照) 例で示されているメソッド append() は、リストオブジェクトで定義されています; このメソッドはリストの末尾に新たな要素を追加します。この例での append() は result = result + [a] と等価ですが、より効率的です。
4.7. 関数定義についてもう少し
可変個の引数を伴う関数を定義することもできます。引数の定義方法には 3 つの形式があり、それらを組み合わせることができます。
4.7.1. デフォルトの引数値
もっとも便利なのは、一つ以上の引数に対してデフォルトの値を指定する形式です。この形式を使うと、定義されている引数より少ない個数の引数で呼び出せる関数を作成します:
def ask_ok(prompt, retries=4, reminder='Please try again!'):
    while True:
        ok = input(prompt)
        if ok in ('y', 'ye', 'yes'):
            return True
        if ok in ('n', 'no', 'nop', 'nope'):
            return False
        retries = retries - 1
        if retries < 0:
            raise ValueError('invalid user response')
        print(reminder)
この関数はいくつかの方法で呼び出せます:
必須の引数のみ与える: ask_ok('Do you really want to quit?')
一つのオプション引数を与える: ask_ok('OK to overwrite the file?', 2)
全ての引数を与える: ask_ok('OK to overwrite the file?', 2, 'Come on, only yes or no!')
この例では in キーワードが導入されています。このキーワードはシーケンスが特定の値を含んでいるかどうか調べるのに使われます。
デフォルト値は、関数が定義された時点で、関数を 定義している 側のスコープ (scope) で評価されるので
i = 5
def f(arg=i):
    print(arg)
i = 6
f()
は 5 を出力します。
重要な警告: デフォルト値は 1 度だけしか評価されません。デフォルト値がリストや辞書のような変更可能なオブジェクトの時にはその影響がでます。例えば以下の関数は、後に続く関数呼び出しで関数に渡されている引数を累積します:
def f(a, L=[]):
    L.append(a)
    return L
print(f(1))
print(f(2))
print(f(3))
このコードは、以下を出力します
[1]
[1, 2]
[1, 2, 3]
後続の関数呼び出しでデフォルト値を共有したくなければ、代わりに以下のように関数を書くことができます:
def f(a, L=None):
    if L is None:
        L = []
    L.append(a)
    return L
4.7.2. キーワード引数
関数を kwarg=value という形式の キーワード引数 を使って呼び出すこともできます。例えば、以下の関数:
def parrot(voltage, state='a stiff', action='voom', type='Norwegian Blue'):
    print("-- This parrot wouldn't", action, end=' ')
    print("if you put", voltage, "volts through it.")
    print("-- Lovely plumage, the", type)
    print("-- It's", state, "!")
は、必須引数 (voltage) とオプション引数 (state、action、type) を受け付けます。この関数は以下のいずれかの方法で呼び出せます:
parrot(1000)                                          # 1 positional argument
parrot(voltage=1000)                                  # 1 keyword argument
parrot(voltage=1000000, action='VOOOOOM')             # 2 keyword arguments
parrot(action='VOOOOOM', voltage=1000000)             # 2 keyword arguments
parrot('a million', 'bereft of life', 'jump')         # 3 positional arguments
parrot('a thousand', state='pushing up the daisies')  # 1 positional, 1 keyword
が、以下の呼び出しは不適切です:
parrot()                     # required argument missing
parrot(voltage=5.0, 'dead')  # non-keyword argument after a keyword argument
parrot(110, voltage=220)     # duplicate value for the same argument
parrot(actor='John Cleese')  # unknown keyword argument
関数の呼び出しにおいて、キーワード引数は位置引数の後でなければなりません。渡されるキーワード引数は全て、関数で受け付けられる引数のいずれかに対応していなければならず (例えば、actor はこの parrot 関数の引数として適切ではありません)、順序は重要ではありません。これはオプションでない引数でも同様です (例えば、parrot(voltage=1000) も適切です)。いかなる引数も値を複数回は受け取れません。この制限により失敗する例は:
>>>
>>> def function(a):
...     pass
...
>>> function(0, a=0)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: function() got multiple values for keyword argument 'a'
仮引数の最後に **name の形式のものがあると、それまでの仮引数に対応したものを除くすべてのキーワード引数が入った辞書 (マッピング型 --- dict を参照) を受け取ります。 **name は *name の形式をとる、仮引数のリストを超えた位置引数の入った タプル を受け取る引数 (次の小節で述べます) と組み合わせられます。 (*name は **name より前になければなりません)。 例えば、ある関数の定義を以下のようにすると:
def cheeseshop(kind, *arguments, **keywords):
    print("-- Do you have any", kind, "?")
    print("-- I'm sorry, we're all out of", kind)
    for arg in arguments:
        print(arg)
    print("-" * 40)
    for kw in keywords:
        print(kw, ":", keywords[kw])
呼び出しは以下のようになり:
cheeseshop("Limburger", "It's very runny, sir.",
           "It's really very, VERY runny, sir.",
           shopkeeper="Michael Palin",
           client="John Cleese",
           sketch="Cheese Shop Sketch")
もちろん以下のように出力されます:
-- Do you have any Limburger ?
-- I'm sorry, we're all out of Limburger
----------------------------------------
shopkeeper : Michael Palin
client : John Cleese
sketch : Cheese Shop Sketch
なお、複数のキーワード引数を与えた場合に、それらが出力される順序は、関数呼び出しで与えられた順序と同じになります。
4.7.3. 特殊なパラメータ
デフォルトでは、引数は位置またはキーワードによる明示で Python 関数に渡されます。 可読性とパフォーマンスのために、その引数が位置、位置またはキーワード、キーワードのどれで渡されるかを開発者が判定するのに関数定義だけを見ればよいように、引数の渡され方を制限することには意味があります。
関数定義は次のようになります:
def f(pos1, pos2, /, pos_or_kwd, *, kwd1, kwd2):
      -----------    ----------     ----------
        |             |                  |
        |        Positional or keyword   |
        |                                - Keyword only
         -- Positional only
ここで、/ と * はオプションです。使用された場合、これらの記号は、引数が関数に渡される方法、すなわち、位置専用、位置またはキーワード、キーワード専用、といった引数の種類を示します。キーワード引数は、名前付き引数とも呼ばれます。
4.7.3.1. 位置またはキーワード引数
関数定義に / も * もない場合は、引数は位置またはキーワードで関数に渡されます。
4.7.3.2. 位置専用引数
これをもう少し詳しく見てみると、特定の引数を 位置専用 と印を付けられます。 位置専用 の場合、引数の順序が重要であり、キーワードで引数を渡せません。 位置専用引数は / （スラッシュ）の前に配置されます。 / は、位置専用引数を残りの引数から論理的に分離するために使用されます。 関数定義に / がない場合、位置専用引数はありません。
/ の後の引数は、 位置またはキーワード 、もしくは、 キーワード専用 です。
4.7.3.3. キーワード専用引数
引数をキーワード引数で渡す必要があることを示す キーワード専用 として引数をマークするには、引数リストの最初の キーワード専用 引数の直前に * を配置します。
4.7.3.4. 関数の例
/ および * といったマーカーに注意を払って、次の関数定義の例を見てください:
>>>
>>> def standard_arg(arg):
...     print(arg)
...
>>> def pos_only_arg(arg, /):
...     print(arg)
...
>>> def kwd_only_arg(*, arg):
...     print(arg)
...
>>> def combined_example(pos_only, /, standard, *, kwd_only):
...     print(pos_only, standard, kwd_only)
最も馴染みのある形式の最初の関数定義 standard_arg は、呼び出し規約に制限を設けておらず、引数は位置またはキーワードで渡されます:
>>>
>>> standard_arg(2)
2
>>> standard_arg(arg=2)
2
2番目の関数の pos_only_arg は、 / が関数定義にあるので、引数は位置専用になります:
>>>
>>> pos_only_arg(1)
1
>>> pos_only_arg(arg=1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: pos_only_arg() got an unexpected keyword argument 'arg'
3番目の関数 kwd_only_args は、関数定義に * があるので、引数はキーワード専用になります:
>>>
>>> kwd_only_arg(3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: kwd_only_arg() takes 0 positional arguments but 1 was given
>>> kwd_only_arg(arg=3)
3
そして最後の関数は3つの引数の種類を一つの関数定義の中で使用しています:
>>>
>>> combined_example(1, 2, 3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: combined_example() takes 2 positional arguments but 3 were given
>>> combined_example(1, 2, kwd_only=3)
1 2 3
>>> combined_example(1, standard=2, kwd_only=3)
1 2 3
>>> combined_example(pos_only=1, standard=2, kwd_only=3)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: combined_example() got an unexpected keyword argument 'pos_only'
最後に、位置引数 name と name をキーとして持つ **kwds の間に潜在的な衝突がある関数定義を考えてみましょう。
def foo(name, **kwds):
    return 'name' in kwds
キーワードに 'name' を入れても、先頭の引数と同じになってしまうため、この関数が True を返すような呼び出しの方法はありません。例えば、次のようになってしまいます:
>>>
>>> foo(1, **{'name': 2})
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: foo() got multiple values for argument 'name'
>>>
しかし位置専用を示す / を使用すれば可能になります。 name は位置引数として、そして 'name' はキーワード引数のキーワードとして認識されるからです:
def foo(name, /, **kwds):
    return 'name' in kwds
>>> foo(1, **{'name': 2})
True
言い換えると、位置専用引数であれば、その名前を **kwds の中で使用しても、曖昧にならないということです。
4.7.3.5. 要約
使用例で、関数定義でどの種類の引数を使うかべきかがわかると思います:
def f(pos1, pos2, /, pos_or_kwd, *, kwd1, kwd2):
ガイドとしては、
もし引数の名前をユーザーに知らせる必要がないなら、位置専用引数を使用しましょう。これは引数の名前がユーザーにとって意味がなく、関数が呼ばれたときの引数の順序が問題であり、または、位置引数と任意のキーワードを使用する必要がある場合に便利です。
引数の名前に意味があり、それにより関数の定義がより明らかになる、または、ユーザーが引数の順番に縛られることを避けたほうがいいと考えるのなら、キーワード専用引数を使用しましょう。
APIの場合、将来引数の名前が変更された場合にAPIの変更ができなくなることを防ぐために、位置専用引数を使用しましょう。
4.7.4. 任意引数リスト
最後に、最も使うことの少ない選択肢として、関数が任意の個数の引数で呼び出せるよう指定する方法があります。これらの引数はタプル (タプルとシーケンス を参照) に格納されます。可変個の引数の前に、ゼロ個かそれ以上の引数があっても構いません。
def write_multiple_items(file, separator, *args):
    file.write(separator.join(args))
通常このような 可変 引数は、関数に渡される入力引数の残りを全て掬い取るために、仮引数リストの最後に置かれます。 *args 引数の後にある仮引数は 'キーワード専用' 引数で、位置引数ではなくキーワード引数としてのみ使えることを意味します。
>>>
>>> def concat(*args, sep="/"):
...     return sep.join(args)
...
>>> concat("earth", "mars", "venus")
'earth/mars/venus'
>>> concat("earth", "mars", "venus", sep=".")
'earth.mars.venus'
4.7.5. 引数リストのアンパック
引数がすでにリストやタプルになっていて、個別な位置引数を要求する関数呼び出しに渡すためにアンパックする必要がある場合には、逆の状況が起こります。例えば、組み込み関数 range() は引数 start と stop を別に与える必要があります。個別に引数を与えることができない場合、関数呼び出しを * 演算子を使って書き、リストやタプルから引数をアンパックします:
>>>
>>> list(range(3, 6))            # normal call with separate arguments
[3, 4, 5]
>>> args = [3, 6]
>>> list(range(*args))            # call with arguments unpacked from a list
[3, 4, 5]
同じやりかたで、** オペレータを使って辞書でもキーワード引数を渡すことができます:
>>>
>>> def parrot(voltage, state='a stiff', action='voom'):
...     print("-- This parrot wouldn't", action, end=' ')
...     print("if you put", voltage, "volts through it.", end=' ')
...     print("E's", state, "!")
...
>>> d = {"voltage": "four million", "state": "bleedin' demised", "action": "VOOM"}
>>> parrot(**d)
-- This parrot wouldn't VOOM if you put four million volts through it. E's bleedin' demised !
4.7.6. ラムダ式
キーワード lambda を使うと、名前のない小さな関数を生成できます。例えば lambda a, b: a+b は、二つの引数の和を返す関数です。ラムダ式の関数は、関数オブジェクトが要求されている場所にならどこでも使うことができます。ラムダ式は、構文上単一の式に制限されています。意味付け的には、ラムダ形式は単に通常の関数定義に構文的な糖衣をかぶせたものに過ぎません。入れ子構造になった関数定義と同様、ラムダ式もそれを取り囲むスコープから変数を参照することができます:
>>>
>>> def make_incrementor(n):
...     return lambda x: x + n
...
>>> f = make_incrementor(42)
>>> f(0)
42
>>> f(1)
43
上記の例は、関数を返すところでラムダ式を使っています。もう1つの例では、ちょっとした関数を引数として渡すのに使っています:
>>>
>>> pairs = [(1, 'one'), (2, 'two'), (3, 'three'), (4, 'four')]
>>> pairs.sort(key=lambda pair: pair[1])
>>> pairs
[(4, 'four'), (1, 'one'), (3, 'three'), (2, 'two')]
4.7.7. ドキュメンテーション文字列
ドキュメンテーション文字列については、その内容と書式に関する慣習をいくつか挙げます。
最初の行は、常に対象物の目的を短く簡潔にまとめたものでなくてはなりません。簡潔に書くために、対象物の名前や型を明示する必要はありません。名前や型は他の方法でも得られるからです (名前がたまたま関数の演算内容を記述する動詞である場合は例外です)。最初の行は大文字で始まり、ピリオドで終わっていなければなりません。
ドキュメンテーション文字列中にさらに記述すべき行がある場合、二行目は空行にし、まとめの行と残りの記述部分を視覚的に分離します。つづく行は一つまたはそれ以上の段落で、対象物の呼び出し規約や副作用について記述します。
Python のパーザは複数行にわたる Python 文字列リテラルからインデントを剥ぎ取らないので、ドキュメントを処理するツールでは必要に応じてインデントを剥ぎ取らなければなりません。この処理は以下の規約に従って行います。最初の行の 後にある 空行でない最初の行が、ドキュメント全体のインデントの量を決めます。(最初の行は通常、文字列を開始するクオートに隣り合っているので、インデントが文字列リテラル中に現れないためです。) このインデント量と "等価な" 空白が、文字列のすべての行頭から剥ぎ取られます。インデントの量が少ない行を書いてはならないのですが、もしそういう行があると、先頭の空白すべてが剥ぎ取られます。インデントの空白の大きさが等しいかどうかは、タブ文字を (通常は 8 文字のスペースとして) 展開した後に調べられます。
以下に複数行のドキュメンテーション文字列の例を示します:
>>>
>>> def my_function():
...     """Do nothing, but document it.
...
...     No, really, it doesn't do anything.
...     """
...     pass
...
>>> print(my_function.__doc__)
    No, really, it doesn't do anything.
4.7.8. 関数のアノテーション
関数アノテーション はユーザ定義関数で使用される型についての完全にオプションなメタデータ情報です (詳細は PEP 3107 と PEP 484 を参照してください)。
アノテーション は関数の __annotations__ 属性に辞書として格納され、関数の他の部分には何も影響がありません。 パラメータアノテーションは、パラメータ名の後にコロンを続けることによって定義され、その後にアノテーションの値として評価される式が置かれます。 戻り値アノテーションは、パラメータリストと def ステートメントの終わりを表すコロンの間に置かれたリテラル -> によって定義され、その後に式が続きます。次の例は位置引数とキーワード引数、そして戻り値アノテーションを持っています:
>>>
>>> def f(ham: str, eggs: str = 'eggs') -> str:
...     print("Annotations:", f.__annotations__)
...     print("Arguments:", ham, eggs)
...     return ham + ' and ' + eggs
...
>>> f('spam')
Annotations: {'ham': <class 'str'>, 'return': <class 'str'>, 'eggs': <class 'str'>}
Arguments: spam eggs
'spam and eggs'
4.8. 間奏曲: コーディングスタイル
これからより長くより複雑な Python のコードを書いていくので、そろそろ コーディングスタイル について語っても良い頃です。ほとんどの言語は様々なスタイルで書け (もっと簡潔に言えば フォーマットでき)、スタイルによって読み易さが異なります。他人にとって読み易いコードにしようとするのはどんなときでも良い考えであり、良いコーディングスタイルを採用することが非常に強力な助けになります。
Python には、ほとんどのプロジェクトが守っているスタイルガイドとして PEP 8 があります。それは非常に読み易く目に優しいコーディングスタイルを推奨しています。全ての Python 開発者はある時点でそれを読むべきです。ここに最も重要な点を抜き出しておきます:
インデントには空白 4 つを使い、タブは使わないこと。
空白 4 つは (深くネストできる) 小さいインデントと (読み易い) 大きいインデントのちょうど中間に当たります。タブは混乱させるので、使わずにおくのが良いです。
ソースコードの幅が 79 文字を越えないように行を折り返すこと。
こうすることで小さいディスプレイを使っているユーザも読み易くなり、大きなディスプレイではソースコードファイルを並べることもできるようになります。
関数やクラスや関数内の大きめのコードブロックの区切りに空行を使うこと。
可能なら、コメントは行に独立で書くこと。
docstring を使うこと。
演算子の前後とコンマの後には空白を入れ、括弧類のすぐ内側には空白を入れないこと: a = f(1, 2) + g(3, 4)。
クラスや関数に一貫性のある名前を付けること。慣習では UpperCamelCase をクラス名に使い、 lowercase_with_underscores を関数名やメソッド名に使います。常に self をメソッドの第 1 引数の名前 (クラスやメソッドについては クラス初見 を見よ) として使うこと。
あなたのコードを世界中で使ってもらうつもりなら、風変りなエンコーディングは使わないこと。どんな場合でも、Python のデフォルト UTF-8 またはプレーン ASCII が最も上手くいきます。
同様に、ほんの少しでも他の言語を話す人がコードを読んだりメンテナンスする可能性があるのであれば、非 ASCII 文字も識別子に使うべきではありません。
5. データ構造
この章では、すでに学んだことについてより詳しく説明するとともに、いくつか新しいことを追加します。
5.1. リスト型についてもう少し
リストデータ型には、他にもいくつかメソッドがあります。リストオブジェクトのすべてのメソッドを以下に示します:
list.append(x)
リストの末尾に要素を一つ追加します。a[len(a):] = [x] と等価です。
list.extend(iterable)
イテラブルのすべての要素を対象のリストに追加し、リストを拡張します。a[len(a):] = iterable と等価です。
list.insert(i, x)
指定した位置に要素を挿入します。第 1 引数は、リストのインデクスで、そのインデクスを持つ要素の直前に挿入が行われます。従って、 a.insert(0, x) はリストの先頭に挿入を行います。また a.insert(len(a), x) は a.append(x) と等価です。
list.remove(x)
リスト中で x と等しい値を持つ最初の要素を削除します。該当する要素がなければ ValueError が送出されます。
list.pop([i])
リスト中の指定された位置にある要素をリストから削除して、その要素を返します。インデクスが指定されなければ、 a.pop() はリストの末尾の要素を削除して返します。この場合も要素は削除されます。 (メソッドの用法 (signature) で i の両側にある角括弧は、この引数がオプションであることを表しているだけなので、角括弧を入力する必要はありません。この表記法は Python Library Reference の中で頻繁に見ることになるでしょう。)
list.clear()
リスト中の全ての要素を削除します。del a[:] と等価です。
list.index(x[, start[, end]])
リスト中で x と等しい値を持つ最初の要素の位置をゼロから始まる添字で返します。 該当する要素がなければ ValueError が送出されます。
任意の引数である start と end はスライス記法として解釈され、リストの探索範囲を指定できます。返される添字は、start 引数からの相対位置ではなく、リスト全体の先頭からの位置になります。
list.count(x)
リストでの x の出現回数を返します。
list.sort(*, key=None, reverse=False)
リストの項目を、インプレース演算 (in place、元のデータを演算結果で置き換えるやりかた) でソートします。引数はソート方法のカスタマイズに使えます。 sorted() の説明を参照してください。
list.reverse()
リストの要素を、インプレース演算で逆順にします。
list.copy()
リストの浅い (shallow) コピーを返します。a[:] と等価です。
以下にリストのメソッドをほぼ全て使った例を示します:
>>>
>>> fruits = ['orange', 'apple', 'pear', 'banana', 'kiwi', 'apple', 'banana']
>>> fruits.count('apple')
2
>>> fruits.count('tangerine')
0
>>> fruits.index('banana')
3
>>> fruits.index('banana', 4)  # Find next banana starting a position 4
6
>>> fruits.reverse()
>>> fruits
['banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange']
>>> fruits.append('grape')
>>> fruits
['banana', 'apple', 'kiwi', 'banana', 'pear', 'apple', 'orange', 'grape']
>>> fruits.sort()
>>> fruits
['apple', 'apple', 'banana', 'banana', 'grape', 'kiwi', 'orange', 'pear']
>>> fruits.pop()
'pear'
insert, remove, sort などのリストを操作するメソッドの戻り値が表示されていないことに気が付いたかもしれません。これらのメソッドは None を返しています。1 これは Python の変更可能なデータ構造全てについての設計上の原則となっています。
気がつくかもしれないもう一つのことは、すべてのデータをソートまたは比較できるわけではないということです。例えば、整数は文字列と比較できず、 None は他の型と比較できないため、 [None, 'hello', 10] はソートされません。また、定義された順序関係を持たないタイプもあります。たとえば、 3+4j < 5+7j は有効な比較ではありません。
5.1.1. リストをスタックとして使う
リスト型のメソッドのおかげで、簡単にリストをスタックとして使えます。スタックでは、最後に追加された要素が最初に取り出されます ("last-in, first-out")。スタックの一番上に要素を追加するには append() を使います。スタックの一番上から要素を取り出すには pop() をインデクスを指定せずに使います。例えば以下のようにします:
>>>
>>> stack = [3, 4, 5]
>>> stack.append(6)
>>> stack.append(7)
>>> stack
[3, 4, 5, 6, 7]
>>> stack.pop()
7
>>> stack
[3, 4, 5, 6]
>>> stack.pop()
6
>>> stack.pop()
5
>>> stack
[3, 4]
5.1.2. リストをキューとして使う
リストをキュー (queue) として使うことも可能です。この場合、最初に追加した要素を最初に取り出します ("first-in, first-out")。しかし、リストでは効率的にこの目的を達成することが出来ません。追加（append）や取り出し（pop）をリストの末尾に対して行うと速いのですが、挿入（insert）や取り出し（pop）をリストの先頭に対して行うと遅くなってしまいます（他の要素をひとつずつずらす必要があるからです）。
キューの実装には、 collections.deque を使うと良いでしょう。このクラスは良く設計されていて、高速な追加（append）と取り出し（pop）を両端に対して実現しています。例えば以下のようにします:
>>>
>>> from collections import deque
>>> queue = deque(["Eric", "John", "Michael"])
>>> queue.append("Terry")           # Terry arrives
>>> queue.append("Graham")          # Graham arrives
>>> queue.popleft()                 # The first to arrive now leaves
'Eric'
>>> queue.popleft()                 # The second to arrive now leaves
'John'
>>> queue                           # Remaining queue in order of arrival
deque(['Michael', 'Terry', 'Graham'])
5.1.3. リストの内包表記
リスト内包表記はリストを生成する簡潔な手段を提供しています。主な利用場面は、あるシーケンスや iterable (イテレート可能オブジェクト) のそれぞれの要素に対してある操作を行った結果を要素にしたリストを作ったり、ある条件を満たす要素だけからなる部分シーケンスを作成することです。
例えば、次のような平方のリストを作りたいとします:
>>>
>>> squares = []
>>> for x in range(10):
...     squares.append(x**2)
...
>>> squares
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
これはループが終了した後にも存在する x という名前の変数を作る (または上書きする) ことに注意してください。以下のようにして平方のリストをいかなる副作用もなく計算することができます:
squares = list(map(lambda x: x**2, range(10)))
もしくは、以下でも同じです:
squares = [x**2 for x in range(10)]
これはより簡潔で読みやすいです。
リスト内包表記は、括弧の中の 式、 for 句、そして0個以上の for か if 句で構成されます。 リスト内包表記の実行結果は、 for と if 句のコンテキスト中で式を評価した結果からなる新しいリストです。 例えば、次のリスト内包表記は2つのリストの要素から、違うもの同士をペアにします。
>>>
>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]
[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]
これは次のコードと等価です:
>>>
>>> combs = []
>>> for x in [1,2,3]:
...     for y in [3,1,4]:
...         if x != y:
...             combs.append((x, y))
...
>>> combs
[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]
for と if 文が両方のコードで同じ順序になっていることに注目してください。
式がタプルの場合 (例: 上の例で式が (x, y) の場合) は、タプルに円括弧が必要です。
>>>
>>> vec = [-4, -2, 0, 2, 4]
>>> # create a new list with the values doubled
>>> [x*2 for x in vec]
[-8, -4, 0, 4, 8]
>>> # filter the list to exclude negative numbers
>>> [x for x in vec if x >= 0]
[0, 2, 4]
>>> # apply a function to all the elements
>>> [abs(x) for x in vec]
[4, 2, 0, 2, 4]
>>> # call a method on each element
>>> freshfruit = ['  banana', '  loganberry ', 'passion fruit  ']
>>> [weapon.strip() for weapon in freshfruit]
['banana', 'loganberry', 'passion fruit']
>>> # create a list of 2-tuples like (number, square)
>>> [(x, x**2) for x in range(6)]
[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]
>>> # the tuple must be parenthesized, otherwise an error is raised
>>> [x, x**2 for x in range(6)]
  File "<stdin>", line 1, in <module>
    [x, x**2 for x in range(6)]
               ^
SyntaxError: invalid syntax
>>> # flatten a list using a listcomp with two 'for'
>>> vec = [[1,2,3], [4,5,6], [7,8,9]]
>>> [num for elem in vec for num in elem]
[1, 2, 3, 4, 5, 6, 7, 8, 9]
リスト内包表記の式には、複雑な式や関数呼び出しのネストができます:
>>>
>>> from math import pi
>>> [str(round(pi, i)) for i in range(1, 6)]
['3.1', '3.14', '3.142', '3.1416', '3.14159']
5.1.4. ネストしたリストの内包表記
リスト内包表記中の最初の式は任意の式なので、そこに他のリスト内包表記を書くこともできます。
次の、長さ4のリスト3つからなる、3x4 の matrix について考えます:
>>>
>>> matrix = [
...     [1, 2, 3, 4],
...     [5, 6, 7, 8],
...     [9, 10, 11, 12],
... ]
次のリスト内包表記は、matrix の行と列を入れ替えます:
>>>
>>> [[row[i] for row in matrix] for i in range(4)]
[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]
前の節で見たように、ネストしたリスト内包表記は、続く for のコンテキストの中で評価されます。なので、この例は次のコードと等価です:
>>>
>>> transposed = []
>>> for i in range(4):
...     transposed.append([row[i] for row in matrix])
...
>>> transposed
[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]
これをもう一度変換すると、次のコードと等価になります:
>>>
>>> transposed = []
>>> for i in range(4):
...     # the following 3 lines implement the nested listcomp
...     transposed_row = []
...     for row in matrix:
...         transposed_row.append(row[i])
...     transposed.append(transposed_row)
...
>>> transposed
[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]
実際には複雑な流れの式よりも組み込み関数を使う方が良いです。この場合 zip() 関数が良い仕事をしてくれるでしょう:
>>>
>>> list(zip(*matrix))
[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]
この行にあるアスタリスクの詳細については 引数リストのアンパック を参照してください。
5.2. del 文
リストから要素を削除する際、値を指定する代わりにインデックスを指定する方法があります。それが del 文です。これは pop() メソッドと違い、値を返しません。 del 文はリストからスライスを除去したり、リスト全体を削除することもできます(以前はスライスに空のリストを代入して行っていました)。例えば以下のようにします:
>>>
>>> a = [-1, 1, 66.25, 333, 333, 1234.5]
>>> del a[0]
>>> a
[1, 66.25, 333, 333, 1234.5]
>>> del a[2:4]
>>> a
[1, 66.25, 1234.5]
>>> del a[:]
>>> a
[]
del は変数全体の削除にも使えます:
>>>
>>> del a
この文の後で名前 a を参照すると、(別の値を a に代入するまで) エラーになります。 del の別の用途についてはまた後で取り上げます。
5.3. タプルとシーケンス
リストや文字列には、インデクスやスライスを使った演算のように、数多くの共通の性質があることを見てきました。これらは シーケンス (sequence) データ型 (シーケンス型 --- list, tuple, range を参照) の二つの例です。 Python はまだ進歩の過程にある言語なので、他のシーケンスデータ型が追加されるかもしれません。標準のシーケンス型はもう一つあります: タプル (tuple) 型です。
タプルはコンマで区切られたいくつかの値からなります。例えば以下のように書きます:
>>>
>>> t = 12345, 54321, 'hello!'
>>> t[0]
12345
>>> t
(12345, 54321, 'hello!')
>>> # Tuples may be nested:
... u = t, (1, 2, 3, 4, 5)
>>> u
((12345, 54321, 'hello!'), (1, 2, 3, 4, 5))
>>> # Tuples are immutable:
... t[0] = 88888
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: 'tuple' object does not support item assignment
>>> # but they can contain mutable objects:
... v = ([1, 2, 3], [3, 2, 1])
>>> v
([1, 2, 3], [3, 2, 1])
ご覧のとおり、タプルの表示には常に丸括弧がついていて、タプルのネストが正しく解釈されるようになっています。タプルを書くときは必ずしも丸括弧で囲まなくてもいいですが、(タプルが大きな式の一部だった場合は) 丸括弧が必要な場合もあります。タプルの要素を代入することはできません。しかし、タプルにリストのような変更可能型を含めることはできます。
タプルはリストと似ていますが、たいてい異なる場面と異なる目的で利用されます。タプルは 不変 で、複数の型の要素からなることもあり、要素はアンパック(この節の後半に出てきます)操作やインデックス (あるいは namedtuples の場合は属性)でアクセスすることが多いです。一方、リストは 可変 で、要素はたいてい同じ型のオブジェクトであり、たいていイテレートによってアクセスします。
問題は 0 個または 1 個の項目からなるタプルの構築です。これらの操作を行うため、構文には特別な細工がされています。空のタプルは空の丸括弧ペアで構築できます。一つの要素を持つタプルは、値の後ろにコンマを続ける (単一の値を丸括弧で囲むだけでは不十分です) ことで構築できます。美しくはないけれども、効果的です。例えば以下のようにします:
>>>
>>> empty = ()
>>> singleton = 'hello',    # <-- note trailing comma
>>> len(empty)
0
>>> len(singleton)
1
>>> singleton
('hello',)
文 t = 12345, 54321, 'hello!' は タプルのパック (tuple packing) の例です。値 12345, 54321, 'hello!' が一つのタプルにパックされます。逆の演算も可能です:
>>>
>>> x, y, z = t
この操作は、シーケンスのアンパック (sequence unpacking) とでも呼ぶべきもので、右辺には全てのシーケンス型を使うことができます。シーケンスのアンパックでは、等号の左辺に列挙されている変数が、右辺のシーケンスの長さと同じ数だけあることが要求されます。複数同時の代入が実はタプルのパックとシーケンスのアンパックを組み合わせたものに過ぎないことに注意してください。
5.4. 集合型
Python には、 集合 (set) を扱うためのデータ型もあります。集合とは、重複する要素をもたない、順序づけられていない要素の集まりです。 Set オブジェクトは、和 (union)、積 (intersection)、差 (difference)、対称差 (symmetric difference)といった数学的な演算もサポートしています。
中括弧、または set() 関数は set を生成するために使用することができます。注: 空集合を作成するためには set() を使用しなければなりません ({} ではなく)。後者は空の辞書を作成します。辞書は次のセクションで議論するデータ構造です。
簡単なデモンストレーションを示します:
>>>
>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}
>>> print(basket)                      # show that duplicates have been removed
{'orange', 'banana', 'pear', 'apple'}
>>> 'orange' in basket                 # fast membership testing
True
>>> 'crabgrass' in basket
False
>>> # Demonstrate set operations on unique letters from two words
...
>>> a = set('abracadabra')
>>> b = set('alacazam')
>>> a                                  # unique letters in a
{'a', 'r', 'b', 'c', 'd'}
>>> a - b                              # letters in a but not in b
{'r', 'd', 'b'}
>>> a | b                              # letters in a or b or both
{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}
>>> a & b                              # letters in both a and b
{'a', 'c'}
>>> a ^ b                              # letters in a or b but not both
{'r', 'd', 'b', 'm', 'z', 'l'}
リスト内包 と同様に、 set 内包もサポートされています:
>>>
>>> a = {x for x in 'abracadabra' if x not in 'abc'}
>>> a
{'r', 'd'}
5.5. 辞書型 (dictionary)
もう一つ、有用な型が Python に組み込まれています。それは 辞書 (dictionary) (マッピング型 --- dict を参照)です。辞書は他の言語にも "連想記憶 (associated memory)" や "連想配列 (associative array)" という名前で存在することがあります。ある範囲の数でインデクス化されているシーケンスと異なり、辞書は キー (key) でインデクス化されています。このキーは何らかの変更不能な型になります。文字列、数値は常にキーにすることができます。タプルは、文字列、数値、その他のタプルのみを含む場合はキーにすることができます。直接、あるいは間接的に変更可能なオブジェクトを含むタプルはキーにできません。リストをキーとして使うことはできません。これは、リストにスライスやインデクス指定の代入を行ったり、 append() や extend() のようなメソッドを使うと、インプレースで変更することができるためです。
辞書は キー(key): 値(value) のペアの集合であり、キーが (辞書の中で)一意でなければならない、と考えるとよいでしょう。波括弧 (brace) のペア: {} は空の辞書を生成します。カンマで区切られた key: value のペアを波括弧ペアの間に入れると、辞書の初期値となる key: value が追加されます; この表現方法は出力時に辞書が書き出されるのと同じ方法です。
辞書での主な操作は、ある値を何らかのキーを付けて記憶することと、キーを指定して値を取り出すことです。 del で key: value のペアを削除することもできます。すでに使われているキーを使って値を記憶すると、以前そのキーに関連づけられていた値は忘れ去られてしまいます。存在しないキーを使って値を取り出そうとするとエラーになります。
辞書オブジェクトに対し list(d) を実行すると、辞書で使われている全てのキーからなるリストをキーが挿入された順番で返します (ソートされたリストが欲しい場合は、代わりに sorted(d) を使ってください)。ある単一のキーが辞書にあるかどうか調べるには、 in キーワードを使います。
以下に、辞書を使った簡単な例を示します:
>>>
>>> tel = {'jack': 4098, 'sape': 4139}
>>> tel['guido'] = 4127
>>> tel
{'jack': 4098, 'sape': 4139, 'guido': 4127}
>>> tel['jack']
4098
>>> del tel['sape']
>>> tel['irv'] = 4127
>>> tel
{'jack': 4098, 'guido': 4127, 'irv': 4127}
>>> list(tel)
['jack', 'guido', 'irv']
>>> sorted(tel)
['guido', 'irv', 'jack']
>>> 'guido' in tel
True
>>> 'jack' not in tel
False
dict() コンストラクタは、キーと値のペアのタプルを含むリストから辞書を生成します:
>>>
>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])
{'sape': 4139, 'guido': 4127, 'jack': 4098}
さらに、辞書内包表現を使って、任意のキーと値のペアから辞書を作れます:
>>>
>>> {x: x**2 for x in (2, 4, 6)}
{2: 4, 4: 16, 6: 36}
キーが単純な文字列の場合、キーワード引数を使って定義する方が単純な場合もあります:
>>>
>>> dict(sape=4139, guido=4127, jack=4098)
{'sape': 4139, 'guido': 4127, 'jack': 4098}
5.6. ループのテクニック
辞書に対してループを行う際、 items() メソッドを使うと、キーとそれに対応する値を同時に取り出せます。
>>>
>>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}
>>> for k, v in knights.items():
...     print(k, v)
...
gallahad the pure
robin the brave
シーケンスにわたるループを行う際、 enumerate() 関数を使うと、要素のインデックスと要素を同時に取り出すことができます。
>>>
>>> for i, v in enumerate(['tic', 'tac', 'toe']):
...     print(i, v)
...
0 tic
1 tac
2 toe
二つまたはそれ以上のシーケンス型を同時にループするために、関数 zip() を使って各要素をひと組みにすることができます。
>>>
>>> questions = ['name', 'quest', 'favorite color']
>>> answers = ['lancelot', 'the holy grail', 'blue']
>>> for q, a in zip(questions, answers):
...     print('What is your {0}?  It is {1}.'.format(q, a))
...
シーケンスを逆方向に渡ってループするには、まずシーケンスの範囲を順方向に指定し、次いで関数 reversed() を呼び出します。
>>>
>>> for i in reversed(range(1, 10, 2)):
...     print(i)
...
9
7
5
3
1
シーケンスをソートされた順序でループするには、 sorted() 関数を使います。この関数は元の配列を変更せず、ソート済みの新たな配列を返します。
>>>
>>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']
>>> for i in sorted(basket):
...     print(i)
...
apple
apple
banana
orange
orange
pear
シーケンスに set() を使うと、重複要素が除去されます。 シーケンスに set() を使った上で、 sorted() を使うという組み合わせ方は、順番が整列されているシーケンスで、同一要素に 1 度のみループでアクセスする慣用的な方法です。
>>>
>>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']
>>> for f in sorted(set(basket)):
...     print(f)
...
apple
banana
orange
pear
ときどきループ内でリストを変更したい誘惑に駆られるでしょうが、代わりに新しいリストを作ってしまうほうがより簡単で安全なことが、ままあります
>>>
>>> import math
>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]
>>> filtered_data = []
>>> for value in raw_data:
...     if not math.isnan(value):
...         filtered_data.append(value)
...
>>> filtered_data
[56.2, 51.7, 55.3, 52.5, 47.8]
5.7. 条件についてもう少し
while や if 文で使った条件 (condition) には、値の比較だけでなく、他の演算子も使うことができます。
比較演算子 in および not in は、ある値があるシーケンス中に存在するか (または存在しないか) どうかを調べます。演算子 is および is not は、二つのオブジェクトが実際に同じオブジェクトであるかどうかを調べます。この比較は、リストのような変更可能なオブジェクトにだけ意味があります。全ての比較演算子は同じ優先順位を持っており、ともに数値演算子よりも低い優先順位となります。(訳注: is は、 is None のように、シングルトンの変更不能オブジェクトとの比較に用いる場合もあります。(「変更可能なオブジェクトにだけ意味があります」の部分を削除することを Doc-SIG に提案中。))
比較は連結させることができます。例えば、 a < b == c は、 a が b より小さく、かつ b と c が等しいかどうかをテストします。
ブール演算子 and や or で比較演算を組み合わせることができます。そして、比較演算 (あるいは何らかのブール式) の結果の否定は not でとれます。これらの演算子は全て、比較演算子よりも低い優先順位になっています。 A and not B or C と (A and (not B)) or C が等価になるように、ブール演算子の中で、 not の優先順位が最も高く、 or が最も低くなっています。もちろん、丸括弧を使えば望みの組み合わせを表現できます。
ブール演算子 and と or は、いわゆる 短絡 (short-circuit) 演算子です。これらの演算子の引数は左から右へと順に評価され、結果が確定した時点で評価を止めます。例えば、 A と C は真で B が偽のとき、 A and B and C は式 C を評価しません。一般に、短絡演算子の戻り値をブール値ではなくて一般的な値として用いると、値は最後に評価された引数になります。
比較や他のブール式の結果を変数に代入することもできます。例えば、
>>>
>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'
>>> non_null = string1 or string2 or string3
>>> non_null
'Trondheim'
Pythonでは、Cとは異なり、式の中での代入は セイウチ演算子 := を使用して明示的に行う必要があることに注意してください。これにより、 == が意図されていたところに = を入力してしまうという、Cプログラムで発生する一般的なクラスの問題を回避できます。
5.8. シーケンスとその他の型の比較
概して、シーケンスオブジェクトは、同じシーケンス型の他のオブジェクトと比較できます。比較には 辞書的な (lexicographical) 順序が用いられます。まず、最初の二つの要素を比較し、その値が等しくなければその時点で比較結果が決まります。等しければ次の二つの要素を比較し、以降シーケンスの要素が尽きるまで続けます。比較しようとする二つの要素がいずれも同じシーケンス型であれば、そのシーケンス間での辞書比較を再帰的に行います。二つのシーケンスの全ての要素の比較結果が等しくなれば、シーケンスは等しいとみなされます。片方のシーケンスがもう一方の先頭部分にあたる部分シーケンスならば、短い方のシーケンスが小さいシーケンスとみなされます。文字列に対する辞書的な順序づけには、個々の文字ごとに ASCII 順序を用います。以下に、同じ型のオブジェクトを持つシーケンス間での比較を行った例を示します:
(1, 2, 3)              < (1, 2, 4)
[1, 2, 3]              < [1, 2, 4]
'ABC' < 'C' < 'Pascal' < 'Python'
(1, 2, 3, 4)           < (1, 2, 4)
(1, 2)                 < (1, 2, -1)
(1, 2, 3)             == (1.0, 2.0, 3.0)
(1, 2, ('aa', 'ab'))   < (1, 2, ('abc', 'a'), 4)
違う型のオブジェクト同士を < や > で比較することも、それらのオブジェクトが適切な比較メソッドを提供しているのであれば許可されます。例えば、異なる数値型同士の比較では、その数値によって比較が行われます。例えば、 0 と 0.0 は等価です。一方、適切な比較順序がない場合は、インタープリターは TypeError 例外を発生させます。
6. モジュール
Python インタプリタを終了させ、再び起動すると、これまでに行ってきた定義 (関数や変数) は失われています。ですから、より長いプログラムを書きたいなら、テキストエディタを使ってインタプリタへの入力を用意しておき、手作業の代わりにファイルを入力に使って動作させるとよいでしょう。この作業を スクリプト (script) の作成と言います。プログラムが長くなるにつれ、メンテナンスを楽にするために、スクリプトをいくつかのファイルに分割したくなるかもしれません。また、いくつかのプログラムで書いてきた便利な関数について、その定義をコピーすることなく個々のプログラムで使いたいと思うかもしれません。
こういった要求をサポートするために、Python では定義をファイルに書いておき、スクリプトの中やインタプリタの対話インスタンス上で使う方法があります。このファイルを モジュール (module) と呼びます。モジュールにある定義は、他のモジュールや main モジュール (実行のトップレベルや電卓モードでアクセスできる変数の集まりを指します) に import (取り込み) することができます。
モジュールは Python の定義や文が入ったファイルです。ファイル名はモジュール名に接尾語 .py がついたものになります。モジュールの中では、(文字列の) モジュール名をグローバル変数 __name__ で取得できます。例えば、お気に入りのテキストエディタを使って、現在のディレクトリに以下の内容のファイル fibo.py を作成してみましょう:
# Fibonacci numbers module
def fib(n):    # write Fibonacci series up to n
    a, b = 0, 1
    while a < n:
        print(a, end=' ')
        a, b = b, a+b
    print()
def fib2(n):   # return Fibonacci series up to n
    result = []
    a, b = 0, 1
    while a < n:
        result.append(a)
        a, b = b, a+b
    return result
次に Python インタプリタに入り、モジュールを以下のコマンドで import しましょう:
>>>
>>> import fibo
この操作では、fibo で定義された関数の名前を直接現在のシンボルテーブルに入力することはありません。単にモジュール名 fibo だけをシンボルテーブルに入れます。関数にはモジュール名を使ってアクセスします:
>>>
>>> fibo.fib(1000)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987
>>> fibo.fib2(100)
[0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]
>>> fibo.__name__
'fibo'
関数を度々使うのなら、ローカルな名前に代入できます:
>>>
>>> fib = fibo.fib
>>> fib(500)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377
6.1. モジュールについてもうすこし
モジュールには、関数定義に加えて実行文を入れることができます。これらの実行文はモジュールを初期化するためのものです。これらの実行文は、インポート文の中で 最初に モジュール名が見つかったときにだけ実行されます。1 (ファイルがスクリプトとして実行される場合も実行されます。)
各々のモジュールは、自分のプライベートなシンボルテーブルを持っていて、モジュールで定義されている関数はこのテーブルをグローバルなシンボルテーブルとして使います。したがって、モジュールの作者は、ユーザのグローバル変数と偶然的な衝突が起こる心配をせずに、グローバルな変数をモジュールで使うことができます。一方、自分が行っている操作をきちんと理解していれば、モジュール内の関数を参照するのと同じ表記法 modname.itemname で、モジュールのグローバル変数をいじることもできます。
モジュールが他のモジュールを import することもできます。 import 文は全てモジュールの(さらに言えばスクリプトでも)先頭に置きますが、これは慣習であって必須ではありません。 import されたモジュール名は import を行っているモジュールのグローバルなシンボルテーブルに置かれます。
import 文には、あるモジュール内の名前を、import を実行しているモジュールのシンボルテーブル内に直接取り込むという変型があります。例えば:
>>>
>>> from fibo import fib, fib2
>>> fib(500)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377
この操作は、import の対象となるモジュール名をローカルなシンボルテーブル内に取り入れることはありません (従って上の例では、 fibo は定義されません)。
モジュールで定義されている名前を全て import するという変型もあります:
>>>
>>> from fibo import *
>>> fib(500)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377
この書き方ではアンダースコア (_) で始まるものを除いてすべての名前をインポートします。殆どの場面で、Python プログラマーはこの書き方を使いません。未知の名前がインタープリターに読み込まれ、定義済みの名前を上書きしてしまう可能性があるからです。
一般的には、モジュールやパッケージから * を import するというやり方には賛同できません。というのは、この操作を行うとしばしば可読性に乏しいコードになるからです。しかし、対話セッションでキータイプの量を減らすために使うのは構わないでしょう。
モジュール名の後に as が続いていた場合は、 as の後ろの名前を直接、インポートされたモジュールが束縛します。
>>>
>>> import fibo as fib
>>> fib.fib(500)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377
これは実質的には import fibo と同じ方法でモジュールをインポートしていて、唯一の違いはインポートしたモジュールが fib という名前で取り扱えるようになっていることです。
このインポート方法は from が付いていても使え、同じ効果が得られます:
>>>
>>> from fibo import fib as fibonacci
>>> fibonacci(500)
0 1 1 2 3 5 8 13 21 34 55 89 144 233 377
注釈 実行効率上の理由で、各モジュールはインタープリタの 1 セッションごとに 1 回だけ import されます。従って、モジュールを修正した場合には、インタープリタを再起動させなければなりません -- もしくは、その場で手直ししてテストしたいモジュールが 1 つだった場合には、例えば import importlib; importlib.reload(modulename) のように importlib.reload() を使ってください。
6.1.1. モジュールをスクリプトとして実行する
Python モジュールを
python fibo.py <arguments>
と実行すると、__name__ に __main__ が設定されている点を除いて import したときと同じようにモジュール内のコードが実行されます。つまりモジュールの末尾に:
if __name__ == "__main__":
    import sys
    fib(int(sys.argv[1]))
このコードを追加することで、このファイルが import できるモジュールであると同時にスクリプトとしても使えるようになります。なぜならモジュールが "main" ファイルとして起動されたときだけ、コマンドラインを解釈するコードが実行されるからです:
$ python fibo.py 50
0 1 1 2 3 5 8 13 21 34
モジュールが import された場合は、そのコードは実行されません:
>>>
>>> import fibo
>>>
この方法はモジュールに便利なユーザインターフェースを提供したり、テストのために (スクリプトをモジュールとして起動しテストスイートを実行して) 使われます。
6.1.2. モジュール検索パス
spam という名前のモジュールをインポートするとき、インタープリターはまずその名前のビルトインモジュールを探します。見つからなかった場合は、 spam.py という名前のファイルを sys.path にあるディレクトリのリストから探します。 sys.path は以下の場所に初期化されます:
入力されたスクリプトのあるディレクトリ (あるいはファイルが指定されなかったときはカレントディレクトリ)。
PYTHONPATH (ディレクトリ名のリスト。シェル変数の PATH と同じ構文)。
インストールごとのデフォルト。
注釈 シンボリックリンクをサポートするファイルシステム上では、入力されたスクリプトのあるディレクトリはシンボリックリンクをたどった後に計算されます。言い換えるとシンボリックリンクを含むディレクトリはモジュール検索パスに追加 されません。
初期化された後、 Python プログラムは sys.path を修正することができます。スクリプトファイルを含むディレクトリが検索パスの先頭、標準ライブラリパスよりも前に追加されます。なので、ライブラリのディレクトリにあるファイルよりも、そのディレクトリにある同じ名前のスクリプトが優先してインポートされます。これは、標準ライブラリを意図して置き換えているのでない限りは間違いのもとです。より詳しい情報は 標準モジュール を参照してください。
6.1.3. "コンパイル" された Python ファイル
モジュールの読み込みを高速化するため、Python はコンパイル済みの各モジュールを __pycache__ ディレクトリの module.version.pyc ファイルとしてキャッシュします。ここで version はコンパイルされたファイルのフォーマットを表すもので、一般的には Python のバージョン番号です。例えば、CPython のリリース 3.3 の、コンパイル済みの spam.py は __pycache__/spam.cpython-33.pyc としてキャッシュされるでしょう。この命名の慣習により、Python の異なる複数のリリースやバージョンのコンパイル済みモジュールが共存できます。
Python はソースの変更日時をコンパイル済みのものと比較し、コンパイル済みのものが最新でなくなり再コンパイルが必要になっていないかを確認します。これは完全に自動で処理されます。また、コンパイル済みモジュールはプラットフォーム非依存なため、アーキテクチャの異なるシステム間で同一のライブラリを共有することもできます。
Python は2つの場合にキャッシュのチェックを行いません。ひとつは、コマンドラインから直接モジュールが読み込まれた場合で、常に再コンパイルされ、結果を保存することはありません。2つめは、ソース・モジュールのない場合で、キャッシュの確認を行いません。ソースのない (コンパイル済みのもののみの) 配布をサポートするには、コンパイル済みモジュールはソース・ディレクトリになくてはならず、ソース・ディレクトリにソース・モジュールがあってはいけません。
エキスパート向けのTips:
コンパイル済みモジュールのサイズを小さくするために、Python コマンドに -O または -OO スイッチを使うことができます。-O スイッチは assert ステートメントを除去し、-OO スイッチは assert ステートメントと __doc__ 文字列を除去します。いくつかのプログラムはこれらの除去されるものに依存している可能性があるため、自分が何をしているかを理解しているときに限ってこれらのオプションを使うべきです。"最適化" されたモジュールは opt- タグを持ち、通常のコンパイル済みモジュールよりサイズが小さくなります。将来のリリースでは最適化の影響が変わる可能性があります。
.pyc ファイルや .pyo ファイルから読み出されたとしても、プログラムは .py ファイルから読み出されたときより何ら高速に動作するわけではありません。.pyc ファイルで高速化されるのは、読み込みにかかる時間だけです。
compileall モジュールを使ってディレクトリ内の全てのモジュールに対して .pyc ファイルを作ることができます。
この処理に関する詳細は、判定のフローチャートを含めて、PEP 3147 に記載されています。
6.2. 標準モジュール
Python は標準モジュールライブラリを同梱していて、別の Python ライブラリリファレンスというドキュメントで解説しています。幾つかのモジュールは言語のコアにはアクセスしないものの、効率や、システムコールなどOSの機能を利用するために、インタープリター内部にビルトインされています。そういったモジュールセットはまたプラットフォームに依存した構成オプションです。例えば、 winreg モジュールは Windows システムでのみ提供されています。 1つ注目に値するモジュールとして、 sys モジュールは、全ての Python インタープリターにビルトインされています。 sys.ps1 と sys.ps2 という変数は一次プロンプトと二次プロンプトに表示する文字列を定義しています:
>>>
>>> import sys
>>> sys.ps1
'>>> '
>>> sys.ps2
'... '
>>> sys.ps1 = 'C> '
C> print('Yuck!')
Yuck!
C>
これらの二つの変数は、インタプリタが対話モードにあるときだけ定義されています。
変数 sys.path は文字列からなるリストで、インタプリタがモジュールを検索するときのパスを決定します。 sys.path は環境変数 PYTHONPATH から得たデフォルトパスに、 PYTHONPATH が設定されていなければ組み込みのデフォルト値に設定されます。標準的なリスト操作で変更することができます:
>>>
>>> import sys
>>> sys.path.append('/ufs/guido/lib/python')
6.3. dir() 関数
組込み関数 dir() は、あるモジュールがどんな名前を定義しているか調べるために使われます。 dir() はソートされた文字列のリストを返します:
>>>
>>> import fibo, sys
>>> dir(fibo)
['__name__', 'fib', 'fib2']
>>> dir(sys)  
['__breakpointhook__', '__displayhook__', '__doc__', '__excepthook__',
 '__interactivehook__', '__loader__', '__name__', '__package__', '__spec__',
 '__stderr__', '__stdin__', '__stdout__', '__unraisablehook__',
 '_clear_type_cache', '_current_frames', '_debugmallocstats', '_framework',
 '_getframe', '_git', '_home', '_xoptions', 'abiflags', 'addaudithook',
 'api_version', 'argv', 'audit', 'base_exec_prefix', 'base_prefix',
 'breakpointhook', 'builtin_module_names', 'byteorder', 'call_tracing',
 'callstats', 'copyright', 'displayhook', 'dont_write_bytecode', 'exc_info',
 'excepthook', 'exec_prefix', 'executable', 'exit', 'flags', 'float_info',
 'float_repr_style', 'get_asyncgen_hooks', 'get_coroutine_origin_tracking_depth',
 'getallocatedblocks', 'getdefaultencoding', 'getdlopenflags',
 'getfilesystemencodeerrors', 'getfilesystemencoding', 'getprofile',
 'getrecursionlimit', 'getrefcount', 'getsizeof', 'getswitchinterval',
 'gettrace', 'hash_info', 'hexversion', 'implementation', 'int_info',
 'intern', 'is_finalizing', 'last_traceback', 'last_type', 'last_value',
 'maxsize', 'maxunicode', 'meta_path', 'modules', 'path', 'path_hooks',
 'path_importer_cache', 'platform', 'prefix', 'ps1', 'ps2', 'pycache_prefix',
 'set_asyncgen_hooks', 'set_coroutine_origin_tracking_depth', 'setdlopenflags',
 'setprofile', 'setrecursionlimit', 'setswitchinterval', 'settrace', 'stderr',
 'stdin', 'stdout', 'thread_info', 'unraisablehook', 'version', 'version_info',
 'warnoptions']
引数がなければ、 dir() は現在定義している名前を列挙します:
>>>
>>> a = [1, 2, 3, 4, 5]
>>> import fibo
>>> fib = fibo.fib
>>> dir()
['__builtins__', '__name__', 'a', 'fib', 'fibo', 'sys']
変数、モジュール、関数、その他の、すべての種類の名前をリストすることに注意してください。
dir() は、組込みの関数や変数の名前はリストしません。これらの名前からなるリストが必要なら、標準モジュール builtins で定義されています:
>>>
>>> import builtins
>>> dir(builtins)  
['ArithmeticError', 'AssertionError', 'AttributeError', 'BaseException',
 'BlockingIOError', 'BrokenPipeError', 'BufferError', 'BytesWarning',
 'ChildProcessError', 'ConnectionAbortedError', 'ConnectionError',
 'ConnectionRefusedError', 'ConnectionResetError', 'DeprecationWarning',
 'EOFError', 'Ellipsis', 'EnvironmentError', 'Exception', 'False',
 'FileExistsError', 'FileNotFoundError', 'FloatingPointError',
 'FutureWarning', 'GeneratorExit', 'IOError', 'ImportError',
 'ImportWarning', 'IndentationError', 'IndexError', 'InterruptedError',
 'IsADirectoryError', 'KeyError', 'KeyboardInterrupt', 'LookupError',
 'MemoryError', 'NameError', 'None', 'NotADirectoryError', 'NotImplemented',
 'NotImplementedError', 'OSError', 'OverflowError',
 'PendingDeprecationWarning', 'PermissionError', 'ProcessLookupError',
 'ReferenceError', 'ResourceWarning', 'RuntimeError', 'RuntimeWarning',
 'StopIteration', 'SyntaxError', 'SyntaxWarning', 'SystemError',
 'SystemExit', 'TabError', 'TimeoutError', 'True', 'TypeError',
 'UnboundLocalError', 'UnicodeDecodeError', 'UnicodeEncodeError',
 'UnicodeError', 'UnicodeTranslateError', 'UnicodeWarning', 'UserWarning',
 'ValueError', 'Warning', 'ZeroDivisionError', '_', '__build_class__',
 '__debug__', '__doc__', '__import__', '__name__', '__package__', 'abs',
 'all', 'any', 'ascii', 'bin', 'bool', 'bytearray', 'bytes', 'callable',
 'chr', 'classmethod', 'compile', 'complex', 'copyright', 'credits',
 'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec', 'exit',
 'filter', 'float', 'format', 'frozenset', 'getattr', 'globals', 'hasattr',
 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance', 'issubclass',
 'iter', 'len', 'license', 'list', 'locals', 'map', 'max', 'memoryview',
 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow', 'print', 'property',
 'quit', 'range', 'repr', 'reversed', 'round', 'set', 'setattr', 'slice',
 'sorted', 'staticmethod', 'str', 'sum', 'super', 'tuple', 'type', 'vars',
 'zip']
6.4. パッケージ
パッケージ (package) は、Python のモジュール名前空間を "ドット付きモジュール名" を使って構造化する手段です。例えば、モジュール名 A.B は、 A というパッケージのサブモジュール B を表します。ちょうど、モジュールを利用すると、別々のモジュールの著者が互いのグローバル変数名について心配しなくても済むようになるのと同じように、ドット付きモジュール名を利用すると、 NumPy や Pillow のように複数モジュールからなるパッケージの著者が、互いのモジュール名について心配しなくても済むようになります。
音声ファイルや音声データを一様に扱うためのモジュールのコレクション ("パッケージ") を設計したいと仮定しましょう。 音声ファイルには多くの異なった形式がある (通常は拡張子、 例えば .wav, .aiff, .au などで認識されます) ので、増え続ける様々なファイル形式を相互変換するモジュールを、 作成したりメンテナンスしたりする必要があるかもしれません。 また、 音声データに対して実行したい様々な独自の操作 (ミキシング、 エコーの追加、 イコライザ関数の適用、 人工的なステレオ効果の作成など) があるかもしれません。 そうなると、 こうした操作を実行するモジュールを果てしなく書くことになるでしょう。 以下に (階層的なファイルシステムで表現した) パッケージの構造案を示します:
sound/                          Top-level package
      __init__.py               Initialize the sound package
      formats/                  Subpackage for file format conversions
              __init__.py
              wavread.py
              wavwrite.py
              aiffread.py
              aiffwrite.py
              auread.py
              auwrite.py
              ...
      effects/                  Subpackage for sound effects
              __init__.py
              echo.py
              surround.py
              reverse.py
              ...
      filters/                  Subpackage for filters
              __init__.py
              equalizer.py
              vocoder.py
              karaoke.py
              ...
パッケージを import する際、 Python は sys.path 上のディレクトリを検索して、トップレベルのパッケージの入ったサブディレクトリを探します。
ファイルを含むディレクトリをパッケージとしてPython に扱わせるには、ファイル __init__.py が必要です。 これにより、 string のようなよくある名前のディレクトリにより、モジュール検索パスの後の方で見つかる正しいモジュールが意図せず隠蔽されてしまうのを防ぐためです。 最も簡単なケースでは __init__.py はただの空ファイルで構いませんが、 __init__.py ではパッケージのための初期化コードを実行したり、後述の __all__ 変数を設定してもかまいません。
パッケージのユーザは、個々のモジュールをパッケージから import することができます。例えば:
import sound.effects.echo
この操作はサブモジュール sound.effects.echo をロードします。このモジュールは、以下のように完全な名前で参照しなければなりません。
sound.effects.echo.echofilter(input, output, delay=0.7, atten=4)
サブモジュールを import するもう一つの方法を示します:
from sound.effects import echo
これもサブモジュール echo をロードし、 echo をパッケージ名を表す接頭辞なしで利用できるようにします。従って以下のように用いることができます:
echo.echofilter(input, output, delay=0.7, atten=4)
さらにもう一つのバリエーションとして、必要な関数や変数を直接 import する方法があります:
from sound.effects.echo import echofilter
この操作も同様にサブモジュール echo をロードしますが、 echofilter() を直接利用できるようにします:
echofilter(input, output, delay=0.7, atten=4)
from package import item を使う場合、 item はパッケージ package のサブモジュール (またはサブパッケージ) でもかまいませんし、関数やクラス、変数のような、 package で定義されている別の名前でもかまわないことに注意してください。 import 文はまず、 item がパッケージ内で定義されているかどうか調べます。定義されていなければ、 item はモジュール名であると仮定して、モジュールをロードしようと試みます。もしモジュールが見つからなければ、 ImportError が送出されます。
反対に、 import item.subitem.subsubitem のような構文を使った場合、最後の subsubitem を除く各要素はパッケージでなければなりません。最後の要素はモジュールかパッケージにできますが、一つ前の要素で定義されているクラスや関数や変数にはできません。
6.4.1. パッケージから * を import する
それでは、ユーザが from sound.effects import * と書いたら、どうなるのでしょうか？理想的には、何らかの方法でファイルシステムが調べられ、そのパッケージにどんなサブモジュールがあるかを調べ上げ、全てを import する、という処理を望むことでしょう。これには長い時間がかかってしまうこともありますし、あるサブモジュールを import することで、そのモジュールが明示的に import されたときのみ発生して欲しい副作用が起きてしまうかもしれません。
唯一の解決策は、パッケージの作者にパッケージの索引を明示的に提供させる というものです。 import 文の使う規約は、パッケージの __init__.py コードに __all__ という名前のリストが定義されていれば、 from package import * が現れたときに import すべきモジュール名のリストとして使う、というものです。 パッケージの新バージョンがリリースされるときにリストを最新の状態に更新するのは パッケージの作者の責任となります。 自分のパッケージから * を import するという使い方が考えられないならば、 パッケージの作者はこの使い方をサポートしないことにしてもかまいません。 例えば、ファイル sound/effects/__init__.py には、次のような コードを入れてもよいかもしれません:
__all__ = ["echo", "surround", "reverse"]
この例では、 from sound.effects import * とすると、 sound パッケージから指定された 3つのサブモジュールが import されることになっている、ということを意味します。
もしも __all__ が定義されていなければ、実行文 from sound.effects import * は、パッケージ sound.effects の全てのサブモジュールを現在の名前空間の中へ import しません 。この文は単に(場合によっては初期化コード __init__.py を実行して) パッケージ sound.effects が import されたということを確認し、そのパッケージで定義されている名前を全て import するだけです。 import される名前には、 __init__.py で定義された名前 (と、明示的にロードされたサブモジュール) が含まれます。パッケージのサブモジュールで、以前の import 文で明示的にロードされたものも含みます。以下のコードを考えてください:
import sound.effects.echo
import sound.effects.surround
from sound.effects import *
上の例では、 echo と surround モジュールが現在の名前空間に import されます。これらのモジュールは from...import 文が実行された際に sound.effects 内で定義されているからです。 (この機構は __all__ が定義されているときにも働きます。)
特定のモジュールでは import * を使ったときに、特定のパターンに従った名前のみを公開 (export) するように設計されてはいますが、それでもやはり製品のコードでは良いことではないと考えます。
from package import specific_submodule を使っても何も問題はないことに留意してください！実際この表記法は、import を行うモジュールが他のパッケージと同じ名前を持つサブモジュールを使わなければならない場合を除いて推奨される方式です。
6.4.2. パッケージ内参照
パッケージが (前述の例の sound パッケージのように) サブパッケージの集まりに構造化されている場合、絶対 import を使って兄弟関係にあるパッケージを参照できます。例えば、モジュール sound.filters.vocoder で sound.effects パッケージの echo モジュールを使いたいとすると、 from sound.effects import echo を使うことができます。
また、明示的な相対importを from module import name の形式の import 文で利用できます。この明示的な相対 import では、先頭のドットで現在および親パッケージを指定します。 surround モジュールの例では、以下のように記述できます:
from . import echo
from .. import formats
from ..filters import equalizer
相対 import は現在のモジュール名をベースにすることに注意してください。メインモジュールの名前は常に "__main__" なので、Python アプリケーションのメインモジュールとして利用されることを意図しているモジュールでは絶対 import を利用するべきです。
6.4.3. 複数ディレクトリ中のパッケージ
パッケージはもう一つ特別な属性として __path__ をサポートしています。この属性は、パッケージの __init__.py 中のコードが実行されるよりも前に、 __init__.py の収められているディレクトリ名の入ったリストになるよう初期化されます。この変数は変更することができます。変更を加えると、以降そのパッケージに入っているモジュールやサブパッケージの検索に影響します。
この機能はほとんど必要にはならないのですが、パッケージ内存在するモジュール群を拡張するために使うことができます。
7. 入力と出力
プログラムの出力方法にはいくつかの種類があります。 データを人間が読める形で出力することもあれば、将来使うためにファイルに書くこともあります。 この章では、こうした幾つかの出力の方法について話します。
7.1. 出力を見やすくフォーマットする
これまでに、値を出力する二つの方法: 式文 (expression statement) と print() 関数が出てきました。 (第三はファイルオブジェクトの write() メソッドを使う方法です。標準出力を表すファイルは sys.stdout で参照できます。詳細はライブラリリファレンスを参照してください。)
単に空白区切りで値を並べただけの出力よりも、フォーマットを制御したいと思うことはよくあることでしょう。 出力をフォーマットする方法はいくつかあります。
フォーマット済み文字列リテラル を使うには、開き引用符や三重の開き引用符の前に f あるいは F を付けて文字列を始めます。 この文字列の内側では、文字 { と文字 } の間に Python の式が書け、その式から変数やリテラル値が参照できます。
>>>
>>> year = 2016
>>> event = 'Referendum'
>>> f'Results of the {year} {event}'
'Results of the 2016 Referendum'
文字列の str.format() メソッドは、もう少し手間がかかります。 ここでも { と } を使って変数に代入する場所の印を付けて、細かいフォーマットの指示を出せますが、フォーマットされる対象の情報を与える必要があります。
>>>
>>> yes_votes = 42_572_654
>>> no_votes = 43_132_495
>>> percentage = yes_votes / (yes_votes + no_votes)
>>> '{:-9} YES votes  {:2.2%}'.format(yes_votes, percentage)
' 42572654 YES votes  49.67%'
最後に、文字列のスライス操作や結合操作を使い、全ての文字列を自分で処理し、思い通りのレイアウトを作成できます。 文字列型には、文字列の間隔を調整して指定されたカラム幅に揃えるのに便利な操作を行うメソッドがいくつかあります。
凝った出力である必要は無いけれど、デバッグ目的で変数をすばやく表示したいときは、 repr() 関数か str() 関数でどんな値も文字列に変換できます。
str() 関数は値の人間に読める表現を返すためのもので、 repr() 関数はインタープリタに読める (あるいは同値となる構文がない場合は必ず SyntaxError になるような) 表現を返すためのものです。人間が読むのに適した特定の表現を持たないオブジェクトにおいては、 str() は repr() と同じ値を返します。数値や、リストや辞書を始めとするデータ構造など、多くの値がどちらの関数に対しても同じ表現を返します。一方、文字列は、2つの異なる表現を持っています。
例:
>>>
>>> s = 'Hello, world.'
>>> str(s)
'Hello, world.'
>>> repr(s)
"'Hello, world.'"
>>> str(1/7)
'0.14285714285714285'
>>> x = 10 * 3.25
>>> y = 200 * 200
>>> s = 'The value of x is ' + repr(x) + ', and y is ' + repr(y) + '...'
>>> print(s)
>>> # The repr() of a string adds string quotes and backslashes:
... hello = 'hello, world\n'
>>> hellos = repr(hello)
>>> print(hellos)
'hello, world\n'
>>> # The argument to repr() may be any Python object:
... repr((x, y, ('spam', 'eggs')))
"(32.5, 40000, ('spam', 'eggs'))"
string モジュールの Template クラスも、文字列中の値を置換する別の方法を提供しています。 $x のようなプレースホルダーを使い、その箇所と辞書にある値を置き換えますが、使えるフォーマット方式はとても少ないです。
7.1.1. フォーマット済み文字列リテラル
フォーマット済み文字リテラル (短くして f-string とも呼びます) では、文字列の頭に f か F を付け、式を {expression} と書くことで、 Python の式の値を文字列の中に入れ込めます。
オプションのフォーマット指定子を式の後ろに付けられます。 このフォーマット指定子によって値のフォーマット方式を制御できます。 次の例では、円周率πを小数点以下3桁に丸めてフォーマットしています:
>>>
>>> import math
>>> print(f'The value of pi is approximately {math.pi:.3f}.')
':' の後ろに整数をつけると、そのフィールドの最小の文字幅を指定できます。 この機能は縦を揃えるのに便利です。
>>>
>>> table = {'Sjoerd': 4127, 'Jack': 4098, 'Dcab': 7678}
>>> for name, phone in table.items():
...     print(f'{name:10} ==> {phone:10d}')
...
Sjoerd     ==>       4127
Jack       ==>       4098
Dcab       ==>       7678
他の修飾子は、フォーマットする前に値を変換するのに使えます。 '!a' は ascii() を、 '!s' は str() を、 '!r' は repr() を適用します:
>>>
>>> animals = 'eels'
>>> print(f'My hovercraft is full of {animals}.')
>>> print(f'My hovercraft is full of {animals!r}.')
これらのフォーマット仕様の参考資料として、 書式指定ミニ言語仕様 のガイドを参照してください。
7.1.2. 文字列の format() メソッド
str.format() メソッドの基本的な使い方は次のようなものです:
>>>
>>> print('We are the {} who say "{}!"'.format('knights', 'Ni'))
We are the knights who say "Ni!"
括弧とその中の文字(これをフォーマットフィールドと呼びます)は、 str.format() メソッドに渡されたオブジェクトに置換されます。括弧の中の数字は str.format() メソッドに渡されたオブジェクトの位置を表すのに使えます。
>>>
>>> print('{0} and {1}'.format('spam', 'eggs'))
spam and eggs
>>> print('{1} and {0}'.format('spam', 'eggs'))
eggs and spam
str.format() メソッドにキーワード引数が渡された場合、その値はキーワード引数の名前によって参照されます。
>>>
>>> print('This {food} is {adjective}.'.format(
...       food='spam', adjective='absolutely horrible'))
順序引数とキーワード引数を組み合わせて使うこともできます:
>>>
>>> print('The story of {0}, {1}, and {other}.'.format('Bill', 'Manfred',
                                                       other='Georg'))
もしも長い書式文字列があり、それを分割したくない場合には、変数を引数の位置ではなく変数の名前で参照できるとよいでしょう。これは、辞書を引数に渡して、角括弧 '[]' を使って辞書のキーを参照することで可能です。
>>>
>>> table = {'Sjoerd': 4127, 'Jack': 4098, 'Dcab': 8637678}
>>> print('Jack: {0[Jack]:d}; Sjoerd: {0[Sjoerd]:d}; '
...       'Dcab: {0[Dcab]:d}'.format(table))
Jack: 4098; Sjoerd: 4127; Dcab: 8637678
table を '**' 記法を使ってキーワード引数として渡す方法もあります。
>>>
>>> table = {'Sjoerd': 4127, 'Jack': 4098, 'Dcab': 8637678}
>>> print('Jack: {Jack:d}; Sjoerd: {Sjoerd:d}; Dcab: {Dcab:d}'.format(**table))
Jack: 4098; Sjoerd: 4127; Dcab: 8637678
全てのローカルな変数が入った辞書を返す組み込み関数 vars() と組み合わせると特に便利です。
例として、下のコード行は与えられた整数とその 2 乗と 3 乗がきちんと揃った列を生成します:
>>>
>>> for x in range(1, 11):
...     print('{0:2d} {1:3d} {2:4d}'.format(x, x*x, x*x*x))
...
 1   1    1
 2   4    8
 3   9   27
 4  16   64
 5  25  125
 6  36  216
 7  49  343
 8  64  512
 9  81  729
10 100 1000
str.format() による文字列書式設定の完全な解説は、 書式指定文字列の文法 を参照してください。
7.1.3. 文字列の手作業でのフォーマット
次は 2 乗と 3 乗の値からなる同じ表を手作業でフォーマットしたものです:
>>>
>>> for x in range(1, 11):
...     print(repr(x).rjust(2), repr(x*x).rjust(3), end=' ')
...     # Note use of 'end' on previous line
...     print(repr(x*x*x).rjust(4))
...
 1   1    1
 2   4    8
 3   9   27
 4  16   64
 5  25  125
 6  36  216
 7  49  343
 8  64  512
 9  81  729
10 100 1000
(各カラムの間のスペース一個分は print() の動作で追加されていることに注意してください。 print() は常に引数間に空白を追加します。)
文字列オブジェクトの str.rjust() メソッドは、指定された幅のフィールド内に文字列が右寄せで入るように左側に空白を追加します。 同様のメソッドとして、 str.ljust() と str.center() があります。 これらのメソッドは何か出力を行うわけではなく、ただ新しい文字列を返します。 入力文字列が長すぎる場合、文字列を切り詰めることはせず、値をそのまま返します。この仕様のためにカラムのレイアウトが滅茶苦茶になるかもしれませんが、嘘の値が代わりに書き出されるよりはましです。 (本当に切り詰めを行いたいのなら、全てのカラムに x.ljust(n)[:n] のようにスライス表記を加えることもできます。)
もう一つのメソッド、 str.zfill() は、数値文字列の左側をゼロ詰めします。このメソッドは正と負の符号を正しく扱います:
>>>
>>> '12'.zfill(5)
'00012'
>>> '-3.14'.zfill(7)
'-003.14'
>>> '3.14159265359'.zfill(5)
'3.14159265359'
7.1.4. 古い文字列書式設定方法
% 演算子 (剰余) は文字列のフォーマットでも使えます。 'string' % values という文字列が与えられた場合、string の中の % 部分はゼロあるいは values の余りの要素に置換えられます。 この操作は文字列補間として知られています。 例えば:
>>>
>>> import math
>>> print('The value of pi is approximately %5.3f.' % math.pi)
より詳しい情報は printf 形式の文字列書式化 にあります。
7.2. ファイルを読み書きする
open() は file object を返します。大抵、 open(filename, mode) のように二つの引数を伴って呼び出されます。
>>>
>>> f = open('workfile', 'w')
最初の引数はファイル名の入った文字列です。二つめの引数も文字列で、ファイルをどのように使うかを示す数個の文字が入っています。 mode は、ファイルが読み出し専用なら 'r' 、書き込み専用 (同名の既存のファイルがあれば消去されます) なら 'w' とします。 'a' はファイルを追記用に開きます。ファイルに書き込まれた内容は自動的にファイルの終端に追加されます。 'r+' はファイルを読み書き両用に開きます。 mode 引数は省略可能で、省略された場合には 'r' であると仮定します。
通常、ファイルはテキストモード (text mode) で開かれ、特定のエンコーディングでエンコードされたファイルに対して文字列を読み書きします。エンコーディングが指定されなければ、デフォルトはプラットフォーム依存です (open() を参照してください) 。モードに 'b' をつけるとファイルをバイナリモード (binary mode) で開き、 byte オブジェクトを読み書きします。テキストファイル以外のすべてのファイルはバイナリモードを利用するべきです。
テキストモードの読み取りでは、プラットフォーム固有の行末記号 (Unix では \n 、Windows では \r\n) をただの \n に変換するのがデフォルトの動作です。テキストモードの書き込みでは、 \n が出てくる箇所をプラットフォーム固有の行末記号に戻すのがデフォルトの動作です。この裏で行われるファイルデータの変換はテキストファイルには上手く働きますが、 JPEG ファイルや EXE ファイルのようなバイナリデータを破壊する恐れがあります。そのようなファイルを読み書きする場合には注意して、バイナリモードを使うようにしてください。
ファイルオブジェクトを扱うときに with キーワードを使うのは良い習慣です。 その利点は、処理中に例外が発生しても必ず最後にファイルをちゃんと閉じることです。 with を使うと、同じことを try-finally ブロックを使って書くよりずっと簡潔に書けます:
>>>
>>> with open('workfile') as f:
...     read_data = f.read()
>>> # We can check that the file has been automatically closed.
>>> f.closed
True
警告 Calling f.write() without using the with keyword or calling f.close() might result in the arguments of f.write() not being completely written to the disk, even if the program exits successfully.
with 文や f.close() の呼び出しによって閉じられた後にファイルオブジェクトを使おうとするとそこで処理が失敗します。:
>>>
>>> f.close()
>>> f.read()
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
7.2.1. ファイルオブジェクトのメソッド
この節の以降の例は、 f というファイルオブジェクトが既に生成されているものと仮定します。
ファイルの内容を読み出すには、 f.read(size) を呼び出します。このメソッドはある量のデータを読み出して、文字列 (テキストモードの場合) か bytes オブジェクト (バイナリーモードの場合) として返します。 size はオプションの数値引数です。 size が省略されたり負の数であった場合、ファイルの内容全てを読み出して返します。ただし、ファイルがマシンのメモリの二倍の大きさもある場合にはどうなるかわかりません。 size が負でない数ならば、最大で (テキストモードの場合) size 文字、(バイナリモードの場合) size バイトを読み出して返します。ファイルの終端にすでに達していた場合、 f.read() は空の文字列 ('') を返します。
>>>
>>> f.read()
'This is the entire file.\n'
>>> f.read()
''
f.readline() はファイルから 1 行だけを読み取ります。改行文字 (\n) は読み出された文字列の終端に残ります。改行が省略されるのは、ファイルが改行で終わっていない場合の最終行のみです。これは、戻り値があいまいでないようにするためです; f.readline() が空の文字列を返したら、ファイルの終端に達したことが分かります。一方、空行は '\n'、すなわち改行 1 文字だけからなる文字列で表現されます。
>>>
>>> f.readline()
'This is the first line of the file.\n'
>>> f.readline()
'Second line of the file\n'
>>> f.readline()
''
ファイルから複数行を読み取るには、ファイルオブジェクトに対してループを書く方法があります。この方法はメモリを効率的に使え、高速で、簡潔なコードになります:
>>>
>>> for line in f:
...     print(line, end='')
...
Second line of the file
ファイルのすべての行をリスト形式で読み取りたいなら、list(f) や f.readlines() を使うこともできます。
f.write(string) は、string の内容をファイルに書き込み、書き込まれた文字数を返します。
>>>
>>> f.write('This is a test\n')
15
オブジェクトの他の型は、書き込む前に変換しなければなりません -- 文字列 (テキストモード) と bytes オブジェクト (バイナリーモード) のいずれかです:
>>>
>>> value = ('the answer', 42)
>>> s = str(value)  # convert the tuple to string
>>> f.write(s)
18
f.tell() は、ファイルオブジェクトのファイル中における現在の位置を示す整数を返します。ファイル中の現在の位置は、バイナリモードではファイルの先頭からのバイト数で、テキストモードでは不明瞭な値で表されます。
ファイルオブジェクトの位置を変更するには、f.seek(offset, whence) を使います。ファイル位置は基準点 (reference point) にオフセット値 offset を足して計算されます。参照点は whence 引数で選びます。whence の値が 0 ならばファイルの 先頭から測り、1 ならば現在のファイル位置を使い、2 ならばファイルの終端を参照点として使います。whence は省略することができ、デフォルトの値は 0、すなわち参照点としてファイルの先頭を使います。
>>>
>>> f = open('workfile', 'rb+')
>>> f.write(b'0123456789abcdef')
16
>>> f.seek(5)      # Go to the 6th byte in the file
5
>>> f.read(1)
b'5'
>>> f.seek(-3, 2)  # Go to the 3rd byte before the end
13
>>> f.read(1)
b'd'
テキストファイル (mode 文字列に b を付けなかった場合) では、ファイルの先頭からの相対位置に対するシークだけが許可されています (例外として、seek(0, 2) でファイルの末尾へのシークは可能です)。また、唯一の有効な offset 値は f.tell() から返された値か、0 のいずれかです。それ以外の offset 値は未定義の振る舞いを引き起こします。
ファイルオブジェクトには、他にも isatty() や truncate() といった、あまり使われないメソッドがあります。ファイルオブジェクトについての完全なガイドは、ライブラリリファレンスを参照してください。
7.2.2. json による構造化されたデータの保存
文字列は簡単にファイルに書き込んだり、ファイルから読み込んだりすることができます。数値の場合には少し努力が必要です。というのも、read() メソッドは文字列しか返さないため、int() のような関数にその文字列を渡して、たとえば文字列 '123' のような文字列を、数値 123 に変換しなくてはならないからです。もっと複雑なデータ型、例えば入れ子になったリストや辞書の場合、手作業でのパースやシリアライズは困難になります。
ユーザが毎回コードを書いたりデバッグしたりして複雑なデータ型をファイルに保存するかわりに、Python では一般的なデータ交換形式である JSON (JavaScript Object Notation) を使うことができます。この標準モジュール json は、Python のデータ 階層を取り、文字列表現に変換します。この処理は シリアライズ (serializing) と呼ばれます。文字列表現からデータを再構築することは、デシリアライズ (deserializing) と呼ばれます。シリアライズされてからデシリアライズされるまでの間に、オブジェクトの文字列表現はファイルやデータの形で保存したり、ネットワークを通じて離れたマシンに送ったりすることができます。
注釈 JSON 形式は現代的なアプリケーションでデータをやりとりする際によく使われます。多くのプログラマーが既に JSON に詳しいため、JSON はデータの相互交換をする場合の良い選択肢です。
オブジェクト x があり、その JSON 形式の文字列表現を見るには、単純な1行のコードを書くだけです:
>>>
>>> import json
>>> json.dumps([1, 'simple', 'list'])
'[1, "simple", "list"]'
dumps() に似た関数に、dump() があり、こちらは単純にオブジェクトを text file にシリアライズします。f が書き込み用に開かれた text file だとすると、次のように書くことができます:
json.dump(x, f)
逆にデシリアライズするには、f が読み込み用に開かれた text file だとすると、次のようになります:
x = json.load(f)
このような単純なシリアライズをする手法は、リストや辞書を扱うことはできますが、任意のクラス・インスタンスを JSON にシリアライズするにはもう少し努力しなくてはなりません。json モジュールのリファレンスにこれについての解説があります。
参考 pickle - pickle モジュール
JSON とは対照的に、 pickle は任意の複雑な Python オブジェクトをシリアライズ可能なプロトコルです。しかし、Python に特有のプロトコルで、他の言語で記述されたアプリケーションと通信するのには使えません。さらに、デフォルトでは安全でなく、信頼できない送信元から送られてきた、スキルのある攻撃者によって生成された pickle データをデシリアライズすると、攻撃者により任意のコードが実行されてしまいます。
8. エラーと例外
これまでエラーメッセージについては簡単に触れるだけでしたが、チュートリアル中の例を自分で試していたら、実際にいくつかのエラーメッセージを見ていることでしょう。エラーには (少なくとも) 二つのはっきり異なる種類があります。それは 構文エラー (syntax error) と 例外 (exception) です。
8.1. 構文エラー
構文エラーは構文解析エラー (parsing error) としても知られており、Python を勉強している間に最もよく遭遇する問題の一つでしょう:
>>>
>>> while True print('Hello world')
  File "<stdin>", line 1
    while True print('Hello world')
                   ^
SyntaxError: invalid syntax
パーサは違反の起きている行を表示し、小さな「矢印」を表示して、行中でエラーが検出された最初の位置を示します。エラーは矢印の 直前の トークンでひき起こされています (または、少なくともそこで検出されています)。上記の例では、エラーは関数 print() で検出されています。コロン (':') がその前に無いからです。入力がスクリプトから来ている場合は、どこを見ればよいか分かるようにファイル名と行番号が出力されます。
8.2. 例外
たとえ文や式が構文的に正しくても、実行しようとしたときにエラーが発生するかもしれません。実行中に検出されたエラーは 例外 (exception) と呼ばれ、常に致命的とは限りません。これから、Python プログラムで例外をどのように扱うかを学んでいきます。ほとんどの例外はプログラムで処理されず、以下に示されるようなメッセージになります:
>>>
>>> 10 * (1/0)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
ZeroDivisionError: division by zero
>>> 4 + spam*3
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'spam' is not defined
>>> '2' + 2
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: Can't convert 'int' object to str implicitly
エラーメッセージの最終行は何が起こったかを示しています。例外は様々な型 (type) で起こり、その型がエラーメッセージの一部として出力されます。上の例での型は ZeroDivisionError, NameError, TypeError です。例外型として出力される文字列は、発生した例外の組み込み名です。これは全ての組み込み例外について成り立ちますが、ユーザ定義の例外では (成り立つようにするのは有意義な慣習ですが) 必ずしも成り立ちません。標準例外の名前は組み込みの識別子です (予約語ではありません)。
残りの行は例外の詳細で、その例外の型と何が起きたかに依存します。
エラーメッセージの先頭部分では、例外が発生した実行コンテキスト (context) を、スタックのトレースバック (stack traceback) の形式で示しています。一般には、この部分にはソースコード行をリストしたトレースバックが表示されます。しかし、標準入力から読み取られたコードは表示されません。
組み込み例外 には、組み込み例外とその意味がリストされています。
8.3. 例外を処理する
例外を選別して処理するようなプログラムを書くことができます。以下の例を見てください。この例では、有効な文字列が入力されるまでユーザに入力を促しますが、ユーザがプログラムに (Control-C か、またはオペレーティングシステムがサポートしている何らかのキーを使って) 割り込みをかけてプログラムを中断させることができるようにしています。ユーザが生成した割り込みは、 KeyboardInterrupt 例外が送出されることで通知されるということに注意してください。
>>>
>>> while True:
...     try:
...         x = int(input("Please enter a number: "))
...         break
...     except ValueError:
...         print("Oops!  That was no valid number.  Try again...")
...
try 文は下記のように動作します。
まず、 try 節 (try clause) (キーワード try と except の間の文) が実行されます。
何も例外が発生しなければ、 except 節 をスキップして try 文の実行を終えます。
try 節内の実行中に例外が発生すると、その節の残りは飛ばされます。次に、例外型が except キーワードの後に指定されている例外に一致する場合、except 節が実行された後、 try 文の後ろへ実行が継続されます。
もしも except 節で指定された例外と一致しない例外が発生すると、その例外は try 文の外側に渡されます。例外に対するハンドラ (handler、処理部) がどこにもなければ、 処理されない例外 (unhandled exception) となり、上記に示したようなメッセージを出して実行を停止します。
一つの try 文には複数の except 節が付けられ、別々の例外に対するハンドラを指定できます。 多くとも一つのハンドラしか実行されません。 ハンドラは対応する try 節内で発生した例外だけを処理し、同じ try 節内の別の例外ハンドラで起きた例外は処理しません。 except 節では丸括弧で囲ったタプルという形で複数の例外を指定できます。例えば次のようにします:
... except (RuntimeError, TypeError, NameError):
...     pass
except 節のクラスは、例外と同じクラスか基底クラスのときに互換 (compatible)となります。 (逆方向では成り立ちません --- 派生クラスの例外がリストされている except 節は基底クラスの例外と互換ではありません)。例えば、次のコードは、 B, C, D を順序通りに出力します:
class B(Exception):
    pass
class C(B):
    pass
class D(C):
    pass
for cls in [B, C, D]:
    try:
        raise cls()
    except D:
        print("D")
    except C:
        print("C")
    except B:
        print("B")
except 節が逆に並んでいた場合 (except B が最初にくる場合)、 B, B, B と出力されるはずだったことに注意してください --- 最初に一致した except 節が駆動されるのです。
最後の except 節では例外名を省いて、ワイルドカード (wildcard、総称記号) にすることができます。ワイルドカードの except 節は非常に注意して使ってください。というのは、ワイルドカードは通常のプログラムエラーをたやすく隠してしまうからです！ワイルドカードの except 節はエラーメッセージを出力した後に例外を再送出する (関数やメソッドの呼び出し側が同様にして例外を処理できるようにする) 用途にも使えます:
import sys
try:
    f = open('myfile.txt')
    s = f.readline()
    i = int(s.strip())
except OSError as err:
    print("OS error: {0}".format(err))
except ValueError:
    print("Could not convert data to an integer.")
except:
    print("Unexpected error:", sys.exc_info()[0])
    raise
try ... except 文には、オプションで else 節 (else clause) を設けることができます。 else 節を設ける場合、全ての except 節よりも後ろに置かなければなりません。 else 節は try 節で全く例外が送出されなかったときに実行されるコードを書くのに役立ちます。例えば次のようにします:
for arg in sys.argv[1:]:
    try:
        f = open(arg, 'r')
    except OSError:
        print('cannot open', arg)
    else:
        print(arg, 'has', len(f.readlines()), 'lines')
        f.close()
追加のコードを付け加えるのは try 節よりも else 節の方がよいでしょう。 なぜなら、そうすることで try ... except 文で保護されたコードから送出されたもの以外の例外を過って捕捉してしまうという事態を避けられるからです。
例外が発生するとき、例外は関連付けられた値を持つことができます。この値は例外の 引数 (argument) とも呼ばれます。引数の有無および引数の型は、例外の型に依存します。
except 節では、例外名の後に変数を指定することができます。この変数は例外インスタンスに結び付けられており、 instance.args に例外インスタンス生成時の引数が入っています。例外インスタンスには __str__() が定義されており、 .args を参照しなくても引数を直接印字できるように利便性が図られています。必要なら、例外を送出する前にインスタンス化して、任意の属性を追加できます。
>>>
>>> try:
...     raise Exception('spam', 'eggs')
... except Exception as inst:
...     print(type(inst))    # the exception instance
...     print(inst.args)     # arguments stored in .args
...     print(inst)          # __str__ allows args to be printed directly,
...                          # but may be overridden in exception subclasses
...     x, y = inst.args     # unpack args
...     print('x =', x)
...     print('y =', y)
...
<class 'Exception'>
('spam', 'eggs')
('spam', 'eggs')
x = spam
y = eggs
例外が引数を持っていれば、それらは処理されない例外のメッセージの最後の部分 (「詳細説明」) に出力されます。
例外ハンドラは、try 節の直接内側で発生した例外を処理するだけではなく、その try 節から (たとえ間接的にでも) 呼び出された関数の内部で発生した例外も処理します。例えば:
>>>
>>> def this_fails():
...     x = 1/0
...
>>> try:
...     this_fails()
... except ZeroDivisionError as err:
...     print('Handling run-time error:', err)
...
Handling run-time error: division by zero
8.4. 例外を送出する
raise 文を使って、特定の例外を発生させることができます。例えば:
>>>
>>> raise NameError('HiThere')
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: HiThere
raise の唯一の引数は送出される例外を指し示します。 これは例外インスタンスか例外クラス (Exception を継承したクラス) でなければなりません。 例外クラスが渡された場合は、引数無しのコンストラクタが呼び出され、暗黙的にインスタンス化されます:
raise ValueError  # shorthand for 'raise ValueError()'
例外が発生したかどうかを判定したいだけで、その例外を処理するつもりがなければ、単純な形式の raise 文を使って例外を再送出させることができます:
>>>
>>> try:
...     raise NameError('HiThere')
... except NameError:
...     print('An exception flew by!')
...     raise
...
An exception flew by!
Traceback (most recent call last):
  File "<stdin>", line 2, in <module>
NameError: HiThere
8.5. 例外の連鎖
The raise statement allows an optional from which enables chaining exceptions. For example:
# exc must be exception instance or None.
raise RuntimeError from exc
これは例外を変換するときに便利です。例えば:
>>>
>>> def func():
...     raise IOError
...
>>> try:
...     func()
... except IOError as exc:
...     raise RuntimeError('Failed to open database') from exc
...
Traceback (most recent call last):
  File "<stdin>", line 2, in <module>
  File "<stdin>", line 2, in func
OSError
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "<stdin>", line 4, in <module>
RuntimeError: Failed to open database
Exception chaining happens automatically when an exception is raised inside an except or finally section. Exception chaining can be disabled by using from None idiom:
>>>
>>> try:
...     open('database.sqlite')
... except IOError:
...     raise RuntimeError from None
...
Traceback (most recent call last):
  File "<stdin>", line 4, in <module>
RuntimeError
8.6. ユーザー定義例外
プログラム上で新しい例外クラスを作成することで、独自の例外を指定することができます (Python のクラスについては クラス 参照)。例外は、典型的に Exception クラスから、直接または間接的に派生したものです。
例外クラスでは、普通のクラスができることなら何でも定義することができますが、通常は単純なものにしておきます。大抵は、いくつかの属性だけを提供し、例外が発生したときにハンドラがエラーに関する情報を取り出せるようにする程度にとどめます。複数の別個の例外を送出するようなモジュールを作成する際には、そのモジュールで定義されている例外の基底クラスを作成するのが一般的なプラクティスです:
class Error(Exception):
    """Base class for exceptions in this module."""
    pass
class InputError(Error):
    """Exception raised for errors in the input.
    Attributes:
        expression -- input expression in which the error occurred
        message -- explanation of the error
    """
    def __init__(self, expression, message):
        self.expression = expression
        self.message = message
class TransitionError(Error):
    """Raised when an operation attempts a state transition that's not
    allowed.
    Attributes:
        previous -- state at beginning of transition
        next -- attempted new state
        message -- explanation of why the specific transition is not allowed
    """
    def __init__(self, previous, next, message):
        self.previous = previous
        self.next = next
        self.message = message
ほとんどの例外は、標準の例外の名前付けと同様に、"Error" で終わる名前で定義されています。
多くの標準モジュールでは、モジュールで定義されている関数内で発生する可能性のあるエラーを報告させるために、独自の例外を定義しています。クラスについての詳細な情報は クラス 章で提供されています。
8.7. クリーンアップ動作を定義する
try 文にはもう一つオプションの節があります。この節はクリーンアップ動作を定義するためのもので、どんな状況でも必ず実行されます。例を示します:
>>>
>>> try:
...     raise KeyboardInterrupt
... finally:
...     print('Goodbye, world!')
...
Goodbye, world!
KeyboardInterrupt
Traceback (most recent call last):
  File "<stdin>", line 2, in <module>
もし finally 節がある場合、 try 文が終わる前の最後の処理を、 finally 節が実行します。 try 文が例外を発生させるか否かに関わらず、 finally 節は実行されます。以下では、例外が発生するという更に複雑なケースを議論します:
もし try 文の実行中に例外が発生したら、その例外は except 節によって処理されるでしょう。もしその例外が except 節によって処理されなければ、 finally 節が実行された後に、その例外が再送出されます。
except 節または else 節の実行中に例外が発生することがあり得ます。その場合も、 finally 節が実行された後に例外が再送出されます。
もし try 文が break 文、 continue 文または return 文のいずれかに達すると、その:keyword:!break 文、 continue 文または return 文の実行の直前に finally 節が実行されます。
もし finally 節が return 文を含む場合、返される値は try 節の return 文ではなく、finally 節の return 文によるものになります。
例えば:
>>>
>>> def bool_return():
...     try:
...         return True
...     finally:
...         return False
...
>>> bool_return()
False
より複雑な例:
>>>
>>> def divide(x, y):
...     try:
...         result = x / y
...     except ZeroDivisionError:
...         print("division by zero!")
...     else:
...         print("result is", result)
...     finally:
...         print("executing finally clause")
...
>>> divide(2, 1)
result is 2.0
executing finally clause
>>> divide(2, 0)
division by zero!
executing finally clause
>>> divide("2", "1")
executing finally clause
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "<stdin>", line 3, in divide
TypeError: unsupported operand type(s) for /: 'str' and 'str'
見てわかるとおり、 finally 節はどの場合にも実行されています。 文字列で割り算をすることで発生した TypeError は except 節で処理されていないので、 finally 節実行後に再度送出されています。
実世界のアプリケーションでは、 finally 節は(ファイルやネットワーク接続などの)外部リソースを、利用が成功したかどうかにかかわらず解放するために便利です。
8.8. 定義済みクリーンアップ処理
オブジェクトのなかには、その利用の成否にかかわらず、不要になった際に実行される標準的なクリーンアップ処理が定義されているものがあります。以下の、ファイルをオープンして内容を画面に表示する例をみてください。
for line in open("myfile.txt"):
    print(line, end="")
このコードの問題点は、コードの実行が終わった後に不定の時間ファイルを開いたままでいることです。これは単純なスクリプトでは問題になりませんが、大きなアプリケーションでは問題になりえます。 with 文はファイルのようなオブジェクトが常に、即座に正しくクリーンアップされることを保証します。
with open("myfile.txt") as f:
    for line in f:
        print(line, end="")
この文が実行されたあとで、たとえ行の処理中に問題があったとしても、ファイル f は常に close されます。ファイルなどの、定義済みクリーンアップ処理を持つオブジェクトについては、それぞれのドキュメントで示されます。
9. クラス
クラスはデータと機能を組み合わせる方法を提供します。 新規にクラスを作成することで、新しいオブジェクトの 型 を作成し、その型を持つ新しい インスタンス が作れます。 クラスのそれぞれのインスタンスは自身の状態を保持する属性を持てます。 クラスのインスタンスは、その状態を変更するための (そのクラスが定義する) メソッドも持てます。
Python は、他のプログラミング言語と比較して、最小限の構文と意味付けを使ってクラスを言語に追加しています。Python のクラスは、C++ と Modula-3 のクラスメカニズムを混ぜたものです。Python のクラス機構はオブジェクト指向プログラミングの標準的な機能を全て提供しています。クラスの継承メカニズムは、複数の基底クラスを持つことができ、派生クラスで基底クラスの任意のメソッドをオーバライドすることができます。メソッドでは、基底クラスのメソッドを同じ名前で呼び出すことができます。オブジェクトには任意の種類と数のデータを格納することができます。モジュールと同じく、クラス機構も Python の動的な性質に従うように設計されています。クラスは実行時に生成され、生成後に変更することができます。
C++ の用語で言えば、通常のクラスメンバ (データメンバも含む) は (プライベート変数 に書かれている例外を除いて) public であり、メンバ関数はすべて 仮想関数(virtual) です。 Modula-3 にあるような、オブジェクトのメンバをメソッドから参照するための短縮した記法は使えません: メソッド関数の宣言では、オブジェクト自体を表す第一引数を明示しなければなりません。第一引数のオブジェクトはメソッド呼び出しの際に暗黙の引数として渡されます。 Smalltalk に似て、クラスはそれ自体がオブジェクトです。そのため、 import や名前変更といった操作が可能です。 C++ や Modula-3 と違って、ユーザーは組込み型を基底クラスにして拡張を行えます。また、C++ とは同じで Modula-3 とは違う点として、特別な構文を伴うほとんどの組み込み演算子 (算術演算子 (arithmetic operator) や添字表記) はクラスインスタンスで使うために再定義できます。
(クラスに関して普遍的な用語定義がないので、 Smalltalk と C++ の用語を場合に応じて使っていくことにします。 C++ よりも Modula-3 の方がオブジェクト指向の意味論が Python に近いので、 Modula-3 の用語を使いたいのですが、ほとんどの読者は Modula-3 についてしらないでしょうから。)
9.1. 名前とオブジェクトについて
オブジェクトには個体性があり、同一のオブジェクトに(複数のスコープから) 複数の名前を割り当てることができます。この機能は他の言語では別名づけ(alias) として知られています。 Python を一見しただけでは、別名づけの重要性は分からないことが多く、変更不能な基本型 (数値、文字列、タプル)を扱うときには無視して差し支えありません。しかしながら、別名付けは、リストや辞書や他の多くの型など、変更可能な型を扱う Python コード上で驚くべき効果があります。別名付けはいくつかの点でポインタのように振舞い、このことは通常はプログラムに利するように使われます。例えば、オブジェクトの受け渡しは、実装上はポインタが渡されるだけなのでコストの低い操作になります。また、関数があるオブジェクトを引数として渡されたとき、関数の呼び出し側からオブジェクトに対する変更を見ることができます --- これにより、 Pascal にあるような二つの引数渡し機構をもつ必要をなくしています。
9.2. Python のスコープと名前空間
クラスを紹介する前に、Python のスコープのルールについてあることを話しておかなければなりません。クラス定義は巧みなトリックを名前空間に施すので、何が起こっているのかを完全に理解するには、スコープと名前空間がどのように動作するかを理解する必要があります。ちなみに、この問題に関する知識は全ての Python プログラマにとって有用です。
まず定義から始めましょう。
名前空間 (namespace) とは、名前からオブジェクトへの対応付け (mapping) です。ほとんどの名前空間は、現状では Python の辞書として実装されていますが、そのことは通常は (パフォーマンス以外では) 目立つことはないし、将来は変更されるかもしれません。名前空間の例には、組込み名の集合 (abs() 等の関数や組込み例外名)、モジュール内のグローバルな名前、関数を呼び出したときのローカルな名前があります。オブジェクトの属性からなる集合もまた、ある意味では名前空間です。名前空間について知っておくべき重要なことは、異なった名前空間にある名前の間には全く関係がないということです。例えば、二つの別々のモジュールの両方で関数 maximize という関数を定義することができ、定義自体は混同されることはありません --- モジュールのユーザは名前の前にモジュール名をつけなければなりません。
ところで、 属性 という言葉は、ドットに続く名前すべてに対して使っています --- 例えば式 z.real で、 real はオブジェクト z の属性です。厳密にいえば、モジュール内の名前に対する参照は属性の参照です。式 modname.funcname では、 modname はあるモジュールオブジェクトで、 funcname はその属性です。この場合には、モジュールの属性とモジュールの中で定義されているグローバル名の間には、直接的な対応付けがされます。これらの名前は同じ名前空間を共有しているのです！ 1
属性は読取り専用にも、書込み可能にもできます。書込み可能であれば、属性に代入することができます。モジュール属性は書込み可能で、 modname.the_answer = 42 と書くことができます。書込み可能な属性は、 del 文で削除することもできます。例えば、 del modname.the_answer は、 modname で指定されたオブジェクトから属性 the_answer を除去します。
名前空間は様々な時点で作成され、その寿命も様々です。組み込みの名前が入った名前空間は Python インタプリタが起動するときに作成され、決して削除されることはありません。モジュールのグローバルな名前空間は、モジュール定義が読み込まれたときに作成されます。通常、モジュールの名前空間は、インタプリタが終了するまで残ります。インタプリタのトップレベルで実行された文は、スクリプトファイルから読み出されたものでも対話的に読み出されたものでも、 __main__ という名前のモジュールの一部分であるとみなされるので、独自の名前空間を持つことになります。 (組み込みの名前は実際にはモジュール内に存在します。そのモジュールは builtins と呼ばれています。)
関数のローカルな名前空間は、関数が呼び出されたときに作成され、関数から戻ったときや、関数内で例外が送出され、かつ関数内で処理されなかった場合に削除されます。 (実際には、忘れられる、と言ったほうが起きていることをよく表しています。) もちろん、再帰呼出しのときには、各々の呼び出しで各自のローカルな名前空間があります。
スコープ (scope) とは、ある名前空間が直接アクセスできるような、 Python プログラムのテキスト上の領域です。 "直接アクセス可能" とは、修飾なしに (訳注: spam.egg ではなく単に egg のように) 名前を参照した際に、その名前空間から名前を見つけようと試みることを意味します。
Although scopes are determined statically, they are used dynamically. At any time during execution, there are 3 or 4 nested scopes whose namespaces are directly accessible:
最初に探される、最も内側のスコープは、ローカルな名前を持っています。
外側の(enclosing)関数のスコープは、近いほうから順に探され、ローカルでもグローバルでもない名前を持っています。
次のスコープは、現在のモジュールのグローバルな名前を持っています。
一番外側の(最後に検索される)スコープはビルトイン名を持っています。
名前が global と宣言されている場合、その名前に対する参照や代入は全て、モジュールのグローバルな名前の入った中間のスコープに対して直接行われます。最内スコープの外側にある変数に再束縛するには、 nonlocal 文が使えます。nonlocal と宣言されなかった変数は、全て読み出し専用となります (そのような変数に対する書き込みは、単に 新しい ローカル変数をもっとも内側のスコープで作成し、外部のスコープの値は変化しません)。
通常、ローカルスコープは (プログラムテキスト上の) 現在の関数のローカルな名前を参照します。関数の外側では、ローカルスコープはグローバルな名前空間と同じ名前空間、モジュールの名前空間を参照します。クラス定義では、ローカルスコープの中にもう一つ名前空間が置かれます。
スコープはテキスト上で決定されていると理解することが重要です。モジュール内で定義される関数のグローバルなスコープは、関数がどこから呼び出されても、どんな別名をつけて呼び出されても、そのモジュールの名前空間になります。反対に、実際の名前の検索は実行時に動的に行われます --- とはいえ、言語の定義は、"コンパイル" 時の静的な名前解決の方向に進化しているので、動的な名前解決に頼ってはいけません！ (事実、ローカルな変数は既に静的に決定されています。)
Python の特徴として、global や nonlocal 文が有効でない場合は、名前に対する参照は常に最も内側のスコープに対して有効になります。 代入はデータをコピーしません。オブジェクトを名前に束縛するだけです。削除も同様で、del x は、ローカルスコープの名前空間から x に対する拘束を取り除きます。 つまるところ、新しい名前を与えるようなすべての操作は、ローカルスコープを使って行われます。 import 文、関数の定義は、モジュールや関数名をローカルスコープの名前に拘束します。
global 文を使うと、特定の変数がグローバルスコープに存在し、そこで再束縛されることを指示できます。 nonlocal 文は、特定の変数が外側のスコープに存在し、そこで再束縛されることを指示します。
9.2.1. スコープと名前空間の例
異なるスコープと名前空間がどのように参照されるか、また global および nonlocal が変数の束縛にどう影響するか、この例で実演します:
def scope_test():
    def do_local():
        spam = "local spam"
    def do_nonlocal():
        nonlocal spam
        spam = "nonlocal spam"
    def do_global():
        global spam
        spam = "global spam"
    spam = "test spam"
    do_local()
    print("After local assignment:", spam)
    do_nonlocal()
    print("After nonlocal assignment:", spam)
    do_global()
    print("After global assignment:", spam)
scope_test()
print("In global scope:", spam)
このコード例の出力は:
After local assignment: test spam
After nonlocal assignment: nonlocal spam
After global assignment: nonlocal spam
In global scope: global spam
このとおり、(デフォルトの) ローカルな 代入は scope_test 上の spam への束縛を変更しませんでした。 nonlocal 代入は scope_test 上の spam への束縛を変更し、 global 代入はモジュールレベルの束縛を変更しました。
またここから、 global 代入の前には spam に何も束縛されていなかったことも分かります。
9.3. クラス初見
クラスでは、新しい構文を少しと、三つの新たなオブジェクト型、そして新たな意味付けをいくつか取り入れています。
9.3.1. クラス定義の構文
クラス定義の最も単純な形式は、次のようになります:
class ClassName:
    <statement-1>
    .
    .
    .
    <statement-N>
関数定義 (def 文) と同様、クラス定義が効果をもつにはまず実行しなければなりません。 (クラス定義を if 文の分岐先や関数内部に置くことも、考え方としてはありえます。)
実際には、クラス定義の内側にある文は、通常は関数定義になりますが、他の文を書くこともでき、それが役に立つこともあります --- これについては後で述べます。クラス内の関数定義は通常、メソッドの呼び出し規約で決められた独特の形式の引数リストを持ちます --- これについても後で述べます。
クラス定義に入ると、新たな名前空間が作成され、ローカルな名前空間として使われます --- 従って、ローカルな変数に対する全ての代入はこの新たな名前空間に入ります。特に、関数定義を行うと、新たな関数の名前はこの名前空間に結び付けられます。
クラス定義から普通に (定義の終端に到達して) 抜けると、 クラスオブジェクト (class object) が生成されます。クラスオブジェクトは、基本的にはクラス定義で作成された名前空間の内容をくるむラッパ (wrapper) です。クラスオブジェクトについては次の節で詳しく学ぶことにします。 (クラス定義に入る前に有効だった) 元のローカルスコープが復帰し、生成されたクラスオブジェクトは復帰したローカルスコープにクラス定義のヘッダで指定した名前 (上の例では ClassName) で結び付けられます。
9.3.2. クラスオブジェクト
クラスオブジェクトでは２種類の演算、属性参照とインスタンス生成をサポートしています。
属性参照 (attribute reference) は、Python におけるすべての属性参照で使われている標準的な構文、 obj.name を使います。クラスオブジェクトが生成された際にクラスの名前空間にあった名前すべてが有効な属性名です。従って、以下のようなクラス定義では:
class MyClass:
    """A simple example class"""
    i = 12345
    def f(self):
        return 'hello world'
MyClass.i と MyClass.f は妥当な属性参照であり、それぞれ整数と関数オブジェクトを返します。クラス属性に代入を行うこともできます。従って、 MyClass.i の値を代入して変更できます。 __doc__ も有効な属性で、そのクラスに属している docstring、この場合は "A simple example class" を返します。
クラスの インスタンス化 (instantiation) には関数のような表記法を使います。クラスオブジェクトのことを、単にクラスの新しいインスタンスを返す引数がない関数のように振る舞います。例えば (上記のクラスでいえば):
x = MyClass()
は、クラスの新しい インスタンス (instance) を生成し、そのオブジェクトをローカル変数 x へ代入します。
このクラスのインスタンス生成操作 (クラスオブジェクトの "呼出し") を行うと、空のオブジェクトを生成します。多くのクラスは、オブジェクトを作成する際に、カスタマイズされた特定の初期状態になってほしいと望んでいます。そのために、クラスには __init__() という名前の特別なメソッド定義することができます。例えば次のようにします:
def __init__(self):
    self.data = []
クラスが __init__() メソッドを定義している場合、クラスのインスタンスを生成すると、新しく生成されたクラスインスタンスに対して自動的に __init__() を呼び出します。従って、この例では、新たな初期済みのインスタンスを次のようにして得ることができます:
x = MyClass()
もちろん、より大きな柔軟性を持たせるために、 __init__() メソッドに複数の引数をもたせることができます。その場合、次の例のように、クラスのインスタンス生成操作に渡された引数は __init__() に渡されます。例えば、
>>>
>>> class Complex:
...     def __init__(self, realpart, imagpart):
...         self.r = realpart
...         self.i = imagpart
...
>>> x = Complex(3.0, -4.5)
>>> x.r, x.i
(3.0, -4.5)
9.3.3. インスタンスオブジェクト
ところで、インスタンスオブジェクトを使うと何ができるのでしょうか？インスタンスオブジェクトが理解できる唯一の操作は、属性の参照です。有効な属性名には (データ属性およびメソッドの) 二種類あります。
データ属性 (data attribute) は、これは Smalltalk の "インスタンス変数" や C++の "データメンバ" に相当します。データ属性を宣言する必要はありません。ローカルな変数と同様に、これらの属性は最初に代入された時点で湧き出てきます。例えば、上で生成した MyClass のインスタンス x に対して、次のコードを実行すると、値 16 を印字し、 x の痕跡は残りません:
x.counter = 1
while x.counter < 10:
    x.counter = x.counter * 2
print(x.counter)
del x.counter
もうひとつのインスタンス属性は メソッド (method) です。メソッドとは、オブジェクトに "属している" 関数のことです。(Python では、メソッドという用語はクラスインスタンスだけのものではありません。オブジェクト型にもメソッドを持つことができます。例えば、リストオブジェクトには、 append, insert, remove, sort などといったメソッドがあります。とはいえ、以下では特に明記しない限り、クラスのインスタンスオブジェクトのメソッドだけを意味するものとして使うことにします。)
インスタンスオブジェクトで有効なメソッド名は、そのクラスによります。定義により、クラスの全ての関数オブジェクトである属性がインスタンスオブジェクトの妥当なメソッド名に決まります。従って、例では、MyClass.f は関数なので、x.f はメソッドの参照として有効です。しかし、MyClass.i は関数ではないので、x.i はメソッドの参照として有効ではありません。x.f は MyClass.f と同じものではありません --- 関数オブジェクトではなく、メソッドオブジェクト (method object) です。
9.3.4. メソッドオブジェクト
普通、メソッドはバインドされた直後に呼び出されます:
x.f()
MyClass の例では、上のコードは文字列 'hello world' を返すでしょう。しかしながら、必ずしもメソッドをその場で呼び出さなければならないわけではありません。 x.f はメソッドオブジェクトであり、どこかに記憶しておいて後で呼び出すことができます。例えば次のコードは:
xf = x.f
while True:
    print(xf())
hello world を時が終わるまで印字し続けるでしょう。
メソッドが呼び出されるときには実際には何が起きているのでしょうか？ f() の関数定義では引数を一つ指定していたにもかかわらず、上の例では x.f() が引数なしで呼び出されています。引数はどうなったのでしょうか？たしか、引数が必要な関数を引数無しで呼び出すと、 Python が例外を送出するはずです --- たとえその引数が実際には使われなくても…。
もう答は想像できているかもしれませんね: メソッドについて特別なこととして、インスタンスオブジェクトが関数の第1引数として渡されます。 例では、 x.f() という呼び出しは、 MyClass.f(x) と厳密に等価なものです。 一般に、 n 個の引数リストもったメソッドの呼出しは、そのメソッドのインスタンスオブジェクトを最初の引数の前に挿入した引数リストで、メソッドに対応する関数を呼び出すことと等価です。
もしまだメソッドの動作を理解できなければ、一度実装を見てみると事情がよく分かるかもしれません。インスタンスの非データ属性が参照されたときは、そのインスタンスのクラスが検索されます。その名前が有効なクラス属性を表している関数オブジェクトなら、インスタンスオブジェクトと見つかった関数オブジェクト (へのポインタ) を抽象オブジェクト、すなわちメソッドオブジェクトにパックして作成します。メソッドオブジェクトが引数リストと共に呼び出されるとき、インスタンスオブジェクトと渡された引数リストから新しい引数リストを作成して、元の関数オブジェクトを新しい引数リストで呼び出します。
9.3.5. クラスとインスタンス変数
一般的に、インスタンス変数はそれぞれのインスタンスについて固有のデータのためのもので、クラス変数はそのクラスのすべてのインスタンスによって共有される属性やメソッドのためのものです:
class Dog:
    kind = 'canine'         # class variable shared by all instances
    def __init__(self, name):
        self.name = name    # instance variable unique to each instance
>>> d = Dog('Fido')
>>> e = Dog('Buddy')
>>> d.kind                  # shared by all dogs
'canine'
>>> e.kind                  # shared by all dogs
'canine'
>>> d.name                  # unique to d
'Fido'
>>> e.name                  # unique to e
'Buddy'
名前とオブジェクトについて で議論したように、共有データはリストや辞書のような mutable オブジェクトが関与すると驚くべき効果を持ち得ます。例えば、以下のコードの tricks リストはクラス変数として使われるべきではありません、なぜならたった一つのリストがすべての Dog インスタンスによって共有されることになり得るからです:
class Dog:
    tricks = []             # mistaken use of a class variable
    def __init__(self, name):
        self.name = name
    def add_trick(self, trick):
        self.tricks.append(trick)
>>> d = Dog('Fido')
>>> e = Dog('Buddy')
>>> d.add_trick('roll over')
>>> e.add_trick('play dead')
>>> d.tricks                # unexpectedly shared by all dogs
['roll over', 'play dead']
このクラスの正しい設計ではインスタンス変数を代わりに使用するべきです:
class Dog:
    def __init__(self, name):
        self.name = name
        self.tricks = []    # creates a new empty list for each dog
    def add_trick(self, trick):
        self.tricks.append(trick)
>>> d = Dog('Fido')
>>> e = Dog('Buddy')
>>> d.add_trick('roll over')
>>> e.add_trick('play dead')
>>> d.tricks
['roll over']
>>> e.tricks
['play dead']
9.4. いろいろな注意点
インスタンスとクラスの両方で同じ属性名が使用されている場合、属性検索はインスタンスが優先されます。
>>>
>>> class Warehouse:
        purpose = 'storage'
        region = 'west'
>>> w1 = Warehouse()
>>> print(w1.purpose, w1.region)
storage west
>>> w2 = Warehouse()
>>> w2.region = 'east'
>>> print(w2.purpose, w2.region)
storage east
データ属性は、メソッドから参照できると同時に、通常のオブジェクトのユーザ ("クライアント") からも参照できます。言い換えると、クラスは純粋な抽象データ型として使うことができません。実際、 Python では、データ隠蔽を補強するための機構はなにもありません --- データの隠蔽はすべて規約に基づいています。 (逆に、C 言語で書かれた Python の実装では実装の詳細を完全に隠蔽し、必要に応じてオブジェクトへのアクセスを制御できます。この機構は C 言語で書かれた Python 拡張で使うことができます。)
クライアントはデータ属性を注意深く扱うべきです --- クライアントは、メソッドが維持しているデータ属性の不変式を踏みにじり、台無しにするかもしれません。クライアントは、名前の衝突が回避されている限り、メソッドの有効性に影響を及ぼすことなくインスタンスに独自の属性を追加することができる、ということに注意してください --- ここでも、名前付けの規約は頭痛の種を無くしてくれます。
メソッドの中から、データ属性を (または別のメソッドも！) 参照するための短縮された記法はありません。私は、この仕様がメソッドの可読性を高めていると感じています。あるメソッドを眺めているときにローカルな変数とインスタンス変数をはっきり区別できるからです。
よく、メソッドの最初の引数を self と呼びます。この名前付けは単なる慣習でしかありません。 self という名前は、 Python では何ら特殊な意味を持ちません。とはいえ、この慣行に従わないと、コードは他の Python プログラマにとってやや読みにくいものとなります。また、 クラスブラウザ (class browser) プログラムがこの慣行をあてにして書かれているかもしれません。
クラス属性である関数オブジェクトはいずれも、そのクラスのインスタンスのためのメソッドを定義しています。関数定義は、テキスト上でクラス定義の中に入っている必要はありません。関数オブジェクトをクラスのローカルな変数の中に代入するのも OK です。例えば以下のコードのようにします:
# Function defined outside the class
def f1(self, x, y):
    return min(x, x+y)
class C:
    f = f1
    def g(self):
        return 'hello world'
    h = g
これで、 f 、 g 、および h は、すべて C の属性であり関数オブジェクトを参照しています。従って、これら全ては、 C のインスタンスのメソッドとなります --- h は g と全く等価です。これを実践しても、大抵は単にプログラムの読者に混乱をもたらすだけなので注意してください。
メソッドは、 self 引数のメソッド属性を使って、他のメソッドを呼び出すことができます:
class Bag:
    def __init__(self):
        self.data = []
    def add(self, x):
        self.data.append(x)
    def addtwice(self, x):
        self.add(x)
        self.add(x)
メソッドは、通常の関数と同じようにしてグローバルな名前を参照します。あるメソッドに関するグローバルスコープは、その定義を含むモジュールです。(クラスはグローバルなスコープとして用いられることはありません。) メソッドでグローバルなデータを使う良い理由はほとんどありませんが、グローバルなスコープを使うべき場面は多々あります。一つ挙げると、メソッド内から、グローバルなスコープに import された関数やモジュールや、そのモジュール中で定義された関数やクラスを使うことができます。通常、メソッドの入っているクラス自体はグローバルなスコープ内で定義されています。次の節では、メソッドが自分のクラスを参照する理由として正当なものを見てみましょう。
個々の値はオブジェクトなので、 クラス (型 とも言います) を持っています。それは object.__class__ に保持されています。
9.5. 継承
言うまでもなく、継承の概念をサポートしない言語機能は "クラス" と呼ぶに値しません。派生クラス (derived class) を定義する構文は次のようになります:
class DerivedClassName(BaseClassName):
    <statement-1>
    .
    .
    .
    <statement-N>
基底クラス (base class) の名前 BaseClassName は、派生クラス定義の入っているスコープで定義されていなければなりません。基底クラス名のかわりに任意の式を入れることもできます。これは次の例のように、基底クラスが別モジュールで定義されているときに便利なことがあります:
class DerivedClassName(modname.BaseClassName):
派生クラス定義の実行は、基底クラスの場合と同じように進められます。クラスオブジェクトが構築される時、基底クラスが記憶されます。記憶された基底クラスは、属性参照を解決するために使われます。要求された属性がクラスに見つからなかった場合、基底クラスに検索が進みます。この規則は、基底クラスが他の何らかのクラスから派生したものであった場合、再帰的に適用されます。
派生クラスのインスタンス化では、特別なことは何もありません。 DerivedClassName() はクラスの新たなインスタンスを生成します。メソッドの参照は次のようにして解決されます。まず対応するクラス属性が検索されます。検索は、必要に応じ、基底クラス連鎖を下って行われ、検索の結果として何らかの関数オブジェクトがもたらされた場合、メソッド参照は有効なものとなります。
派生クラスは基底クラスのメソッドを上書き (override) することができます。メソッドは同じオブジェクトの別のメソッドを呼び出す際に何ら特殊な権限を持ちません。このため、ある基底クラスのメソッドが、同じ基底クラスで定義されているもう一つのメソッド呼び出しを行っている場合、派生クラスで上書きされた何らかのメソッドが呼び出されることになるかもしれません。 (C++ プログラマへ: Python では、すべてのメソッドは事実上 virtual です。)
派生クラスで上書きしているメソッドでは、基底クラスの同名のメソッドを置き換えるのではなく、拡張したいのかもしれません。基底クラスのメソッドを直接呼び出す簡単な方法があります。単に BaseClassName.methodname(self, arguments) を呼び出すだけです。この仕様は、場合によってはクライアントでも役に立ちます。 (この呼び出し方が動作するのは、基底クラスがグローバルスコープの BaseClassName という名前でアクセスできるときだけです。)
Python には継承に関係する 2 つの組み込み関数があります:
isinstance() を使うとインスタンスの型が調べられます。 isinstance(obj, int) は obj.__class__ が int や int の派生クラスの場合に限り True になります。
issubclass() を使うとクラスの継承関係が調べられます。 bool は int のサブクラスなので issubclass(bool, int) は True です。しかし、 float は int のサブクラスではないので issubclass(float, int) は False です。
9.5.1. 多重継承
Python では、多重継承 (multiple inheritance) の形式もサポートしています。複数の基底クラスをもつクラス定義は次のようになります:
class DerivedClassName(Base1, Base2, Base3):
    <statement-1>
    .
    .
    .
    <statement-N>
ほとんどのシンプルな多重継承において、親クラスから継承される属性の検索は、深さ優先で、左から右に、そして継承の階層の中で同じクラスが複数出てくる（訳注: ダイアモンド継承と呼ばれます）場合に２度探索をしない、と考えることができます。なので、 DerivedClassName にある属性が存在しない場合、まず Base1 から検索され、そして（再帰的に） Base1 の基底クラスから検索され、それでも見つからなかった場合は Base2 から検索される、といった具合になります。
実際には、それよりもう少しだけ複雑です。協調的な super() の呼び出しのためにメソッドの解決順序は動的に変更されます。このアプローチは他の多重継承のある言語で call-next-method として知られており、単一継承しかない言語の super 呼び出しよりも強力です。
多重継承の全ての場合に 1 つかそれ以上のダイヤモンド継承 (少なくとも 1 つの祖先クラスに対し最も下のクラスから到達する経路が複数ある状態) があるので、動的順序付けが必要です。例えば、全ての新形式のクラスは object を継承しているので、どの多重継承でも object へ到達するための道は複数存在します。基底クラスが複数回アクセスされないようにするために、動的アルゴリズムで検索順序を直列化し、各クラスで指定されている祖先クラスどうしの左から右への順序は崩さず、各祖先クラスを一度だけ呼び出し、かつ一様になる (つまり祖先クラスの順序に影響を与えずにサブクラス化できる) ようにします。まとめると、これらの特徴のおかげで信頼性と拡張性のある多重継承したクラスを設計することができるのです。さらに詳細を知りたければ、 https://www.python.org/download/releases/2.3/mro/ を見てください。
9.6. プライベート変数
オブジェクトの中からしかアクセス出来ない "プライベート" インスタンス変数は、 Python にはありません。しかし、ほとんどの Python コードが従っている慣習があります。アンダースコアで始まる名前 (例えば _spam) は、 (関数であれメソッドであれデータメンバであれ) 非 public なAPIとして扱います。これらは、予告なく変更されるかもしれない実装の詳細として扱われるべきです。
クラスのプライベートメンバについて適切なユースケース(特にサブクラスで定義された名前との衝突を避ける場合)があるので、名前マングリング (name mangling) と呼ばれる、限定されたサポート機構があります。 __spam (先頭に二個以上の下線文字、末尾に一個以下の下線文字) という形式の識別子は、 _classname__spam へとテキスト置換されるようになりました。ここで classname は、現在のクラス名から先頭の下線文字をはぎとった名前になります。このような難号化 (mangle) は、識別子の文法的な位置にかかわらず行われるので、クラス定義内に現れた識別子全てに対して実行されます。
名前マングリングは、サブクラスが内部のメソッド呼び出しを壊さずにメソッドをオーバーライドするのに便利です。例えば:
class Mapping:
    def __init__(self, iterable):
        self.items_list = []
        self.__update(iterable)
    def update(self, iterable):
        for item in iterable:
            self.items_list.append(item)
    __update = update   # private copy of original update() method
class MappingSubclass(Mapping):
    def update(self, keys, values):
        # provides new signature for update()
        # but does not break __init__()
        for item in zip(keys, values):
            self.items_list.append(item)
上の例は、もし仮に MappingSubclass に __update 識別子を実装したとしてもきちんと動きます。 その理由は、 Mapping クラスではその識別子を _Mapping__update に、 MappingSubclass クラスでは _MappingSubclass__update にそれぞれ置き換えるからです。
難号化の規則は主に不慮の事故を防ぐためのものだということに注意してください; 確信犯的な方法で、プライベートとされている変数にアクセスしたり変更することは依然として可能なのです。デバッガのような特殊な状況では、この仕様は便利ですらあります。
exec() や eval() へ渡されたコードでは、呼出し元のクラス名を現在のクラスと見なさないことに注意してください。この仕様は global 文の効果と似ており、その効果もまた同様に、バイトコンパイルされたコードに制限されています。同じ制約が getattr() と setattr() と delattr() にも適用されます。また、__dict__ を直接参照するときにも適用されます。
9.7. 残りのはしばし
Pascal の "レコード (record)" や、C 言語の "構造体 (struct)" のような、名前つきのデータ要素を一まとめにするデータ型があると便利なことがあります。空のクラス定義を使うとうまくできます:
class Employee:
    pass
john = Employee()  # Create an empty employee record
# Fill the fields of the record
john.name = 'John Doe'
john.dept = 'computer lab'
john.salary = 1000
ある特定の抽象データ型を要求する Python コードの断片に、そのデータ型のメソッドをエミュレーションするクラスを代わりに渡すことができます。例えば、ファイルオブジェクトから何らかのデータを構築する関数がある場合、 read() と readline() を持つクラスを定義して、ファイルではなく文字列バッファからデータを取得するようにしておき、引数として渡すことができます。
インスタンスメソッドオブジェクトにも属性があります。 m.__self__ はメソッド m() の属しているインスタンスオブジェクトで、 m.__func__ はメソッドに対応する関数オブジェクトです。
9.8. イテレータ (iterator)
すでに気づいているでしょうが、 for 文を使うとほとんどのコンテナオブジェクトにわたってループを行うことができます:
for element in [1, 2, 3]:
    print(element)
for element in (1, 2, 3):
    print(element)
for key in {'one':1, 'two':2}:
    print(key)
for char in "123":
    print(char)
for line in open("myfile.txt"):
    print(line, end='')
こういう要素へのアクセス方法は明確で簡潔で使い易いものです。イテレータの活用は Python へ広く行き渡り、統一感を持たせています。裏では for 文はコンテナオブジェクトに対して iter() 関数を呼んでいます。関数は、コンテナの中の要素に1つずつアクセスする __next__() メソッドが定義されているイテレータオブジェクトを返します。これ以上要素が無い場合は、 __next__() メソッドは StopIteration 例外を送出し、その通知を受け for ループは終了します。組み込みの next() 関数を使って __next__() メソッドを直接呼ぶこともできます; この例は関数がどう働くのかを示しています:
>>>
>>> s = 'abc'
>>> it = iter(s)
>>> it
<iterator object at 0x00A1DB50>
>>> next(it)
'a'
>>> next(it)
'b'
>>> next(it)
'c'
>>> next(it)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
    next(it)
StopIteration
イテレータプロトコルの裏にある仕組みを観察していれば、自作のクラスにイテレータとしての振舞いを追加するのは簡単です。 __next__() メソッドを持つオブジェクトを返す __iter__() メソッドを定義するのです。クラスが __next__() メソッドを定義している場合、 __iter__() メソッドは単に self を返すことも可能です:
class Reverse:
    """Iterator for looping over a sequence backwards."""
    def __init__(self, data):
        self.data = data
        self.index = len(data)
    def __iter__(self):
        return self
    def __next__(self):
        if self.index == 0:
            raise StopIteration
        self.index = self.index - 1
        return self.data[self.index]
>>>
>>> rev = Reverse('spam')
>>> iter(rev)
<__main__.Reverse object at 0x00A1DB50>
>>> for char in rev:
...     print(char)
...
m
a
p
s
9.9. ジェネレータ (generator)
Generators are a simple and powerful tool for creating iterators. They are written like regular functions but use the yield statement whenever they want to return data. Each time next() is called on it, the generator resumes where it left off (it remembers all the data values and which statement was last executed). An example shows that generators can be trivially easy to create:
def reverse(data):
    for index in range(len(data)-1, -1, -1):
        yield data[index]
>>>
>>> for char in reverse('golf'):
...     print(char)
...
f
l
o
g
ジェネレータでできることは、前の節で解説したクラスを使ったイテレータでも実現できます。ジェネレータの定義がコンパクトになるのは __iter__() メソッドと __next__() メソッドが自動で作成されるからです。
ジェネレータのもう一つの重要な機能は、呼び出しごとにローカル変数と実行状態が自動的に保存されるということです。これにより、 self.index や self.data といったインスタンス変数を使ったアプローチよりも簡単に関数を書くことができるようになります。
メソッドを自動生成したりプログラムの実行状態を自動保存するほかに、ジェネレータは終了時に自動的に StopIteration を送出します。これらの機能を組み合わせると、通常の関数を書くのと同じ労力で、簡単にイテレータを生成できます。
9.10. ジェネレータ式
単純なジェネレータなら式として簡潔にコーディングできます。 その式はリスト内包表記に似た構文を使いますが、角括弧ではなく丸括弧で囲います。 ジェネレータ式は、関数の中でジェネレータをすぐに使いたいような状況のために用意されています。 ジェネレータ式は完全なジェネレータの定義よりコンパクトですが、ちょっと融通の効かないところがあります。 同じ内容を返すリスト内包表記よりはメモリに優しいことが多いという利点があります。
例:
>>>
>>> sum(i*i for i in range(10))                 # sum of squares
285
>>> xvec = [10, 20, 30]
>>> yvec = [7, 5, 3]
>>> sum(x*y for x,y in zip(xvec, yvec))         # dot product
260
>>> unique_words = set(word for line in page  for word in line.split())
>>> valedictorian = max((student.gpa, student.name) for student in graduates)
>>> data = 'golf'
>>> list(data[i] for i in range(len(data)-1, -1, -1))
['f', 'l', 'o', 'g']
10. 標準ライブラリミニツアー
10.1. OSへのインタフェース
os モジュールは、オペレーティングシステムと対話するための多くの関数を提供しています:
>>>
>>> import os
>>> os.getcwd()      # Return the current working directory
'C:\\Python39'
>>> os.chdir('/server/accesslogs')   # Change current working directory
>>> os.system('mkdir today')   # Run the command mkdir in the system shell
0
from os import * ではなく、 import os 形式を使うようにしてください。そうすることで、動作が大きく異なる組み込み関数 open() が os.open() で遮蔽されるのを避けられます。
組み込み関数 dir() および help() は、 os のような大規模なモジュールで作業をするときに、対話的な操作上の助けになります:
>>>
>>> import os
>>> dir(os)
<returns a list of all module functions>
>>> help(os)
<returns an extensive manual page created from the module's docstrings>
ファイルやディレクトリの日常的な管理作業のために、より簡単に使える高水準のインタフェースが shutil モジュールで提供されています:
>>>
>>> import shutil
>>> shutil.copyfile('data.db', 'archive.db')
'archive.db'
>>> shutil.move('/build/executables', 'installdir')
'installdir'
10.2. ファイルのワイルドカード表記
glob モジュールでは、ディレクトリのワイルドカード検索からファイルのリストを生成するための関数を提供しています:
>>>
>>> import glob
>>> glob.glob('*.py')
['primes.py', 'random.py', 'quote.py']
10.3. コマンドライン引数
一般的なユーティリティスクリプトでは、よくコマンドライン引数を扱う必要があります。コマンドライン引数は sys モジュールの argv 属性にリストとして保存されています。例えば、以下の出力は、 python demo.py one two three とコマンドライン上で起動した時に得られるものです:
>>>
>>> import sys
>>> print(sys.argv)
['demo.py', 'one', 'two', 'three']
argparse モジュールは、コマンドライン引数を処理するための更に洗練された仕組みを提供します。次のスクリプトは1つ以上のファイル名を抽出し、オプションで行数を表示します。
import argparse
parser = argparse.ArgumentParser(prog = 'top',
    description = 'Show top lines from each file')
parser.add_argument('filenames', nargs='+')
parser.add_argument('-l', '--lines', type=int, default=10)
args = parser.parse_args()
print(args)
コマンドラインで python top.py --lines=5 alpha.txt beta.txt を実行すると、上のスクリプトは args.lines を 5 、 args.filenames を ['alpha.txt', 'beta.txt'] に設定します。
10.4. エラー出力のリダイレクトとプログラムの終了
sys モジュールには、 stdin, stdout, stderr を表す属性も存在します。 stderr は、警告やエラーメッセージを出力して、 stdout がリダイレクトされた場合でも読めるようにするために便利です:
>>>
>>> sys.stderr.write('Warning, log file not found starting a new one\n')
Warning, log file not found starting a new one
sys.exit() は、スクリプトを終了させるもっとも直接的な方法です。
10.5. 文字列のパターンマッチング
re モジュールでは、より高度な文字列処理のための正規表現を提供しています。正規表現は複雑な一致検索や操作に対して簡潔で最適化された解決策を提供します:
>>>
>>> import re
>>> re.findall(r'\bf[a-z]*', 'which foot or hand fell fastest')
['foot', 'fell', 'fastest']
>>> re.sub(r'(\b[a-z]+) \1', r'\1', 'cat in the the hat')
'cat in the hat'
最小限の機能だけが必要なら、読みやすくデバッグしやすい文字列メソッドの方がお勧めです:
>>>
>>> 'tea for too'.replace('too', 'two')
'tea for two'
10.6. 数学
math モジュールは、浮動小数点演算のための C 言語ライブラリ関数にアクセスする手段を提供しています:
>>>
>>> import math
>>> math.cos(math.pi / 4)
0.70710678118654757
>>> math.log(1024, 2)
10.0
random モジュールは、乱数に基づいた要素選択のためのツールを提供しています:
>>>
>>> import random
>>> random.choice(['apple', 'pear', 'banana'])
'apple'
>>> random.sample(range(100), 10)   # sampling without replacement
[30, 83, 16, 4, 8, 81, 41, 50, 18, 33]
>>> random.random()    # random float
0.17970987693706186
>>> random.randrange(6)    # random integer chosen from range(6)
4
statistics モジュールは数値データの基礎的な統計的特性（平均、中央値、分散等）を計算します:
>>>
>>> import statistics
>>> data = [2.75, 1.75, 1.25, 0.25, 0.5, 1.25, 3.5]
>>> statistics.mean(data)
1.6071428571428572
>>> statistics.median(data)
1.25
>>> statistics.variance(data)
1.3720238095238095
SciPy プロジェクト <https://scipy.org> は数値処理のための多くのモジュールを提供しています。
10.7. インターネットへのアクセス
インターネットにアクセスしたりインターネットプロトコルを処理したりするための多くのモジュールがあります。最も単純な2つのモジュールは、 URL からデータを取得するための urllib.request と、メールを送るための smtplib です:
>>>
>>> from urllib.request import urlopen
>>> with urlopen('http://tycho.usno.navy.mil/cgi-bin/timer.pl') as response:
...     for line in response:
...         line = line.decode('utf-8')  # Decoding the binary data to text.
...         if 'EST' in line or 'EDT' in line:  # look for Eastern Time
...             print(line)
<BR>Nov. 25, 09:43:32 PM EST
>>> import smtplib
>>> server = smtplib.SMTP('localhost')
>>> server.sendmail('soothsayer@example.org', 'jcaesar@example.org',
... """To: jcaesar@example.org
... From: soothsayer@example.org
...
... Beware the Ides of March.
... """)
>>> server.quit()
(2つ目の例は localhost でメールサーバーが動いている必要があることに注意してください。)
10.8. 日付と時刻
datetime モジュールは、日付や時刻を操作するためのクラスを、単純な方法と複雑な方法の両方で提供しています。日付や時刻に対する算術がサポートされている一方、実装では出力のフォーマットや操作のための効率的なデータメンバ抽出に重点を置いています。このモジュールでは、タイムゾーンに対応したオブジェクトもサポートしています。
>>>
>>> # dates are easily constructed and formatted
>>> from datetime import date
>>> now = date.today()
>>> now
datetime.date(2003, 12, 2)
>>> now.strftime("%m-%d-%y. %d %b %Y is a %A on the %d day of %B.")
'12-02-03. 02 Dec 2003 is a Tuesday on the 02 day of December.'
>>> # dates support calendar arithmetic
>>> birthday = date(1964, 7, 31)
>>> age = now - birthday
>>> age.days
14368
10.9. データ圧縮
一般的なデータアーカイブと圧縮形式は、以下のようなモジュールによって直接的にサポートされます: zlib, gzip, bz2, lzma, zipfile, tarfile。
>>>
>>> import zlib
>>> s = b'witch which has which witches wrist watch'
>>> len(s)
41
>>> t = zlib.compress(s)
>>> len(t)
37
>>> zlib.decompress(t)
b'witch which has which witches wrist watch'
>>> zlib.crc32(s)
226805979
10.10. パフォーマンスの計測
Python ユーザの中には、同じ問題を異なったアプローチで解いた際の相対的なパフォーマンスについて知りたいという深い興味を持っている人がいます。Python は、そういった疑問に即座に答える計測ツールを提供しています。
例えば、引数の入れ替え操作に対して、伝統的なアプローチの代わりにタプルのパックやアンパックを使ってみたいと思うかもしれません。 timeit モジュールを使えば、パフォーマンスがほんの少し良いことがすぐに分かります:
>>>
>>> from timeit import Timer
>>> Timer('t=a; a=b; b=t', 'a=1; b=2').timeit()
0.57535828626024577
>>> Timer('a,b = b,a', 'a=1; b=2').timeit()
0.54962537085770791
timeit では小さい粒度を提供しているのに対し、 profile や pstats モジュールではより大きなコードブロックにおいて律速となる部分を判定するためのツールを提供しています。
10.11. 品質管理
高い品質のソフトウェアを開発するための一つのアプローチは、各関数に対して開発と同時にテストを書き、開発の過程で頻繁にテストを走らせるというものです。
doctest モジュールでは、モジュールを検索してプログラムの docstring に埋め込まれたテストの評価を行うためのツールを提供しています。テストの作り方は単純で、典型的な呼び出し例とその結果を docstring にカット&ペーストするだけです。この作業は、ユーザに使用例を与えるという意味でドキュメントの情報を増やすと同時に、ドキュメントに書かれているコードが正しい事を確認できるようになります:
def average(values):
    """Computes the arithmetic mean of a list of numbers.
    >>> print(average([20, 30, 70]))
    40.0
    """
    return sum(values) / len(values)
import doctest
doctest.testmod()   # automatically validate the embedded tests
unittest モジュールは doctest モジュールほど気楽に使えるものではありませんが、より網羅的なテストセットを別のファイルで管理することができます:
import unittest
class TestStatisticalFunctions(unittest.TestCase):
    def test_average(self):
        self.assertEqual(average([20, 30, 70]), 40.0)
        self.assertEqual(round(average([1, 5, 7]), 1), 4.3)
        with self.assertRaises(ZeroDivisionError):
            average([])
        with self.assertRaises(TypeError):
            average(20, 30, 70)
unittest.main()  # Calling from the command line invokes all tests
10.12. バッテリー同梱
Python には "バッテリー同梱 (batteries included)" 哲学があります。この哲学は、洗練され、安定した機能を持つ Python の膨大なパッケージ群に如実に表れています。例えば:
xmlrpc.client および xmlrpc.server モジュールは、遠隔手続き呼び出し (remote procedure call) を全く大したことのない作業に変えてしまいます。モジュール名とは違い、XML を扱うための直接的な知識は必要ありません。
email パッケージは、MIME やその他の RFC 2822 に基づくメッセージ文書を含む電子メールメッセージを管理するためのライブラリです。実際にメッセージを送信したり受信したりする smtplib や poplib と違って、email パッケージには (添付文書を含む) 複雑なメッセージ構造の構築やデコードを行ったり、インターネット標準のエンコードやヘッダプロトコルの実装を行ったりするための完全なツールセットを備えています。
json パッケージはこの一般的なデータ交換形式のパースをロバストにサポートしています。csv モジュールはデータベースや表計算で一般的にサポートされている CSV ファイルを直接読み書きするのをサポートしています。xml.etree.ElementTree、xml.dom ならびに xml.sax パッケージは XML の処理をサポートしています。総合すると、これらのモジュールによって Python アプリケーションと他のツールの間でとても簡単にデータを受け渡すことが出来ます。
sqlite3 モジュールは SQLite データベースライブラリのラッパです。若干非標準の SQL シンタックスを用いて更新や接続出来る永続的なデータベースを提供します。
国際化に関する機能は、 gettext, locale, codecs パッケージといったモジュール群でサポートされています。
11. 標準ライブラリミニツアー --- その 2
ツアーの第2部では、プロフェッショナルプログラミングを支えるもっと高度なモジュールをカバーします。ここで挙げるモジュールは、小さなスクリプトの開発ではほとんど使いません。
11.1. 出力のフォーマット
reprlib モジュールは、大きなコンテナや、深くネストしたコンテナを省略して表示するバージョンの repr() を提供しています:
>>>
>>> import reprlib
>>> reprlib.repr(set('supercalifragilisticexpialidocious'))
"{'a', 'c', 'd', 'e', 'f', 'g', ...}"
pprint モジュールは、組み込み型やユーザ定義型をわかりやすく表示するための洗練された制御手段を提供しています。表示結果が複数行にわたる場合は、 "pretty printer" と呼ばれるものが改行やインデントを追加して、データ構造がより明確になるように印字します:
>>>
>>> import pprint
>>> t = [[[['black', 'cyan'], 'white', ['green', 'red']], [['magenta',
...     'yellow'], 'blue']]]
...
>>> pprint.pprint(t, width=30)
[[[['black', 'cyan'],
   'white',
   ['green', 'red']],
  [['magenta', 'yellow'],
   'blue']]]
textwrap モジュールは、段落で構成された文章を、指定したスクリーン幅にぴったり収まるように調整します:
>>>
>>> import textwrap
>>> doc = """The wrap() method is just like fill() except that it returns
... a list of strings instead of one big string with newlines to separate
... the wrapped lines."""
...
>>> print(textwrap.fill(doc, width=40))
The wrap() method is just like fill()
except that it returns a list of strings
instead of one big string with newlines
to separate the wrapped lines.
locale モジュールは、文化により異なるデータ表現形式のデータベースにアクセスします。 locale の format() 関数の grouping 属性を使えば、数値を適切な桁区切り文字によりグループ化された形式に変換できます:
>>>
>>> import locale
>>> locale.setlocale(locale.LC_ALL, 'English_United States.1252')
'English_United States.1252'
>>> conv = locale.localeconv()          # get a mapping of conventions
>>> x = 1234567.8
>>> locale.format("%d", x, grouping=True)
'1,234,567'
>>> locale.format_string("%s%.*f", (conv['currency_symbol'],
...                      conv['frac_digits'], x), grouping=True)
'$1,234,567.80'
11.2. 文字列テンプレート
string モジュールには、柔軟で、エンドユーザが簡単に編集できる簡単な構文を備えた Template クラスが入っています。このクラスを使うと、ユーザがアプリケーションを修正することなしにアプリケーションの出力をカスタマイズできるようになります。
テンプレートでは、$ と有効な Python 識別子名 (英数字とアンダースコア) からなるプレースホルダ名を使います。プレースホルダの周りを {} で囲えば、プレースホルダの後ろにスペースを挟まず、英数文字を続けることができます。$$ のようにすると、$ 自体をエスケープできます:
>>>
>>> from string import Template
>>> t = Template('${village}folk send $$10 to $cause.')
>>> t.substitute(village='Nottingham', cause='the ditch fund')
'Nottinghamfolk send $10 to the ditch fund.'
substitute() メソッドは、プレースホルダに相当する値が辞書やキーワード引数にない場合に KeyError を送出します。メールマージ機能のようなアプリケーションの場合、ユーザが入力するデータは不完全なことがあるので、欠落したデータがあるとプレースホルダをそのままにして出力する safe_substitute() メソッドを使う方が適切かもしれません:
>>>
>>> t = Template('Return the $item to $owner.')
>>> d = dict(item='unladen swallow')
>>> t.substitute(d)
Traceback (most recent call last):
  ...
KeyError: 'owner'
>>> t.safe_substitute(d)
'Return the unladen swallow to $owner.'
区切り文字はデフォルトは $ ですが、Template のサブクラスを派生すると変更することができます。例えば、画像ブラウザ用に一括で名前を変更するユーティリティを作っていたとして、現在の日付や画像のシーケンス番号、ファイル形式といったプレースホルダにパーセント記号を使うことにしたら、次のようになります:
>>>
>>> import time, os.path
>>> photofiles = ['img_1074.jpg', 'img_1076.jpg', 'img_1077.jpg']
>>> class BatchRename(Template):
...     delimiter = '%'
>>> fmt = input('Enter rename style (%d-date %n-seqnum %f-format):  ')
Enter rename style (%d-date %n-seqnum %f-format):  Ashley_%n%f
>>> t = BatchRename(fmt)
>>> date = time.strftime('%d%b%y')
>>> for i, filename in enumerate(photofiles):
...     base, ext = os.path.splitext(filename)
...     newname = t.substitute(d=date, n=i, f=ext)
...     print('{0} --> {1}'.format(filename, newname))
img_1074.jpg --> Ashley_0.jpg
img_1076.jpg --> Ashley_1.jpg
img_1077.jpg --> Ashley_2.jpg
テンプレートのもう一つの用途は、複数ある出力フォーマットからのプログラムロジックの分離です。これにより、XMLファイル用、プレーンテキストのレポート用、HTMLのwebレポート用のテンプレートに、同じプログラムロジックから値を埋め込むことができます。
11.3. バイナリデータレコードの操作
struct モジュールでは、様々な長さのバイナリレコード形式を操作する pack() や unpack() といった関数を提供しています。 以下の例では、 zipfile モジュールを使わずに、ZIP ファイルのヘッダ情報を巡回する方法を示しています。"H" と "I" というパック符号は、それぞれ2バイトと4バイトの符号無し 整数を表しています。 "<" は、そのパック符号が standard サイズであり、バイトオーダーがリトルエンディアンであることを示しています:
import struct
with open('myfile.zip', 'rb') as f:
    data = f.read()
start = 0
for i in range(3):                      # show the first 3 file headers
    start += 14
    fields = struct.unpack('<IIIHH', data[start:start+16])
    crc32, comp_size, uncomp_size, filenamesize, extra_size = fields
    start += 16
    filename = data[start:start+filenamesize]
    start += filenamesize
    extra = data[start:start+extra_size]
    print(filename, hex(crc32), comp_size, uncomp_size)
    start += extra_size + comp_size     # skip to the next header
11.4. マルチスレッディング
スレッド処理 (threading) とは、順序的な依存関係にない複数のタスクを分割するテクニックです。スレッドは、ユーザの入力を受け付けつつ、背後で別のタスクを動かすようなアプリケーションの応答性を高めます。同じような使用例として、I/O を別のスレッドの計算処理と並列して動作させるというものがあります。
以下のコードでは、高水準のモジュール threading でメインのプログラムを動かしながら背後で別のタスクを動作させられるようにする方法を示しています:
import threading, zipfile
class AsyncZip(threading.Thread):
    def __init__(self, infile, outfile):
        threading.Thread.__init__(self)
        self.infile = infile
        self.outfile = outfile
    def run(self):
        f = zipfile.ZipFile(self.outfile, 'w', zipfile.ZIP_DEFLATED)
        f.write(self.infile)
        f.close()
        print('Finished background zip of:', self.infile)
background = AsyncZip('mydata.txt', 'myarchive.zip')
background.start()
print('The main program continues to run in foreground.')
background.join()    # Wait for the background task to finish
print('Main program waited until background was done.')
マルチスレッドアプリケーションを作る上で最も難しい問題は、データやリソースを共有するスレッド間の調整 (coordination)です。この問題を解決するため、threading モジュールではロックやイベント、状態変数、セマフォといった数々の同期プリミティブを提供しています。
こうしたツールは強力な一方、ちょっとした設計上の欠陥で再現困難な問題を引き起こすことがあります。したがって、タスク間調整では queue モジュールを使って他の複数のスレッドからのリクエストを一つのスレッドに送り込み、一つのリソースへのアクセスをできるだけ一つのスレッドに集中させるほうが良いでしょう。スレッド間の通信や調整に Queue オブジェクトを使うと、設計が容易になり、可読性が高まり、信頼性が増します。
11.5. ログ記録
logging モジュールでは、数多くの機能をそなえた柔軟性のあるログ記録システムを提供しています。最も簡単な使い方では、ログメッセージをファイルや sys.stderr に送信します:
import logging
logging.debug('Debugging information')
logging.info('Informational message')
logging.warning('Warning:config file %s not found', 'server.conf')
logging.error('Error occurred')
logging.critical('Critical error -- shutting down')
これは以下の出力を生成します:
WARNING:root:Warning:config file server.conf not found
ERROR:root:Error occurred
CRITICAL:root:Critical error -- shutting down
デフォルトでは、info() と debug() による出力は抑制され、出力は標準エラーに送信されます。選択可能な送信先には、email、データグラム、ソケット、HTTP サーバへの送信などがあります。新たにフィルタを作成すると、DEBUG、INFO、WARNING、ERROR、CRITICAL といったメッセージのプライオリティによって異なる送信先を選択することができます。
ログ記録システムは Python から直接設定することもできますし、アプリケーションを変更しなくてもカスタマイズできるよう、ユーザが編集可能な設定ファイルによって設定することもできます。
11.6. 弱参照
Python は自動的にメモリを管理します (ほとんどのオブジェクトは参照カウント方式で管理し、 ガベージコレクション で循環参照を除去します)。オブジェクトに対する最後の参照がなくなってしばらくするとメモリは解放されます。
このようなアプローチはほとんどのアプリケーションでうまく動作しますが、中にはオブジェクトをどこか別の場所で利用している間だけ追跡しておきたい場合もあります。残念ながら、オブジェクトを追跡するだけでオブジェクトに対する恒久的な参照を作ることになってしまいます。 weakref モジュールでは、オブジェクトへの参照を作らずに追跡するためのツールを提供しています。弱参照オブジェクトが不要になると、弱参照 (weakref) テーブルから自動的に除去され、コールバック関数がトリガされます。弱参照を使う典型的な応用例には、作成コストの大きいオブジェクトのキャッシュがあります:
>>>
>>> import weakref, gc
>>> class A:
...     def __init__(self, value):
...         self.value = value
...     def __repr__(self):
...         return str(self.value)
...
>>> a = A(10)                   # create a reference
>>> d = weakref.WeakValueDictionary()
>>> d['primary'] = a            # does not create a reference
>>> d['primary']                # fetch the object if it is still alive
10
>>> del a                       # remove the one reference
>>> gc.collect()                # run garbage collection right away
0
>>> d['primary']                # entry was automatically removed
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
    d['primary']                # entry was automatically removed
  File "C:/python39/lib/weakref.py", line 46, in __getitem__
    o = self.data[key]()
KeyError: 'primary'
11.7. リスト操作のためのツール
多くのデータ構造は、組み込みリスト型を使った実装で事足ります。とはいえ、時には組み込みリストとは違うパフォーマンス上のトレードオフを持つような実装が必要になこともあります。
array (配列) モジュールでは、array() オブジェクトを提供しています。配列はリストに似ていますが、同じ形式のデータだけが保存でき、よりコンパクトに保存されます。以下の例では、通常 1 要素あたり 16 バイトを必要とする Python 整数型のリストの 代りに、2 バイトの符号無しの 2 進数 (タイプコード "H") の配列を使っています:
>>>
>>> from array import array
>>> a = array('H', [4000, 10, 700, 22222])
>>> sum(a)
26932
>>> a[1:3]
array('H', [10, 700])
collections モジュールでは、deque() オブジェクトを提供しています。リスト型に似ていますが、データの追加と左端からの取り出しが速く、その一方で中間にある値の参照は遅くなります。こうしたオブジェクトはキューや木構造の幅優先探索の実装に向いています:
>>>
>>> from collections import deque
>>> d = deque(["task1", "task2", "task3"])
>>> d.append("task4")
>>> print("Handling", d.popleft())
Handling task1
unsearched = deque([starting_node])
def breadth_first_search(unsearched):
    node = unsearched.popleft()
    for m in gen_moves(node):
        if is_goal(m):
            return m
        unsearched.append(m)
リストの代わりの実装以外にも、標準ライブラリにはソート済みのリストを操作するための関数を備えた bisect のようなツールも提供しています:
>>>
>>> import bisect
>>> scores = [(100, 'perl'), (200, 'tcl'), (400, 'lua'), (500, 'python')]
>>> bisect.insort(scores, (300, 'ruby'))
>>> scores
[(100, 'perl'), (200, 'tcl'), (300, 'ruby'), (400, 'lua'), (500, 'python')]
heapq モジュールは、通常のリストでヒープを実装するための関数を提供しています。ヒープでは、最も低い値をもつエントリがつねにゼロの位置に配置されます。ヒープは、毎回リストをソートすることなく、最小の値をもつ要素に繰り返しアクセスするようなアプリケーションで便利です:
>>>
>>> from heapq import heapify, heappop, heappush
>>> data = [1, 3, 5, 7, 9, 2, 4, 6, 8, 0]
>>> heapify(data)                      # rearrange the list into heap order
>>> heappush(data, -5)                 # add a new entry
>>> [heappop(data) for i in range(3)]  # fetch the three smallest entries
[-5, 0, 1]
11.8. 10 進浮動小数演算
decimal モジュールでは、 10 進浮動小数の算術演算をサポートする Decimal データ型を提供しています。組み込みの 2 進浮動小数の実装である float に比べて、このクラスがとりわけ便利なのは、以下の場合です
財務アプリケーションやその他の正確な10進表記が必要なアプリケーション、
精度の制御、
法的または規制上の理由に基づく値丸めの制御、
有効桁数の追跡が必要になる場合
ユーザが手計算の結果と同じ演算結果を期待するようなアプリケーション。
例えば、70 セントの電話代にかかる 5% の税金を計算しようとすると、10 進の浮動小数点値と 2 進の浮動小数点値では違う結果になってしまいます。計算結果を四捨五入してセント単位にしようとすると、以下のように違いがはっきり現れます:
>>>
>>> from decimal import *
>>> round(Decimal('0.70') * Decimal('1.05'), 2)
Decimal('0.74')
>>> round(.70 * 1.05, 2)
0.73
上の例で、Decimal を使った計算では、末尾桁のゼロが保存されており、有効数字2桁の被乗数から自動的に有効数字を 4 桁と判断しています。Decimal は手計算と 同じ方法で計算を行い、2 進浮動小数が 10 進小数成分を正確に表現できないことに よって起きる問題を回避しています。
Decimal クラスは厳密な値を表現できるため、2 進浮動小数点数では 期待通りに計算できないような剰余の計算や等値テストも実現できます:
>>>
>>> Decimal('1.00') % Decimal('.10')
Decimal('0.00')
>>> 1.00 % 0.10
0.09999999999999995
>>> sum([Decimal('0.1')]*10) == Decimal('1.0')
True
>>> sum([0.1]*10) == 1.0
False
decimal モジュールを使うと、必要なだけの精度で算術演算を行えます:
>>>
>>> getcontext().prec = 36
>>> Decimal(1) / Decimal(7)
Decimal('0.142857142857142857142857142857142857')
12. 仮想環境とパッケージ
12.1. はじめに
Python アプリケーションはよく標準ライブラリ以外のパッケージやモジュールを利用します。またアプリケーションがあるバグ修正を必要としていたり、過去のバージョンのインターフェイスに依存しているために、ライブラリの特定のバージョンを必要とすることもあります。
そのため、1つのインストールされたPythonが全てのアプリケーションの要求に対応することは不可能です。もしアプリケーションAがあるモジュールのバージョン 1.0 を要求していて、別のアプリケーションBが同じモジュールのバージョン 2.0 を要求している場合、2つの要求は衝突していて、1.0 と 2.0 のどちらかのバージョンをインストールしても片方のアプリケーションが動きません。
この問題の解決策は 仮想環境 を作ることです。仮想環境とは、特定のバージョンの Python と幾つかの追加パッケージを含んだ Python インストールを構成するディレクトリです。
別のアプリケーションはそれぞれ別の仮想環境を使うことができます。先の例にあった要求の衝突を解決する場合、アプリケーションAが固有の仮想環境を持ってそこにライブラリのバージョン 1.0 をインストールし、アプリケーションBが持つ別の仮想環境にライブラリのバージョン 2.0 をインストールすることができます。そしてアプリケーションBがライブラリのバージョンを 3.0 に更新することを要求する場合も、アプリケーションAに影響しません。
12.2. 仮想環境の作成
仮想環境の作成と管理を行うためのモジュールが venv です。 venv は通常利用可能なもっとも新しいバージョンの Python をインストールします。複数のバージョンの Python がインストールされている場合、 python3 のように利用したいバージョンを指定して実行することで Python バージョンを選択できます。
仮想環境を作るには、仮想環境を置くディレクトリを決めて、 そのディレクトリのパスを指定して、 venv をスクリプトとして実行します:
python3 -m venv tutorial-env
これは tutorial-env ディレクトリがなければ作成して、その中に Python インタプリタ、標準ライブラリ、その他関連するファイルを含むサブディレクトリを作ります。
仮想環境の一般的なディレクトリの場所は .venv です。この名前は、通常はシェルで隠されているため、ディレクトリが存在する理由を説明する名前を付けても、邪魔にはなりません。また、一部のツールでサポートされている .env 環境変数定義ファイルによるクラッシュも防止します。
仮想環境を作ったら、それを有効化する必要があります。
Windows の場合:
tutorial-env\Scripts\activate.bat
Unix や Mac OS の場合:
source tutorial-env/bin/activate
(このスクリプトは bash shell で書かれています。 csh や fish を利用している場合、代わりに利用できる activate.csh と activate.fish スクリプトがあります。)
仮想環境を有効化すると、シェルのプロンプトに利用中の仮想環境が表示されるようになり、python を実行するとその仮想環境の Python を実行するようになります:
$ source ~/envs/tutorial-env/bin/activate
(tutorial-env) $ python
Python 3.5.1 (default, May  6 2016, 10:59:36)
  ...
>>> import sys
>>> sys.path
['', '/usr/local/lib/python35.zip', ...,
'~/envs/tutorial-env/lib/python3.5/site-packages']
>>>
12.3. pip を使ったパッケージ管理
You can install, upgrade, and remove packages using a program called pip. By default pip will install packages from the Python Package Index, <https://pypi.org>. You can browse the Python Package Index by going to it in your web browser, or you can use pip's limited search feature:
(tutorial-env) $ pip search astronomy
skyfield               - Elegant astronomy for Python
gary                   - Galactic astronomy and gravitational dynamics.
novas                  - The United States Naval Observatory NOVAS astronomy library
astroobs               - Provides astronomy ephemeris to plan telescope observations
...
pip は "search", "install", "uninstall", "freeze" など、いくつかのサブコマンドを持っています。 (pip の完全なドキュメントは Python モジュールのインストール ガイドを参照してください。)
パッケージ名を指定してそのパッケージの最新版をインストールすることができます:
(tutorial-env) $ python -m pip install novas
Collecting novas
  Downloading novas-3.1.1.3.tar.gz (136kB)
Installing collected packages: novas
  Running setup.py install for novas
Successfully installed novas-3.1.1.3
パッケージ名のあとに == とバージョン番号を付けることで、特定のバージョンのパッケージをインストールすることもできます:
(tutorial-env) $ python -m pip install requests==2.6.0
Collecting requests==2.6.0
  Using cached requests-2.6.0-py2.py3-none-any.whl
Installing collected packages: requests
Successfully installed requests-2.6.0
同じコマンドを再び実行した場合、pip は要求されたバージョンがインストール済みだと表示して何もしません。別のバージョン番号を指定すればそのバージョンをインストールしますし、pip install --upgrade を実行すればそのパッケージを最新版に更新します:
(tutorial-env) $ python -m pip install --upgrade requests
Collecting requests
Installing collected packages: requests
  Found existing installation: requests 2.6.0
    Uninstalling requests-2.6.0:
      Successfully uninstalled requests-2.6.0
Successfully installed requests-2.7.0
pip uninstall コマンドに削除するパッケージ名を1つ以上指定します。
pip show は指定されたパッケージの情報を表示します:
(tutorial-env) $ pip show requests
---
Metadata-Version: 2.0
Name: requests
Version: 2.7.0
Home-page: http://python-requests.org
Author: Kenneth Reitz
Author-email: me@kennethreitz.com
License: Apache 2.0
Location: /Users/akuchling/envs/tutorial-env/lib/python3.4/site-packages
Requires:
pip list は仮想環境にインストールされた全てのパッケージを表示します:
(tutorial-env) $ pip list
novas (3.1.1.3)
numpy (1.9.2)
pip (7.0.3)
requests (2.7.0)
setuptools (16.0)
pip freeze はインストールされたパッケージ一覧を、pip install が解釈するフォーマットで生成します。一般的な慣習として、このリストを requirements.txt というファイルに保存します:
(tutorial-env) $ pip freeze > requirements.txt
(tutorial-env) $ cat requirements.txt
novas==3.1.1.3
numpy==1.9.2
requests==2.7.0
requirements.txt をバージョン管理システムにコミットして、アプリケーションの一部として配布することができます。ユーザーは必要なパッケージを install -r でインストールできます:
(tutorial-env) $ python -m pip install -r requirements.txt
Collecting novas==3.1.1.3 (from -r requirements.txt (line 1))
  ...
Collecting numpy==1.9.2 (from -r requirements.txt (line 2))
  ...
Collecting requests==2.7.0 (from -r requirements.txt (line 3))
  ...
Installing collected packages: novas, numpy, requests
  Running setup.py install for novas
Successfully installed novas-3.1.1.3 numpy-1.9.2 requests-2.7.0
pip にはたくさんのオプションがあります。 pip の完全なドキュメントは Python モジュールのインストール を参照してください。パッケージを作成してそれを Python Package Index で公開したい場合、 Python モジュールの配布 ガイドを参照してください。
13. さあ何を？
このチュートリアルを読んだことで、おそらく Python を使ってみようという関心はますます強くなったことでしょう --- 現実世界の問題を解決するために、Python を適用してみたくなったはずです。さて、それではどこで勉強をしたらよいのでしょうか？
このチュートリアルは Python のドキュメンテーションセットの一部です。セットの中の他のドキュメンテーションをいくつか紹介します:
Python 標準ライブラリ:
このマニュアルをざっと眺めておくと便利です。このマニュアルは型、関数、標準ライブラリのモジュールについての完全なリファレンスです。標準的なPython配布物は たくさんの 追加コードを含んでいます。Unix メールボックスの読み込み、HTTPによるドキュメント取得、乱数の生成、コマンドラインオプションの構文解析、CGIプログラムの作成、データ圧縮やその他たくさんのタスクのためのモジュールがあります。ライブラリリファレンスをざっと見ることで、何が利用できるかのイメージをつかむことができます。
Python モジュールのインストール は、他のPythonユーザによって書かれた追加モジュールをどうやってインストールするかを説明しています。
Python 言語リファレンス: Pythonの文法とセマンティクスを詳しく説明しています。読むのは大変ですが、言語の完全なガイドとして有用です。
さらなる Python に関するリソース:
https://www.python.org: メインの Python Web サイト。このサイトには、コード、ドキュメント、そして Web のあちこちの Python に関連したページへのポインタがあります。この Web サイトは世界のあちこちのさまざまな場所、例えばヨーロッパ、日本、オーストラリアなどでミラーされています。地理的な位置によっては、メインのサイトよりミラーのほうが速いかもしれません。
https://docs.python.org: Pythonドキュメントへの素早いアクセスを提供します。
https://pypi.org: Python パッケージインデックス、以前は Cheese Shop 1 という愛称でも呼ばれていました。これは、ユーザ作成のダウンロードできる Python モジュールの索引です。コードのリリースをしたら、ここに登録することで他の人が見つけられます。
https://code.activestate.com/recipes/langs/python/: Python クックブックはコード例、モジュール、実用的なスクリプトの巨大なコレクションです。主要なものは同名の本Python Cookbook (O'Reilly & Associates, ISBN 0-596-00797-3)に収録されています。
http://www.pyvideo.org は学会やユーザグループの会合から Python 関連のビデオのリンクを集めています。
https://scipy.org: Scientific Python プロジェクトは配列の高速な計算・操作モジュールに加え、線形代数、フーリエ変換、非線形ソルバー、乱数分布、統計分析などの多くのパッケージを提供しています。
Python 関連の質問や問題の報告については、ニュースグループ comp.lang.python に投稿するか、またはメーリングリスト python-list@python.org に送ることができます。ニュースグループとメーリングリストはゲートウェイされます。したがって、片方に投稿されたメッセージは、もう片方へ自動的に転送されます。質問(と回答)、新しい機能の提案、新しいモジュールの発表などで、1日に数百通の投稿があります。メーリングリストのアーカイブは https://mail.python.org/pipermail/ で利用可能です。
投稿の前に、必ず よくある質問 (FAQとも呼ばれます) のリストをチェックしてください。 FAQ は繰り返し取り上げられる多くの質問に答えています。あなたの問題に対する解決が既に含まれているかもしれません。
14. 対話入力編集と履歴置換
いくつかのバージョンの Python インタプリタでは、Korn シェルや GNU Bash シェルに見られる機能に似た、現在の入力行に対する編集機能や履歴置換機能をサポートしています。この機能は様々な編集スタイルをサポートしている、GNU Readline ライブラリを使って実装されています。このライブラリには独自のドキュメントがあり、ここでそれを繰り返すつもりはありません。
14.1. タブ補完と履歴編集
変数とモジュール名の補完はインタプリタの起動時に 自動的に有効化されます 。 従って Tab キーは補完機能を呼び出し、Python の文の名前、現在のローカル変数、および利用可能なモジュール名を検索します。string.a のようなドットで区切られた式については、最後の '.' までの式を評価し、結果として得られたオブジェクトの属性から補完候補を示します。 __getattr__() メソッドを持ったオブジェクトが式に含まれている場合、 __getattr__() がアプリケーション定義のコードを実行するかもしれないので注意してください。デフォルトの設定ではあなたのユーザーディレクトリの .python_history という名前のファイルに履歴を保存します。 履歴は次の対話的なインタプリタのセッションで再び利用することができます。
14.2. 対話的インタープリタの代替
この機能は、初期の版のインタープリタに比べれば大きな進歩です。とはいえ、まだいくつかの要望が残されています。例えば、行を継続するときに正しいインデントが提示されたら快適でしょう (パーサは次の行でインデントトークンが必要かどうかを知っています)。補完機構がインタープリタのシンボルテーブルを使ってもよいかもしれません。括弧やクォートなどの対応をチェックする (あるいは指示する) コマンドも有用でしょう。
より優れた対話的インタープリタの代替の一つに IPython があります。このインタープリタは、様々なところで使われていて、タブ補完、オブジェクト探索や先進的な履歴管理といった機能を持っています。他のアプリケーションにカスタマイズされたり、組込まれこともあります。別の優れたインタラクティブ環境としては bpython があります。
15. 浮動小数点演算、その問題と制限
浮動小数点数は、計算機ハードウェアの中では、基数を 2 とする (2進法の) 分数として表現されています。例えば、小数
0.125
は、 1/10 + 2/100 + 5/1000 という値を持ちますが、これと同様に、2 進法の分数
0.001
は 0/2 + 0/4 + 1/8 という値になります。これら二つの分数は同じ値を持っていますが、ただ一つ、最初の分数は基数 10 で記述されており、二番目の分数は基数 2 で記述されていることが違います。
残念なことに、ほとんどの小数は 2 進法の分数として正確に表わすことができません。その結果、一般に、入力した 10 進の浮動小数点数は、 2 進法の浮動小数点数で近似された後、実際にマシンに記憶されます。
最初は基数 10 を使うと問題を簡単に理解できます。分数 1/3 を考えてみましょう。分数 1/3 は、基数 10 の分数として、以下のように近似することができます:
0.3
さらに正確な近似は、
0.33
さらに正確な近似は、
0.333
となり、以後同様です。何個桁数を増やして書こうが、結果は決して厳密な 1/3 にはなりません。しかし、少しづつ正確な近似にはなっていくでしょう。
同様に、基数を 2 とした表現で何桁使おうとも、10 進数の 0.1 は基数を 2 とした小数で正確に表現することはできません。基数 2 では、1/10 は循環小数 (repeating fraction) となります
0.0001100110011001100110011001100110011001100110011...
どこか有限の桁で止めると、近似値を得ることになります。近年の殆どのコンピュータでは float 型は、最上位ビットから数えて最初の 53 ビットを分子、2 の冪乗を分母とした、二進小数で近似されます。1/10 の場合は、二進小数は 3602879701896397 / 2 ** 55 となります。これは、1/10 に近いですが、厳密に同じ値ではありません。
値が表示される方法のために、ほとんどのユーザは、近似に気づきません。Python はマシンに格納されている二進近似値の10進小数での近似値を表示するので、格納されている値が元の10進小数の近似値でしか無いことを忘れがちです。ほとんどのマシンで、もし Python が2進数で近似された 0.1 の近似値をそのまま10進数で表示していたら、その結果は次のようになったでしょう
>>>
>>> 0.1
0.1000000000000000055511151231257827021181583404541015625
これは、ほとんどの人が必要と感じるよりも多すぎる桁数です。なので、Python は丸めた値を表示することで、桁数を扱いやすい範囲にとどめます
>>>
>>> 1 / 10
0.1
表示された結果が正確に 1/10 であるように見えたとしても、実際に格納されている値は最も近く表現できる二進小数であるということだけは覚えておいてください。
幾つかの異なる10進数の値が、同じ2進有理数の近似値を共有しています。例えば、0.1 と 0.10000000000000001 と 0.1000000000000000055511151231257827021181583404541015625 はどれも 3602879701896397 / 2 ** 55 に近似されます。同じ近似値を共有しているので、どの10進数の値も eval(repr(x)) == x という条件を満たしたまま同じように表示されます。
昔の Python は、プロンプトと repr() ビルトイン関数は 17 桁の有効数字を持つ 0.10000000000000001 のような10進数の値を選んで表示していました。 Python 3.1 からは、ほとんどの場面で 0.1 のような最も短い桁数の10進数の値を選ぶようになりました。
この動作は2進数の浮動小数点にとってはごく自然なものです。これは Python のバグではありませんし、あなたのコードのバグでもありません。ハードウェアの浮動小数点演算をサポートしている全ての言語で同じ種類の問題を見つけることができます (いくつかの言語ではデフォルトの、あるいはどの出力モードを選んでも、この差を 表示 しないかもしれませんが)。
よりよい出力のために、文字列フォーマットを利用して有効桁数を制限した10進数表現を得ることができます:
>>>
>>> format(math.pi, '.12g')  # give 12 significant digits
'3.14159265359'
>>> format(math.pi, '.2f')   # give 2 digits after the point
'3.14'
>>> repr(math.pi)
'3.141592653589793'
これが、実際のコンピューター上の値の 表示 を丸めているだけの、いわば錯覚だということを認識しておいてください。
もう一つの錯覚を紹介します。例えば、0.1 が正確には 1/10 ではないために、それを3回足した値もまた正確には 0.3 ではありません:
>>>
>>> .1 + .1 + .1 == .3
False
0.1 はこれ以上 1/10 に近くなることができない値で、 0.3 もまた 3/10 に一番近い値なので、 round() 関数を使って計算前に丸めを行なっても意味がありません:
>>>
>>> round(.1, 1) + round(.1, 1) + round(.1, 1) == round(.3, 1)
False
数字が正確な値に最も近い値になっているとはいえ、 round() 関数を使って計算後の値を丸めることで、不正確な代わりに他の値と比較できるようになる事があります:
>>>
>>> round(.1 + .1 + .1, 10) == round(.3, 10)
True
2 進の浮動小数点数に対する算術演算は、このような意外性をたくさん持っています。 "0.1" に関する問題は、以下の "表現エラー" の章で詳細に説明します。 2 進法の浮動小数点演算にともなうその他のよく知られた意外な事象に関しては The Perils of Floating Point を参照してください。
究極的にいうと、"容易な答えはありません"。ですが、浮動小数点数のことを過度に警戒しないでください！ Python の float 型操作におけるエラーは浮動小数点処理ハードウェアから受けついたものであり、ほとんどのマシン上では一つの演算あたり高々 2**53 分の 1 です。この誤差はほとんどの作業で充分以上のものですが、浮動小数点演算は 10 進の演算ではなく、浮動小数点の演算を新たに行うと、新たな丸め誤差の影響を受けることを心にとどめておいてください。
異常なケースが存在する一方で、普段の浮動小数点演算の利用では、単に最終的な結果の値を必要な 10 進の桁数に丸めて表示するのなら、最終的には期待通りの結果を得ることになるでしょう。たいては str() で十分ですが、きめ細かな制御をしたければ、 書式指定文字列の文法 にある str.format() メソッドのフォーマット仕様を参照してください。
正確な10進数表現が必要となるような場合には、 decimal モジュールを利用してみてください。このモジュールは会計アプリケーションや高精度の計算が求められるアプリケーションに適した、10進数の計算を実装しています。
別の正確な計算方法として、 fractions モジュールが有理数に基づく計算を実装しています (1/3 のような数を正確に表すことができます)。
あなたが浮動小数点演算のヘビーユーザーなら、SciPy プロジェクトが提供している Numerical Python パッケージやその他の数学用パッケージを調べてみるべきです。 <https://scipy.org> を参照してください。
Python は 本当に float の正確な値が必要なレアケースに対応するためのツールを提供しています。 float.as_integer_ratio() メソッドは float の値を有理数として表現します:
>>>
>>> x = 3.14159
>>> x.as_integer_ratio()
(3537115888337719, 1125899906842624)
この分数は正確なので、元の値を完全に復元することができます:
>>>
>>> x == 3537115888337719 / 1125899906842624
True
float.hex() メソッドは float の値を16進数で表現します。この値もコンピューターが持っている正確な値を表現できます:
>>>
>>> x.hex()
'0x1.921f9f01b866ep+1'
この正確な16進数表現はもとの float 値を正確に復元するために使うことができます:
>>>
>>> x == float.fromhex('0x1.921f9f01b866ep+1')
True
この16進数表現は正確なので、値を (プラットフォームにも依存せず) バージョンの異なるPython 間でやり取りしたり、他のこのフォーマットをサポートした言語 (Java や C99 など) と正確にやり取りするのに利用することができます。
別の便利なツールとして、合計処理における精度のロスを緩和してくれる math.fsum() 関数があります。この関数は値を合計値に足し込みながら、 "失われた桁" を管理します。これにより、誤差が最終的な合計値に影響を与えるまで蓄積されなくなり、結果が改善されます:
>>>
>>> sum([0.1] * 10) == 1.0
False
>>> math.fsum([0.1] * 10) == 1.0
True
15.1. 表現エラー
この章では、"0.1" の例について詳細に説明し、このようなケースに対してどのようにすれば正確な分析を自分で行えるかを示します。ここでは、 2 進法表現の浮動小数点数についての基礎的な知識があるものとして話を進めます。
表現エラー(Representation error)は、いくつかの (実際にはほとんどの) 10 進の小数が 2 進法 (基数 2)の分数として表現できないという事実に関係しています。これは Python (あるいは Perl, C, C++, Java, Fortran. およびその他多く) が期待通りの正確な 10 進数を表示できない主要な理由です。
なぜこうなるのでしょうか？ 1/10 は 2 進法の小数で厳密に表現することができません。今日 (2000年11月) のマシンは、ほとんどすべて IEEE-754 浮動小数点演算を使用しており、ほとんどすべてのプラットフォームでは Python の浮動小数点を IEEE-754 における "倍精度(double precision)" に対応付けます。754 の double には 53 ビットの精度を持つ数が入るので、計算機に入力を行おうとすると、可能な限り 0.1 を最も近い値の分数に変換し、J/2**N の形式にしようと努力します。J はちょうど 53 ビットの精度の整数です
1 / 10 ~= J / (2**N)
を書き直すと
J ~= 2**N / 10
となります。 J は厳密に 53 ビットの精度を持っている (>= 2**52 だが < 2**53 ) ことを思い出すと、 N として最適な値は 56 になります:
>>>
>>> 2**52 <=  2**56 // 10  < 2**53
True
すなわち、56 は J をちょうど 53 ビットの精度のままに保つ N の唯一の値です。J の取りえる値はその商を丸めたものです:
>>>
>>> q, r = divmod(2**56, 10)
>>> r
6
剰余が 10 の半分以上なので、最良の近似は切り上げて丸めたものになります。
>>>
>>> q+1
7205759403792794
従って、754 倍精度における 1/10 の取りえる最良の近似は:
7205759403792794 / 2 ** 56
分子と分母を2で割って分数を小さくします:
3602879701896397 / 2 ** 55
丸めたときに切り上げたので、この値は実際には 1/10 より少し大きいことに注目してください。 もし切り捨てをした場合は、商は 1/10 よりもわずかに小さくなります。どちらにしろ 厳密な 1/10 ではありません！
つまり、計算機は 1/10 を "理解する" ことは決してありません。計算機が理解できるのは、上記のような厳密な分数であり、 754 の倍精度浮動小数点数で得られるもっともよい近似は以下になります:
>>>
>>> 0.1 * 2 ** 55
3602879701896397.0
この分数に 10**55 を掛ければ、55 桁の十進数の値を見ることができます:
>>>
>>> 3602879701896397 * 10 ** 55 // 2 ** 55
1000000000000000055511151231257827021181583404541015625
これは、計算機が記憶している正確な数値が、10 進数値 0.1000000000000000055511151231257827021181583404541015625 にほぼ等しいということです。多くの言語 (古いバージョンの Python を含む) では、完全な 10 進値を表示するのではなく、結果を有効数字 17 桁に丸めます:
>>>
>>> format(0.1, '.17f')
'0.10000000000000001'
fractions モジュールと decimal モジュールを使うとこれらの計算を簡単に行えます:
>>>
>>> from decimal import Decimal
>>> from fractions import Fraction
>>> Fraction.from_float(0.1)
Fraction(3602879701896397, 36028797018963968)
>>> (0.1).as_integer_ratio()
(3602879701896397, 36028797018963968)
>>> Decimal.from_float(0.1)
Decimal('0.1000000000000000055511151231257827021181583404541015625')
>>> format(Decimal.from_float(0.1), '.17')
'0.10000000000000001'
16. 付録
16.1. 対話モード
16.1.1. エラー処理
エラーが発生すると、インタプリタはエラーメッセージとスタックトレース (stack trace) を出力します。対話モードにいるときは、インタプリタは一次プロンプトに戻ります; スクリプトをファイルから実行しているときは、インタプリタはスタックトレースを出力した後、非ゼロの終了ステータスで終了します。 (try 文の except 節で処理された例外は、ここでいうエラーにはあたりません。) いくつかのエラーは常に致命的であり、非ゼロの終了ステータスとなるプログラムの終了を引き起こします。例えばインタプリタ内部の矛盾やある種のメモリ枯渇が当てはまります。エラーメッセージは全て標準エラー出力に書き込まれます; これに対して、通常は実行した命令から出力される内容は標準出力に書き込まれます。
割り込み文字 (interrupt character、普通は Control-C か Delete) を一次または二次プロンプトに対してタイプすると、入力が取り消されて一次プロンプトに戻ります。 1 コマンドの実行中に割り込み文字をタイプすると KeyboardInterrupt 例外が送出されます。この例外は try 文で処理できます。
16.1.2. 実行可能な Python スクリプト
BSD 風の Unix システムでは、Python スクリプトはシェルスクリプトのように直接実行可能にできます。これを行うには、以下の行
#!/usr/bin/env python3.5
(ここではインタプリタがユーザの PATH 上にあると仮定しています) をスクリプトの先頭に置き、スクリプトファイルに実行可能モードを設定します。 #! はファイルの最初の２文字でなければなりません。プラットフォームによっては、この最初の行を終端する改行文字が Windows 形式 ('\r\n') ではなく、 Unix形式('\n')でなければならないことがあります。ハッシュまたはポンド文字、すなわち '#' は、Python ではコメントを書き始めるために使われていることに注意してください。
chmod コマンドを使えば、スクリプトに実行モードや実行権限を与えることができます。
$ chmod +x myscript.py
Windows では、"実行モード" のような概念はありません。Python のインストーラーは自動的に .py ファイルを python.exe に関連付けるので、Python ファイルをダブルクリックするとそれをスクリプトとして実行します。.pyw 拡張子も(訳注: pythonw.exe に)関連付けられ、通常コンソールウィンドウを抑制して実行します。
16.1.3. 対話モード用の起動時実行ファイル
Python を対話的に使うときには、インタプリタが起動する度に実行される何らかの標準的なコマンドがあると便利なことがよくあります。これを行うには、 PYTHONSTARTUP と呼ばれる環境変数を、インタプリタ起動時に実行されるコマンドが入ったファイル名に設定します。この機能は Unix シェルの .profile に似ています。
このファイルは対話セッションのときだけ読み出されます。 Python がコマンドをスクリプトから読み出しているときや、 /dev/tty がコマンドの入力元として明示的に指定されている(この場合対話的セッションのように動作します) わけではない 場合にはこのファイルは読み出されません。ファイル内のコマンドは、対話的コマンドが実行される名前空間と同じ名前空間内で実行されます。このため、ファイル内で定義されていたり import されたオブジェクトは、そのまま対話セッション内で使うことができます。また、このファイル内で sys.ps1 や sys.ps2 を変更して、プロンプトを変更することもできます。
もし現在のディレクトリから追加でスタートアップファイルを読み出したいのなら、グローバルのスタートアップファイルの中に if os.path.isfile('.pythonrc.py'): exec(open('.pythonrc.py').read()) のようなプログラムを書くことができます。スクリプト中でスタートアップファイルを使いたいのなら、以下のようにしてスクリプト中で明示的に実行しなければなりません:
import os
filename = os.environ.get('PYTHONSTARTUP')
if filename and os.path.isfile(filename):
    with open(filename) as fobj:
        startup_file = fobj.read()
    exec(startup_file)
16.1.4. カスタマイズ用モジュール
Python はユーザーが Python をカスタマイズするための2つのフック、 sitecustomize と usercustomize を提供しています。これがどのように動作しているかを知るには、まずはユーザーの site-packages ディレクトリの場所を見つける必要があります。Python を起動して次のコードを実行してください:
>>>
>>> import site
>>> site.getusersitepackages()
'/home/user/.local/lib/python3.5/site-packages'
usercustomize.py をそのディレクトリに作成して、そこでやりたいことをすべて書くことができます。このファイルは自動インポートを無効にする -s オプションを使わない限り、全ての Python の起動時に実行されます。
sitecustomize モジュールも同じように動作しますが、一般的にコンピューターの管理者によって、グローバルの site-packages ディレクトリに作成され、 usercustomize より先にインポートされます。詳細は site モジュールのドキュメントを参照してください。
